summary 
 
 
Abstract | The jellyfish Aequorea victoria expresses green fluorescent protein (GFP). A complementary DNA can be expressed in prokaryotic or eukaryotic cells. Other substrates or cofactors are not necessary for this fluorescence. Thus, GFP can be used to monitor gene expression and protein localization in living organisms. 
 
Introduction | In the jellyfish Aequorea victoria, the green fluorescent protein (GFP) emits a green light. When the photoprotein aequorin binds to calcium, GFP absorbs excitation energy from aequorin. GFP absorbs blue light and emits green light. The fluorescence is stable, and the fluorophore hardly breaks down. The fluorescence does not need any extra gene products. The fluorophore formation is not species-specific.  
 
﻿Aims | Chalfie et al. studies the properties of GFP. They examine whether some organisms can express GFP. 
 
Methods | The researchers used PCR to amplify the fragment of GFP. They used the restriction enzymes NheI and EcoRI. They transformed organisms with ampicillin on the nutrient plates. Researchers used epifluorescence microscopy to see the GFP. 
 
Results | Escherichia coli emitted green fluorescence with the expression of GFP. Researchers used an ultraviolet (UV) source to view the bacteria (Figure 1). The plates also contained isopropyl-β-D-thiogalactoside (IPTC), which induces the protein expression. GFP did not appear to have a toxic effect on cells. The excitation and emission spectra of the E. coli were identical to the spectra of the native jellyfish (Figure 2). Thus, the fluorescence does not need other jellyfish products.The researchers transformed GFP into the roundworm Caenorhabditis elegans (Figure 3). GFP was expressed in the neurons with the promoter for the mec-7 gene. The mec-7 gene codes for tubulin that is abundant in six touch receptor neurons. The GFP expression was like the fluorescence detected using the MEC-7 antibody. The touch neurons, including the terminal branches, grow throughout the embryonic stages. The neurons become functional in the fourth larval stage. The fluorescence of GFP in the neurons are consistent with previous data. Fluorescence is not detected in newly hatched or late first-stage larvae. Fluorescence is seen is some middle stage larvae. All the early fourth stage larvae and almost all the young adults emit fluorescence. GFP is stable when illuminated with 450 to 490 nm light in both E. coli and C. elegans. Some photobleaching occurs with lower wavelength lights. 
 
Conclusion | GFP can be useful for monitoring gene expression and protein localization because its activity is not limited by other substrates. GFP does not seem to interfere with cell growth and function. So, GFP can be used as a marker for cell growth, such as in the C. elegans neuronal growth. GFP is small, so it will diffuse throughout the cytoplasm of cells. GFP fluorescence lasts even after killing cells with formaldehyde. Thus, GFP can be used to view fixed cells. 
 
 
Abstract | There are many existing hypotheses for the mechanism of DNA replication. There are three main models. The conservative model states that the parent DNA molecule remains completely intact. New DNA molecules are made of completely new strands. The semiconservative model states that each new DNA has one new strand and one parent strand. The dispersive model states that fragments of the parent are randomly passed on.Previous experiments used radioisotope labels to study DNA. In this experiment, Meselsohn and Stahl used differences in density instead. The density differences allowed them to see how nucleotides move through replication. They put DNA in a solution of concentrated cesium chloride. Then, they centrifuged the DNA until a solid band forms at a particular position. The location corresponds to buoyant density of the sample. The density of the DNA increases with increasing centrifugal force in a gradient. The researchers labeled DNA with heavy nitrogen (N15) and unlabeled (N14) nitrogen. Centrifugation allowed the detection of the different densities of nitrogen isotope in DNA.AimsMeselsohn and Stahl analyzes DNA replication. They attempt to disprove the conservative and dispersive models of replication. 
 
Methods | Researchers grew Escherichia coli B in N15 for 14 generations (Figure 3). They kept track of the amount of bacteria with microscope counts and colony assays. Then, they changed the medium to N14. They took samples of bacteria at various points in time. They lysed the bacteria with 15 sodium dodecyl sulfate to isolate the DNA. They centrifuged the DNA, and they determined the density with a microdensitometer (Figure 2). They took ultraviolet absorption photographs of the bands. The buoyant density of the DNA varies has a direct relationship with the fraction of N15 it contains. Thus, researchers can determine the amount of N15 based on the position of the band. They can compare the band position to the labeled and unlabeled DNA bands. They also used heat denaturation to separate the two strands and analyze them. 
 
Results | The parent DNA molecule is completely labeled with N15. After one generation, the two daughter DNA molecules are both half-labeled. Both daughter DNA molecules contain equal amounts of labeled nitrogen. After two generations, half of the DNA is half-labeled and the other half is unlabeled (Figure 4). Thus, the daughter molecule receive equal amounts of nitrogen from the parent molecule. And, strands remain intact through many generations. Moreover, each daughter molecule receives one parental strand after replication. Otherwise, there would be a mix of completely labeled strands and unlabeled strands. After each replication, the number of molecules double.When DNA is heated, its strands come apart because there is enough energy to break the hydrogen bonds. Single-stranded DNA is denser than the double helix. Still, the researchers were able to determine the DNA density from a microdensitometer. Meselsohn and Stahl also had a way of determining the concentration of DNA based on the band width. This ability still held even with single strands of DNA.Next, Meselsohn and Stahl heat denatured hybrid DNA. The hybrid DNA (two strands) consisted of half N14 and half N15. But, they did not know the amount of each nitrogen in each strand. When heat denaturation separated the DNA strands, there were two distinct density peaks. One peak corresponded to denatured N14 and one corresponded to denatured N15. As a control, they tested the density gradient of a heated mixture of N14 DNA and N15 DNA. The density peaks resembled the peaks produced by the denatured hybrid DNA. Thus, heat did indeed separate the hybrid DNA. Furthermore, each DNA strand is conserved through replication. One of the new strands consists completely of N14 DNA. The other new strand consists of N15 DNA only (Figure 9). These results support the semi-conservative model of DNA replication. 
 
Conclusion | The results are consistent with Watson and Crick's model of DNA replication. In the Watson and Crick model, the DNA strands first separate. The separation exposes the hydrogen bond sites of the bases. Because of base-pairing restrictions, each strand is a template for the daughter molecules. The template allows for the synthesis of a complementary strand. Thus, each daughter molecule has one parent strand and one newly synthesized strand (Figure 6). Still, this experiment does not prove the DNA structure proposed by Watson and Crick. These results support the semi-conservative model of DNA replication. They disprove the conservative and dispersive models. 
 
 
Introduction | 	Other scientists in the field have already put forth several models for the structure of deoxyribose nucleic acid (DNA), but there are errors in their models. Some errors are the lack of hydrogen bonding and the repulsion of the phosphate groups. 
 
Aims | Watson and Crick propose a model for DNA structure. 
 
Methods |  X-ray crystallography images give clues to the shape of the DNA molecule. 
 
Results | In the model, DNA consists of two chains coiled in a helix around one axis. The adjacent phosphates and sugars are connected by 3’,5’ linkages. The sequences on each chain run in opposite directions of each other. The bases are on the inside and the phosphates are on the outside of the helix. The helix turns at precise and uniform angles. The distances between nucleotides are uniform as well. Less water content in the molecule can make DNA more compact. 
 
Conclusion | Two base pairs on different chains that lie side by side form hydrogen bonds. They bind in a direction perpendicular to the long axis. One of the bases in the pair must be a purine, and the other base must be a pyrimidine. Thus, only certain base pairs can be together. Adenine (purine) must pair with thymine (pyrimidine). Guanine (purine) must pair with cytosine (pyrimidine). Along one chain, the nucleotides can appear in any order. In this case, the nucleotide order on the other chain will be automatically determined due to the specific base pairing.If ribose sugar replaces deoxyribose in the backbone to form RNA, a helix would not form. The extra oxygen atom instead of an -OH would create too much repulsion. The specific base pairing suggests a mechanism in which genetic material can be copied during DNA replication. 
 
 
Abstract | The drug BI-RG-587 inhibits HIV-1 reverse transcriptase. It is noncompetitive with respect to dGTP. BI-RG-587 inhibited HIV-1 replication in vitro. BI-RG-587 showed little cytotoxic effects until very high concentrations in culture. 
 
Introduction | 	Many drug therapies for HIV-1 target the reverse transcriptase because reverse transcriptase is needed for virus replication. Reverse transcriptase is an enzyme that generates DNA from an RNA template. Many effective inhibitors are nucleoside analogs. They stop the nucleotide chain during replication. The first approved drug for HIV-1 infection was the nucleoside analog azidothymidine (AZT). But, there are many side effects with AZT use because AZT can affect normal replication. Viral replication is also not completely inhibited. 
 
Aims | Merluzzi et al. proposes new drug therapy against HIV-1. This drug, BI-RG-587, is not a nucleoside analog. So, this drug does not have the usual side effects. 
 
Methods | 	Researchers conducted an enzyme activity assay to determine the Michaelis-Menten constant. The assay revealed BI-RG-587’s noncompetitive mechanism. Merluzzi et al. also tracked HIV-1 replication. They measured the inhibition of the HIV capsid protein p24 in a T cell culture. To measure cytotoxicity in normal cells, they performed a tetrazolium salt (MTT) metabolic assay. They used in situ hybridization and p24 studies to detect HIV-1 in human samples. 
 
Results / Conclusion | 	The compound BI-RG-587 is a powerful noncompetitive inhibitor of HIV-1 reverse transcriptase. The inhibitor is not a nucleoside analog structure, so it will not have the same side effects as AZT. BI-RG-587 does not compete with deoxyguanosine triphosphate (dGTP) (Figure 2). The noncompetitive character suggests BI-RG-587 works by allosteric binding to the reverse transcriptase. BI-RG-587 inhibited the reverse transcriptase even with different templates and primers. As the concentration of BI-RG-587 increases, reverse transcriptase inhibition increases. As a result, there is less viral replication.	BI-RG-587 is very specific for HIV-1 reverse transcriptase. It does not inhibit other viruses, human DNA polymerases, or other enzymes (Table 1). BI-RG-587 causes partial inhibition of HIV-1 ribonuclease (RNase) H activity. The partial inhibition may reflect BI-RG-587 binding to a site other than the active site. But, BI-RG-587 binding causes a greater conformational change of the reverse transcriptase than RNase H.Very low amounts of BI-RG-587 can inhibit HIV-1 replication. The IC50 against HIV-1 strain IIIb was 40 nM in T cells. BI-RG-587 causes cytotoxic effects only at extremely high concentrations (&gt;105 nM) (Figure 3). BI-RG-587 inhibited three HIV virus strains equally well: HIV-1IIIb, HIV-1RF, and HIV-1UMGL. BI-RG-587 also inhibited the replication of HIV-1 primary isolates in four patients. These patients were undergoing AZT therapy. 
 
 
Abstract | The three proteins, Sar1p, Sec13p complex, and Sec23p complex, contribute to the synthesis of transport vesicles.The vesicles derive from the endoplasmic reticulum. Vesicle formation requires GTP. But, GMP-PNP, a nonhydrolyzable analog of GTP, can cause vesicle formation as well. But, GMP-PNP vesicles cannot target and fuse with the Golgi complex. All three proteins remain on the vesicles. Yet, GTP vesicles are functional. Sar1p dissociates from GTP vesicles, allowing for fusion. Thin section electron microscopy reveal a thick coat around the vesicles. The subunits of the novel coat are different from clathrin, another coat protein. Two proteins drive the budding cycle in similar ways. So, Barlowe et al. proposes to call these two coat structures COPI and COPII. 
 
Introduction | In intercompartmental transport in eukaryotes, vesicles uncoat before fusion with the acceptor compartment. For example, clathrin mediates transport involving the trans-Golgi and plasma membrane. COP-coated Golgi-derived vesicles mediate intra-Golgi transport.The three different proteins have different functions. Sar1p is a GTPase functioning on the cytosolic face of the ER. Sec12p, an integral membrane glycoprotein, activates Sar1p by a GDP/GTP exchange. The Sec23p complex consists of two proteins: Sec23p and Sec24p. Sec23p is a Sar1p-specific GTPase activating protein. Sec24p aids secretion of vesicles. The Sec13p complex consists of Sec13p and another 150kDa polypeptide. Vesicle formation requires both proteins in vitro. These three proteins are components of the vesicle coat and aid in vesicle synthesis. A distinct coat structure appears to be mediating each intracellular vesicle budding. These vesicles contain membrane-bound proteins that are characteristic of uncoated ER-derived transport vesicles. 
 
Aims | Barlowe et al. tries to understand the roles COPII and COPI play in vesicle budding. 
 
Methods | Researchers produced a recombinant Sar1p with restriction sites and a plasmid. They used yeast and E. coli. To study budding and vesicle formation, they did an analytical budding assay. They measured the amount of protease protected to determine vesicle release. Then, they did a vesicle chase to track vesicle transport. Proteins and vesicles were viewed with immunoblots and electron microscopy, respectively. 
 
Results / Conclusion | The budding process if as follows (Figure 9). Sar1p goes to the ER. Sec12p converts Sar1p-GDP to the activated GTP-bound form. This causes Sar1p to be membrane-bound. GTP is the best nucleotide for budding. Then, Sar1p-GTP recruits Sec23p and Sec13p complexes to form COPII. COPII executes the budding event. Sar1p hydrolyzes GTP, stimulated by the Sec23p subunit of the Sec23p complex. GTP hydrolysis leads to the loss of Sar1p from vesicles, causing coat instability. The Sar1p loss exposes targeting proteins on the vesicle, such as Sec22p and Bos1p. These proteins provide binding selectivity to the target proteins on the Golgi membrane. If vesicles form with a nonhydrolyzable analog like GMP-PNP, Sar1p and the COPII proteins remain on the vesicle (Figure 8). The remaining Sar1p and COPII proteins hinder access of the vesicle to the Golgi. The vesicle will not be able to fuse with the acceptor membrane.COPII formation resembles the assembly of COPI. But, COPI and COPII are distinct. Unlike COPI, COPII contains a GTPase activating protein (GAP) subunit. For COPII, retention of the Sec23p and Sec13p complexes do not depend on the presence of Sar1p. In contrast, COPI-coated vesicles keep ADP ribosylation factor (ARF) when the vesicles form with GTP or with GTPγS. ARF-GAP may stimulate GTP hydrolysis and COPI disassembly. Palmityl coenzyme A aids COPI assembly in incubation. Formation of COPII-coated vesicles do not need acyl coenzyme A.COPII vesicles have specific protein packages. The proteins selected have more affinity for COPII. Proteins that function in the ER are not included in these vesicles. For example, Sec12p is not on vesicles. Sec12p has no affinity for COPII, so it will remain in the ER. Sec12p helps later rounds of budding. GTP hydrolysis is not required for protein sorting. Rather, GTP hydrolysis is important for the fusion of the vesicle. The depletion of coatomer does not affect ER budding.Vesicles formed with crude cytosolic proteins contain Bos1p, Sec22p, and Ypt1p. The researchers find Sec22p in vesicles formed with pure cytosolic proteins. But, they cannot detect Ypt1p in these vesicles. Ypt1p may be normally recruited from the cytosol toform a bud. Vesicles that do not have Ypt1p may get it on the way to targeting the Golgi complex. Vesicles formed with pure proteins need Ypt1p to target and fuse with the Golgi.Vesicle targeting requires Bet1p. But, Bet1p is not recovered in vesicles formed with crude cytosol. Rather, Bet1p is packaged along with α-factor precursor and Sec22p in these vesicles. This may be due to the presence or absence of Ypt1p. Ypt1p may regulate vesicle packaging or retention of certain targeting or cargo molecules.COPI vesicles seem to exclude Golgi membrane proteins while incorporating relevant cargo molecules. COPII- and COPI-mediated budding events likely differ in cargo enrichment during transport. Viral glycoproteins become concentrated about 10-fold after exiting the ER. But, they are not further concentrated once they are in the Golgi. The COPII budding process likely includes a mechanism for cargo concentration.COPI is essential for protein transport from the ER and within the Golgi complex. SEC21 codes for the γ subunit of yeast coatomer. The sec21 mutant blocks transport between the ER and Golgi. Polyclonal antibodies and Fab fragments against mammalian β-COP inhibit transport of vesicular stomatitis virus G protein. Addition of COPI and ARF have no effects on vesicle formation mediated by COPII.Various transport reactions need COPI to differing extents. Sometimes, COPII may be sufficient for the complete budding process. Other times, COPI and COPII may cohabit the same vesicle or create different vesicles. COPI may replace COPII on ER-derived vesicles. In this case, COPI may serve as a scaffold for the attachment of Ypt1p. COPI may regulate the targeting of a vesicle to the correct compartment. COPI may also affect the budding of a vesicle. 
 
 
Abstract | Tree growth was investigated in Isle Royale National Park in Michigan to reveal the influence of herbivores and carnivores on plants in an intimately linked food chain. Plant growth rates were regulated by the amount of certain types of animals present (moose and wolves), and the plants only responded to annual changes in primary productivity when they were no longer under pressure from moose. The study revealed top-down control in the Isle Royale ecosystem. 
 
Background | The top-down model predicts that changes in density at one trophic level are caused by opposite changes in the next higher trophic level. In other words, if the number of carnivores decreases, the amount of herbivores should increase. Thus changes in primary productivity (the energy flow of plants), becomes noticeable when higher trophic levels are removed.When carnivores are released from a three-level system (carnivores, herbivores, and primary producers), control is passed to the herbivores. The bottom up theory predicts that changes in higher trophic levels does not affect density patterns in lower levels. 
 
Methods/Figures/Results| Ring growth analysis revealed cyclic intervals of ring growth suppression that accompanied elevated moose densities in the ecosystem. In the west end of the island there was higher evapotranspiration (which is related to primary productivity) than in the east end, where moose levels were higher because of a lag in the moose density cycle. In the early summer temperatures, AET (evapotranspiration) was supposed to be particularly high across the island. Figure 3 reveals that when wolves were scarce, moose numbers grew and balsam fir were depleted (as evidenced by decreased tree ring growth). This is why the wolf and tree ring cycles resemble each other and are the opposite of the moose cycle. Figure 3E reveals that a clear trend in AET can be seen when the moose population was low, but that there was no reasonable pattern when the moose population increased. 
 
Discussion| The opposite cycles of wolf/fir growth and moose, coupled with the fact that vegetation dynamics were more closely linked to wolf-moose interactions rather than to seasonal weather patterns suggests top-down control in the Isle Royale ecosystem. Furthermore, there is a more intelligible pattern in primary productivity linked to seasonal conditions when plants are released from herbivore predation. 
 
 
Abstract |  Carotenoids are colored compounds produced by plants, fungi, and microorganisms. Pea aphids can appear in a red or green color, and the carotenoid torulene occurs only in red pea aphids. The aphid genome encodes multiple enzymes for carotenoid biosynthesis. These genes are derived from fungal genes, which have been integrated into the aphid genome and duplicated. A mutation of a certain region in the red aphid genome that encodes a single carotenoid desaturase results in a loss of forulene and red body color, meaning that aphids make their own carotenoids. 
 
Background | Green pea aphids contain alpha, beta and gamma carotene, and red pea aphids contain all of these plus torulene. There are three hypotheses that researchers have for the presence of carotenoids in aphids. The first is that they were obtained from aphid diets, but because carotenoids are not expected to exist significantly in phloem sap, and because carotenoid profiles of aphids and host plants are very different, this hypothesis is not the case. The second hypothesis is that aphids acquired carotenoids through bacterial endosymbiosis, but because aphid carotenoid biosynthetic genes are not homologous to primary symbionts, this hypothesis is not the case either. The third hypothesis is that aphids make their own carotenoids through genes that were laterally transferred from fungi. 
 
Figures and Results | A GenBank protein database search was carried out and revealed that the closest sequence homology to pea aphid biosynthetic genes was found in several fungi and no other animal. Phylogenetic analyses revealed that aphid copies of carotenoid desaturase proteins and carotenoid cyclase-carotenoid synthase proteins form a clade that is nested within a fungal clade. Figure 2 clearly shows that aphid carotenoid biosynthesis genes indeed form a distinct clade that is nested within those of fungi. They also show a single origin of these genes within fungi. Furthermore, the gene arrangement between pea aphids and certain fungi were found to be similar. A point mutation was induced on a red aphid carotenoid desaturase coding region, and it resulted in the inability of these aphids to make toluene. 
 
Discussion | The aforementioned evidence reveals that aphid carotenoid genes were transferred from a fungus to an aphid ancestor as a single event and that subsequent gene duplication occurred. The transfer preserved the gene arrangement observed in fungi. The red-green polymorphism observed in pea aphids because of the lack or presence of torulene results in differential susceptibility by natural predators. This is to say that, depending on the visual cues that different predators use to find prey, it may be more advantageous for aphids to appear as one color over the other, increasing the frequency of the phenotype. 
 
 
Abstract | The theory of historical contingency is that repeated occurrences of an evolutionary event result in dramatically different outcomes. This theory was tested on the same four types of anolis species (ecomorphs) on four different islands in the Greater Antilles. The similar morphologies and niches of the lizards among the islands can be explained by one of two hypotheses: all ecomorphs originated from a common ancestor on one island and then dispersed to different islands, or that there was independent evolution of each set of ecomorphs on each island. The researchers found the latter to be true, indicating that adaptive radiation is a stronger driving force than historical contingency in producing evolutionary outcomes across islands. 
 
Background | The theory of historical contingency is that repeated occurrences of an evolutionary event result in dramatically different outcomes. For instance, fauna that have evolved in similar environments exhibit more differences than similarities, and these differences stem in large part from unique historical events and subtle environmental differences in different areas. Such historical factors, however, do not always lead to disparate outcomes. 
 
Results/Figures | Six morphometric characteristics that are closely linked to habitat use for members of each ecomorph class were investigated. The investigation revealed that members of an ecomorph class are more similar to members of that class on different islands than they are to members of a different class on the same island. Phylogenetic analysis based on mitochondrial DNA sequences indicated most members of the same ecomorph class from different islands are not closely related. Figure 1B depicts the most parsimonious tree derived from the DNA data, and the frequent transitions among the ecomorph classes reveal that ecomorphs on one island aren’t closely related to their counterparts in other islands. Statistical analysis revealed that at least 17 evolutionary transitions among ecomorph classes have occurred. Figure 1C indicates that within each island, there are different topologies of the four ecomorphs. In other words, the ecomorphs evolved in a different order on each island, which is a reflection of different historical events. 
 
Discussion | Based on the data the researchers came up with, each set of ecomorphs evolved independently on each island. Also, members of an ecomorph class are more similar to members of that class on different islands than they are to members of a different class on the same island, meaning that, at least across islands, historical contingency is not an evolutionary driving force, and that adaptive radiation is. Within each island, however, the topologies of the ecomorphs are different, and this is the exact result of different historical events that occurred on each island. Therefore, within islands, historical contingency is a major evolutionary driving force.  
 
 
Abstract |  
 
The embryo of the common fruit fly (Drosophilia) develops based on a body plan that is set by maternal-effect genes, which are expressed in the mother. In this paper, the nos protein produced by the maternal-effect gene nanos is found to be necessary for the abdomen to form. In addition, if nos is not produced, blocking the maternal-effect gene hunchback can restore the abdomen. These results suggest that the nos gene product blocks the activity of the gene product hb of maternal hunchback. |  
 
Background |  
 
Maternal-effect genes produce mRNA transcripts that are then deposited in the egg cells in a concentration gradient along the front and back of the egg. The transcripts are then translated into proteins, and the amounts of these proteins in different locations of the cell determine the body structure that part of the cell will eventually become. While the concentration gradient of nos in the embryo is required for the abdomen to form, a concentration gradient of hb is required for parts of the head and thorax to form. |  
 
Aims |  
 
The purpose of the research was to determine whether the hb maternal gene product is a primary factor in determining the development of the lower body in Drosophilia embryos. |  
 
Methods, Figures, and Results |  
 
The scientists examined the physical characteristics, or phenotypes, of embryos that lacked maternal nos and both maternal hb and nos to test the effects of the maternal hb gene product. Pole cell transplantation was used to create the maternal donor for embryos without maternal hb because embryos lacking hb do not survive to reproduce. When there was no maternal nos gene product but both maternal and zygotic hb were intact, the embryo was missing an abdomen (Figure 2a). However, embryos missing both maternal nos and hb developed normally (Figure 2d). Removing maternal hb along with maternal nos restored the normal phenotype. This suggests that the nos gene product suppresses the function of the maternal hb gene product. |  
 
Discussion |  
 
This relationship between nos and hb highlights how maternal-effect genes can drastically influence development. From this study, we learned that the maternal nos gene product acts to suppress the function of the maternal hb gene product in the development of a Drosophilia embryo. Without nos, a removal of hb can rescue the normal lower body development. In addition, this paper highlights the pole cell transplantation method in creating fertile embryos that can’t be produced by crossbreeding. |  
 
 
Abstract | Many filament-like cyanobacteria have a repeating growth pattern of single heterocysts, or cells that specialize in nitrogen fixation, separated by 10 somatic cells. It was discovered that overexpressing a gene, patS, blocked the normal development of heterocysts. When patS was mutated to completely lose its function, there was an increased frequency of heterocysts and an abnormal pattern. When GFP was used as a reporter gene for patS (reporter gene fusion), fluorescence was strongest in somatic cells that were developing into heterocysts. Moreover, adding a synthetic peptide containing only the last five amino acids of PatS was sufficient to inhibit heterocyst development. PatS appears to control heterocyst pattern formation through intercellular signaling.BackgroundCell-cell communication plays a key role in controlling the development of different cells. Diazotrophs are cyanobacteria that do their own nitrogen fixation. Nitrogenase, or the enzyme that breaks down nitrogen, loses its function when oxidized. However, many cyanobacteria produce energy from photosynthesis, from which oxygen is a byproduct. In diazotrophs, approximately every tenth somatic cell differentiates into a heterocyst, which effectively separates the two processes of photosynthesis and nitrogen fixation. PatS is a gene that mediates heterocyst expression. This experiment is done to effectively determine the effects of manipulating patS on heterocyst formation and pattern. 
 
Methods | Using translational fusion with lacZ, patS was determined to be translated and regulated during heterocyst development. As a result, the researchers hypothesized that the patS gene was responsible for encoding a signaling molecule.In Figure 1, the main idea that is shown is that mutations in patS result in the loss of ability to suppress heterocyst formation, while overexpression of patS results in no development of heterocysts. The main idea in Figure 2 is that each mutation that resulted in loss of function of patS occurred in the last five amino acids of the sequence. In addition, this sequence corresponded to a peptide that was found to be involved with cell-signaling in other cyanobacteria. Thus, this peptide was hypothesized to be the signaling molecule.  
 
Results | Expression of the pentapeptide (five amino acid string) was enough to suppress heterocyst growth to nearly the original levels in cyanobacteria with a non-functioning patS gene. However, the pattern of growth was still abnormal. Figure 3G demonstrates that a promoter that is present in pre-heterocyst cells needs to be expressed along with patS in order to restore normal heterocyst pattern and levels.Figure 4 reinforces Figure 3 by demonstrating that developing pre-heterocysts expressed the most patS. The scientists determined this by attaching a GFP (green fluorescent protein) reporter to patS using transcriptional fusion. 
 
Discussion | Overall, the expression of patS in pre-heterocysts plays a key role in inhibiting the formation of heterocysts in neighboring cells. This effect, called lateral inhibition, makes pattern formation in eukaryotes possible. In addition, the fact that patS-producing cells don’t inhibit each other suggests that there must be a mechanism that makes these cells immune to the patS signal. 
 
 
Abstract | The main focus of this paper is on retrogenes and transposons. Transposons are pieces of genetic material that can reinsert themselves back into the genome. Retrogenes are genes that can be created when these transposons are reinserted. While most retrogenes can cause detrimental mutations, there are a small number of retrogenes that can actually create functioning proteins. In this study, chondrodysplasia, a disease that causes some breeds of dogs to have shorter legs, is linked to a retrogene that encodes a growth factor, fgf4. This demonstrates how a single retrogene can drastically affect evolutionary development in the domestic dog. 
 
Background | While there are several breeds of the domestic dog, they are all categorized under the same species. This makes the modern domestic dog one of the most diverse mammals in terms of physical traits. While there is little morphological variation within a breed, the variation in morphologies between breeds is considerable. This makes it easier to compare breeds of dogs when studying individual traits. While there are several competing theories for why dog morphologies are so diverse, very little attention has been given to the idea of gene duplication. This study aims to identify the cause of chondrodysplasia, a trait that is dominant and allelic based on breeding studies of over a dozen dog breeds. 
 
Aims | The purpose of the research was to determine the genetic basis of chondrodysplasia. The scientists in this study hypothesized that chondrodysplasia was due to a mutation resulting from a retrogene. 
 
Methods, Figures, and Results | To look for the genes responsible for chondrodysplasia, the scientists in this experiment used a SNP chip analysis on dogs from 76 different dog breeds, 8 of which had chondrodysplasia. SNP chip analysis showed that there was a strong correlation between several SNPs on chromosome 18 and chondrodysplasia (Figure 1B). As part of their hypothesis that this trait is controlled by a single gene, the scientists also hypothesized that this trait would be selected for by breeders in breeds with the trait. To test this, they examined the proportion of individual dogs that were heterozygous for the SNPs on chromosome 18 in dog breeds with and without the trait. The SNPs that have the highest likelihood to be associated with chondrodysplasia should have the lowest amount of dogs with chondrodysplasia that were heterozygous for the SNPs. This was demonstrated in Figure 2, where a small sequence of SNPs had no dogs with chondrodysplasia that were heterozygous for those SNPs. By running more tests using PCR and sequencing methods, the scientists were able to identify that this sequence corresponded to FGF4, a gene on a different position of the same chromosome. Thus, the sequence was a retrogene made from a transposon that contained the FGF4 gene.Retrogenes are different from gene duplication that simply doubles the effect of the original gene since retrogenes are inserted at a different DNA position. This means that retrogenes have to borrow a different promoter from neighboring genes to be expressed. As a result, the scientists ran several PCR-based tests on the cDNA of fetal dogs in breeds with the trait and found that the retrogene was being expressed. 
 
Discussion | While these chondrodysplastic breeds do not share a recent common ancestry, the fact that they all have the same 24kb fgf4 retrogene sequence means that it is likely that the chondrodysplastic trait only evolved once before humans bred them into the modern breeds we have today. Then, human breeders selected for this trait according to purposes specific for each breed. In this study, the scientists have discovered a retrogene that was expressed and strongly affected the evolutionary direction of many dog breeds. If future research discovers such gene duplication is found to be associated with a drastic phenotypic evolution in undomesticated species, it may be the key to understanding the different ways in which organisms evolve. 
 
 
Summary | The retrovirus HaMSV was used to introduce activated ras genes to mice. After the tumor promoter TPA was added, the same mice developed benign tumors. Some benign tumors eventually became malignant. Cells initiated by HaMSV can remain in the body for at least four months. This study shows that activating ras genes in mice has the same effect as giving them chemical carcinogens. This suggests that ras and other oncogenes have an important role in tumor development. 
 
Introduction | Cancer development is now recognized as a multi-stage process. The progression from stage to stage may be spurred on by the activation of proto-oncogenes. These genes have remained in the genome because they support cell growth. Scientists know that they’re involved in tumor development because they’re activated in many cancers. However, at the time this article was written, the stage of tumor development during which these genes activate was unknown. Their activation’s exact effect on cells was also not well understood.To uncover these unknowns, the authors of this article made tumors form in mice. They did this by giving them some amount of a carcinogen. They then gave the mice chemicals that made visible tumors appear. These chemicals are called promoting agents. The tumors that appeared afterwards were usually benign, but some go through more change and eventually invade other parts of the body.During one round of these experiments, the authors found that the Harvey-ras gene, abbreviated as c-rasH, was frequently activated at the same time benign tumors began to form. This suggested that the gene is activated pretty early in the tumor development process. If this is the case, one would expect that the activation of this gene would achieve the same effect as exposing a mouse to a carcinogen. From then, adding promoting agents to mice with activated c-rasH genes would likely make benign tumors form, just as if a carcinogen was added first. This is what the authors show with the study detailed in this article. 
 
Results | Induction of Skin Papillomas Using HaMSV and TPAIn the experiment described, the authors initiated tumor development in mice by exposing them to the HaMSV retrovirus, which is expected to activate the c-rasH gene. Afterwards, some of these mice were treated with TPA while some were treated with acetone. The mice that received acetone did not develop any tumors. The mice that received TPA developed visible tumors in 4-5 weeks. When compared to the tumors initiated by chemical carcinogens, the tumors initiated by HaMSV grew faster but looked similar. Tumors initiated by HaMSV also had cells that were less differentiated.HaMSV-Initiated Cells Can Remain Latent in Epidermis for Several MonthsCells initiated with chemical carcinogens are able to stay in the body for up to a year. The authors tried to see if the same is true for cells initiated with HaMSV. HaMSV-exposed mice that received promoting agents four months after infection developed tumors, showing that HaMSV-initiated cells can stay in the body for extended periods of time. However, these tumors were smaller than the ones developed in mice that received promoting agents right after infection. This suggests that some initiated cells in HaMSV-infected mice can be lost.Conversion of HaMSV Papillomas to CarcinomasThe results of the study suggest that benign tumors developed from HaMSV-initiated mice spent less time dormant before becoming malignant when compared to chemical-initiated mice. The study also seems to suggest that a greater percent of HaMSV-initiated benign tumors eventually become malignant than chemical-initiated tumors. However, this study should be repeated with more mice to properly support these conclusions.Clonality of HaMSV-Induced Skin TumorsThrough restriction enzyme digests, the authors concluded that the benign tumors that appeared in HaMSV-initiated mice contain cells that came from several different populations. However, the malignant tumors that formed in these mice were likely caused by an event that took place in one or two cells.Expression of v-rasH Sequences in HaMSV TumorsThe authors wished to make sure that HaMSV-initiated mice did indeed have more activated rasHgenes than chemical-initiated mice. A northern blot revealed that a chemically-initiated benign tumor had only normal copies of the rasH gene. It also showed that there was greater expression of rasHin HaMSV-initiated tumors than in chemical-initiated tumors.Expression and Cytochemical Localization of The rasH gene of HaMSV differs from the equivalent norv-rasH P21 in HaMSV-TumorsHaSMV copies of the rasH gene differ normal copies of the rasH gene, as they contain two mutations. These mutations alter the protein product they produce and endow it with different properties. 
 
Discussion | One issue in uncovering the role of oncogenes in tumor development was whether oncogene activation was the cause or result of tumor development. The study described in this article shows that oncogene activation could be a key step in cancer formation. This is evidenced by the fact that activation of an oncogene imitates the effect of chemical carcinogen exposure in mice.ras Gene Mutation As the initiation Event in Mouse Skin CarcinogenesisThese experiments can’t completely validate the idea that chemical carcinogens must directly cause the c-rasH gene to mutate in order for mouse skin carcinoma to form. Nor can they tell whether its mutation occurs right at the start of or after tumor initiation. However, they can strongly support the idea that c-rasH mutation is the initiating event of this cancer.Chemical and Viral Initiation: Similarities and DifferencesThis section summarizes and elaborates upon the differences between tumors initiated with chemical carcinogens and those initiated with retroviruses. Virus-initiated tumors grow faster. Virus-initiated cells are dormant for less time before they become benign tumors. Virus-initiated mice tend to have more activated rasH genes.Synergism between ras Gene Activation and TPAThe activation of the ras gene alone isn’t enough to trigger tumor development. It requires TPA in order to manifest into a tumor. In cases where the ras gene was activated and TPA wasn’t received, no tumors formed. This implies an interaction between TPA and the ras protein product that is necessary for tumor development. 
 
Conclusions and Prospects | The authors have shown that v-ras genes can be introduced in live animals and stimulate skin carcinoma development. Prior to this study, it was believed that HaMSV was only able to induce sarcomas or erythroid leukemias. Future studies could look into the potential for other oncogenes to cause cancers after being introduced through a retrovirus. 
 
Experimental Procedures | The authors go over the various techniques used to carry out the study, including cell culture, virus preparation, DNA isolation, and so on. 
 
 
﻿Abstract | Braun et al. tested the effect of cytokeratin-positive cancer cells on the development of breast cancer. The authors extracted bone marrow aspirates from the upper iliac crests of patients, with stage I, II, or III breast cancer, who had the tumor removed. Bone marrow aspirates were also extracted from non-cancerous controls. The aspirates were stained with a monoclonal antibody, A45-B/B3, which is bound to antigens on cytokeratins. Follow up appointments ranged from 10-70 months and the end goal was survival. Cytokeratin-positive cells were found in the bone marrow of one percent of the controls and thirty-six percent of the patients with breast cancer. Braun et al. found that the presence of occult metastatic cells in bone marrow was unrelated to that of lymph-node metastasis. 49 patients out of the 199 patients with occult metastatic cells died of cancer, whereas out of the 353 patients without such cells, 22 died of cancer-related causes. Out of 301 women without lymph-node metastases, 100 had bone marrow micrometastases. 14 of the 100 died of cancer-related causes, as did 2 of the 201 without bone marrow micrometastases. These results show that the presence of occult cytokeratin-positive metastatic cells in bone marrow increases the risk of relapse in patients with breast cancer. 
 
Introduction | It is important to track the early spreading of cancer cells because this is one of the biggest causes of relapse and death. These cells influence the spread of cancer in patients. The presence of ectopic epithelial cells in the bone marrow was shown to influence the development of patients with colorectal, gastric, and non–small-cell lung carcinomas, tumors. In breast cancer, antibodies against antigens of the polymorphic epithelial mucin family have been used to identify ectopic epithelial cells. Results from a study of 49 patients showed that cytokeratin-specific antibodies were able to detect breast-cancer micrometastases from bone marrow smears. This prompted Braun et al. to study a defined number of bone marrow cells, and a monoclonal antibody against an antigen shared by various cytokeratin peptides. The results of Braun et al.’s study demonstrates that cytokeratin-positive cells in bone marrow are indeed tumor cells. 
 
Methods | From January 1994 to December 1997, the I. Frauenklinik at Ludwig Maximilians University in Munich and the Zentralklinikum in Augsburg, Germany, studied 743 patients. These patients had bone marrow aspirates taken from both upper iliac crests before removing the cancer. Braun et al. used this method to examine the bone marrow obtained from 552 patients with stage I, II, or III breast cancer. Of the 552 patients with breast cancer, 298 patients went through breast conservation 254, modified radical mastectomy. All patients had the tumor removed. Out of the patients treated with breast-conserving surgery, 298 received radiation therapy. 72, of the 170 postmenopausal women with node-positive breast cancer (with estrogen-receptor–positive tumors) received 20 to 30 mg of tamoxifen daily. Both premenopausal and postmenopausal patients with estrogen-receptor–negative tumors were treated with chemotherapy.The base-line diagnostic evaluation for distant metastases, at the time of primary surgery, included plain chest radiography, mammography of the contralateral breast, ultrasonography of the liver, and bone scanning of the entire body. Patients were met with clinical examinations every three months after surgery and were only tested further if they showed any symptoms.Braun et al. obtained bone marrow samples from the upper iliac crests of the patients by needle aspiration. during primary surgery and stored in heparin-treated tubes.The authors screened 2×106 cells by bright-field microscopy. All slides they produced were examined separately by two different observers who agreed on the results for over 95 percent of specimens.Braun et al. used monoclonal antibody A45-B/B3 to find tumor cells in cytospin preparations of bone marrow. The authors used the breast-cancer cell line BT-20 as a positive control for cytokeratin immunostaining and they used the log-rank test to compare the patients with bone marrow micrometastases against those without micrometastases. Braun et al. used Cox proportional-hazards analysis to estimate the effect of various variables on the development of the disease, and they used the chi-square test to compare categorical variables. Finally, for statistical analyses, the authors used SPSS software for Macintosh. 
 
Results | 199 of the 552 patients, who had bone marrow aspirates taken, had cytokeratin-positive tumor cells in the bone marrow at the time of the initial resection of the primary tumor. In the majority of the specimens, occult cells were present as dispersed single cells and the frequency of occult metastatic cells was low. Bone marrow aspirates from the 191 controls were also analyzed before the final result was disclosed. Stained cytokeratin-positive cells were detected in only two of the 191 patients.58 percent of the patients had primary tumors that were no more than 2 cm in diameter. Primary tumors that were larger than 2cm were more likely to have a higher count of micrometastases. Of the 43 patients with stage pT4 tumors, 19 had inflammatory breast cancer; of the 19, 15 had occult metastatic cells in the bone marrow. Twenty-three percent of patients with stage pT1a tumors, 35 percent of patients with stage pT1b tumor, and 30 percent of patients with pT1c tumors had occult disease.Braun et al. found that the incidence of bone marrow micrometastases was similar in patients with lymph-node metastasis and those without it.After a 10 to 70 month range of follow-ups, 135 patients experienced a relapse of the tumor. 28 of the 135 patients had a locoregional relapse, and 107 had distant metastases. Locoregional relapses were not associated with the presence of micrometastases in bone marrow; however, distant metastases were.49 patients with occult metastatic cells, out of 199, died of cancer-related causes. On the other hand, out of 353 patients without occult tumor cells in the marrow, only 22 died of breast cancer. 14 patients died of cancer-related causes out of 100 patients with node-negative cancer and micrometastases. However, only 2 patients died of cancer-related causes out of the 201 patients without micrometastases. Braun et al. found no significant difference in survival between patients with node-negative cancer who had micrometastases and patients with node-positive cancer who did not have micrometastases.Braun et al. analyzed 245 patients with node-negative cancer who didn’t receive adjuvant therapy separately due to the possibility of locoregional relapse and distant metastasis being influenced by adjuvant treatment. 81 of the 245 had occult metastatic cells. Of the patients, who didn’t receive Adjuvant therapy, the risk of cancer-related deaths was higher of the 81 patients with micrometastases rather than of the 164 without micrometastases.The authors found that bone marrow micrometastasis, estrogen receptors, and lymph-node metastasis were each independent predictors of both recurrence with distant metastases and cancer-related death through a Cox multiple-regression analysis. 
 
Discussion | Braun et al.’findings support the view that different pathways of tumor-cell dissemination cause distinct patterns of metastasis this is supported by the studies which found no concordance between the presence of lymph-node metastasis and the presence of bone marrow micrometastases. 
 
 
Abstract / Introduction | Finding genes that are mutated in human cancers has given us knowledge on how cancers form. This knowledge has allowed us to develop new ways to treat cancer. In this study, researchers analyze the genetic changes that take place during the development of breast and colorectal cancers. They did so by sequencing DNA from breast and colorectal tumors while also browsing RefSeq, a database that details most known human gene sequences. 
 
Sequencing Strategy | The researchers used the RefSeq database to find the sequences of known human genes. They used their knowledge of these sequences to develop primers necessary for polymerase chain reaction (PCR). Then, they used PCR to produce many copies of every gene from both tumor samples and cells from healthy people. Afterwards, they looked for differences between the genes from the tumor samples and the same genes from healthy people. They took measures to make sure these apparent differences weren’t due to errors in PCR or natural variations in DNA sequences. From then, they determined the sequences of the tumor genes that differed from normal genes. PCR was run on these specific genes again to make sure that these gene alterations were really somatic. 
 
Somatic Mutations | It was found that 9.4 of the analyzed genes from the tumor samples had mutations that were responsible for some bodily change. Most of these mutations were changes in a single nucleotide pair. There was a strikingly high number of transitions from cytosine to thymine at sites near the promoter for colorectal cancer. 
 
Passenger Mutation Rates | Mutations in cancer are classified as either “drivers” or “passengers”. Drivers have involvement in tumor development and thus have a higher chance of manifesting during cancer progression.Passengers appear by chance and do not affect tumor development one way or another. However, once they appear, they can remain when the cell they appear in replicates enough times.The researchers measured the rate in which passenger mutations appear using a technique called high-density oligonucleotide microarrays. They found that roughly 0.55 passengers that result in a change in protein product show up in every one million base pairs of DNA. 
 
Evaluating Mutated Genes | From the data collected up to this point, the researchers pinpointed mutated genes that were the most likely to be drivers. Genes that were considered more likely to be drivers had at least one protein-changing mutation and a sufficient number of mutations per nucleotide. Such genes were termed candidate cancer genes, or CAN-genes. A total of 280 CAN-genes were identified.Genes that are mutated more frequently than expected during cancer development are likely to be drivers. Using this logic, the researchers assigned scores to the 280 CAN-genes based on their mutation frequency in tumor samples. These scores were called cancer mutation prevalence (CaMP) scores. The genes with the highest CaMP scores were considered most likely to be drivers.To further determine how often these genes are mutated in cancers, the researchers analyzed a subset of 40 CAN-genes across 96 colorectal cancer patients. These genes’ CaMP scores were among the top half of all CAN-genes. About two-thirds of these genes were found to be mutated in at least one patient. Most were mutated in less than 5 of these patients. A bit over a third of these genes were not mutated in any patients. 
 
Additional Analyses of Mutated Genes | When deciding which genes needed to be studied further, the researchers considered more than just a gene’s mutation rate. They also considered how likely a gene’s mutations were to cause negative effects. To figure out how likely a gene’s mutations were to interfere with protein function, they examined the structures of the mutations. They also looked to see if their mutations happened in the same place as mutations known to cause other diseases. 
 
Analysis of Mutated Pathways | It is biological pathways rather than mutations in single genes that influence tumor development. The researchers set out to find whether certain pathways were more likely to have mutated genes in cancers than other pathways. They found 108 such pathways in breast cancers and 38 in colorectal cancers. The pathways included those that are involved in cell adhesion, the cytoskeleton, and the extracellular matrix. These findings suggest that interactions between cancer cells and extracellular environments are important in cancer development. There were also mutant protein products that interacted with other mutated genes unusually often. 
 
The genomic landscapes of colorectal and breast cancers | In the colorectal cancers studied, the median number of mutations with a bodily effect was 76. This number was 84 for breast cancers. The average number of mutations per colorectal tumor was 49 to 111. In breast cancers, this was 38 to 193, which is less consistent. The average number of mutated CAN genes among the two groups of cancers was 14 to 15. When visualizing these mutations, the researchers found a few of what they called “gene mountains” and many of what they call “gene hills”. 
 
Discussion | The results detailed in this article add to research done on genetic changes in breast / colorectal cancers. More tumor genes have been sequenced than in past studies. This study also includes data on noncoding mutations while others do not. These contributions give a more complete picture of the genes involved in cancer development. The research team also found better ways to both assess mutation rate and find better ways to identify important mutated genes.Research in the field of cancer genomics has made practices like analyzing a person’s genome viable approaches to fighting cancer. It can be hard to understand how exactly a mutation influences cancer formation, but new developments are making this more feasible. This study and others like it could open the doors to more personalized cancer treatments. Additionally, mutations in a given cancer can offer insight to guide patient management. 
 
 
Abstract | The researchers studied wild-type and Arabidopsis thaliana mutants with off-cycle circadian rhythms. The plants that had a matching circadian clock to the light-dark environment cycles had increased growth and survival. For example, these plants fixed more carbon and had more chlorophyll. 
 
Introduction | Circadian clocks are the body's biological clock that works to match external light-dark cycles. Circadian clocks give an advantage to organisms. In plants, circadian clock rhythm genes regulate opening of the stomata and reproduction. Circadian resonance occurs when the internal clock matches the external environment. When the cycles match, plants gain an advantage. Plants can optimize the timing of biological functions based on their accurate clock. T cycles are the length of an external cycle.First, the researchers used wild-type Columbia-0 (Col-0) plants that had an internal cycle of 24 hours. This wild-type plant was grown in various environments. The external days included lengths of 20 hours (T20), 24 hours (T24), and 28 hours (T28). Half of these days are light and half of these days are dark. The mutant ztl-1 had an internal clock longer than normal (27.1-32.5 hours). The mutant toc-l had an internal clock shorter than normal (20.7 hours). Another mutant CCA1-ox overexpressed CCA1. CCA1 is a gene involved in creating the cycles of the circadian clock. So, CCA1-ox had irregular circadian rhythms. The authors studied the plants during vegetative growth, which is when a plant is growing but not flowering. 
 
Results and Discussion | Leaves of the wild-type plant had the most chlorophyll in T24 after 30 days compared to plants grown in T20 and T28. The mutant ztl-1 had more chlorophyll in T28 than in T20. The mutant toc1-1 had more chlorophyll in T20 than in T28 (Figure 1). Thus, plants have more chlorophyll if their circadian clocks match the external cycles. The pigments that harvest light are relatively uniform throughout time. But, there are proteins that are degraded by light as a regulation. So, if there are longer cycles of light, more proteins will be degraded than anticipated.Carbon fixation is when plants take carbon dioxide to create organic compounds for their own use. The mutants ztl-1 and toc1-1 fixed more carbon when the external cycles matched their circadian cycles. The mutant CCA1-ox fixed less carbon than the wild-type plant. In continuous light, the wild-type plant fixed carbon in a cyclic manner. But, the mutant CCA1-ox fixed carbon constantly and in an increasing manner. When the external environment was cyclic, the stomata of both the wild-type plant and CCA1-ox opened and closed. But, the wild-type plant could anticipate darkness or “dusk.” So, its stomata closed earlier. The wild-type plant conserved more water as a result (Figure 2).Plants with circadian resonance grow the most. The researchers grew the plants for 32 days.The wild-type plant grown in T20 had 47 less aerial biomass than the plant grown in T24. The wild-type plant grown in T28 had 42 less aerial biomass than the plant grown in T24. The mutants ztl-1 and toc1-1 had the most aerial biomass and leaf surface area when grown in T28 and T20, respectively. The mutant CCA1-ox had less biomass and leaf surface area than the wild-type (Figure 3). Thus, circadian resonance increases plant fitness.The researchers did not find a significant difference in seed production between plants and mutants. However, flowering depends on circadian clocks. So, the mutant genes may ambiguously affect seed production.Plants with circadian resonance have a competitive advantage against other plants. The researchers created a lawn combined with the ztl-1 and toc1-1. When the lawn was grown in T20, toc1-1 outgrew ztl-1 in terms of biomass. The mortality of ztl-1 was higher than toc1-1. The reverse was true for T28. In a second experiment, the researchers looked at two more mutants. The additional mutants help control for any other alleles that may provide a competitive advantage in the first experiment. One was toc1-2, which has an internal clock of about 20 hours. The other was ztl-27, which has an internal clock of about 28 hours. When the lawn was in T20, toc1-2 outgrew ztl-27. The mortality of ztl-27 was higher than toc1-2. The reverse was true for T28 (Figure 4). The competitive advantage was likely due to the increased ability for photosynthesis. 
 
Conclusion | The circadian clock can help the Arabidopsis thaliana grow up to twice as much as a mutant. The clock allows the plant to anticipate the external light-dark cycles. Because of the competitive advantage, the circadian clock was selected for during evolution. The researchers urge that selective breeding should be done carefully. Keeping the circadian clock genes can increase plant production significantly. 
 
 
Abstract | The COVID-19 outbreak has become a worldwide pandemic. In this paper, the lockdown strategy enforced by the Chinese government is examined in depth to determine whether it is an effective measure to take for countries that are experiencing severe outbreaks. The researchers examined data on confirmed COVID-19 cases and changes in diagnostic criteria, and found that the spread of the virus was slowed dramatically as soon as the lockdown was implemented, and even more so once more stringent diagnostic and testing guidelines were introduced. 
 
Background | The COVID-19 outbreak was declared a public health emergency of international concern (PHEIC) by the World Health Organization (WHO). As a result, many countries have implemented flight restrictions to China. In addition, the Chinese government has strictly enforced a lockdown protocol for the entire Hubei province, including the epicenter of the outbreak in Wuhan.In comparison to Italy's lockdown, in which citizens are still allowed to work and dine in restaurants as long as they respected a 1m physical distancing rule, the Hubei province lockdown has effectively confined every Hubei resident within their homes, with only essential businesses allowed to continue operations. However, as COVID-19 has continued to spread in these areas due to community transmission, it is still unclear whether these measures have been effective in reducing the spread of COVID-19 cases. 
 
 |  
 
Methods and Results | The scientists analyzed available data on the development of confirmed domestic and international COVID-19 cases before and after lockdown measures. They evaluated the correlation of domestic air traffic to the number of confirmed COVID-19 cases and determined the growth curves of COVID-19 cases within China before and after lockdown as well as after changes in COVID-19 diagnostic criteria.An analysis of the growth curves before the lockdown, after the lockdown, and after the changes in diagnostic criteria indicated a significant increase in doubling time of confirmed cases, from 2days to 4days, after imposing lockdown (Figure 4). Once more specific diagnostic and testing guidelines were introduced on February 7th, this doubling time increased drastically to 19.3 days. Furthermore, the correlation between domestic air traffic and COVID-19 spread weakened following lockdown, from 0.96 to 0.83, as can be seen in Figure 3. This is also demonstrated in the analysis of COVID-19 cases outside of China, in which there were fewer COVID-19 positive patients that had travel history to China. 
 
Discussion | It appears that an increase in doubling time was a significant result of the measures imposed upon the Hubei province. This can be attributed to the lockdown strategy, travel restrictions, and better articulated diagnostic criteria. As the scientists are drawing from a totality of data, it is not possible to determine which measure had a greater impact on increasing the doubling time of confirmed cases. However, more stringent confinement of people in high risk areas seem to have a potential to slow down the spread of COVID-19 and reduce the pressure on medical facilities. 
 
 
Aims: | The researchers aimed to study early clinical and CT developments of COVID-19 pneumonia. These signs can provide clues for early diagnosis, prevention, and treatment. 
 
Introduction: | The severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) causes the coronavirus disease (COVID-19). The virus has an envelope and granules. It originated from Wuhan, Hubei, China. Symptoms are acute, onset, and severe. The disease is very infectious. The virus is spread through respiratory droplets, contact, and fecal-oral route. The World Health Organization (WHO) has declared COVID-19 a global public health emergency. To diagnose this disease, doctors use epidemiological factors, clinical signs, CT findings, and nucleic acid detection of SARS-CoV-2. There is a recent change in diagnosis. If a patient has a combination of clinical signs and CT findings of pneumonia, they can be diagnosed as a confirmed case.  
 
Methods: | The severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) nucleic acid test using reverse transcription polymerase chain reaction (RT-PCR) confirmed COVID-19 pneumonia in patients. Doctors looked at symptoms, lab results, and CT scans.  
 
Results: | This study included 108 patients with mild COVID-19 pneumonia. 1-3 days were allowed between onset of symptoms and CT examination. 87 percent of patients had a fever. Table 1 shows the different clinical symptoms. Table 2 shows the laboratory findings. All patients had a normal or decreased white blood cell count. 60 percent of patients had decreased lymphocyte count, and 40 percent of patients had normal levels. 99 percent of patients had increased high-sensitivity C-reactive protein levels. Table 3 shows CT findings. 65 percent of patients had multiple affected lung lobes. In patients where multiple lobes were affected, 97 percent of lesions were in the peripheral zone of the lung. If a single lobe was affected, 79 percent of cases involved the right lower lobe. Patchy ground-glass opacification (GGO)(86 percent) and GGO (80 percent) with consolidation are the most common CT features (Figures 1 and 2). Vascular thickening was seen in 80 percent of patients (Figure 3 and 4). The crazy paving pattern was seen in 40 percent of patients (Figure 4). 48 percent of patients had the air bronchogram sign (Figures 3 and 5), and 64 percent of patients have the halo sign (Figures 2 and 5). 63 percent of lesions were larger than 1 cm. No one had lymph node enlargement, pleural effusion, or pleural thickening. 
 
Discussion: | Early detection and immediate treatment of COVID-19 is essential to stopping the spread. As of February 13, 2020, there are more than 60,000 cases in China. The SARS-CoV-2 nucleic acid detection is the reference standard. But, there is a high false-negative due to errors in nasopharyngeal swabbing. Multiple samples are often needed. Many patients delay treatment, contributing to spread. High-resolution CT that can detect millimeter-size lesions are important for early diagnosis of COVID-19 pneumonia. COVID-19 pneumonia is common in adults (mean age, 45), but rare in children and infants. 	The right lower lobe may be most commonly affected due to its anatomy. The virus can easily infect the lobe because the bronchus is short and thick. COVID-19 may be similar to other coronaviruses, such as SARS-CoV and MERS-CoV, where an inflammatory cytokine storm causes pneumonia. There is diffuse alveolar damage. Exudation and edema in the alveoli are not obvious, possibly causing GGO, because the hyaline membrane is between the alveolar walls. Fibrosis and developments outside the lungs, such as lymph node enlargement are not seen in early lesions of COVID-19, but may be seen in later and more severe stages.	One limitation was the lack of follow-up CT scans to investigate treatment efficacy and lack of lung biopsies to compare to CT data. 
 
Conclusion: | The early symptoms include low to midgrade fever, dry cough, and fatigue. Clinical manifestations include normal white blood cell (WBC) count, reduced lymphocyte count, and increased high-sensitivity C-reactive protein level. In the CT scans, doctors found patchy ground-glass opacification (GGO) either in one lobe or multiple lobes, mainly in the peripheral zone. Halo sign, vascular thickening, crazy paving pattern, or air bronchogram sign accompanies the GGO. 
 
 
Abstract | Understanding the severity of COVID-19 is crucial for proper healthcare. A simple approach to assessing disease seriousness is presented. The reference group consists of influenza patients with pneumonia from German hospitals. It was found that there were more deaths among COVID-19 patients without underlying conditions than in the reference group.  
 
Methods | The assessment of the seriousness of COVID-19 was generated by comparing well-described cases from hospitalized COVID-19 patients from Wuhan, Beijing, Shenzhen, Hubei and Zhejiang to a reference group consisting of inpatients diagnosed with influenza-associated pneumonia in several German Hospitals. Several parameters of seriousness associated with COVID-19 were compared, such as acute respiratory distress syndrome, ventilation, intensive care, and case fatality. Outcomes and risk factors for critically ill patients such as the reception of intensive care and ventilation were also compared. Differences in the different cohorts, such as age and gender ratios, were adjusted accordingly. 
 
Outcomes | Before discussing outcomes, it is important to note that the proportion of patients with co-morbidities was much smaller in the COVID-19 groups (20-51 percent) than in the pneumonia group (70-77 percent). Hypertension and diabetes were the most important chronic co-morbidities among both COVID-19 patients and pneumonia patients. The proportion of patients in the ICU among the German pneumonia cohort was 20 percent. Three case series of COVID-19 produced proportions of ICU patients at 10 percent or lower, and two produced proportions of around 20 percent. The median age of ICU patients for COVID-19 and influenza-associated pneumonia were 66 and 67 years respectively. 28 percent of COVID-19 patients treated on the ICU did not have any reported comorbidity, whereas only 16 percent of German ICU patients were without comorbidities.	Three COVID-19 case series found the proportion of COVID-19 inpatients who required ventilation was around 25 percent. German pneumonia patients had a much lower ventilation rate of 9 percent. This difference can be attributed to a high rate of acute respiratory distress syndrome (ARDS) among COVID-19 patients. ARDS is only observed in 1 percent of influenza-associated pneumonia patients.	The case fatality rate of the German pneumonia cohort hovered at around 6 percent. For case studies of COVID-19 in which the proportion of patients who were still hospitalized was 60 percent or below, the fatality rate ranged from 4 percent to 12 percent. A different study by Yang et al. found that among 25 critically ill COVID-19 patients younger than 60 years, 12 died within 28 days after admission to the ICU, and that of 31 patients without chronic illnesses, 15 died. In the German hospitals, of 462 pneumonia patients who were critically ill, 92 were younger than 60 years, of whom 12 (13 percent) died. In addition, 18 of the critically ill pneumonia patients were without chronic preconditions and four of them died. 
 
Discussion | The proportion of severe cases requiring intensive care and the case fatality ratios were strikingly similar among COVID-19 and German pneumonia patients. Disease severity in younger adults below the age of 60 and in patients without chronic preconditions seems to be higher in COVID-19 patients than in pneumonia patients. Also, the rate of ARDS and use of ventilation was higher in COVID-19 patients than in influenza-associated pneumonia patients. 
 
Conclusion | Hospitals in regions across the globe that are becoming increasingly affected by COVID-19 must prepare for the high utilization of ventilation and intensive care resources, and this early preparation can promote positive outcomes. Also, although fatalities occur mostly among elderly people with chronic preconditions, COVID-19 infection still occurs in younger, healthy patients, and in a much higher rate than previously expected. 
IntroductionCoronaviruses cause respiratory and intestinal infections in animals and humans.They were not considered to be highly pathogenic to humans until the outbreak ofsevere acute respiratory syndrome(SARS) in 2002 and 2003.Ten years after SARS, another coronavirus: Middle East respiratory syndrome coronavirus (MERS-CoV) emerged in Middle Eastern countries.SARS Coronavirus uses "ACE2" (angiotensin-converting enzyme 2)as a receptor to infect specific lung cells (ciliated bronchial epithelial cells and type II pneumocytes). MERS uses "DDP4" (dipeptidyl peptidase 4) as a receptor to infect specific lung cells (unciliated bronchial epithelial cells and type II pneumocytes).SARS and MERSwere transmitted to humans from market civets and camels, respectively. Both viruses are thought to have originated in bats.Studies of these two coronaviruses have led to a better understanding of coronavirus biology and led to more coronavirus discovery in bats.This review focusses on the origin and evolution of SARS and MERS.With a focus on the ecological distribution, genetic diversity, interspecies transmission and potential for disease development SARS and MERS related coronaviruses in bats. This information can help prepare countermeasures against new coronaviruses disease in humans.Coronavirus DiversityCoronaviruses are members of the subfamilyCoronavirinae. This subfamily consists of four genera —Alphacoronavirus,Betacoronavirus,GammacoronavirusandDeltacoronavirus— based on their evolutionary similarity and genomic structures (Fig.1). The alphacoronaviruses and betacoronaviruses infect only mammals. The gammacoronaviruses and deltacoronaviruses infect birds, but some of them can also infect mammals.Alphacoronaviruses and betacoronaviruses usually cause respiratory illness in humans and infectious diarrhoea in animals. SARSand MERS, cause severe respiratory syndrome in humans, and the other four human coronaviruses (HCoV-NL63, HCoV-229E, HCoV-OC43 and HKU1) cause mild upper respiratory diseases in people with weak immune systems, although some can cause severe infections in infants, young children and elderly individuals. Alphacoronaviruses and betacoronaviruses can pose a heavy disease burden on livestock. Based on current databases, all human coronaviruses have animal origins: SARS-CoV, MERS-CoV, HCoV-NL63 and HCoV-229E are considered to have originated in bats; HCoV-OC43 and HKU1 likely originated from rodents. Domestic animals may be intermediate hosts that enable virus transmission from other animals to humans. Domestic animals themselves can suffer disease caused by coronaviruses: genomic sequences highly similar to PEDV were detected in bats, and SADS-CoV is a recent spread from bats to pigs(Fig.2). Currently, 7 of 11ICTV-assigned(International Committee on Taxonomy of Viruses)Alphacoronavirusspecies and 4 of 9Betacoronavirusspecies were identified only in bats (Fig.3). Thus, bats are likely the major natural reservoirs of alphacoronaviruses and betacoronaviruses.Animal Origin and Evolution of SARSAt the beginning of the SARS epidemic, almost all inital patients had animal exposure before developing disease. Traces of antibodies linked to SARS were found in masked palm civets (Paguma larvata) and animal handlers in a market place. However, later, investigations of farmed and wild-caught civets revealed that the SARS-CoV strains found in market civets were transmitted to them from other animals. In 2005, two teams independently reported the discovery of new coronaviruses related to human SARS-CoV,in horseshoe bats (genusRhinolophus). These werenamed SARS-CoV-related viruses or SARS-like coronaviruses. These discoveries suggested that bats may be natural hosts for SARS-CoV and that civets were only intermediate hosts. Many coronaviruses with evolutionary relations to SARS-CoV were discovered in bats from different provinces in China and also from European, African and Southeast Asian countries(Fig.4; Supplementary Fig.S1a). According to the ICTV (International Committee on Taxonomy of Viruses)criteria, only the strains found inRhinolophusbats in European countries, Southeast Asian countries and China are SARS related. Those fromHipposiderosbats in Africa are less related to SARS-CoV and should be classified as a new coronavirus species. These data indicate that SARS related viruses have wide geographical spread and might have been present in bats for a very long time. A 5-year study revealed the existence of many different SARS-related viruses in bat populations in one cave of Yunnan province, China. This location the SARS-related viruses in this location contain all varieties found in other locations of China. Furthermore, the viral strains that exist in this one location contain all genetic elements that are needed to form SARS-CoV (Fig.5). Since no direct predecessor of SARS-CoV was found in bat populations despite 15 years of searching, and as RNA recombination is frequent within coronaviruses, it is likely that SARS emerged through recombination of related viruses in bats. Previous data supports this idea.Given the prevalence and great genetic diversity of SARS-related viruses in bats, their close coexistence and the frequent recombination of the coronaviruses, it is expected that there will be new coronaviruses in the future. Because there were no SARS cases in Yunnan province during the SARS outbreak, it is believed that the predecessor of SARS-CoV was produced by within bats, spread directly or indirectly (via another mamal) to civets. When the virus-infected civets were transported to Guangdong market, the virus spread in market civets and further mutated before spreading to humans.Variability of bat SARSr-CoVsSARS-CoVs and SARS-Related viruses in bats mainly vary in three regions: S, ORF8 and ORF3 (Fig.5).Receptor usage of SARS-CoV and SARSr-CoVThe binding of the ACE2 receptor is essential for a range of coronaviruses. Different strains of the virus bind to varying degrees. Those which bind more strongly to ACE2 in humans transmit more effectively between humans. Some virus may bind well to ACE2 in animals like civets but bind poorly in humans, leading to less human transmission. Understanding thee usage of receptors by coronaviruses is essential to prevent future disease outbreaks.Origin and evolution of MERS-CoVMost early cases of MERS came from camels. MERS strains found in camels were almost identical to those found in humans. MERS-specific antibodies were found in camels as well as infections detected in 1983 in camels. This suggests MERS was present in camels for 30 years. MERS related viruses have also been found in bats.Variability of human and camel MERS-CoVMERS virus in humans and camels were over 99 identical. Mains variations were inS, ORF4b and ORF3, particularly in African camels.Variability of bat MERSr-CoVsCurrently, MERS in bats and camels have similar genomic structures but different genomic sequences. The higher similarity between MERS related virus in bats and camels was ~85. Several MERS strains in bats in China were similar enough to be considered the same species.Receptor usage of MERS-CoV and MERSr-CoVIn contrast to SARS-CoV, which uses ACE2 as its receptor, MERS-CoV uses DPP4. MERS strains in camels and humans are quite similar, using DPP4 efficiently. Similar to SARS, receptor recognition is essential MERS to infect and animal.SADS-CoVFrom 28 October 2016 to 2 May 2017, swine acute diarrhoea syndrome (SADS) was observed in four pig breeding farms in Guangdong province. Up to 90of piglets younger than 5 days old died. A new bat related coronavirus names SADS-CoV was the cause. The virus was almost identical in all 4 farms. Virus that were 96-98 similar were later found in other farms. Analysis indicates that currently known receptors like ACE2 and DPP4 were not used for SADS. Further study is required on this topic.Conclusions and future perspectivesThe collected data demonstrated that SARS likely originated in bats through recombination of related viruses. Recombination likely occurred in bats before SARS was introduced into Guangdong province through infected civets or other infected mammals from Yunnan. The introduced virus underwent rapid mutations inSandorf8regions, successfully spreading in market civets. After several independent transmissions to humans, some of the strains further mutated inSand became the SARS epidemic in 2002–2003. However, a recent investigation revealed the presence of antibodies against SARS related viruses in humans living near a bat cave.These people did not show signs of disease, suggesting that the virus can infect humans through frequent contact.A similar scenario might have happened for MERS. Since its outbreak in 2012, MERS and related viruses have been found in bat species in five continents. Given the massive number of coronaviruses carried by different bat species, and other features such as adaptive mutation and recombination, it is expected that there will be frequent transmission from bats to animals and humans.Currently, no clinical treatments or prevention strategies are available for any human coronavirus. In addition, little information is available on HKU3-related strains that have much wider geographical distribution. Similarly, antibodies against MERS-CoV could not protect from infection with a virus bearing the MERS related virus in bats. Little is known about the replication and disease spread of these bat viruses. Thus, future work should be focused on the biological properties of these viruses. The resulting data would help the prevention and control of SARS-like or MERS-like diseases in the future.It is widely accepted that many viruses have existed in their natural reservoirs for a very long time. The constant transmission of viruses from natural hosts to humans and other animals is largely due to human activities, including modern agricultural practices and urbanization. Therefore, the most effective way to prevent viral infections from animals is to maintain the barriers between natural reservoirs and human society.  
 
 
Note | Dcyphr summaries are not a substitute for medical advice. Always consult your physician before taking any new drugs or changing your diet in any way. The data on the current COVID-19 outbreak is also changing, so there may be updates. 
 
Aims | The authors aim to explain the origins of chloroquine and its current use. They expand what this means for the current COVID-19 outbreak. 
 
Summary | Drug repositioning is finding an alternative use for another drug. Drug repositioning has gained momentum in recent years. It is important to use drugs that are safe, where the molecular mechanism and optimal dosage is known. In the current novel coronavirus (SARS-Cov-2) outbreak, many drugs are possibly repositioned, especially chloroquine. Researchers have studied chloroquine for the past 20 years. Researchers have found chloroquine to be effective in vitro against many viruses. This drug increases the pH of the phagolysosome. The phagolysosome is a cytoplasmic body that decreases the pH of the surroundings to kill pathogens during phagocytosis. Thus, chloroquine impairs low pH-dependent activities in viral replication, including fusion and uncoating. Other mechanisms of antiviral activity are not explained well.During the severe acute respiratory syndrome (SARS)-associated coronavirus in 2003, chloroquine was effective in vitro. It has a 50 effective concentration (EC50) of about 8 µM. These findings were forgotten when SARS disappeared. The novel coronavirus caused a re-evaluation of many drugs. The new antiviral drug remdesivir and chloroquine are effective against virus replication with an EC50 of 1.1 µM.Chloroquine is one of the most prescribed drugs today. For the past two decades, Europeans have taken chloroquine to prevent malaria when visiting areas with prevalent malaria. Local residents have taken chloroquine regularly. Treatment often uses chloroquine. Physicians use hydroxychloroquine to treat autoimmune diseases at high doses (up to 600 mg/day). The cost is negligible. Thus, it is reasonable that chloroquine may be used as prevention and a cure for the novel coronavirus. Chinese researchers are currently evaluating chloroquine. 
 
 
Introduction | A novel coronavirus has caused a viral pneumonia outbreak in China. There is evidence of person-to-person transmission. But, the researchers have not yet seen reports of COVID-19 transmission from an asymptomatic carrier. The carrier would have a normal chest computed tomography (CT). 
 
Aims | The researchers report a possible transmission of COVID-19 through an asymptomatic carrier. 
 
Methods | In January 2020, the physicians admitted 5 symptomatic and 1 asymptomatic family members. The symptomatic patients had fevers and respiratory symptoms. The physicians analyzed patient records. All patients received chest CT scans. Physicians used nasopharyngeal swabs and real-time reverse transcriptase polymerase chain reaction (RT-PCR) tests to test for COVID-19. 
 
Results | Let's assume the asymptomatic carrier is patient 1. Patient 1 is a 20-year old woman from Wuhan. She traveled to Anyang on January 10, 2020 to meet patients 2 and 3. On January 13, she went with patients 2 to 6 to visit a relative in another hospital (Figure). This hospital had no reported cases of COVID-19. When the five relatives developed symptoms, physicians isolated patient 1. Patient 1 had no symptoms as of February 11. She had no fever, gastrointestinal, nor respiratory symptoms. Chest CTs on January 27 and 31 had no abnormalities. The table shows she had normal C-reactive protein levels and lymphocyte counts. She tested negative on January 26, positive on January 28, and negative on February 5 and 8.Patients 2 through 6 developed COVID-19. Four were women, and ages ranged from 42 to 57 years. None of them had traveled to Wuhan or was in contact with anyone from Wuhan except for patient 1. Patients 2 to 5 developed fevers and respiratory symptoms between January 23 and 26. All patients had positive RT-PCR results within 1 day. Patient 6 developed a fever and sore throat on January 17. She went to a local clinic for treatment. There were no reported cases in the clinic. Her symptoms worsened, so she went to the hospital, where she tested positive on January 26. Two patients developed severe pneumonia. The rest of the infections were moderate.The symptomatic patients had CTs that showed multifocal ground-glass opacities. One also had subsegmental areas of consolidation and fibrosis. All symptomatic patients had increased C-reactive protein levels and reduced lymphocyte counts (Table). 
 
Discussion | The familial cluster of COVID-19 in Anyang, China had contact with the asymptomatic family member. The timeline of events suggest that the asymptomatic carrier transmitted the coronavirus. The patient had an incubation period of 1 to 19 days, which is long. But, this is within the reported range of 0 to 24 days. Her first PCR test was negative. False negatives are due to the quality of the kit, the quality of the sample, or performance of the test. RT-PCR is often used for viral diagnoses. It has very few false positives. Thus, the positive result was unlikely to be a false positive. The physicians counted this test as the date patient 1 had a confirmed infection.Another study showed a 10-year old boy was asymptomatic. But, he had an abnormal chest CT. If researchers replicate these findings of asymptomatic transmission, the coronavirus infection will be difficult to prevent. The mechanism in which asymptomatic carriers acquire and transmit the virus needs more research. 
 
 
Introduction | A contagious, unusual pneumonia broke out in Wuhan, China in December 2019. The virus originated from another animal and jumped to humans, and it was named COVID-19. This is similar to the SARS and MERS coronavirus. China has 33,789 confirmed cases and 811 deaths as of February 8, 2020.The basic reproductive number (R0)is the average number of new infections that will be created by an infectious person. The R0 is an indication of how transmissible a virus is in a population. If R0 is greater than 1, more people will be infected. If R0 is less than 1, the transmission will stop eventually. 
 
Aims | The researchers aim to study the reproductive number of COVID-19. 
 
Methods | 	Researchers used 12 studies that estimated R0 between January 1, 2020 and February 7, 2020. They used PubMed, bioRxiv, and Google Scholar. 
 
Results | 	Initial studies indicated lower R0 values. The values increased and have recently decreased. The data ranged from 1.4 to 6.49, has a mean of 3.28, and has a median of 2.79. The range between the 25th and 75th percentiles is 1.16 (Table 1). 
 
Discussion | 	The World Health Organization (WHO) estimates R0 to range from 1.4 to 2.5. The R0 estimates in this study are much greater than estimates by WHO. The difference in R0 estimates across studies could be due to the estimation methods. Stochastic and statistical models produce reasonable R0 values. R0 values from mathematical models are higher on average. This could be because of different modeling assumptions. Recent studies are more reliable because there is more data. Moreover, these estimates can include the effect of interventions. Recent studies estimate R0 to be 2-3.Researchers estimate SARS to have an R0 of 2 to 5. This value is similar to COVID-19, which is expected due to the similarities in the virus. But, COVID-19 is already more widespread than SARS even with more public awareness and increased intervention. Thus, COVID-19 may be more transmissible than SARS. 
 
Conclusion | 	This study estimates the mean R0 for COVID-19 to be 3.28. The WHO estimate of 1.95 is much lower. The estimation method and assumptions affect the estimate. There is still not enough data, so estimates are likely biased. Estimation error should decrease with more data. Considering everything, the R0 is likely around 2-3, which is somewhat consistent with the WHO estimate. 
 
 
Note | Summaries from dcyphr do not substitute the advice of health professionals. The information on COVID-19 is constantly changing. Also, this study has an extremely low sample size, and more research needs to be done. 
 
Abstract | 	Researchers detected the 2019 novel coronavirus in 11 out of 12 (91.7) of patients. Saliva taken incrementally showed a decrease in virus concentration with time. Viral culture indicated the presence of live viruses. Saliva testing is promising for detection of 2019-nCoV in patients. 
 
Introduction | 	The severe acute respiratory syndrome coronavirus (SARS-CoV) caused a global outbreak in 2003. The death rate was 10. In December 2019, the 2019 novel coronavirus (2019-nCoV) emerged from the Hubei Province of China. The virus has spread quickly around the world. The 2019-nCoV is similar to bat SARS-like coronaviruses. Based on phylogenetic analyses, the 2019-nCoV is from the Betacoronavirus genus lineage B. The ORF8 and ORF3b proteins of 2019-nCoV is significantly different from other SARS coronaviruses. The difference could be why 2019-nCoV has different mechanisms of infection and transmission. The 2019-nCoV can be transmitted between humans like SARS-CoV.	Currently, hospitals use nasopharyngeal and oropharyngeal swabs to obtain respiratory samples. But, this requires hospital workers to come in close contact with patients. Current testing methods can cause discomfort and bleeding, especially if the patient has a low platelet count. Sputum samples are noninvasive from the lower respiratory tract. But, only 28 of patients with 2019-nCoV could produce a sample in one study.	Patients can give saliva samples by spitting in a sterile bottle. This lowers the exposure to healthcare workers. Previously, researchers have shown that saliva samples indicate the same results as nasopharyngeal specimens in coronaviruses. Sometimes, tests can detect respiratory viruses in patients without symptoms. 
 
Aims | The researchers aim to evaluate if saliva samples are effective for the testing of 2019-nCoV. 
 
Methods | 	Patients were confirmed to have 2019-nCoV with a nasopharyngeal or sputum sample. Patients coughed out saliva from their throat into a sterile container. Then, researchers added 2 mL volume of viral transport medium to the sample. Researchers conducted a total nucleic acid extraction. Then, they performed a reverse transcription-quantitative polymerase chain reaction (RT-qPCR) to detect the virus. Viral cultures were used to detect live viruses in saliva specimens. 
 
Results | 	The study included twelve patients with laboratory-confirmed 2019-nCoV. Researchers collected saliva samples a mean of 2 days after hospitalization. The range was 0-7 days (Figure 1). In 11 out of 12 (91.7) of patients, researchers detected 2019-nCoV. Viral load is the amount of virus per volume of fluid. The median viral load of the initial specimens is 3.3 x 106 copies / mL. The range is 9.9 x 102 to 1.2 x 108 copies / mL.	Samples were incrementally for six patients. The viral load was highest in the first sample for five patients (83.3). For one patient, researchers detected viral shedding on day 11 after hospitalization. In 33 patients whose nasopharyngeal tests came back negative, their saliva samples were also negative. 
 
Discussion | 	Saliva samples provide several advantages. The procedure is noninvasive, and samples can be collected outside of hospitals. Healthcare workers are not required, and results will be available sooner. During the SARS outbreak in 2003, the peak viral load occurred after 10 days of symptom onset on average. Early detection and isolation is important for a decrease in viral load and for antiviral therapies.	The live viral cultures indicate that live viruses are present in saliva. Thus, 2019-nCoV can be transmitted through saliva. This can be in fine respiratory droplets when sneezing or coughing, even without symptoms. Thus, people should wear surgical masks to control the spread. Researchers need to conduct more studies for the source of the virus in saliva. Possible sources include salivary glands, the nasopharynx, or the cilia lining in the lungs. 
 
 
Abstract | Social media has rapidly grown as a medium to disperse information. The popularity of social media has led certain movements such as veganism to become more visible to the average person. This exposure helps veganism to become more accepted by the mainstream. Despite this there is a lack of research on how to properly manage a vegan diet for athletic causes. The researchers of this study reviewed applicable research papers regarding vegan diets. There is little data regarding sports nutrition specifically. Veganism can create nutritional challenges that need to be accounted for. The reviewed articles mention Sufficiency of energy, protein, vitamin B12, iron, zinc, calcium, iodine and vitamin D, and the lack of long chain fatty acids. However, these can all be managed with strategic food management and proper supplementation. The purpose of this paper is to show that an inclusive and healthy vegan diet can be created for athletes. Beta-alanine and creatine were suggested as supplements that could be of great use to vegans. However, empirical research is needed to observe the effects of these diets in athletes. 
 
Background | Veganism is a form of vegetarianism that prohibits the consumption of any animal or animal product. The increased visibility of celebrities that abide by veganism suggests veganism could be more wide-spread accepted. However, poorly planned vegan diets can produce deficiencies in certain macronutrients (protein, n-3) and micronutrients( Vitamin B12 and D; iron, zinc, calcium, iodine). Vegan diets are even purported to have potential performance benefits due to the antioxidant(polyphenols), extra micro nutrients( vitamin C, E) and carbohydrate rich foods that aid in recovery. However, there are no studies that provide data on this subject. In order for a balanced diet basic dietary requirements must be met. In order for this to be applicable to athletes it must also be sufficient for their energy requirements. This is the aim of this research paper. The researchers wanted to provide practical recommendations for dieticians, coaches, or trainers who work with vegan athletes. Special attention will be given towards achieving proper macro/micro nutrients requirements for athletes. 
 
Main Text | Information in this review has been gathered from a broad range of academic disciplines. In some instances, recommendations in this article have yet to be proved via empirical investigation.EnergyOmnivorous diets provide sufficient energy to most athletes. Very large athletes may have a harder time acquiring the proper caloric intake. On the other end is athletes with very low body weight who are at risk for developing low density bones as a result of their training and eating habits. Additionally high intensity training can reduce appetite along with various other factors such as hectic travel schedules.The consequence of not acquiring enough energy is far reaching. Potential loss of immune function, weight loss, and reduced muscle power and tone. Managing a proper diet can be difficult for those not a vegan diet. The harmful effects of an improper diet can be inflated by a diet that promotes early satiety. The vegan diet is rich in fibre and emphasizes raw foods. These all lead someone to early satiety when eating a meal, and can cause less calories to be ingested. This can lead to restricted macronutrient (protein) absorption. Having early satiety in meals is good for weight loss regiments, but can cause issues in athletes who require high calorie meals. However, increasing eating frequency and intake of energy dense foods such as seeds, oils, and nuts can be helpful to meet the caloric needs of the athlete. Careful monitoring of unwanted body mass fluctuations would help the athlete to better tailor their diet to their caloric needs.Macronutrients(1) Protein The general consensus is that athletes require more protein than non-athletes. Strength training athletes are recommended 1.6-1.7grams per kg of body mass per day, whereas endurance is recommended 1.2-1.4grams per kg of body mass per day. This is significantly more than the 0.8grams per kg of body mass per day recommended for non athletes. The role of protein in the human body is not obvious. The balance between Muscle Protein Breakdown (MPB) and Muscle Protein Synthesis (MPS) is known as Net Protein Balance (NPB). In order to build muscle an athlete must achieve elevated levels of MPS. This will promote recovery, adaption, and muscle building. However, in conditions where the athlete consumes less overall calories than normal they might still require elevated protein intake to preserve muscle mass. Vegan athletes however consume less protein than their omnivorous and vegetarian equivalents. Plant-based protein is often incomplete. It is missing essential amino acids, and contains significantly less Branched Chain Amino Acids (BCAA) than their animal protein counterparts. The amino acid Leucine appears to be a trigger of recovery and (MPS). Evidence suggests that milk-based proteins might be superior to other protein sources at promoting MPS. This is thought to be due to the higher concentration of (BCAA). Similarly, it has been found that regular consumption of milk protein gives better muscle growth than the Soy-protein equivalent. The amino acids commonly missing from plant protein are lysine, methionine, isoleucine, threonine and tryptophan. Lysine is commonly absent from grain. However foods such as beans and legumes are rich in Lysine. Lysine can also be obtained from soy beans and lentils. BCAAs can be found in seeds, tree nuts, and chickpeas. The Academy of Nutrition and Dietetics (AND) recommend vegans/ vegetarians consume a variety of foods to meet their protein requirements. High protein foods are uncooked Pumpkin seeds, uncooked Lentils, uncooked black beans, raw almonds, tofu, oats, and Quinoa. At this time plant based protein supplements are less researched. Further research is required to understand the effects of animal protein supplementation in a vegan diet if protein acquisitions from wholefoods proves implausible.Protein DigestibilitySystems created to quantify a protein's digestibility both show that animal-derived protein scores higher than plant-based protein. Important plant-based protein sources such as rice, peas, and hemp score significantly lower than animal-derived. To compensate for the lower digestibility of plant-based protein it is advised that vegans consume a higher than recommended dose of protein. This would account for the decreased digestibility of the plant-based protein.(2) CarbohydrateVegan diets tend to be high in carbohydrates. It has been suggested that endurance athletes adopt vegan diets in order to meet their carbohydrate needs or to assist in weight management. In order to achieve more than required protein consumption it is recommended that vegans consume lentils, grains, pulses, and beans daily. The issue with this is that those foods are high in fiber and thus contribute significant bulk and increase the satiety signal. This leads to decreased intake and prolonged satiety feelings. For athletes with higher caloric needs this may prove to be ineffective. High fiber diets can also cause Gastrointestinal issues for some individuals. Therefore to meet this caloric intake it is recommended that vegan athletes consume foods such as rice, pasta, noodles, and buckwheat to meet their caloric intake.Carbohydrate Timing and SupplementationCarbohydrate doses can be scaled with respect to the intensity and duration of the athletic event. Generally, carbohydrates are vegan-friendly and their consumption is reasonable for vegan athletes. Alternatively, calcium fortified fruit juice as a liquid carbohydrate might serve two purposes. It can provide adequate carbohydrate requirements while meeting the calcium requirements simultaneously.(3) FatVegan diets are typically lower in saturated fats than omnivores. This is associated with less cardiovascular issues such as heart disease, hypertension, type II diabetes, excess cholesterol, or cancer. However, the harmful effects of fat consumption are not universally agreed upon. Lower fat consumption can have negative effects on testosterone production in males. Which might be of importance to athletes trying to maximize muscle growth. However, evidence has shown that vegan males do not have statistically significant lower levels of testosterone than omnivores. The relationship between athletic performance, hormones, and fats requires additional research. Attention should be paid to quantity and quality of consumed fats. Adequate consumption 0.5-1.5grams per kg of body mass per day is easily achievable for vegans by consumptions of oils, avacadods, nuts, and seeds.(4) ALA, EPA and DHAVegans do not eat marine life, thus they appear to consume less n-3 fatty acids. Vegans have overall lower levels of n-3 Fatty acids inside their blood. n-3 fatty acids are important for normal growth and development, cardiovascular health, immunity, and in chronic disease. n-3 fatty acids also increase nitric oxide production and improve heart function. n-3 fatty acids also contain anti-inflammatory properties, antithrombotic, antiarrhythmic, vasodilatory, antiproliferative properties. Both n-6 and n-3 fatty acids are essential and the n-3 (EPA) and n-6 (DHA) are under consumed by vegans. Thus vegans are encouraged to combine food sources of ALA with supplemental DHA from microalgae oil to optimize a vegan’s n-3 intake. Optimization of the vegan diet for n-3 intake is currently lacking at the time of this article's writing. However, recommendations of 1-2 grams per day of EPA and DHA in a 2:1 ratio have been suggested for athletes elsewhere.Micronutrients Proper micronutrient intake is crucial to all athletes. It has been recommended that special attention be given to Vitamin B12, iron, zin, calcium, iodine, and Vitamin D intakes.  (1) Vitamin B12 Animal and Dairy products contain large amounts of vitamin B12 (cobalamin). Therefore vegans are at increased risk of developing B12 deficiencies. There are no plant based sources of cobalamin. The only time cobalamin would be in a plant is if it was contaminated with manure from animal waste. Cobalamin is vital to nervous system function, metabolism, homeostasis, and DNA synthesis. Short term B12 deficiencies led to changes in blood cells and neurological issues. Long term B12 deficiencies can lead to irreversible neurological damage. Roughly 50 of vegans tested are low for B12 and 21 are considered very low. Surprisingly vegans who took B12 supplements did not have blood levels statistically different than vegans who didn’t take B12 supplements. Which indicates that supplements are not enough to achieve sufficient vitamin B12 levels. Sources suitable for vegans are breakfast cereals enriched with vitamin B12 and nutritional yeast. It is estimated that only 2 of Vitamin B12 supplements will be absorbed into the body. Vegans are advised to consume up to 6 ug per day of vitamin B12.(2) IronVegans and Vegetarians consume similar levels of iron as omnivores. Most likely due to consumption of whole-grains and legumes. However, the iron found in plant matter is in the non-haem form that is less useful to the body than the haem form that is found in animal matter. Vegan diets also commonly contain dietary inhibitors such as polyphenols tannin (found in coffee, tea, and coca) and phytates (found in whole grain and legumes). These inhibitors reduce the amount of iron absorbed from the diet into the body. Research has shown that male vegans tend to have sufficient iron stores, but female vegans do not. This can lead to anemia. Due to the iron type, and the presence of polyphenol inhibitors it is advised that vegans consume up to 1.8 times the normal recommended amount for omnivores. It has been suggested that high iron intakes cause other mineral interactions and cardiovascular issues. Vegan athletes should eat wholefood iron sources, reduce consumption of inhibitors, contain foods, and incorporate soaked, sprouted and/or fermented foods to their diets. Females with large menstrual loss may consider taking additional iron supplements(3) ZincZinc is vital for various enzymatic processes involving DNA. Zinc has similar absorption issues to iron. Some studies say that vegans do not need to pay special attention to increased consumption as the body adjusts to decreased zinc intake. While others suggest consuming 50 more zinc than recommended. Common sources of zinc are beans, whole grains, nuts, and seeds. Zinc should not be consumed at the same time as other supplemental forms of folic acid, iron, calcium, copper, or magnesium. Doing so will decrease the absorption of zinc. Multivitamins might not be enough to ensure the proper amounts of nutrients are absorbed. It is recommended that vegans consume zinc rich foods such as hemp, pumpkin seeds, and other grains, nuts and beans.(4) Calcium  Large amounts of Calcium are found in dairy products. Vegans have been shown to be at a higher risk of bone fracture due to decreased calcium intake. This can be especially problematic for growing children or teens. As with most nutrients the body can change the amount absorbed from a diet to better meet the body's needs. It is reported that protein rich diets do not promote calcium excretion. They actually work to increase calcium retention and bone metabolism. Calcium is necessary for blood clotting, nerve transmission, muscle stimulation, vitamin D metabolism, and maintaining bone structure. Vegan athletes should consume plant-based sources of calcium such as beans, pulses, and green vegetables to achieve 1000 mg per day. Broccoli, bok choy and kale are particularly high in calcium. Green vegetables such as spinach and arugula contain a compound that inhibits calcium absorption. Vegans athletes are also advised to eat calcium fortified foods if whole-foods are not plausible for their lifestyle.(5) Iodine Iodine is an essential element needed for physical and mental growth + development. It also plays a pivotal role in metabolism. Vegans eat either excessively large or small amounts of iodine depending on their diet choices. A study found that 80 of Slovakian vegans were iodine deficient. However, another study found that vegans consumed too much iodine from seaweed. Excessively high or low levels of iodine consumption can lead to thyroid dysfunction. Goitrogens, found in cabbage, cauliflower, and rutabaga decrease iodine utilization. Large amounts of these vegetables can cause thyroid dysfunction. However, cooking such foods tends to destroy most of the Goitrogens making this effect not likely. Iodine in seaweed has shown to be unreliable, which is why it is suggested that iodized table salt is a good solution for vegans. It can also be found in potatoes and cranberries.(6) Vitamin D Vitamin D is a fat soluble vitamin produced in the skin by contact with UV radiation. It is important for calcium absorption, bone health, and many physiological processes. It can be found in animal products and fortified foods but is mostly acquired from exposure to the sun. Dietary intake is required when sun exposure is not enough. There exist varying supplements with different degrees of absorption into the body. The optimal level of Vitamin D for athletes has yet to be researched properly.Supplements and Ergogenic Aids(1) Creatine Research shows that vegan/vegetarian diets reduce the creatine stored in muscles. Creatine is an organic acid synthesized in the body from an amino acid (arginine, glycine, and methionine). Meat, fish, and poultry all contain Creatine. Its performance enhancing effects are well studied. It increases short-term high-intensity exercise performance, muscle building, and maximum strength. Vegan athletes should consider creatine supplements to compensate for the reduced creatinine levels from their diet. Dosing creatine requires muscle saturation. Regimens for 20 grams per day for a week followed by 3-5 grams per day as maintenance. Athletes could also chose to take 3-5 grams per day for 4 weeks to achieve the same amount of muscle saturation(2) Beta Alanine  Meat and poultry are the main sources for beta-alanine in the diet. Supplementation has shown to increase muscle carnosine concentrations. Carnosine is protein found in skeletal muscle and the central nervous system. It is shown to lead to improvements in high-intensity exercise performance by getting rid of free radicals. The effectiveness of Beta-alanine supplementation has been confirmed in exercises that are longer than one minute. The effects below one minute remain unclear. Further research is needed to verify and explore its application. 
 
Conclusions | In general vegan diets tend to be lower in calories, protein, fat, vitamin B12, n-3 fats, calcium, and iodine than omnivorous diets. However, vegan diets are higher in carbohydrates, fiber, micronutrients, phytochemicals, and antioxidants. With proper selection and attention to macro/micro nutrients a vegan diet can attain a good balance. Supplementation with creatine and Beta-alanine might offer performance benefits to vegans who already have lower levels. Further research must be done to understand the performance enhancing effects of Beta-alanine and creatine. However issues with digestibility must be addressed. Increasing the amount of macro/micronutrients might be a way to combat the issues with digestibility and absorption. The shortcomings of this study is that there is no direct research of veganism in sports. To circumvent this tissue information was gathered from varied sources and compiled. Inferences were made based upon available data. Therefore, many of the recommendations in this article require authentication. The researchers want this article to act as guidance and a catalyst for future research into this topic. The main strength of this review is its complete analysis of the variables.  
 
 
Abstract | This study examined the stress and psychological distress of severe acute respiratory syndrome (SARS) survivors 1 year after the outbreak in 2003. During the SARS outbreak, the researchers used the 10-item Perceived Stress Scale (PSS-10) to assess SARS survivors in 2 hospitals. They evaluated the survivors 1 year later to complete the PSS-10 in 2004. They were also asked to complete the General Health Questionnaire (GHQ-12) and tests for depression, anxiety, and posttraumatic symptoms. The researchers found that SARS survivors had higher stress levels during the outbreak, which persisted 1 year later without decreasing. They also showed increased levels of depression, anxiety, and posttraumatic symptoms. 64 scored above the GHQ-12 cutoff, suggesting high incidence of mental illness. During the outbreak, healthcare worker SARS survivors had similar stress levels to non-healthcare worker SARS survivors. However, healthcare workers were more stressed and had higher rates of depression, anxiety, and posttraumatic symptoms in 2004. People should not ignore the psychological consequences of infectious diseases should not and mental health services could play an important role in treatment. 
 
Aims | The researchers wanted to evaluate the stress level and psychological distress of healthcare worker and non-healthcare worker SARS survivors 1 year after the outbreak. 
 
Introduction | Infectious diseases are one of the biggest threats to human health, and threaten not only life but psychological health as well. The psychological consequences of SARS include higher stress levels, poor sleep, depressed mood, weepiness, nightmares, and poor concentration. However, there is little information about long-term mental health consequences in SARS survivors. After being discharged, SARS survivors face a wide range of health issues and complications, and it is possible that their psychological health might get worse. The researchers conducted a 1-year assessment of SARS survivors during and after the outbreak. They also examined if there are differences in stress between healthcare workers and non-healthcare workers who survived SARS. 
 
Results | Stress LevelsAverage PSS-10 scores of SARS survivors were significantly higher than those of the general population, and persisted in 2004 without decreasing. PSS-10 scores were higher among female survivors. Neither education or age had an impact on PSS-10 scores.Psychological DistressAverage scores for anxiety and depression in SARS survivors were higher than average scores for the general population. Depressive symptoms were moderate-to-severe in 36.3 of the participants, and extremely severe in 4.4 of the participants. Anxiety symptoms were moderate-to-severe in 36.7 of the participants and extremely severe in 14.4 of the participants. 64 of participants scored above the threshold on the GHQ-12, indicating a high rate of potential mental illness.Female SARS survivors had higher scores for depression and anxiety. Female SARS survivors were more than 3 times likely to score above the GHQ threshold than male survivors, and 77.4 of female survivors scored above the GHQ-12 threshold.Differences Between Healthcare Worker SARS Survivors and Non-Healthcare Worker SARS SurvivorsDuring the outbreak, healthcare worker SARS survivors and non-healthcare worker SARS survivors had similar PSS-10 scores. One year after the outbreak, healthcare worker SARS survivors had higher PSS-10 scores, while non-healthcare worker SARS survivors maintained the same PSS-10 scores.	Healthcare worker SARS survivors also had higher scores for depression, anxiety, and posttraumatic stress. A greater number of healthcare worker SARS survivors scored above the GHQ-12 threshold than non-healthcare worker survivors. 
 
Discussion | SARS survivors had greater stress and psychological distress 1 year after the SARS outbreak, which failed to decrease. They were affected by a combination of stress, anxiety, long-term stress and psychological distress. Instead of improving over time, survivors’ psychological health seemed to deteriorate.The reasons for why SARS survivors have increased mental health issues and why their mental health did not improve over time need further examination. It is possible that during the outbreak, SARS victims were trying to survive their infection and other concerns were not a priority, and these concerns resurfaced after recovery. These concerns could be related to complications of SARS and its treatment, financial concerns or stigma.Other than PTSD, there is little understanding about the long-term impact of infectious disease. This study expanded current understanding by finding that on top of PTSD, survivors are also affected by depression, anxiety, and stress. This calls for greater attention to a wider range of mental health problems that could affect survivors after outbreaks.Being a woman and being a healthcare worker were risk factors for deteriorating mental health in SARS survivors. Female survivors had higher stress levels, psychological distress, and more likely to have mental illness. Healthcare worker SARS survivors also had higher stress levels and psychological distress. More than 90 of healthcare worker SARS survivors scored above the GHQ-12 cutoff, which is especially concerning. A possible explanation is that they were under a combined stress of illness and working on the frontlines. It is interesting that their stress levels increased 1 year after the outbreak. It is possible that after the outbreak, positive responses to SARS faded and healthcare workers faced greater vulnerability to psychological distress.Psychological services could be important for rehabilitation of SARS survivors. 
 
Methods | The researchers assessed SARS patients in 2 hospitals in Hong Kong with a questionnaire that included demographic information and the PSS-10.One year later, the researchers assessed recovered SARS patients from the same 2 hospitals using the PSS-10, anxiety and depression assessments, and the GHQ-12.The researchers analyzed data with SPSS. They used ANOVA to examine the associations between characteristics of the patients and measures of stress and psychological distress.   
 
 
Abstract | This is a retrospective study revealing mortality information about 52 critically illadult patients diagnosed with SARS-CoV-2 in Wuhan Jin Yin-tan hospital. Symptom, laboratory, comorbidity and outcome data was gathered about these ICU patients. Overall findings noted significant mortality for ill individuals over 65 years of age and a frequent need for mechanical respiration. 
 
Introduction | 	The initial spread of the now global SARS-CoV-2 virus was traced back to areas around Wuhan, China. This is one of the earliest studies presenting data of cases in this region, aiming to improve outcome information available to healthcare professionals. The retrospective nature of the study allowed researchers to collect mortality data and to observe survivors follow-up. 
 
Methods | 	The Wuhan Jin Yin-tan hospital was used as the data source for this study, as it was a designated treatment center for SARS-CoV-2 in the region. 52 critically ill patients (deemed “critical” based on ICU admission, need for mechanical ventilation, or low inspired oxygen levels) admitted between Dec 24, 2019 and Jan 26, 2020 were observed.	Age, sex, exposure history, chronic illness history, lab data, and various in-hospital symptoms (cough, fever, headache, chest pain…) were all collected and evaluated. Certain details such as ventilator settings could not be recorded due to the emergency nature of some provisional ICU’s. Primary outcome was 28-day mortality following a patient’s ICU admission, secondary outcomes were incidence of acute respiratory distress syndrome (ARDS, fluid build up in alveoli) and the need for mechanical ventilation.	Mean age of patients was 59.7, with 67 being men. 33 of patients had known exposure to the Huanan seafood market and 40 had known chronic illnesses.	 
 
Results | 	98 of patients experienced fever (most common symptom), 77 experienced cough and 63.5 displayed labored breathing (dyspnoea). Some patients took 2-8 days to develop a fever after showing other initial symptoms. The time between the onset of symptoms and pneumonia confirmation (via radiology) was 5 days.	Organ function damage was prevalent , with 67 developing ARDS, 29 suffering from kidney injury, 23 experiencing cardiac problems, and 29 having liver issues. Some (13) patients also developed hospital acquired infection.Treatment was mainly supportive care, including high-flow nasal cannula (oxygen supplementation), mechanical ventilation (required by 71 of patients), antiviral agents, antibacterial agents, glucocorticoids (immunosuppression), and others.61.5 of patients died within the 28 day time frame established by the study. An average of 7 days elapsed from ICU admission to death in nonsurvivors. Only 8 of 20 surviving patients were discharged within the 28 days (the rest requiring continued care). Nonsurvivors tended to be older (average of 64.6 years) and to have chronic illnesses (53 had known conditions). Nonsurvivors were also more likely to develop ARDS and to require mechanical ventilation. 
 
Discussion | The high mortality rate presented by this study is consistent with prior coronaviruses, but higher than SARS of MERS. This higher mortality can be connected to the prevalence of severe ARDS in severe pneumonia patients. It is notable that 70 of patients infected with SARS-CoV-2 were men (based on previous studies) and that nonsurvivors tended to be older relative to survivors. Additionally, over 80 of patients in this study displayed abnormally low blood lymphocyte levels (a consequence of SARS-CoV-2’s damaging effect on patient’s lymphocytes).  
 
 
Abstract | Researchers conducted a phylogenetic analysis of 160 human severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) genomes. They found three major variants of the virus: A, B, and C. The A variant represents the ancestral type with the bat coronavirus as the outgroup. The B variant is common in East Asia. But, this variant often mutates when it leaves East Asia. Thus, genetic variation may be lost for the B type of virus outside of Asia. There may also be immunological or environmental resistance. The variants A and C are most common among Europeans and Americans. Phylogenetic networks can be used to trace the path of infections and identify undocumented sources. This can lead to the prevention of infections. 
 
Aims | Researchers aim to demonstrate how phylogenetic network analysis can be used for studying evolution and the ancestral genome of viruses. 
 
Methods | The researchers used phylogenetics. They studied the coronavirus genomes from humans, pangolins, and bats. Laboratories and reliable sequencing programs confirmed the mutations. 
 
Results | Researchers have used phylogenetic networks to construct hypotheses for prehistoric populations. They use phylogenetic networks to study virus evolution. Using the GISAID database, they created a phylogenetic network of SARS-CoV-2 (Figure 1). Bat coronavirus was the outgroup for this network. Bat coronavirus is 96.2 similar to the human coronavirus.The variant A has two subclusters: the T-allele subcluster and the C-allele subcluster. The subclusters are differentiated by the mutation T29095C. Nearly half of the C-allele subcluster types are found outside of Asia.74 out of 93 type B genomes were found in Asia. Type B differs from A due to the mutations T8782C and C28144T. The C28144T mutation is nonsynonymous, meaning that there is an amino acid change due to the mutation. Specifically, a serine replaced a leucine. The ancestral B genome is found only in East Asians. All 19 genomes found outside of Asia have evolved mutations. The derived types have a long mutation branch. The reason does not appear to be the time lag in spread nor mutations before the spread. Possibilities include a founder scenario, or the virus had to develop some resistance outside East Asia. In relation to type B, type C has the mutation G26144T. A valine replaces a glycine. Type C is mainly found in Europeans.Researchers can use phylogenetics to trace the route of infection. For example, type C is found in both Brazil and Italy with a mutational link. This is due to a Brazilian who contracted the virus in Italy. The phylogenetic network represents early cases without considering complications due to migration and mutations.There are still questions if researchers should use the oldest genome as the root. The patterns in the phylogenetic network are due to migrations, founder effects, and sample size. The different variants perhaps may cause different clinical manifestations. Phylogenetics may be used to understand the epidemiology, spread, and prevention of the disease. The networks may help especially in developing treatments and vaccines. 
 
 
Abstract | In February 2020, there were available tests for IgG and IgM antibodies for SARS-CoV-2 (severe acute respiratory syndrome coronavirus). The National Health Commission of the People’s Republic of China added serological tests as a diagnostic criteria for COVID-19. Previous studies show there is no evidence of antibody transmission from mother to infant for mothers with COVID-19. In this study, they added serological tests to examine how newborns are affected. 
 
Methods | Researchers took throat swabs and blood samples of mothers and used neonatal blood samples. They took chest computed tomography (CT) scans and used RT-PCR. They tested for antibodies in neonatal sera. 
 
Results | Researchers tested 6 mothers with COVID-19 symptoms. Babies were delivered by cesarean sections, and they had high Apgar scores of 8 to 10 after one and five minutes. This means the babies were healthy. Two infants had elevated IgG and IgM levels. Their mothers also had a corresponding increase in these antibodies. Three infants had increased IgG levels but not IgM levels. Two of their mothers had increases in both antibodies and one had only increased IgG. All infants had a slightly increased level inflammatory cytokine IL-6. None of the infants had COVID-19 symptoms. 
 
Discussion | IgG can pass through the placenta from mother to the infant but IgM cannot. Another study showed mothers recovering from the SARS-CoV in their third trimester had abnormal placenta pathology. Researchers do not know about the pathology of placentas in this study. Another possibility is that the virus passed through the placenta, and the baby made IgM antibodies. This study has an extremely small data size. The quality of the data is limited by the quality of the samples. Data is still incomplete, and more research needs to be done. 
 
 
Abstract: | COVID-19 is an acute respiratory tract infection. Understanding where exactly the SARS-CoV-2 virus replicates and infects within the body is important in trying to contain the virus. The paper reports, based on review of nine cases, that the SARS-CoV-2 virus can replicate in upper respiratory tract tissues. Active replication in the throat was confirmed by the presence of viral replicative RNA in throat samples. Significant amounts of virus can still be found in the sputum (phlegm) of patients even after symptoms disappear and antibodies develop. 
 
Methods/Results: | Throat swabs of the nine patients were taken on the first day of the onset of COVID symptoms through the 28th day post onset. Viral load, or copies of SARS-CoV-2 RNA per swab, was measured after each swab. From day 1-5, the average viral load was 6.76x10^5 copies per swab, and after the fifth day, the average viral load was 3.44x10^5 copies per swab. Within 7 days of onset, infectious virus could be readily isolated (grown in culture) in swab and sputum samples, suggesting that the virus can replicate in upper respiratory tract tissues. The virus could not be isolated in any sample after 8 days of onset despite high viral loads. Despite symptoms declining for most patients after the first week, viral RNA could be detected in throat samples well into the second week, and sputum samples of most patients were positive for SARS-CoV-2 RNA into the 3rd and 4th week, despite full disappearance of symptoms. Seroconversion, or the development of antibodies to the virus, occurred on average after 7 days of the onset of symptoms. 
 
Conclusion: | Despite all patients displaying only mild symptoms of SARS-CoV-2, simple throat swabs were still sufficient to measure viral load, which is not the case for the SARS virus. Also, while it only took five days for SARS-CoV-2 to reach peak concentration of viral RNA, it took 7 days for the SARS virus, and even then its peak concentration was 1000 times less than that of SARS-CoV-2. Furthermore, while live virus isolation could be obtained from throat swab samples of COVID-19 patients, this was not possible for SARS patients, suggesting that SARS-CoV-2, unlike SARS-CoV, can replicate in the upper respiratory tract as well as the lungs. Authors also propose based on current findings that hospitalized patients can be discharged after 10 days of symptoms onset if viral load is less than 100,000 copies per mL, as there is little risk of infectivity at this point. It is also important to note that, even after the development of SARS-CoV-2 antibodies and the disappearance of symptoms, there is not a rapid decline in viral load. However, because of the inability to isolate infectious virus after 8 days, viral emission in sputum at this point is likely not as infectious as it is within the first 7 days. 
 
 
Note: Due to the nature of the format, this is presented as the original, unaltered letter article. |  
 
Background | Different viral agents are associated with an increased risk of more severe disease course and respiratory complications in immunocompromised patients. The recent outbreak of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) disease 2019 (COVID-19) responsible for a severe acute respiratory syndrome (SARS) represents a source of concern for the management of patients with inflammatory rheumatic diseases. Lombardy is the region in Northern Italy with the highest incidence of COVID-19 cases, with more than 33 000 confirmed patients and 1250 requiring admission to the intensive care unit within 1 month. Since the first reports of COVID-19 cases in Italy, we have circulated a survey with a 2-week follow-up contact to patients with chronic arthritis treated with biological disease-modifying antirheumatic drugs (bDMARDs) or targeted synthetic disease-modifying antirheumatic drugs (tsDMARDs) followed up at our biological outpatient clinic in Pavia, Lombardy. The survey investigated the patients’ health conditions, the presence of contacts with subjects known to be affected by COVID-19 and management of the DMARDs during the first few weeks of pandemic. All patients had provided their informed consent for the use of personal and clinical data for scientific purposes, and no patient refused to participate.Methods and ResultsDuring the first month, we have collected information on 320 patients (female 68, mean age 55±14 years) treated with bDMARDs or tsDMARDs (57 with rheumatoid arthritis, 43 with spondyloarthritis, 52 treated with tumour necrosis factor inhibitors, 40 with other bDMARDs and 8 with tsDMARDs). As shown intable 1, four were confirmed cases of COVID-19 identified through rhinopharyngeal swabs. Another four patients reported symptoms which were highly suggestive of COVID-19. Five additional patients with reported certain contacts remained asymptomatic at the end of the 2-week observation period.All patients with confirmed COVID-19 received at least one antibiotic course, and the hospitalised patient also received antiviral therapy and hydroxychloroquine. Overall, five patients were on previous stable treatment with hydroxychloroquine. All patients with symptoms of infection temporarily withdrew the bDMARD or tsDMARD at the time of symptom onset. To date, there have been no significant relapses of the rheumatic disease. None of the patients with a confirmed diagnosis of COVID-19 or with a highly suggestive clinical picture developed severe respiratory complications or died. Only one patient, aged 65, required admission to hospital and low-flow oxygen supplementation for a few days.ConclusionOur findings do not allow any conclusions on the incidence rate of SARS-CoV-2 infection in patients with rheumatic diseases, nor on the overall outcome of immunocompromised patients affected by COVID-19. A high level of vigilance and strict follow-up should be maintained on these patients, including the exclusion of superimposed infections. However, our preliminary experience shows that patients with chronic arthritis treated with bDMARDs or tsDMARDs do not seem to be at increased risk of respiratory or life-threatening complications from SARS-CoV-2 compared with the general population.These findings are not surprising as the severe respiratory complications caused by coronaviruses are thought to be driven by the aberrant inflammatory and cytokine response perpetuated by the host immune system.During different coronavirus outbreaks, such as SARS and Middle East respiratory syndrome, there has been no increased mortality reported in patients undergoing immunosuppression for organ transplantation, cancer or autoimmune diseases.Accordingly, among 700 patients admitted for severe COVID-19 at our hospital (a referral centre for SARS-CoV-2 infection) during last month, none was receiving bDMARDs or tsDMARDs.Although continuous surveillance of patients with rheumatic diseases receiving immunosuppressive drugs is warranted, these data can support rheumatologists for the management and counselling of their patients, avoiding the unjustifiable preventive withdrawal of DMARDs, which could lead to an increased risk of relapses and morbidity from the chronic rheumatological condition. 
 
 
Abstract | Goal is to assess the risk of Intensive Care Unit (ICU) admission for patients with diabetes and COVID-19. After analyzing existing datasets, we found that diabetic patients with COVID-19 are at higher risk of ICU admission, and are more likely to die. 
 
Introduction | It's well known that diabetes patients are at higher risk of infection from various diseases, including COVID-19. Recent investigations have found that diabetes mellitus (DM) is one of the most common comorbidities. Separate studies concluded that having diabetes makes it more likely you'll die of COVID-19 infection. This paper will review and analyze the data to determine the risk of Intensive Care Unit (ICU) admission and the risk of death for diabetes patients with COVID-19 infection. 
 
Study Design and Eligibility | For each study we extracted the number of patients, mean age, male gender, prevalence of diabetes mellitus, the number of diabetic subjects admitted or not to the ICU, as well as the number of diabetic survivors/deaths. We pulled this data from MEDLINE, Scopus, and Web of Science. We only used data in English.Out of 135 papers relevant to this topic, we pulled the data from 4 to determine if patients with diabetes are at higher risk of going to the ICU after contracting COVID-19. Another 4 were used to determine if patients with diabetes are at higher risk of dying with COVID-19. 
 
Results | Risk of ICU admission: Out of 1382 patients, patients with diabetes were 2.79 times more likely to be admitted to the ICU.Mortality risk: Out of 471 patients, patients with diabetes were 3.21 times more likely to die while having COVID-19. 
 
Discussion | This paper did not attempt to show that diabetes increases the risk of infection of COVID-19, but other papers are currently studying that. We were not able to examine different types of diabetes, or how they were treated in the ICU. Diabetic patients should be considered to be at higher risk of complications when they're infected with COVID-19. 
 
Limitations | 1. Very few studies separated patients by survivors and non-survivors as well as ICU vs non-ICU patients. It would strengthen the results to have more patient data.2. We didn't compare the outcomes of patients with diabetes based on different treatments. 
 
Conclusion | Our analysis suggests that diabetic patients with COVID-19 infection have an higher risk to be admitted to the ICU and show an higher mortality risk during the disease. 
 
 
Aims | The authors aim to analyze characteristics and outcomes of patients with COVID-19. They analyzed the New York City Area to further understand the outbreak in the United States. 
 
Introduction | The first COVID-19 outbreaks in the United States were in Washington State and California. Now, the United States has more infections than in Italy and China combined. New York City has the greatest population density, so New York has more than 30 of the cases in the United States. New York also has more cases than every single state as of April 20, 2020.	There is limited information about COVID-19. A study from China revealed the demographics and the comorbidities of COVID-19. But, the population demographics in China is very different from that in the United States. 
 
Methods | 	Patients studied came from those at the Northwell Health System. Northwell is the largest academic hospital system, with patients from Long Island, New York City, and Westchester County. A patient had an infection if the patient tested positive from the polymerase chain reaction test. Physicians tested patients using nasopharyngeal samples. Patients were retested if the quality of the sample was low. If there was a patient transfer within a system, this was counted as one visit. There were no patient transfers out of the system. Statistical analyses were done using R.	The researchers collected data in categories, including initial laboratory tests, demographic information, comorbidities, treatments, and outcome. The data for outcome include the length of hospital stay and if the patient was discharged alive. Patients self-reported race and ethnicity. Researchers used the Charlson Comorbidity Index in the analysis of comorbidity. The Charlson Comorbidity Index gives the percent chance of survival in the next 10 years given a certain comorbidity. 
 
Results | 	The study included 5,700 patients (Table 1). The median time for test results was 15.4 hours. The most common comorbidities were hypertension, obesity, and diabetes. The Charlson Comorbidity Index predicted a median of 53 survival for 10 years. The most common symptoms were fever and high respiratory rate (Table 2 and 3). Most patients (96.8) tested positive the first time. There were no mortalities of people under 20 years of age. Males had a higher mortality rate than females at every age interval.	2634 patients were discharged or died when the study ended. Of these patients, 14.2 percent were in the ICU, 12.2 percent received mechanical ventilation, 3.2 percent underwent kidney replacement therapy, and 21 percent died. For patients on mechanical ventilation, mortality rates were much higher than for patients that did not need mechanical ventilation. About 2.2 percent of patients were readmitted after a median of 3 days. Out of the patients with a final outcome, 436 patients were under 50 years old and had no comorbidities. Nine of these patients died.	A greater percentage of patients between 18 and 65 years old were in the ICU and required ventilation than those over 65 (Table 5). Older patients had lower lymphocyte counts and higher readmission rates. More patients with diabetes that have died were on ventilation and in the ICU than those without diabetes. A higher percentage of those without hypertension received ventilation and ICU care than those with hypertension. Diabetes patients were more likely to experience kidney damage.	For patients with outcomes, the researchers had prescription medicine data for 2411 (92 percent) of them. 7.8 percent of these 2411 patients were on angiotensin-converting enzyme inhibitor (ACEi), and 11.1 percent were on angiotensin II receptor blocker (ARB). These medications lower blood pressure. They are important to consider because they increase the transcription of cardiac angiotensin-converting enzyme 2 (ACE2). Thus, ACEi and ARB may affect COVID-19, since ACE2 is used by some coronaviruses to enter the cell. More studies need to be done.	Older people, men, and those with hypertension and/or diabetes were more prevalent in the United States population than the China population. But, there is a lower mortality rate in the United States. But, all outcomes are not known, and the data can change with time.	 
 
Limitations | 	This study only included patients in the New York City Area. Researchers stored data electronically rather than collecting in person. Also, only 46.2 of patients in this study had final outcomes because the reset are still hospitalized. Physicians followed up on patients in a median of 4.4 days, which is short. More time is needed to analyze the full course of the disease. 
 
 
Abstract | Men and women appear to have different susceptibilities to (COVID-19). The S protein found on the surface of coronaviruses allows the virus to attach to the target (host) cell. After the virus is attached to the host, it will signal for a protein that modifies the S protein and allows the coronavirus to enter the cell. With higher levels of androgens (testosterone), the gene that codes for this protein is expressed more. This could explain why men are more susceptible to COVID19. In order to test this, a study was performed on men already using certain androgenic (testosterone) reduction therapies. The two anti-adrenergic therapies were 5-Alpha reductase inhibitors (5ARIs) and androgen deprivation therapy (ADT). Both therapies contained patients of a higher age which correlates to a much higher chance of death. Therefore, it is difficult to infer specific conclusions from this study. However, the results of this study do suggest a protective effect of anti-adrengeric therapies for the male sex. A potential issue is that the sample size in this observational study may have been too low to be generalized to a larger population. 
 
Background | The Coronavirus disease 2019 (COVID19) pandemic has been slowly shifting westward since its initial discovery. Currently Italy has the highest rates of infection at 258 cases per 100,000 people. Italy also has the highest mortality rate at 12.7 vs the average value of 6.2 (as of April 13th 2020). Although men and women get infected in roughly equal amounts, there is a higher vulnerability to the disease in men than in women, regardless of age. Understanding the gender differences will both directly and indirectly help alleviate the strain COVID-19 outbreak has on the world.The (S) Spike protein on the outside of the coronavirus is what allows the virus to initially bind to the cell surface. The coronavirus uses a portion of the (S) protein known as S1 to bind to the cell surface receptor called angiotensin converting enzyme 2 or (ACE2). After the virus is bound to the receptor this stimulates an enzyme called a protease, which is a type of enzyme that will cut the protein in a specific site. This enzyme is a serine protease known as TMPRSS2. This enzyme will then cut a specific site between the S1/S2 protein units on the (S) spike protein. The cutting of the protein (S) makes S2 active and the virus can now enter the cell. Therefore, without the TMPRSS2 enzyme the virus lacks the ability to enter the cell and cause harm. It has been noted that the TMPRSS2 enzyme is sensitive to androgens (testosterone) and therefore this study explores anti-adrenergic therapies in relation to its effectiveness against SARS-CoV2. 
 
Methods | This study included patients who were referred to the researchers’ study centre from March 1st to 31st, 2020. In order to be considered the patients must be positive for SARS-CoV02 according to the WHO guidelines. Researchers were interested in patients undergoing some version of anti-adrenergic therapy. These patients of interest were those who received 5 alpha reductase inhibitors (5ARI’s) for the treatment of prostate diseases, patients who are currently under androgen deprivation therapy (ADT) for treatment of prostate cancer, or patients who failed ADT androgen deprivation therapy treatment for certain prostate cancer types. This study focused not on the severity of COVID19, but on the lethality of the virus in men who were under anti-adrenergic therapy vs men who were not under anti-adrenergic therapy. 
 
Results | Data from 421 patients positive for SARS-CoV2 were analyzed. Of those 421 patients 137 were women (32.54) and 284 were men (67.56). Overall, 84 of the 421 patients died. Of the 84 deceased patients 28 were women (33.33) and 56 were men (66.67). There was a significant difference in the mean age of living 61.41 yrs +/- 13.5 versus dead 75.08 +/- 10.4 patients. The overall lethality rate for male patients taking anti-androgen therapies was 27.78. The lethality rate of all male patients included in this study was 19.17. This result can be explained by the higher age of males on anti-androgen therapies (mean age 75.66yrs +-11.46). 
 
Discussion | Hospitals and Intensive care units (ICU) have a limited capacity. In order to most successfully prevent the spread of the pandemic, institutions must understand the probable patient outcomes of various patient populations. This study does suggest that anti-adrenergic therapies are helpful as a protective measure, but it should be noted that this study has numerous limitations. This study observed a highly specialized group of individuals within a short time frame. The sample size was small, and patients with other illnesses accompanying the COVID-19 infection were not accounted for in the data. Similarly, this study suggests a correlation between anti-adrenergic therapies and the level of TMPRSS2 expression but does not investigate it directly. This study also does not test for a correlation between severity of disease, but instead focuses on lethality rate. Further studies should be conducted to address these limitations. 
 
 
Background | The scientists aimed to describe the prevalence and characteristics of anosmia in patients with confirmed COVID-19, as it has been rarely described in medical literature. 
 
Methods | The scientists conducted a retrospective observational study in which they included COVID-19 patients with anosmia. They used SARS-CoV-2 real time PCR on respiratory samples to confirm the cases. The scientists called non-hospitalised and discharged patients seven days (± 7 days) after the first symptoms and every week until recovery to monitor clinical outcome. The scientists used usual descriptive statistics. 
 
Results | Fifty-four of 114 patients (47) with confirmed COVID-19 reported anosmia. Mean age of the 54 patients was 47 (± 16) years. Thirty-six (67) were females. Twenty of the patients (37)were hospitalised. Fifteen (28) patients with COVID-19 received a clinical diagnosis of pneumonia. Forty-six patients (85) had dysgeusia. Anosmia began 4.4 (± 1.9 [1–8]) days after infection onset and lasted 8.9 (± 6.3 [1–21]) days. Only one patient did not recover from anosmia after 28 days.Anosmia was the third symptom in 38 (22/52) of cases. In Figure 1 scientists show that the duration of anosmia was ≥ 7 days for 55and ≥ 14days for 20 of patients. 
 
Discussion | This study seems to be the main monocentric cohort of confirmed COVID-19 patients with anosmia in France and in the medical literature. The scientists had similar results to those published by the recent multicentric European study by Lechien et al.Anosmia was a frequent symptom in COVID-19 patients in both studies. The scientistsdiscussed the differences between Asia and Europe, as in Asia there are only a few descriptions of ENT symptoms available. Their assumptions includedthe theoretical possibility of a mutation of SARS-CoV-2 viral genome associated with a clinical impact, as well as, the difficulty to precisely report ENT symptoms of critical patients. The scientists considered that the limited number of patients was a limitation of the study.ConclusionThe scientists detected anosmia in half of their European COVID-19 patients. In more than 80 of cases anosmia was associated with dysgeusia. Most patients (98) recovered from anosmia after 28 days. 
 
 
Introduction | The severe acute respiratory syndrome coronavirus (SARS-CoV-2) is currently causing a pandemic. The 50 tissue-culture infectious dose [TCID50] is the concentration of the virus needed to kill 50 of its host cells. 
 
Methods | The authors used a Bayesian regression model to collect data on the decay rates of the SARS viruses. They defined aerosols as particles less than 5 µm in size. They created aerosols using a three-jet Collison nebulizer and a Goldberg drum. The environment created is similar to that in the human respiratory tracts. 
 
Results | In aerosols, SARS-CoV-2 remained viable for 3 hours. The TCID50 dropped from 10^3.5 to 10^2.7 per liter of air. SARS-CoV-1 also had similar levels in aerosols. SARS-CoV-2 remained stable on plastic and stainless steel for 72 hours. SARS-CoV-1 had similar stability. But on copper, SARS-CoV-2 was viable for only 4 hours, and SARS-CoV-1 was viable for only 8 hours. On cardboard, SARS-CoV-2 was not viable after 24 hours, and SARS-CoV-1 was not viable after 8 hours (Figure 1A).SARS-CoV-2 and SARS-CoV-1 decay in an exponential pattern. The half-lives of both viruses were a median of 1.1 to 1.2 hours in aerosols. On copper, the viruses had similar values. On cardboard, SARS-CoV-2 had a larger half-life than SARS-CoV-1. On stainless steel and plastic, both viruses had the longest half-lives compared to other environments. The half-life for SARS-CoV-2 on plastic and stainless steel is about 5.6 hours and 6.8 hours, respectively. 
 
Discussion | SARS-CoV-2 is similar to SARS-CoV-1 in terms of stability. Thus, the difference between SARS-CoV-2 and SARS-CoV-1 is likely due to other factors. Such factors include the high concentration of SARS-CoV-2 in the upper respiratory tract and the possibility of asymptomatic transmission. The results indicate that it is possible to transmit SARS-CoV-2 through aerosols or surfaces. This is because SARS-CoV-2 can remain viable in the air or on surfaces for many hours or days. 
Abstract: Respiratory infections such as Coronavirus Disease 2019 (COVID-19) can spread through droplets, airborne particles, and aerosols from speaking, sneezing, or coughing. The spread of the virus can come from presymptomatic, asymptomatic, or symptomatic individuals.The CDC has recommended home-made cloth face coverings for the general public.N95 respirators are the gold standard. Currently they are in short supply and should be reserved for the medical professionals. There is little research exploring the effectiveness of various mask materials. This study assesses the performance of ten different fabrics.  The mask should as breathable without hurting the performance. Most single layer masks were found to block a considerable amount of droplets. When the mask is a two layer system it reaches the efficiency of a surgical mask while being easily breathable. Finally, it has been observed that home fabrics are hydrophilic. Meaning they readily soak of water. Whereas, medical masks are hydrophobic and tend to repel water. Homemade masks are hydrophilic. Meaning they tend to absorb incoming droplets. This could be a understudied advantage of homemade cloth masks.  
 
Introduction:  |Behind every pandemic is a disease causing agent that spreads globally. Current avenues for SARS-Cov2 are not entirely understood. Based upon knowledge from past infectious agents there appear to be three major routes of transmission. Large droplets can fall to surfaces due to gravity and can be a route for contact spread. Smaller droplets can travel in the air longer, and droplets inhaled directly into the lungs can easily enter the body. WIth various routes of infection the CDC recommends that the general public wear homemade cloth face masks. Existing research on home-made masks focuses on filtration efficacy against particles less than 1 micrometer in size. This is not helpful for SARS-Cov2 because the virus is several times smaller than that. A fabric with high breathability may have low blocking efficiency and vice versa. The ideal fabric would maximize breathability and blocking efficiency.. Therefore this study evaluates 10 different regular household fabrics: 100 cotton, 100 polyester, several ratios of cotton to polyester, used dishcloth, silk, and a 3 layered medical mask fabric.  
 
Methods:  |	Five different qualities of the fabrics were analyzed:(1) Droplet blocking efficiency, (2) breathability, (3) weight, (4) hydrophilicity, (5) microscopic texture. To measure droplet blocking efficiency the researchers loaded a metered-dose inhaler with 100nanometer-diameter fluorescent beads to mimic the virus. The fabrics were placed over a petri dish by attaching the fabric cut-outs to the rim of the petri dish with double sided tape. The number of fluorescent beads captured vs the total number showed thedroplet blocking efficiency of the fabric.  Breathability was measured by observing the air flow rate and pressure created by a specified air flow rate. Special equipment was used throughout this experiment to test all parameters, but the researchers offer a simple home breathability test and droplet soaking test that offer a qualitative measurement of a fabrics breathability.     
 
Results: |A Medical surgical mask provided a baseline blocking efficiency of 96.3 with a breathability of 2.5 mm/Pa*s. The fabric that offers the worst protection is a used T-shirt made from 75 cotton and 25 polyester. This fabric offers a blocking efficiency of 42.6, with the highest breathability of 15.3 mm/Pa*s. Whereas, the fabric that offers the best blocking efficiency was a 3 layered New T-shirt made from 60 cotton and 40 polyester. This fabric offered a blocking efficiency of 99.98 and a breathability of 3.1 mm/Pa*s. The three layered T-shirt design offered a breathability and blocking efficiency higher than that of a standard surgical mask.  
 
Discussion: |Breathability and particle blocking efficiency are important, but a balance must be made between these two parameters. If the mask is too breathable then blocking efficiency suffers heavily. If the mask is too restrictive then airflow will have to come from between the mask and the face of the person wearing it. This offers no true protection and the mask offers nothing more than a false feeling of protection. However, if the mask uses proper fabric like a 2 layer shirt mask, there will be a 98 blocking efficiency for low velocity droplets received from an infected individual. Therefore homemade 2 layer T-shirt masks may help prevent the spread of droplets from those infected to a healthy individual. The hydrophilicity of homemade masks does not discount them as effective and should be further researched as a potential benefit of understudied advantage. Therefore, the researchers of this study conclude that during pandemics, a home-made mask can be effective against transmission of infection through low-speed droplets. However, proper mask usage and education are as effective in accordance with social distancing rules and other preventive measures.         
 
 
Abstract |This study was done to see if a disposable N95 mask can be sanitized and reused. Being able to reuse N95 masks would help with the shortage of masks for healthcare workers. Vaporized hydrogen peroxide, ultraviolet light, and ethanol were all tested as decontaminants. The best decontaminant was determined by how well the masks were decontaminated and how well the physical material of the masks held up, known as integrity.  
 
Introduction |As we know, the SARS-CoV-2 has become a global pandemic. This has caused a high demand in hospitals for personal protective equipment. Due to how SARS-CoV-2 spreads, the N95 mask is a very effective piece of protective equipment. N95 masks are often used when the healthcare worker is trying to protect themselves from a respiratory disease. The N95 mask is supposed to be a one time use mask. But, in these desperate times many healthcare workers have to reuse their masks if they want to stay protected. Some healthcare workers are sanitizing the masks with whatever decontaminant they can find. However, the effect of these household decontaminants on the mask's structural integrity have not been tested on the N95. There have been previous studies done on how vaporized hydrogen peroxide, ultraviolet light, and ethanol affect the function of the N95 mask. However, the decontaminants have not been tested on how well they kill the SARS-CoV-2 if it is on the N95 mask. In this study, they test how well the decontaminants will kill SARS-CoV-2 present on the masks and if it affects the mask's ability to function.  
 
Results | IntegrityFirst, they tested the integrity of the mask after the treatment with vaporized hydrogen peroxide, ultraviolet light, and 70 ethanol. This test used a respirator to measure the air particles inside and outside of the mask. A FIT score was calculated based on the ratio of particles inside to particles outside. A FIT score of over 100 means the mask is safe to use in a hospital setting. The FIT score of a new, untreated N95 mask is about 200, so it is well beyond the minimum requirement of 100. The ethanol and ultraviolet treatments lowered the FIT scores, but still averaged over 100. The vaporized hydrogen peroxide maintained a high FIT score without altering the function of the N95 mask.DecontaminationSecond, the vaporized hydrogen peroxide, ultraviolet light, and ethanol were tested to see how well they would decontaminate the mask from SARS-CoV-2. Nose swabs from SARS-CoV-2 positive patients were collected and applied to N95 masks. Then, the masks were decontaminated using the three methods. After decontamination, the masks were dipped in a liquid solution of cell culture media. Dipping the masks allowed any of the viral RNA to be transferred into the cell culture media. The media containing viral RNA can now be tested to see if the decontamination worked. The viral RNA was found in every mask that SARS-CoV-2 nasal swabs were applied to. Just because RNA was found, doesn’t mean the virus is alive and infectious. To test if the RNA was still infectious, a cell culture was treated with the RNA positive media of each sample. These cells were grown for four days in an incubator. Then, the level of RNA was tested again. There were lower levels of RNA in the vaporized hydrogen peroxide and ultraviolet light samples compared to the samples which did not go through decontamination. In the samples that had been treated with ethanol, zero RNA was detected. 
 
Discussion | Three factors are necessary for a mask to be considered safe for decontamination and reuse. The decontaminant must be safe for human use, successfully kill the virus, and maintain the function of the mask. Ethanol had the worst integrity of the mask after treatment, but was very effective against the viral RNA test. With the ethanol treatment, the decrease in function of the mask was time dependent. So, 30 minutes after treatment with ethanol, the mask was less functional than 4 hours after treatment. Throughout the entire time span, the average FIT test was still over 100. Overall, all decontamination strategies did lower the amount of viral RNA present. Though this study is consistent with prior research, there are some clear limitations that should be noted. First, the viral RNA test was only done once because of lack of time, risk of exposure to SARS-CoV-2, and lack of resources. Another limitation is that there are several types of N95 masks, and this study only tested N95 types 1860 and 1870+(healthcare grade), and 8511(non health care grade). The different mask types had slightly different outcomes and this may be due to the fluid resistant coating on the healthcare grade masks. This study did not test the effect of the decontaminants on the fluid resistant coating specifically. Due to the way the FIT test measures mask fitness, it also may have given a false low fitness of the treated masks. The viral RNA test may not also be accurate compared to a real healthcare setting. This is because 100microliters of the SARS-CoV-2 positive nasal swab solution was applied directly to the mask. This is a large volume compared to a couple of droplets landing on the mask after a patient coughed. So in actual practice, vaporized hydrogen peroxide and ultraviolet light would most likely be very effective in decontamination.The study confirms that the decontamination of the N95 mask does reduce the function of the mask. This is not normally recommended for N95 use, but these are unprecedented times. If there was a mask shortage, this study can help guide healthcare providers to safely consider mask decontamination. 
 
 
Abstract: | Respiratory infections such as Coronavirus Disease 2019 (COVID-19) can spread through droplets, airborne particles, and aerosols from speaking, sneezing, or coughing. The spread of the virus can come from presymptomatic, asymptomatic, or symptomatic individuals. Due to its high infectivity the CDC has recommended home-made cloth face coverings for the general public. N95 respirators are the gold standard however they are in short supply and therefore reserved for the medical professionals who need them the most. Despite the CDC’s recommendation there is little research exploring the effectiveness of various mask materials. This study assesses the performance of ten different fabrics. The breathability and ability to soak water were also tested as a mask should as breathable without hurting the performance. Most single layer masks were found to block a considerable amount of droplets. When the mask is a two layer system it reaches the efficiency of a surgical mask while being easily breathable. Finally, it has been observed that home fabrics are hydrophilic and therefore readily soak of water. Whereas, medical masks are hydrophobic and tend to repel water. Since, homemade masks are hydrophilic they tend to absorb incoming droplets which could be a yet understudied advantage of homemade cloth masks. 
 
Introduction: | Behind every pandemic is a disease causing agent that spreads globally. Current avenues for SARS-Cov2 are not entirely understood. Based upon knowledge from past infectious agents there appear to be three major routes of transmission. Large droplets can fall to surfaces due to gravity and can be a route for contact spread. Smaller droplets can travel in the air longer, and droplets inhaled directly into the lungs can easily enter the body. WIth various routes of infection the CDC recommends that the general public wear homemade cloth face masks. Existing research on home-made masks focuses on filtration efficacy against particles less than 1 micrometer in size. This is not helpful for SARS-Cov2 because the virus is several times smaller than that. A fabric with high breathability may have low blocking efficiency and vice versa. The ideal fabric would maximize breathability and blocking efficiency.. Therefore this study evaluates 10 different regular household fabrics: 100 cotton, 100 polyester, several ratios of cotton to polyester, used dishcloth, silk, and a 3 layered medical mask fabric. 
 
Methods: | 	Five different qualities of the fabrics were analyzed:(1) Droplet blocking efficiency, (2) breathability, (3) weight, (4) hydrophilicity, (5) microscopic texture. To measure droplet blocking efficiency the researchers loaded a metered-dose inhaler with 100nanometer-diameter fluorescent beads to mimic the virus. The fabrics were placed over a petri dish by attaching the fabric cut-outs to the rim of the petri dish with double sided tape. The number of fluorescent beads captured vs the total number showed the droplet blocking efficiency of the fabric. Breathability was measured by observing the air flow rate and pressure created by a specified air flow rate. Special equipment was used throughout this experiment to test all parameters, but the researchers offer a simple home breathability test and droplet soaking test that offer a qualitative measurement of a fabrics breathability 
 
Results: | A Medical surgical mask provided a baseline blocking efficiency of 96.3 with a breathability of 2.5 mm/Pa*s. The fabric that offers the worst protection is a used T-shirt made from 75 cotton and 25 polyester. This fabric offers a blocking efficiency of 42.6, with the highest breathability of 15.3 mm/Pa*s. Whereas, the fabric that offers the best blocking efficiency was a 3 layered New T-shirt made from 60 cotton and 40 polyester. This fabric offered a blocking efficiency of 99.98 and a breathability of 3.1 mm/Pa*s. The three layered T-shirt design offered a breathability and blocking efficiency higher than that of a standard surgical mask. 
 
Discussion: | Breathability and particle blocking efficiency are important, but a balance must be made between these two parameters. If the mask is too breathable then blocking efficiency suffers heavily. If the mask is too restrictive then airflow will have to come from between the mask and the face of the person wearing it. This offers no true protection and the mask offers nothing more than a false feeling of protection. However, if the mask uses proper fabric like a 2 layer shirt mask, there will be a 98 blocking efficiency for low velocity droplets received from an infected individual. Therefore homemade 2 layer T-shirt masks may help prevent the spread of droplets from those infected to a healthy individual. The hydrophilicity of homemade masks does not discount them as effective and should be further researched as a potential benefit of understudied advantage. Therefore, the researchers of this study conclude that during pandemics, a home-made mask can be effective against transmission of infection through low-speed droplets. However, proper mask usage and education are just as effective in accordance with social distancing rules and other preventive measures.  
AbstractIn this study, the IgM and IgG antibodies associated with SARS-CoV-2 are analyzed from 221 COVID19 positive patients. These antibodies can give insight on the diagnosis, cause of the virus, and course of the virus. The concentration of the IgM antibodies was highest between day 16 and 18 after the first day of symptoms. IgG antibodies peaked between days 19 and 21. The IgG concentration was much higher in severe cases compared to other cases of COVID19. Just over 50 of patients who discharged tested positive for SARS-CoV-2 RNA after a nasal swab. The patients who tested positive for the RNA had lower levels of IgG than patients who tested negative for RNA. Two weeks after discharge, IgG and IgM levels still decreased for both RNA positive and negative patients. This study concludes that the antibody concentration does not affect the course or the outcome of the virus. Immunity to the virus by the presence of the IgG antibody is still unclear and needs further investigation.   IntroductionSARS-CoV-2 is one of seven coronaviruses that can infect humans. Out of the coronaviruses, SARS-CoV-2 causes more severe symptoms. When a patient is infected with SARS-CoV-2, the immune response is activated. The specific immune response produces IgM and IgG antibodies. IgM antibodies develop the fastest and tells us there is current infection. IgG antibodies are the most common antibodies of the immune response. IgG antibodies also develop the slowest. The presence of IgG can show that a patient has recovered. Testing for both IgM and IgG can tell physicians if you have COVID19 and how long you have had it. IgM testing is already used as diagnosis criteria in China. But, the ability of IgG levels to show if we have long term immunity has not been confirmed. Some patietns test positive for viral RNA after they are discharged and feeling better. The relationship of IgM and IgG antibodies to these patients is also unknown.Methods211 confirmed COVID-19 patients in China were included in this study, with a range of mild and severe cases. IgG and IgM antibody testing was done every three days after the onset of symptoms. Antibodies were analyzed for concentration differences between mild and severe patients. Some patients were positive or negative for IgG or IgM upon admission to the hospital. Throughout Days 16-21 age, other chronic diseases, fever, white blood cell count, pulmonary inflammation index and other various factors were all looked at in association to the presence or absence of IgG and IgM antibodies. Patients were discharged after meeting the criteria of the Guidelines for the Diagnosis and Treatment of Novel Coronavirus Infection by the National Health Commission. The antibodies were detected by using fluorescence and luminescence techniques. Using this analysis, a value of less than 1 is considered negative for the antibody.ResultsPatients who were older, had diabetes, cardiovascular diseases, or chronic obstructive pulmonary disease were more likely to have a more critical illness. The concentrations of IgG and IgM peaked from 19-21 days after symptom onset. After the peak, IgM decreased slowly while IgG stayed high. The IgM levels were the same between mild and severe COVID-19 cases, but the IgG levels were much higher in those with severe cases. A higher pulmonary inflammation index was found with patients who tested negative for IgM. For people who tested positive for IgG and IgM from 16 to 21 days after symptom onset, the antibody levels were not associated with length of hospital stay, duration of positive virus detection, duration of fever, changes in the pulmonary inflammation index, or outcome of the virus. Of the 74 patients who were discharged during the study, 52.7 of them tested positive for SARS-CoV-2 RNA. The positive RNA patients had lower IgG concentrations after discharge, but very little change in IgM after 7 days. The entire group of discharged patients experienced a drop in the level of IgG, IgM, any white blood cells after 14 days post discharge.   DiscussionDespite the findings of this study, there were two patients who did not develop IgM or IgG antibodies throughout the virus. So, the antibody testing is a good indicator of the course and onset of the virus, but should not be used to rule out SARS-CoV-2. RT-PCR is another diagnosis test that should be used if the patient is negative for the IgG or IgM antibodies. Since a decrease in IgG after discharge was seen, we cannot be sure that IgG antibodies give us long term immunity against SARS-CoV-2. More research should study if IgG can give us long term immunity. This study could be helpful in developing a vaccine because it has shown the timeline of IgG and IgM levels throughout the virus. The higher pulmonary inflammation index in patients who were negative for IgM shows that people with a slower immune response have more severe respiratory symptoms. Still, this supports that the best available current treatment is still human immune activity. Other studies have found that IgG against the spike protein of COVID-19 is associated with lung inflammation and injury. So, the possible protective effect of IgG antibodies and lung damage needs to be investigated. Some studies have suggestedtreating critical COVID-19 patients with serum of recovering COVID-19 patients, but this also needs more investigation since there have been mixed findings about the harmful organ damage and protective effects of IgG antibodies in patients with SARS-CoV-2.      
﻿AbstractThis study examines how average temperature (AT) and average relative humidity (ART) relates to COVID-19 cases. This study considers 30 Chinese provinces. There was a strong relation between AT, ART and COVID-19. The correlation was negative. This means that higher AT and ART related to lower COVID-19 cases.When ARH was 67-85.5, every 1 °C increase in the AT led to a decrease in the daily confirmed cases by 36-57. When AT was5.04-8.2 °C, every 1 increase in ARH led to a decrease in the daily confirmed cases by 11-22. These associations were not consistent throughout China.IntroductionIn December 2019 there was an outbreak of COVID-19 in China. Typical symptoms included fever, dry cough and pneumonia. The disease could progress and cause death. As of 23 March 2020, there were 81603 confirmed cases. There were also 3276 deaths.The disease can spread from cough and sneeze droplets. This means that the environment can affect the spread. This is because humidity and temperature can affect the survival of the virus.There is no prior investigation on the effect of the weather on COVID-19. Theresearchers used data from all Chinese provinces to investigate this. Theresearchers aim to observe the link between climate factors and COVID-19.Materials and MethodsStudy Area and DataThe researcherslooked at daily counts of confirmed cases in all Chinese provinces. Theyused data from theNational Health Commission of People's Republic of China. The definition of a confirmed case has been published online. The researchers did not include Tibet as there was only 1 case.The climate data was taken from "Weather Underground". The researchers investigated "health seeking behaviour" by looking at internet data from "Baidu".Statistical analysisCOVID-19 had a 14-day incubation period. The researchers factored this into their calculations to make a moving average. This was compared to AT and ARH.Sensitivity AnalysisThe researchers performed a sensitivity analysis to verify the results.Results33453 cases occurred in Hubei. This accounts for 74.7 of confirmed cases. The average AT was -16.96 to 19.3°C. The average ARH was 17.93 to 86.20. The number of cases in Hubei increased sharply after 20 Jan 2020. The temperature was usually around 6 °C. The humidity was usually above 70. For other provinces over 88 of cases occurred between 23 Jan and 8 Feb 2020. ARH and AT varied by province.There was a significant interaction between AT and ARH. The Baidu index (health seeking behaviour) was also significant. The provinces of Zhejiang, Shandong, Hebei, Jilin, and Gansu, showed significant interaction between AT and ARH.AT showed an association with COVID-19 cases. Higher AT had lower number of cases. There was a similar relationship with ARH and COVID-19 cases. Higher ARH had lower number of cases.When ARH was 67-85.5, every 1 °C increase in the AT led to a decrease in the daily confirmed cases by 36-57. When AT was5.04-8.2 °C, every 1 increase in ARH led to a decrease in the daily confirmed cases by 11-22.DiscussionThis study shows that AT and ARH influence COVID-19 cases in Hubei and some other provinces. The association was not consistent.The study period was longer for Hubei. This means that the results are more stable. The data from Hubei was from before travel restriction were implemented. This means that Hubei most likely demonstrates the real effect of AT and ARH on COVID-19 cases. This showed that increased AT and ART led to fewer cases.Other coronaviruses seem to follow similar patterns. One study said that the risk of SARS was 18 times higher on a cold day compared to a warm day. SARS and MERS are more stable in cold and dry conditions. Low temperature and humidity allows more particles to be in the air. This is ideal for virus spread.This study found that low temperature and humidly can also lead to more COVID-19 cases. The exact mechanism of this is unclear. One possibility is that it causes human mucus membranes to dry and rupture.When estimating COVID-19 risk, climate factors should be considered. In spring there may be fewer cases of COVID-19 in China due to higher AT. Northern regions should be careful asAT and ARHremain low. The study does have limitations. The researchers could not identify Potential COVID-19 risk factors like socio-economic status.The imposed travel restrictions could affect the correlation found in other provinces. The climate applies only to the capital of each province. Provinces other than Hubei had a short study period with many imported cases.In conclusion, climate factors affect COVID-19 spread. This is likely related to AT and ARH. The inconsistencies between provinces need to be studied further. 
*Letter to the editor*﻿There are many studies on the COVID-19 outbreak. Lan et. al reported a positive test on discharged patients. The author is reporting data on discharged patients who tested positive for the disease inGuangzhou City, China.The data is from the "Guangzhou Center for Disease Control and Prevention". The data included when the patient had symptoms, diagnosis date, discharge date, date when they tested positive. Discharged patients had the following criteria: a) normal temperature after 3 days, b) no symptoms, c) better results on CT scans, d) 2 negative "nucleic acid tests" taken 1 day apart.161 discharged patients were re-tested. 22 patients were positive for the disease. The time between discharge and positive re-test shows that doctors discharged them too soon. The current 14-day observation needs to be extended.Before discharge, hospitals tested patients by throat and anal swabs. After discharge, doctors used nasal swabs which led to more positive cases. The 22 positive retests means that institutions should increase discharge standards. The authors tested 3 discharged patients with nasal swabs. All 3 patients retested positive.The authors note that there were two family clusters retested.Zou LR et al. noticed there were more viral loads in the nose than the throat. We should use nasal swabs to reduced false-negatives. One patient gave multiple types of samples but only 1 tested positive. The authors suggest testing different parts of the body for COVID-19. There were 8 patients testing positive only on the fourth test. This means there is a high rate of false-negatives. We do not know the duration of the disease. Our current knowledge on its characteristics are insufficient. We need to collect more information. 
 
 
Abstract  |  Angiotensin Converting Enzyme (ACE2) is a known binding site for Coronavirus 2019 (COVID-19). Angiotensin Converting Enzyme Inhibitors (ACEIs) and Angiotensin Receptor Blockers (ARBs) work to decrease the ability of (ACE2) to function properly. It is hypothesized by researchers that the blockage of (ACE2) will lead the body to increase expression of the gene to produce more (ACE2). This could potentially bring about an overall increase in the potential binding sites available for COVID-19. This study reviews (ACE2) expression in animal and human subjects using direct and indirect methods of protein analysis. The animal models provide no conclusive data and the human data heavily implies that administration of ACEIs/ARBs do not increase ACE2 protein expression. Based upon past evidence and the findings of this study the researchers conclude that ACEIs and ARBs offer no additional risk of complications from COVID-19 infection.  
 
Introduction and Methods |The data regarding ACE2 expression in the presence of inhibitors is largely mixed. Data from animal models was nonspecific and there was limited human data. This study reviews literature studying the expression of ACE2 with inhibitors in order to acquire a more complete understanding of the data available. The researchers searched Google scholars and Pubmed for all available literature. No restrictions were imposed on the search for literature and all data acquired was manually curated to affirm validity.  
 
Results  | The animal model studies did not provide consistent evidence for any conclusion. Several studies showed an increase in ACE2 expression while others showed none. The results were generally unreliable and showed no real trend. The lack of consistency could be due to a lack of proper analysis to ascertain a proper therapeutic dose. Therefore, the researchers did not know the best dose for any particular animal model. These values were adjusted to be used in a 60kg human, which resulted in a dose that is higher than what is considered safe for human use. Because the animal studies fail to have a recommended dose they have little to no meaning when their data is applied to a human model. The human model studies had mixed results like the animal model. However, when looking at the bulk of the data available from these studies it strongly implies that there is no association between ACE2 expression levels in a human body and the use of ARBs or ACEIs.  
 
Discussion | In order for the hypothesis to be supported, several experimental findings would need to be observed. 1) ACE2 expression would need to be observed to increase in animal models. This claim is largely unsupported by the data in this study. 2) Tissues with low expression of ACE2 would have an increase in expression in the presence of ARBs/ACEIs. There is no available evidence supporting this claim either. 3) An increase in ACE2 via ARBs/ACEIs leads to increased COVID-19 cell infection. SARS-CoV-2 has an incredibly high affinity for ACE2. However, ACE2 expression decreases with age yet the elderly tend to have more severe symptoms. It is largely unclear weather changes in ACE2 could lead to increased infection. 4) Human studies would need to find a significant difference in expression in reference to ARBs/ACEIs versus if there were none present. There are studies that support this claim, however no data from these studies is statistically significant and is modest support at best. 5) Data showing patients with COVID-19 that take ARBs/ACEIs have higher morbidity and mortality rates that are dose dependent. Studies actually show the opposite effect on morbidity and mortality. Patients taking ARBs/ACEIs actually have a lower morbidity rate and mortality which contradicts the hypothesis. Therefore, based upon the data found the researchers concluded that patients should continue their use of ARBs/ACEIs as recommended by health associations and other publications.    
 
 
Abstract | 	In cell samples grown in a laboratory setting, the antiparasitic medication ivermectin has shown to be effective against SARS-CoV-2. This has peaked interest because it could possiblytreat COVID-19. This study looks at the feasibility of ivermectin as a treatment for COVID-19. The dose needed to be effective against COVID-19 is likely too high for humans to use safely. 
 
Introduction | 	As the COVID-19 pandemic continues, several possible drugs are being explored as a treatment option. Due to public uncertainty and political pressure, some drugs have been highly mentioned in the media even though they have not been properly tested for human use or its effectiveness against COVID-19. The media has also failed tomention possible side effects or explore the feasibility for obtaining the medication in a large scale. Many medication suggestions are based on preliminary research. These medication publications often have not shown any sign of being safe and effective for treating humans with COVID-19. In the case of ivermectin, a study was done where a SARS-CoV-2 infected cell sample was constantly exposed to the drug at different concentrations. At a high concentration of 5 micromoles/liter, the virus was totally eradicated over time. Though this is a clear result, ivermectin has gotten anenormous amount of media coverage without any research about the feasibility of this in humans.     
 
Materials and Methods | Published dose recommendations and the side effects that arose after high dosing were examined. These values were compared to the necessary concentration to be effective against the virus in preliminary studies of ivermectin and COVID-19.     
 
Results  | When ivermectin is used to treat parasitic diseases, the doses range from 150 micrograms/kilogram (ug/kg) to 400 ug/kg per year. The drug works by paralyzing and killing the parasites through a special binding site that only invertebrates have, so mammals will not have many side effects if the correct dose is given. It has been found that humans do not have adverse side effects up to an 800 ug/kg dose over a year. The largest dose predicted to be healthy for a human is 2000ug/kg. The 5 micromol/Liter dose seen in the preliminary ivermectin study discussed earlier is converted into the dose a human would need to take to be effective against COVID-19, the human would need to take over 50 times more than 700ug/kg. Moreover, a single dose of ivermectin is prescribed per year to patients with parasitic diseases. In the preliminary study exploring ivermectin, the human would have to be constantly exposed to ivermectin for it to be effective against COVID-19. Even with excessive dosing of the drug, humans cannot metabolize the concentration needed to see an effect of the drug on COVID-19.     
 
Discussion |  Hydroxychloroquine is a common antimalarial drug that has a more appropriate dosing to treat COVID-19 in humans. Remdesivir is an antiviral drug that also has a realistic treatment dosage for humans and has shown to be effective against SARS-CoV-2. Ivermectin would need an unrealistic dose to treat humans. A dose so high has never been attempted in humans, and it is thought that the drug could get through the blood brian barrier, causing lethal neurological side effects. The use of a drug after minimal preliminary research is not scientifically or ethically appropriate. Due to some tragic events that have already occurred after the misuse of proposed COVID-19 treatments, it should be strongly encouraged to avoid self medication of ivermectin or any other drug which has not been FDA approved for COVID-19 related illnesses.     
 
 
﻿Abstract | It is essential to find a vaccine for COVID-19. COVID-19 is a potentially lethal coronavirus like SARS and MERS. As of April 2020 there is no available vaccine. Knowledge from SARS and MERS can be used for developing COVID-19 vaccines. This study investigates how research from similar coronaviruses can be applied to COVID-19. 
 
Introduction | Coronaviruses are viruses that belong to the family Coronaviridae. They have a single RNA strand. Their genome size is relatively large.Coronaviruses infect mammals and birds. It can cause symptoms such as lung disease and diarrhoea. In humans, it can be fatal.In 2002-2003 SARS emerged in southern China. It had 8096 cases and 774 deaths. The scientific community was unable to develop an accessible vaccine for it. SARS cases stopped being reported from 2004.In 2012 MERS emerged in Saudi Arabia. It had 2494 cases with 858 deaths. MERS cases are still reported however, there has not been a major outbreak since 2015. There is no accessible vaccine for MERS.There are varying reasons for the lack of commercial vaccines. MERS likely has no vaccines because of costs for effective animals models. Additionally, MERS is not spread globally. Thus, diseases like HIV and tuberculosis are likelier to be investigated. Similarly, SARS has not been reported since 2004.COVID-19 was first reported in Wuhan, China in December 2019. According to the World Health Organisation there are 1,669,595 cases worldwide. COVID-19 has also killed 106,138 people. COVID-19 has mild symptoms but may becomes severe in those with other conditions.Vaccine efforts for SARS and MERS could be useful towards COVID-19. This study focusses on active immunity as it works long-term. This study is based on previous research alone. 
 
Vaccine for SARS Virus | After SARS, several labs started to develop vaccines. Most of these vaccines target a specific protein in the virus. These proteins allow the virus to enter a human cell. Therefore, a vaccine targetting this protein will prevent the virus from entering human cells.Different types of vaccines were studies. Inactivated vaccines use the entire virus in a weakened state as the vaccine. These viruses are designed to not replicate or be less infectious.The researchers believe that only inactivated-virus vaccines reached the clinical stage. To know if a vaccine is effective, vaccinated people and animals are exposed to the disease. Since SARS was dangerous, there were no human studies. Thus, we don't know how effective these vaccines are. 
 
Vaccines for MERS | There are many vaccines under development for MERS. Most target the same protein as in SARS. Various types of vaccines have been tested in animal models. The researchers believe that only DNA-based vaccines reached clinical trials. 
 
Vaccines for COVID-19 | The disease emerged recently. This means that no clinical stage has been completed. The World Health Organization says that 41 vaccines are under development. There is not much information regarding these vaccines. By March 13, 2020, there was only one vaccine in clinical trials. 
 
Toward Protective Vaccines for Clinically Relevant Coronavirus Strains | Vaccine development effort for SARS and MERS should help towards COVID-19. This section describes important information this experiments obtained.Animal ModelsA lack of suitable animal models slowed down, vaccine development for SARS and MERS. This is because the virus could not severely infect animals. This meant that it was not possible to determine the effectiveness of vaccines.There were 2 main solutions for this. 1. Transgenic animals. These animals have human cells in them which are susceptible to the virus. 2. A mouse-adapted coronavirus modelled the illness similarly to humans. Transgenic mouse models for SARS and MERS are now available.Non-human primates also did not develop similar symptoms as humans. However, in some species there are limited symptoms. This has allowed analysis of the viability of vaccines.Correlates of ProtectionFew studies have discussed the potential of long-term protection using a vaccination regime.Natural Infection of Coronavirus StrainsExposure to SARS and MERS can show possible mechanisms of protection. In humans a fast immune response was related to disease severity and recovery time. This shows that an immune response needs to be triggered to recover from the disease.It would be ideal for a vaccine to give long term protection. Debates are ongoing whether this can be achieved by vaccination or exposure to the disease. However, certain relevant cells have been detected up to 24 months after infection.SafetyStudies about the safety of SARS and MERS vaccines are rare. In SARS vaccines, some adverse effects have been seen in animals.Some SARS vaccinated animals were not protected from MERS and vice-versa.Areas of Opportunity in Vaccine DevelopmentExperiments comparing different vaccine types are rare. Some studies found equal or varying degree of protection in mice and primates with different vaccine types. It is difficult to determine what vaccine type would be more or less protective.Some types of coronavirus have never been tested clinically. There are also new technologies for new types of vaccines (mRNA-based). The emergence of new vaccine types means that their effectiveness against coronavirus is unknown. 
 
Conclusions | Vaccine development efforts for SARS and MERS can help COVID-19. An effective vaccine should consider possible adverse effects. Vaccine development efforts should consider the possibility of short term ability to generate an immune response seen in SARS and MERS after an infection.Evidence that short term ability to generate and immune response in COVID-19 patients does not mean that an effective vaccine is impossible. This is seen in vaccines for viruses that don't have naturally acquired immunity (eg.smallpox). 
Cardiovascular problems are a threat in COVID-19. The disproportionate effect of COVID-19 on patients with other cardiovascular issues are not fully understood.COVID-19 infects using the "ACE2" receptor. This receptor if found in many organs including lung, heart and kidney. ACE2 receptors are also seen in endothelial cells. Endothelial cells line the inner surface of blood vessels. The authors demonstrate how these cells are involved in different organs of COVID-19 patients.Patient 1 was a male kidney transplant recipient. He was aged 71 years, with coronary artery disease and high blood pressure. The patient's condition worsened with COVID-19. He required a ventilator to breathe. The patient died on day 8 after multiple organ failure.After death, the transplanted kidney was observed. An electron microscope showed viral inclusion structures in endothelial cells.Patient 2 was a woman, aged 58 years. She had diabetes, high blood pressure, and obesity. She developed respiratory failure due to COVID-19. She later developed multi-organ failure. Her damaged kidney meant that she needed blood filtration. On day 16, a lack of blood supply meant a dead part of her small intestine had to be removed. She died due to a heart attack. Analysis after hear death showed immune response in the endothelium of her lung, heart, kidney, and liver. Additionally, there was death of liver cells. The authors found evidence ofa heart attack. The small intestine hadimmune responses in the endothelium of some vessels..Patient 3 was a man, aged 69 years. He had high blood pressure and developed respiratory failure due to COVID-19. He required a ventilation. He had a circulatory failure with a lack of blood supply in the small intestine. Part of the small intestine was removed. The patient survived. Analysis of the small intestine showed immune responses in the endothelium of some vessels.The authors found evidence of direct viral infection in the endothelial cells. Though the virus uses ACE2 receptors in the lung cells, ACE2 receptor is also seen in endothelial cells in various organs.These finding show viral elements in endothelial cells. These finding suggest that COVID-19 triggers an immune response in endothelial cells. Endothelial cells are present in several organs. This could explain why there is poor micro circulation in certain parts of the body of COVID-19 patients. This hypothesis could suggest therapies to stabilize the endothelium while dealing with viral replication. The viral replication can be targeted with various drugs including ACE inhibitors. This strategy could be especially useful for patients with poor functioning endothelium. This poor function can be caused by smoking, high blood pressure, diabetes, obesity another cardiovascular disease. 
 
 
Introduction | The outbreak of the epidemic of 2019 novel coronavirus (COVID-19) brought a serious threat to life and health with the number of older patients infected with COVID-19 increasing in the world. Older people are more susceptible to many diseases than younger, including COVID-19 infection, which could dramatically increased the healthcare burden in an aging population. 
 
Methods | The scientists collected the data on the 60 older patients transferred by Beijing Emergency Medical Service (from Jan 20 to Feb 29, 2020) to the designated hospitals infected with laboratory confirmed COVID-19 and analyzed the epidemiological and clinical characteristics of them. The information they included were demographic, epidemiological, clinical, classification of severity and outcomes. They categorized all cases into three groups and compared the difference between aged 50–64 years (81 patients), 65–79 years (44 patients) and older than 80 years (16 patients). 
 
Results | Of the 60 older patients, the scientists categorized 44 patients into aged 65–79 years group, 16 patients into older than 80 years group. Furthermore, 56.7 of all patients were male. Thirty-one patients had medical history record information, including hypertension (48.4), chronic obstructive pulmonary disease (COPD) (29.0), coronary heart disease (16.1), diabetes (9.7), cerebrovascular disease (6.5) and other diseases (25.8).The scientists found that the most common symptoms of COVID-19 infection were fever (78.3), cough (56.7), dyspnea (30.0), and fatigue (23.3). According to the scientists, the classification of severity had statistically significant differences between the three groups, compared with middle-aged patients and aged 65–79 years group, older than 80 years group had significant statistical differences in contacted to symptomatic case in 14 days. According to Figure 2, both the number of patients with underlying diseases and the severe patients were increased as aging. The scientists found that at Feb 29, 38.3 patients had discharged and 53.3 patients remained in hospital, as the fatality of COVID-19 infection in elderly was 8.3. According to Figure 1, the fatality in the aged older than 80 years group was 18.8, significantly higher than those in other two groups. 
 
Discussions | The scientists found that the most common symptoms were fever (78.3 ) and cough (56.7 ) in the older patients, which were same as the results of many studies. Moreover the scientists claim that severe patients were significantly more than mild patients in older patients, which was similar with recent study that patients have more severe symptom in elderly population. The scientists claimed that their study has some limitations and that it would be better to cover as wide population as possible to get more accurate results. 
 
Conclusions | The COVID-19 infection is generally susceptible with a relatively high fatality rate in older patients, there should pay more attention to the elderly patients with COVID-19 infection. 
Letter to the EditorCOVID-19 is a new infectious disease, which was declared as a pandemic, causing a global public health emergency. This is related with the SARS-CoV-2's high contagiosity and quick transmission.Previous studies mainly focused on epidemiological characteristics and prevention of COVID-19, while few studies looked on the duration of SARS-CoV-2 carrying in COVID-19 patients. According to the sceintists, learning more about the SARS-CoV-2carrying duration, the time of infection, as well as its antiviral treatment period can help to a better management and treatment for COVID-19.The scientists collected the positive SARS-CoV-2 cases and examined the duration for SARS-CoV-2 carrying and its characteristics in different ages, gender and if they had severe or non-severe symptoms. They defined the duration for carrying SARS-CoV-2 as the time from a contact with the source of infection to the last positive test. They collected tests from patients with a specific SARS-CoV-2 epidemiological history and a positive SARS-CoV-2 test, in Henan province.The scientists collected 161 cases from which 89 (55.3) were male, and 72 (44.7) were female. The median duration for carrying SARS-CoV-2 was 21 days in 89 male patients, and 20 days in 72 female patients, with no statistically significant difference between them. The scientists found that there were 126 cases in the 0–59 age group with a median duration for carrying SARS-CoV-2 of 20 days and 35 cases in the ≥ 60-year-old group with a median time of 28 days. The median duration for carrying SARS-CoV-2 was 20 days in the group of the non-severe type, and 27 days in the severe group.According to the scientists, 8 results of their study show that the duration for carrying SARS-CoV-2 isn't related to gender. Their results indicate that the duration for carrying SARS-CoV-2 is related to the age of patients. The scientists concluded that long existence of virus SARS-CoV-2 in the body could be a reason for the high mortality rate in elderly patients. This study also showed that the virus was carried longer in the severe cases than in the non-severe.The scientists concluded that patients infected with COVID-19 tend to have a long SARS-CoV-2 carrying and infectious duration. This could help to better measures for treatment with early isolation and monitoring strategy, as well as longer antiviral therapy for infected patients. Longer SARS-CoV-2 carrying could be a reason for the severity of the condition in elderly and severe patients over 60 years of age. 
 
 
﻿Abstract | Genetics might influence the chance for COVID-19 infection. 2633 volunteers from TwinsUK completed a survey. This allowed a twin study of COVID-19 symptoms. 
 
Introduction | There might be a heritable factor to infectious diseases. The likelihood to get the disease, an immune response, and the severity of the response might be partially genetic. Understanding how symptoms of COVID-19 pass through the population can help allocate hospital resources. The authors developed the "C-19 COVID Symptom Tracker app" to collect real time data during the COVID-19 pandemic. Ethics committee approval was obtained. The aim of the study was to estimate heritability of COVID-19 symptoms. 
 
Methods | The app asks the user daily about common COVID-19 symptoms. This includes cough, fever, chest pain, delirium, loss of smell. The app was downloaded by over 2 million people. Heritability of symptoms and 'Predicted COVID-19' was investigated. Their model considered genetic, common environmental and unique environmental factors. 'Predicted COVID-19' was determined based on a combination of age, gender and reported symptoms.The authors have shown in another study that his model is effective in predicting COVID-19 compared to swab tests.The authors got further data regarding the participants housing arrangement. The authors factored the likelihood of infection within households and compared this to twins not living together. 
 
Results | 2633 adult same-sex twins provided data between 25 March and 3 April 2020. The sample had 728 pairs with 86.9 being female. Prevalence of symptoms in TwinsUK was similar to a larger dataset of 1.85 million people.The authors found that there may have been genetic influences for delirium, fever, fatigue, loss of smell, shortness of breath and diarrhoea. There was no influence for hoarse voice, cough, skipped meals, chest pain and abdominal pain which were based on the environment.Heritability estimates for twins that were living apart were similar. 
 
Discussion | The authors report that 50 of the variance of 'Predicted COVID-19' is due to genetic reasons. Currently, 2.9 of the population has 'Predicted COVID-19'. Symptoms related to immune response have a heritability over 35. These symptoms include fever, delirium and fatigue. Loss of smell, which is a good predictor of COVID-19, is 48 heritable.Infection of COVID-19 is influenced by a range of genetic factors. This may be because of variation in the host's immune response. The findings can help identify therapies for COVID-19 and identify at risk groups.This study has several strengths. TwinsUK and the symptom recording is representative of the UK population. Predicting infection based on comparing symptoms to a large training set is a practical solution for widespread testing.One limitation is the likelihood of healthy volunteer bias. Another limitation is that symptoms are non-specific and are prevalent during spring time due to allergies/flu season. However, the sample size was sufficiently large. The results could be biased by identical twins being likelier to live together than fraternal twins. This was accounted for bu excluding cohabiting pairs through the real time data collection. Finally, the sample is mostly female which do not represent the population fully.The genetic influence on COVID-19 symptoms may relate to genes such as those for the ACE2 receptor. Further research is required to determine whether the ACE2R gene can predict symptoms. Identifying those with a higher risk to COVID-19 can help with policymaking. 
Dear Editor,In February 25th 2020, the first SARS-CoV-2 was confirmed in Barcelona, Spain. Since then, Spain has become the second country worldwide in cases (after the USA) and deaths (after Italy). Madrid and Catalonia where hit the hardest.Many factors can affect coronaviruses' transmission, including the weather, so understanding its effect on COVID-19's transmission is essential, but evidence is lacking. An association with temperature is suggested by a study of the four major Chinese cities, and preprints indicate that low temperatures make transmission easier. These are not yet peer reviewed, though.For the days between March 2nd and April 5th 2020, the incidence rates confirmed with PRC tests in Barcelona's Health Region and daily maximum temperatures were gathered. The methods used to study this data accounted for several factors that could cause mistakes.On average, each increase of 1°C reduced diagnosed incidents infected that day by 7.5, but had little to no effect on the following days. This seems to behave linearly.This research's accuracy is improved compared to other similar ones, because a smaller area was used, and so geographical factors aren't altering the results. On the other hand, other weather factors such as humidity and UV radiation were not taken into account. Daily deaths would be a better measure, as they are less variable on the amount of daily tests, but their distance from the day of infection would be larger and more variable.Relatively few days were considered, so further research is needed, but this could hint at a temperature-transmission relationship, as displayed on the genetically-similar SARS. 
 
 
Introduction | Patients are at risk for many cardiovascular complications due to COVID-19. Such diseases include excessive inflammation, lack of oxygen, inability to move, and diffuse intravascular coagulation (DIC). DIC is when small clots build up throughout the body. Thrombosis is when a blood clot forms and blocks a blood vessel. 
 
Methods | Patients in this study were from three different Dutch hospitals. All had COVID-19 pneumonia. They all received varying amounts of thrombophylaxis. Thrombophylaxis is anything that prevents blood clot formation. Doses increased over time as complications increased. Physicians used CT pulmonary angiography and ultrasonography to detect thrombotic complications. 
 
Results | Overall, 31 percent of patients developed complications even with thrombophylaxis (Figure 1). 27 percent of the patients developed venous thromboembolism. 3.7 percent of patients developed clots in the artery. Of these patients, 81 percent of them experienced pulmonary embolisms. Age and coagulopathy were independent factors in complications. Coagulopathy is when the body cannot form clots. Physicians did not find small clots (DIC) in any of the patients. 
 
Conclusions | The numbers in this study are an underestimate of the total cases of thrombotic complications. Most patients still remain in the ICU. There are also strict restrictions on testing for venous thromboembolism in intubated patients. Because of the high amount of thrombotic complications, the physicians recommend all ICU patients with COVID-19 receive thrombophylaxis. The doses should be given in increasing amounts. Furthermore, more tests for thrombotic complications should be done at a lower threshold.  
 
 
Abstract | Objective: To determine the association between smoking and progression of COVID-19.Design: A meta-analysis of 12 published papers.Data Source: PubMed database was searched on April 6, 2020.Eligibility criteria and data analysis: The authors included studies reporting smoking behaviour ofCOVID-19 patients and progression of disease.Main Outcome Measures: The study outcome was progression of COVID-19 among peoplewho already had the disease.Results: The authors identified 12 papers with a total of 9,025 COVID-19 patients.495 patients had a history of smoking. The analysis showed association between smoking and COVID-19. Limitations in the papers suggest that the actual risk of smoking may be higher.Conclusions: Smoking is a risk factor for COVID-19. Health professionals should collect data on smoking as part of clinical management. 
 
Introduction | COVID-19 is a pandemic. Smoking increases the risk of infections as it damages the upper airways. The authors reviewed and summarized 12 papers presenting data on the association between COVID-19 and smoking. 
 
Methods | PubMed database was searched on April 6, 2020. 12 relevant studies were identified. The researchers compared disease progression in smokers and non-smokers in these 12 studies. 
 
Results | 9025 patients were investigated. 878 patients had disease progression. 495 patients had a history of smoking. 88 patients with smoking history had disease progression. This was a higher percentage than that of non-smokers.The analysis showed a relation between smoking and COVID-19 progression. 
 
Discussion | This analysis confirms that smoking is a risk factor for COVID-19. Smokers have 2.25 times risk of severe COVID-19 outcomes compared to never-smokers. This is unsurprising due to the adverse effects of smoking on the body.The study has several limitations. The definition of smoking was not consistent. Only 3 studies differentiated between current smokers and former smokers. Since the lung can recover in former smokers, the data is somewhat biased.The smoking prevalence in the studies was lower than the population in general. This means that some smokers may have been identified as non-smokers. This increase bias in the study.None of these studies investigated e-cigarettes.These limitations suggest that the risk of smoking has been underestimated. All 12 studies investigated people who already had the disease. This means that the study does not investigate the risk of getting COVID-19 but the risk of COVID-19 becoming severe.As disease testing increases, it would be useful to collect data on smoking. 
 
Conclusions | Smoking is associated with COVID-19 progressions. Health professionals should collect data on smoking. They should also advice the public to stop smoking to reduce the pandemic spread. 
 
 
Abstract: | This paper examined current population-based mortality rates, compared them with the expected rate of mortality based on data for the past 3 years, and compared any excess in deaths with the number of deaths attributed to COVID-19.Data came from government sources in England, Wales, the Netherlands, Scotland, and New York State.We found there was an increase in observed, compared with expected, mortality in Scotland (+27), England and Wales (+35), the Netherlands (+60) and New York state (+26). Of these deaths, only 43 in Scotland and England and Wales, 49 in the Netherlands and 30 in New York state were attributed to COVID-19 leaving a number of excess deaths not attributed to COVID-19. These excess deaths may be due to non-COVID-19 causes, or may be undiagnosed COVID-19. 
 
Introduction: | The huge influx of COVID-19 patients has led to hospitals cancelling elective in-patient procedures and outpatient activity. Even non COVID-19 emergency department activity has declined. As a result, there is concern that deaths from non-COVID-19 causes could increase, due to reduced routine care. To assess whether or not this is the case, we examined recent observed population-based mortality rates, compared with expected rates, and compared any excess in deaths with the number of deaths attributed to Covid-19. We have analysed these data for 4 countries which have provided such data on a routine basis for at least 5 years. 
 
Methods: | The number of excess deaths was defined as the difference between the observed number of deaths and the number of deaths expected according to the observed number from 2015-2019. The number of deaths related to Covid-19 was then deducted from the excess deaths to calculate the number of non-Covid-19 defined excess deaths. All the data was drawn from Scotland, England &amp; Wales, the Netherlands, and New York State, USA.As this analysis utilized publicly available national statistics, no ethical approval was required. 
 
Results: | Scotland: There were 604 excess deaths in Scotland in the period 23 March to 5 April 2020 compared to the same period in 2015-2019 (an increase of 27). Of these excess deaths only 344 (57) were recorded as related to Covid-19.England and Wales: In England and Wales there were 7093 excess deaths in the period 21 March to 3 Apri 2020, a 35 increase from the prior 5-year average. Of these excess deaths, 4014 (57)were Covid-19-related.The Netherlands: the number of deaths increased from an expected 5953 (based on the prior 5-year average) to 9523 (60 increase) over the period 23 March to 5 April 2020. Of the 3,570 excess deaths, 1814 (51) were related to Covid-19.In the New York state the number of deaths increased from an expected 34835 (based on the prior average from 2015-2018)to 43962 (26 increase) over the period 26 January to 11 April 2020. Of the 9127 excess deaths, 6402 (70) were related to Covid-19. 
 
Discussion: | The increase in mortality is not wholly explained by deaths attributed to Covid-19. Indeed, only between 51 and 60 of the excess in deaths can be explained by official Covid-19 reports. The two most likely explanations for the discrepancy between the overall excess of deaths and the extra deaths explained by Covid-19 are either there are additional deaths caused (or contributed to) by Covid-19, but not recognized as such,or that there is an increase in deaths from non-Covid-19 causes, potentially resulting from diminished routine diagnosis and treatment of other conditions. We believe that both are likely. There are also anecdotal reports of people choosing to stay home and not go to a hospital to be diagnosed for fear of dying alone without their loved ones, which could contribute to this discrepancy.Clearly it will take time to fully explain the trends we have described and, especially, to quantify the exact causes of the excess of non-Covid-19 deaths. Even then it may be difficult to accurately determine whether Covid-19 caused or contributed to death. In patients requiring mechanical ventilation for Covid-19 induced respiratory failure it may be appropriate to attribute cause of death to Covid-19 but other patients may have the cause attributed to Covid-19 while dying from worsening heart failure or unidentified pulmonary thromboembolism. If it is correct that the Covid-19 pandemic has had a detrimental effect on medical care more generally, other “downstream” consequences are likely.Our analysis has several limitations. We relied on publicly available data that are collected and collated in a fast-moving pandemic and may be subject to revision. The coding and therefore definition of a Covid-19 related death may be influenced by local regulations and guidelines on certifying the cause of death in each country. In addition, a lack of testing in each country may mean that patients were dying from Covid-19 but were not coded as such. 
 
Final Summary: | In summary, a substantial proportion of excess deaths observed during the current COVID-19 pandemic are not attributed to COVID-19. This may indicate an increase in non-COVID-19 deaths due to changes in routine health care delivery during this pandemic. People should be reminded that it is still appropriate to seek medical attention for other serious life-threatening illnesses during this period. 
 
 
Introduction | The coronavirus disease 2019 (COVID-19) outbreak originated in the city of Wuhan at the end of 2019, China, and is now a global pandemic. The scientists explain that the Infection Fatality Rate (IFR) is the number of deaths as a proportion of all persons infected with the SARS-CoV-2 novel coronavirus. Case Fatality Rate (CFR) is the proportion among confirmed cases. According to the scientists, the IFR can be lower than the CFR if many SARS-CoV-2 infections with mild or no symptoms are not being detected. The scientists' aim was to estimate the ascertainment rate by applying epidemic modeling to publicly reported confirmed COVID-19 cases in Wuhan. Their secondary aim was to estimate among other epidemic parameters, the basic reproduction number R0. 
 
Methods | The scientists used the most recent confirmed case data from Wuhan using the R package ‘nCov2019’, for the period between 3 January and 9 March 2020. Wuhan was chosen because after the lockdown that started on 23 January 2020 the cases showed a steady decline since mid-February. 
 
Results | The scientists estimated that for Wuhan the ascertainment rate is at 0.465. According to the scientists this shows that for every confirmed case in Wuhan there had been 200 infections that were not detected. Scientists found that the R0 was estimated at 3.07. The scientists estimated that the R0 would be 5.33 until the Wuhan lockdown, decreasing to 2.09 until 10 February rising to 3.83 later, with an ascertainment rate of 0.48. According to the their results, half of Wuhan's population was already infected by 27 January, while at 23 February only 585,000 of these remained. This would mean that 94.7 of the population had been infected but if the contact between people dropped to 85 after the lockdown, the percentage would be 52.7. 
 
Conclusions | The scientists proposed that a possible scenario for Wuhan's outbreak control was the fact that a large majority of the population was infected, and only a small percentage of infections were detected, without this meaning that the measures taken did not help to "flatten the curve".According to the scientists, it is crucial to estimate the case ascertainmentto accurately assess the true nature of the COVID-19 pandemic. Based on their findings scientists claim that testing and contact tracing are probably not the best solution, and it could lead to take us further away from the initial goal which to “flatten the curve” as much as possible, so that the health care systems are not burdened and the most vulnerable people are protected.The scientist conclude that more surveys like this should take pace in order to find out the true size of infection in different population, as the ascertainment rate they estimated for Wuhan is on the lower end of what was previously published. 
 
 
Abstract | Studies have shown that the 2019-nCoV virus primarily infects host cells with the ACE2 receptor. This receptor allows the virus to enter the host cell. Using RNA sequencing data, the researchers found that many cells in the oral mucosa (mucous membrane) express ACE2. Many receptors were specifically found in the epithelial cells of the tongue. This indicates that cells in the oral cavity are possibly at high risk for 2019-nCoV infection. 
 
Aims | The researchers aim to study if the virus could enter cells in the mucosa in the oral cavity. 
 
Introduction | Many patients have gotten Coronavirus Disease 19 (COVID-19) since December 2019. They experienced pneumonia, fatigue, respiratory failure, and other complications. The 2019-nCoV virus has a receptor binding domain (RBD) is similar to that of SARS-CoV. The study Zhou et al. showed that 2019-nCoV primarily infects cells through the angiotensin-converting enzyme II (ACE2) receptor. Other receptors are not used. The study Xu et al. showed that the spike protein interacts with human ACE2. The spike protein (S protein) is responsible for virus binding to the host receptor. Therefore, cells with a high number of ACE2 receptors may have a high risk of coronavirus infection. 
 
Results | In Figure 1, the researchers show that many organs express ACE2. These organs include the intestine, kidney, colon, gallbladder, and heart muscle. When examining the oral cavity, they found high ACE2 expression in the tongue, floor of the mouth, and the base of the tongue. The tongue had the most ACE2 expression, but this difference was not significant compared to other sites in the mouth. The analysis came from the public RNA sequencing (RNA-Seq) databases.	Researchers conducted RNA sequencing on many cells, including epithelial cells, T cells, and fibroblasts. Out of the ACE2 positive cells in the mouth, 95.86 came from the tongue rather than the cheek or gums. Most of the ACE2 positive cells were epithelial cells. But, T cells, B cells, and fibroblasts were also ACE2 positive (Figure 2). Thus, the epithelial cells of the tongue have the highest concentration of the ACE2 receptor. 
 
Discussion | An interesting result is that lymphocytes in the oral mucosa had ACE2 receptors. The lungs and the digestive system organs also had lymphocytes that were ACE2 positive. More studies need to be done on how 2019-nCoV infects lymphocytes.Oral symptoms are rare in COVID-19. But, an oral route of infection cannot be dismissed. In another study, 4 out of 62 stool specimens of patients with COVID-19 tested positive for 2019-nCoV. Thus, an oral-fecal transmission route for 2019-nCoV is possible.Histology studies are still needed to elaborate on these findings. The results further inform how COVID-19 can be prevented. 
 
Methods | The researchers used single cell RNA sequencing for various tissues. They also used RNA sequencing data from two databases. They studied para-carcinoma normal tissue in 13 organ types from the Cancer Genome Atlas (TCGA) and normal tissue in 14 organ types from the Functional Annotation of The Mammalian Genome Cape Analysis of Gene Expression (FANTOM5 CAGE). The researchers used the software R for analyses. 
 
 
Abstract | The abnormal blood coagulation function of severe COVID-19 patients is well known. But the prevalence of venous thromboembolism (VTE) is not. This study aims to determine the prevalence of VTE in severe COVID-19 patients. An ultrasound was used to determine if 81 severe patients had VTE. 25 of the patients had VTE, and 40 of the patients with VTE passed away. Age, lymphocytes, activated partial thromboplastin time (APTT), and D-dimer were all differing factors between VTE and non-VTE patients. 
 
Introduction | Many studies on SARS-CoV-2 have shown coagulation dysfunction in severe patients. This coagulation is associated with a poor outcome. VTE in severe COVID-19 patients and its effects are not well understood. This study identifies VTE in patients and the difference between VTE and non-VTE patients. 81 patients with severe COVID-19 cases were included in this study. The patients had a clinical examination, blood work, chest CT, lower limb venous doppler ultrasound, and an RT-PCR test for COVID-19. They were tested for prothrombin time, activated partial thromboplastin time, thrombin time, international normalized ratio, fibrinogen, and D-dimer. These are known as conventional coagulation tests. 
 
Results and Discussion | The average age of the patients was 59.9 years. 41 of the patients had another chronic disease and 43 of the patients were smokers. 25 of the patients developed VTE. The VTE patients were older on average than the non-VTE patients. The VTE patients also had lower lymphocyte counts, longer activated partial thromboplastin time (APTT), and higher D-dimer. The D-dimer was still higher than the normal range for both VTE and non-VTE patients.Other studies have also shown SARS-CoV-2 infection leads to low lymphocyte count. T cells seemed to be the most affected because they were half of the low limit. Abnormal expression of T cell mRNA can cause VTE, and older patients are more likely to have this complication.SARS-CoV-2 can also lead to sepsis and the release of proinflammatory cytokines. Inflammatory cytokines can activate blood coagulation therefore promoting VTE. Sepsis can also cause a spread in clots into vasculature which occurred in deceased patients at a rate of 71.4. This shows that abnormal blood coagulation and thrombosis do not have a favorable outcome in severe COVID-19 patients.High D-dimer levels are linked to high coagulation and hyperfibrinolysis. After the patients had anticoagulant medication. The D-dimer level decreased slowly. D-dimer can therefore predict thrombosis and monitor how effective the anticoagulant medication is.Though this study was small and the clinical outcomes of all of the patients are yet to be discovered, this study will assist in the prevention, diagnosis, and treatment of VTE. 
 
 
﻿Abstract |     This research team studied the lung and skin tissue of 5 patients with lung failure due to COVID-19. They found damage to the capillaries in the lungs surrounding the alveoli. There were also Neutrophils, a type of white blood cell, found in the capillaries. Molecules from the complement system were also found. These molecules are membrane attack complex (C5b-9), C4d, and mannose binding lectin-associated serine protease 2 (MASP2). In the skin, C5b-9 and C4d were also found. This suggests that severe cases of COVID-19 are influenced by damage due to the complement system. 
 
Introduction | SARS-CoV-2 is one of many existing coronaviruses. Many coronaviruses cause respiratory failure, and may develop into acute respiratory distress syndrome (ARDS). Early studies of COVID-19 showed that the virus could cause ARDS, but more recent studies have shown that the effects of COVID-19 are actually different from ARDS. The patients in the study had microvascular thrombosis, which is when the immune system tries to stop the travel of the pathogen by narrowing the vessels. It can cause a purple coloring to the skin. Microvascular thrombosis can be caused by the complement system. Since MASP2 binds to the spike protein of SARS-CoV in mice, it is likely that MASP2 binds to the spike protein of SARS-CoV-2 in humans. There are several different pathways that the complement system can use to function. Based on the molecules that were found, the alternative pathway (AP) and the lectin pathway (LP) are the two that scientists could target to treat severe cases of COVID-19. C5b-9, C4d, and MASP2 are all components or byproducts of the complement system. So finding these molecules in the tissue tells us that the complement system is active and could be damaging the tissues. Finding fibrin can show that the vessel walls were damaged and are trying to heal. 
 
Methods | The patients who were tested in this study were tested wit PCR to make sure they were COVID-19 positive and negative for any other infection that could influence their condition. The researchers used antibodies and a light microscope to test if C5b-9, C4d, and MASP2 were present in the tissue samples. They used another stain specific for the SARS-CoV-2 spike protein to detect if it was present in the tissue samples since it may bind to MASP2. 
 
Results | Case 1This 62 year old patient came into the emergency room with low oxygen levels and high blood pressure. He had coronary artery disease, diabetes, heart failure, and kidney disease. This patient passed away a few hours after coming to the ER. When they looked at the tissue, the researchers found a protein called fibrin in his capillaries of his lungs. Fibrin is a protein that helps clot blood when there is a wound. The vessel walls were dying, and were full of white blood cells. Most of the lung damage was actually to the capillaries, and the actual lung cells were not damaged. C5b-9 and C4d were found in the capillaries of the lungs.Case 2This 72 year old patient came to the ER with a fever, rapid breathing rate, and very low oxygen level. He had a history of smoking, obesity, and prediabetes. The patient was put on a ventilator right away and soon developed an irregular heart rhythm and kidney failure. The carbon dioxide rose in his blood and he passed away 4 days after he came to the ER. When analyzing the tissue, fibrin was found in the capillaries and in the alveoli. This patient had more damage to the lung tissue compared to Patient 1 because this patient was on the ventilator for four days. C5b-9 was found in unhealthy lung tissue, healthy lung tissue and the trachea. C4d and MASP2 were only found in the capillaries.Case 3This 32 year old man came to the ER after a week of coughing and a fever. He had a history of obesity, sleep apnea, steroid use, and using testosterone supplements. He had respiratory failure and was placed on a ventilator. He spent three weeks on the ventilator. He was treated with hydroxychloroquine, azithromycin, and remdesivir. He had tissue death on the skin of the buttocks. A biopsy of the dying tissue was taken and the capillaries were full of white blood cells and C5b-9.Case 4This 66 year old female came to the ER with fever, cough, diarrhea, and chest pain. She had low oxygen levels and was admitted to the hospital. She was given hydroxychloroquine and other medications. After three days, she had to be put on a ventilator. She had a purple rash on her hands from blood leaking out of the capillaries. This tissue was biopsied, and there were high levels of C5b-9 and C4d in the capillaries. The patient lost blood supply to many parts of her brain during ventilation and was in a coma.Case 5A 40 year old female came to the ER with a cough, fever, body aches, diarrhea, and difficulty breathing. She had been diagnosed with COVID-19 a week earlier, but was feeling worse. She then had to be put on ventilation for respiratory failure. She had the purple rash around her chest, legs, and arms. These were biopsied and there were high levels of C5b-9 and C4d in the capillaries. 
 
Discussion | Microvascular thrombosis in severe COVID-19 cases can cause damage to the skin and the lungs. C5b-9, C4d, and MASP2 were found in both the damaged purple rashes and the healthy tissue near the rash. Early studies showed COVID-19 caused ARDS. But this study shows that severe COVID-19 effects are caused by microvascular thrombosis. The complement system is causing damage to the wall of the vessels, which is why the clotting factor fibrin was found in some of the capillaries. In another study, mice were genetically modified so they didn’t have a functioning complement system (C3 -/- knockout mice). When infected with SARS-CoV, the C3 -/- knockout mice did not become as severe as the regular mice. The regular mice had worse lung function, more white blood cells in the capillaries, more inflammation, and more weight loss. This shows that a potential treatment for COVID-19 is stopping the complement system. Stopping the complement system will not stop the virus from spreading, but it can decrease the most severe symptoms of COVID-19.This study has some limitations. It was a case study that only followed 5 patients, which is a small sample size. The virus also binds to ACE2 to enter the cell, which may account for some of the results of this study. Binding to ACE2 can cause inflammation and damage to the vessels similar to the complement system. More research should be done to confirm the complement system as a potential method of treatment for COVID-19. 
 
 
Abstract | Since COVID-19 clearly affects the respiratory system, the effect of the kidneys has not been well studied. This study looks at the kidneys of 26 COVID-19 patient autopsies. The patients passed away from respiratory failure and multiple organ dysfunction syndrome. 9 of the 26 had kidney injury that increased serum creatine and protein in the urine. The tubules of the kidney showed tissue death, red blood cell clusters, SARS-CoV-2 like clusters, and upregulated ACE2. This study shows direct evidence that SARS-CoV-2 
 
Introduction | SARS-CoV-2 is the name of the virus that causes the disease COVID-19. The common symptoms include cough, fever, and fatigue. But the symptoms can range from nothing to severe respiratory failure. Since the lungs, blood, and immune system are mainly involved in COVID-19, research on the other organs is lacking. Ranges from 1 to 29 of patients in different areas have acute kidney injury with COVID-19. 
 
Methods | Families of the patients provided consent for the study, and RT-PCR confirmed these patients were positive for COVID-19. All tissue samples were collected and preserved within 6 hours of fatality. 
 
Results | Clinical Information19 males and 7 females ranging from 39 to 87 years of age were included in the study. All 26 patients had tested positive for COVID-19.Light MicroscopyLight microscopy tested for acute tubule injury. This was seen by damage, dilation, or death of the tubule tissue. Red blood cells were found in clusters in the glomerular capillaries, which sometimes caused a blockage in the capillary. In 3 patients, creatine phosphokinase was found in the urine, which can be a sign that the patient’s muscles were damaged and breaking down. Patients with diabetes or hypertension had less healthy glomeruli, and the condition of each glomerulus was varied.Transmission Electron MicroscopyCoronavirus-like particles were found in the tubules. These particles had spikes matching the spike protein of SARS-CoV-2. Red blood cell clusters causing blockages were found in peritubular capillaries as well.ImmunohistochemistryThere was no build up of any inflammatory cells based on this study. White blood cells were found and caused scarring of the capillaries. Staining showed that the peritubular capillaries were almost completely blocked by red blood cells, but no platelets were found. 
 
Discussion | This study shows there is a wide range of kidney abnormalities in severe COVID-19 patients. This study may be important for less severe COVID-19 patients who have kidney damage. There was damage caused by blockage in tubules and capillaries. Some of the results are similar to how other beta-coronaviruses infect the kidney. The coronavirus-like particles were found in podocytes and matched the spike protein of coronaviruses. Immunohistochemistry shows that SARS-CoV-2 can directly infect the tubules and podocytes of the kidney. This caused acute kidney injury and protein in the urine. The breakdown of damaged skeletal muscle in some patients could be a side effect of the medications they were on, or could be caused by the virus.SARS-CoV and SARS-CoV-2 have a 79 resemblance and are both beta-coronaviruses. Since the virus uses ACE2 to enter the cell and there is a high concentration of ACE2 in the kidneys, they could explain some of the damage in the tubules and podocytes.CD147 is a glycoprotein on the membrane surface that is involved in several kidney diseases. It was recently shown in another study that SARS-CoV-2 can infect cells using CD147. This interaction may be useful to target to treat COVID-19.Acute kidney injury could have also been caused by low oxygen levels, cytokine storms, secondary infections, and drug interactions. This study was limited by a small sample size, and further research would help confirm the results of this study. 
 
 
Abstract | 	This study evaluated the efficacy of several known antiviral drugs (ribavirin, penciclovir, nitazoxanide, nafamostat, chloroquine, remdesivir, and favipiravir) in treating 2019-nCoV. These medications were tested on lab isolated 2019-nCoV in vitro. A series of standard assays were used to gather cytotoxicity, virus yield, and infection rate data. Overall, remdesivir and chloroquine stand out for their effectiveness against 2019-nCoV and because of the experience the medical community has with them. 
 
Introduction | 	This study suggests that the development of drugs fighting novel coronavirus can be expedited if existing antiviral medications are experimented with. The researchers selected several FDA approved antivirals, attempting to lay groundwork for future 2019-nCoV treatment. 
 
Methods | In Vero E6 cells (cultures good for propagating viruses) were infected with Wuhan sourced nCoV and were used to test the medications. The first step in this study was to evaluate the cytotoxicity (toxic effect on cells) of all the candidates tested. This was done with a CCK-8 assay (a method using dye to determine the number of living cells). Next, the effectiveness of the drugs was determined by observing the quantity of viral copies in the cells used after 48 hours. This step used RT-PCR along with visual confirmation based on microscopy of nucleoprotein expression. The tests performed came together in selectivity indexes (SI): ratios comparing cytotoxicity to antiviral activity.	 
 
Results | 	Three of seven medications (including ribavirin) required large concentrations of three nucleoside analogues (nucleic acid analogue and sugar) in order to effectively fight the viral infection. Nafamostat (used to fight MERS-CoV) inhibited 2019-nCoV. Nitazoxanide was also inhibitive at a low molecular concentration.Most notably, however, remdesivir and chloroquine “potently blocked” virus infection at low concentrations with high SI (good ratio of antiviral effect vs toxicity to cells). Remdesivir inhibited virus infection on human liver cancer cells, which are susceptible to the virus. Chloroquine’s tests on infected in Vero E6 cells showed it is also effective, both on entry and post entry stages of the infection. The study proves that both of these medications are “highly effective in the control of 2019-nCoV infection in vitro.” 
 
	Discussion | 	Past studies using non-human primate models showed that a 10mg/kg dose of remdesivir resulted in lasting levels of its effective form in blood and it has proven extremely (100) effective against Ebola virus.Chloroquine has been used for decades as an antimalarial and autoimmune disease drug. It blocks virus infection by altering the pH conditions necessary for a virus to attach to a cell. The drug spreads effectively throughout the whole body and has a potentially beneficial immune-modulating property. It has a low cost and is safe with known doses.	Further testing is recommended for certain medications, as past studies have shown discrepancies between tests performed on Vero cells and other samples, such as mice.	 
 
 
Abstract | 	This is a statement from the Indian Heart Rhythm Society (IHRS) summarizing the cardiovascular effects of hydroxychloroquine. The primary effects discussed are QT interval prolongation (heart taking too long for electrical recharge) and potentially fatal arrhythmia (irregular heartbeat). This paper also addresses methods of identifying high risk groups and the monitoring necessary to prevent cardiac related death. 
 
Introduction | 	Hydroxychloroquine is often used for “autoimmune disorders, and related inflammatory and dermatological conditions.” The drug is a safer (according to clinical studies) version of chloroquine, the difference being an additional hydroxyl (-OH) group. It effectively inhibits SARS-CoV2 binding by raising intravesicular pH, inhibiting lysosomal activity, and changing antigen processing. Despite its potential for fighting SARS-CoV2, the medication can cause QT prolongation in certain patients (especially when combined with other medications such as azithromycin). This paper aims to address and help prevent such risks. 
 
Risks and Prevention | 	Using a 12-lead ECG, or using a rhythm strip and comparing to RR interval (comparison of spikes on an electrocardiogram reading), patients should have baseline measurements taken for their QT interval. Due to personal protective equipment shortages and other logistical issues of taking COVID patient ECG readings repeatedly, some alternatives are available. These include continuous rhythm monitoring systems or apps and devices available to the public (such as Kardia Mobile).	Based on the above measurements, potential hydroxychloroquine recipients should be categorized into risk groups. Low-risk: normal QT interval, moderate-risk: QT prolongation of up to 500ms, and high-risk: QT prolongation greater than 500ms. Low-risk groups can be given hydroxychloroquine without further risk analysis. Moderate-risk individuals can be given hydroxychloroquine with caution and with attention being paid to removable risks like improper electrolyte levels in the blood. High-risk patients should not be given hydroxychloroquine or should be monitored extremely closely if they are taking it. ECG readings should be taken 2-4 hours after the first dose in high risk patients and then again in two to four days.	Dosage for prophylactic use of hydroxychloroquine should be:-400mg twice a day on day one and 400mg once a week for the next seven weeks forasymptomatic healthcare workers-400mg twice a day on day one and 400mg once a week for the next three weeks for asymptomatic household contacts of lab confirmed COVID patientsThe drug is not recommended for children under 15 years of age. 
 
Discussion | 	The Indian Heart Rhythm Society “strongly discourages it’s [hydroxychloroquine] use for the general public without medical supervision…” With this being said, shortage of equipment and logistical issues in preventing transmission to healthcare workers are acknowledged in the paper. Mobile applications and other self-monitoring tools are strongly encouraged to overcome resource limitations. 
 
 
Abstract | 	This paper discusses the measures taken in Guangdong, China (most populated province in the country) to curb the spread of COVID-19. Many of the region's recent draconian measures are based on its experience from fighting the 2003 SARS outbreak. Strict regulations combined with extensive healthcare measures resulted in significant day-on-day infection ratio drop offs starting Feb 1st. 
 
Introduction | 	China’s early spike in COVID-19 cases makes it a valuable source of information for other nations who experienced peak infection numbers more recently. The densely populated Guangdong Province in China (population 113.46 million) received 94,000 travelers from Wuhan China in late January during the Spring Festival period. This holiday travel resulted in the rapid spread of COVID-19 through the region. In response to this spread, the government adopted a policy of “‘early detection, early reporting, early isolation, and early treatment.’” 
 
Methods | 	On January 23rd, 2020, the government enacted protocols for its highest level of public emergency. Temperatures in public areas were monitored, public transport was limited or closed, and respirator use was enforced. Due to the 2-14 day incubation period, a main concern was transmission between individuals unaware of their condition. To avoid mass panic and misinformation, epidemic data, expert interviews, and general health information were shared on a large scale.	Online medical services were developed to prevent nosocomial transmission. Holiday breaks were extended and residents were instructed to stay indoors and to avoid public spaces. Rules for respirator use were also established, with punishments enforced for those who did not obey them. Ventilation of public areas was also a priority, with strict disinfection (four times a day) standards being set for spaces such as elevators. Dining establishments were required to transition to take out meals instead of in-restaurant serving.	Lastly, 17,000 medical professionals in 104 hospitals were mobilized to ensure patients were taken care of promptly and effectively. 
 
Results | 	All of these strict measures resulted in a significant drop off in day-on-day ratios in Guangdong Province. Data from Jan and Feb shows that the province experienced consistently lower ratios (number of people infected in a given day compared to cumulative number of all previous days) than mainland China (except Wuhan). By mid to late Feb, the region’s ratio of new cases to total cases leveled off to nearly zero. 
 
Discussion | 	Guangdong Province’s previous experience with the 2003 SARS outbreak enabled it to act quickly and decisively following the outbreak of COVID-19. The region's strict social and medical protocols resulted in a rapid reduction of new cases following a late Jan peak. While the outcome is encouraging, 435,000 people will be traveling back to Guangdong from Wuhan when traffic reopens. This migration opens up new risks, and strict monitoring in the region will continue.  
 
 
Introduction | Researchers have raised the alarm of possible dental risks associated with COVID-19. Other researchers have established that viruses can infect cells in the oral mucosa. The oral mucosa is the membrane lining the mouth. SARS-CoV-2 infects a cell by binding to the ACE2 (angiotensin-converting enzyme II) receptor. 
 
Methods | The authors looked at how much ACE2 lined different human organs. They used the GTEx portal. 
 
Results | The researchers found that there is a higher concentration of the ACE2 receptor in salivary glands than the lungs. This means that the novel coronavirus can likely infect the salivary glands. Moreover, viral RNA of SARS-CoV can be detected before lung lesions occur. Thus, asymptomatic transmission of COVID-19 may occur from saliva, which can contain live virus. The researchers warn that infection of the salivary glands and not just infected saliva may cause asymptomatic infections. 
 
 
Abstract: | There are no approved treatments to kill the virus responsible for COVID-19. Plasma from recovered patients can fight the virus. This study uses this plasma to help patients very sick with COVID-19. The symptoms of the patients improved within 3 days. No negative side effects were observed. Convalescent Plasma therapy could improve severe COVID-19 cases. More work is needed to find the right dose and time to administer the therapy. 
 
Introduction: | The SARS-CoV-2 coronavirus causes the disease COVID-19 and there is no approved treatment to kill this specific virus.Convalescent Plasma (CP) therapy is the use of blood plasma from patients who have recovered from a disease. This type of treatment was effective to treat SARS and MERS. These viruses are similar to COVID-19, so CP therapy is a promising treatment for this disease. 
 
Results: | The researchers first tested whether the convalescent plasma from patients who recovered from COVID-19 was able to neutralize the virus. They found that 39 of the 40 plasmas tested had very high antibodies count against the virus. This means the virus is neutralized by the plasma.Patients in the trial10 severe COVID-19 patients, 6 males and 4 females, received transfusion of convalescent plasma 11 to 19 days after their symptoms first started. Four patients had underlying chronic diseases. Patients received antiviral or antibiotic treatment if needed. All patients had lung injury.Effects of CP transfusionAll symptoms in all 10 patients disappeared or improved within 3 days of CP transfusion, including fever, cough, shortness of breath, and chest pain. The patients needed less oxygen and ventilation than before treatment. The lesions in the lungs of patients were reduced after CP transfusion. 7 out of 10 patients showed higher white blood cell counts. Lung function also seemed to recover. Before treatment, 7 patients were positive for the virus and 3 were not. Within one week of CP transfusion, all 7 patients tested negative. A group of 10 patients with severe COVID-19 were not given CP. The outcome was much better for the group that received CP treatment.Adverse effects of CP transfusionsOne patient had a temporary red spot on their face, but there were no serious negative reactions to the treatment. 
 
Discussion: | This study shows that one dose of 200-mL of CP transfusion was well tolerated by patients and that their symptoms improved a lot.COVID-19 can cause severe pneumonia and is characterized by high inflammation and lung injury, as well as low immune cell counts. Convalescent Plasma obtained from recovered COVID-19 patients contains a lot of antibodies that can neutralize the virus in the blood and lungs. All the patients in this study became negative for the virus after CP transfusion. There was no death in the group.It is important to get plasma from donors with high levels of antibody against the virus. Antibody levels decreased in a few months in patients recovered from SARS and MERS. This means recently recovered patients are most suitable for plasma donations.The time when the CP transfusion is administered is also very important. The patients who received transfusion within 14 days of feeling ill had the best improvement compared to patients given the transfusion after 14 days.No negative effects were observed in this study. One risk of plasma transfusion is transmitting the virus. In this study the potentially present virus was inactivated.There are limitations to this study. Patients received antiviral treatments and standard care, which can contribute to recovery. The treatment schedule and amount of plasma and antibodies to give also needs to be clarified. However, these first results are very promising. One dose of CP improved the state of the patients. 
 
Materials and methods: | PatientsAll 10 patients from 3 hospitals in Wuhan, China had severe COVID-19. They received antibiotic, antiviral, and antifungal treatment as well as oxygen support if needed.Donors and plasma10 donor patients who had recovered from COVID-19 were recruited from the 3 hospitals. Plasma samples were stored at 4°C in 200-mL doses. They were treated to inactivate any potential virus contained in the plasma. 
Background Severe acute respiratory syndrome-coronavirus-2 SARS-CoV-2 was declared to have emerged from Wuhan china in December 2019. SARS-CoV-2 is the third coronavirus to have caused respiratory illness in humans. Coronavirus disease 2019 (COVID-19) was recognized as a global pandemic in March 2020 and has had an deleterious effect on the economy and global health. 20 of COVID-19 cases experience pneumonia and fever which cause acute respiratory distress syndrome (ARDS). This is similar to the cytokine release syndrome (CRS) that induced (ARDS) and secondary hemophagocytic lymphocytosis (sHLH) that was observed in SARS-Cov, MERS-CoV, and leukemia patients receiving engineering T-Cells. These past experiences have shown that treatment of inflammation is important in reduction and infection severity. Thus, mediations like tocilizumab have become of recent importance. SARS-CoV-2 is a betacoronavirus that is most closely related to SARS-Cov. Both viruses use angiotensin-converting enzyme-related carboxypeptidase (ACE2) receptor to gain entry into the cell. This receptor is mainly produced in the cardiopulmonary tissues and hematopoietic cells such as monocytes and macrophages. Low white blood cell count correlates with SARS-CoV-2 infection severity. However, low white blood cell counts are not unique to COVID-19 as it was seen with H1N1 infection. Cytokine release syndrome (CRS) was a major cause of death in the SARS-CoV and MERS-CoV infections. Elevated levels of proinflammatory marker cytokine interleukin-6 (IL-6) and other biomarkers are indicative of severe MERS-CoV infections. Similarly, (CRS) is common in patients with COVID-19 infection. Higher levels of (IL-6) are associated with the development of acute respiratory distress failure (ARDS) and poor clinical outcomes. (IL-6) promotes the production of the protein C-reactive protein (CRP) which is a marker of severe betacoronavirus infection. Infection of the body's monocytes, macrophages, and dendritic cells will result in activation. This will cause a secretion in (IL-6) and other inflammatory cytokines. (IL-6) can signal through two main pathways cis and trans.CIS signaling pathwayIn cis signaling (IL-6) will bind to membrane-bound (IL-6) receptor (mIL-6R) in a complex with gp130. Later the signaling pathway is mediated by JAKs (Janus kinases) and STAT3 (signal transducer and activator of transcription 3). The membrane bound gp130 receptor is produced throughout the body, but mIL-6R is restricted to immune cells. This activation of the cis pathway results an activation of the adaptive immune system (T and B cells) and the innate immune system (Neutrophils, macrophages, and natural killer [NK] cells). The activation of these pathways will result in CRS.Trans signaling pathwayIn trans signaling high levels of plasma IL-6 will bind to the soluble form of IL-6R (sIL-6R). This will form a complex with gp130 on potentially all cellular surfaces as gp130 is expressed everywhere. This results in a IL-6-sIL-6R-JAK-STAT3 complex that will activate downstream signaling in cells that do not express the mIL-6R receptor, specifically endothelial cells. This will result in a systematic “cytokine storm” from the resultant secretions of the endothelial cells. These activated cells secrete vascular endothelial growth factor (VEGF), monocyte chemoattractant protein-1 (MCP-1), IL-8, and additional IL-6, and reduced E-cadherin expression on endothelial cells. VEGF and reduced E-cadherin work in conjunction to contribute to vascular permeability and leakage. This participates in hypotension and the pulmonary issues seen in acute respiratory distress failure (ARDS).Secondary hemophagocytic lymphohistiocytosis (sHLH) is a hyper inflammatory condition marked by CRS, low blood cell count, and multiorgan failure. This can be seen in leukemia patients receiving T-cell treatments or those with multiple viral infections. Similarly, higher levels of cytokines and ferritin are notable biomarkers. Cells that express CD163 are important as a source of ferritin. Therefore (sHLH) is also known as macrophage activation. Higher levels of ferritin and IL-6 was associated with patient death. Patients receiving chimeric antigen receptor (CAR) T cell therapy can develop CRS and sHLH. The first patient to receive engineered T-cells to treat leukemia resulted in extreme inflammation in the form of developing CRS and sHLH. This led to ARDS with accompanied multiorgan failure and hypotension. There were incredibly high levels of IL-6 present so the researchers treated this patient with tocilizumab, and IL-6 antagonist. At the time it was used to treat rheumatic conditions. The patients recovered rapidly. The efficacy of IL-6-IL-6R antagonists for CRS and sHLH treatment shows the role of IL-6 signaling in hyperinflammatory conditions. Therefore severe conditions of COVID-19 may benefit from IL-6 pathway dependent inhibition. A Chinese study of 21 patients using tocilizumab shows that fever reduced within the first day and the oxygen requirements of the patients decreased in 75 of participants. Early tests are promising, but additional research must be done on IL-6 or IL-6R antagonists. IL-6 inhibitors prevent both cis and trans pathways. However, IL-6R inhibitors prevent cis, trans, and trans presentation pathways. Recently corticosteroids were used for SARS and MARS patients to reduce systemic inflammation. However, it resulted in delayed clearance of the virus and thus the WHO advises to avoid using corticosteroids on COVID-19 patients currently. Long term treatments of IL-6 inhibitors result in complications, but one or two doses are unlikely to cause issues. It is possible that IL-6 therapies could be used in future pandemics. 
 
 
Abstract | This study shares the case of a 6 month infant simultaneously diagnosed with Kawasaki disease (KD) and COVID-19. The significance of the COVID-19 diagnosis parallel to the KD diagnosis is not clear; the paper simply shares symptoms and patient characteristics for future reference. Treatment for this case was routine and included intravenous immunoglobulin and high dose aspirin. 
 
Introduction | 	While COVID-19 has developed into a global pandemic with hundreds of thousands of deaths, its effect on the pediatric population appears significantly smaller than that on adults. While studying 1412 pediatric patients with suspected COVID-19, this research group found little information on the virus’s coincidence with other clinical conditions. This study serves as one of the first accounts of such a case, observing an infant diagnosed with KD and testing positive for COVID-19. 
 
Methods | 	This specific case involved a full term, healthy, and vaccinated 6 month old infant brought in for fever, fusiness, and refusal to be fed. Her initial temperature was 38.8℃ and no cough, congestion, or rhinorrhea (mucus filled nasal cavity) was observed. Influenza swab and catheterized urinalysis were performed, bothing coming back negative. During her second day of fever, the infant developed an erythematous (red), non-pruritic (non-itchy) rash. Oxygen saturation was 100 and 200 beat/min sinus tachycardia was observed. Additional symptoms included irritability, conjunctivitis (with sclera around iris being white).	Lab tests indicated left shifted white blood cell count (immature neutrophils present) , normocytic anemia (low red blood cell count), elevated c-reactive protein (liver protein suggesting inflammation), and a high erythrocyte sedimentation rate (red blood cell test indicating inflammation or infection). The patient also had low sodium levels and low albumin levels. An echocardiogram showed no cardiac abnormalities. 
 
Results | 	Treatment included a single dose of intravenous immunoglobulin and a high dose of acetylsalicylic acid. COVID-19 diagnosis was confirmed by RT-PCR testing and the patient’s family was instructed to quarantine for two weeks.	Treatment for the KD was routine and the significance of the COVID-19 present at the same time remains unclear. 
 
Discussion	 | 	The infant did not exhibit respiratory problems which are often used as a constraint to authorize testing in areas where it is limited. This study suggests that pediatric patients exhibiting only fever may be missed (not tested for COVID-19) due to the lack of respiratory symptoms. With the inconclusive impact of COVID-19 and unknown origin of KD, this paper is more a reference for future cases than groundbreaking discovery. 
 
 
Introduction | The Coronavirus Disease 2019 (COVID-19) has spread throughout China and many European countries. Many countries have shut down businesses, schools, etc. Another strategy is to develop herd immunity while protecting those at greatest risk for COVID-19. 
 
Methods | This study used the effective reproductive number (Rt) instead of the basic reproductive number (R0). The Rt is the estimated number of people that an infected person can transmit the virus to, based on clinical data and testing. The researchers used the exponential data on the new daily cases. They conducted analyses using the software R. Then, they calculated the Pcrit value. The Pcrit is the minimum percentage of a population needed to be immune in order to stop the spread of the virus. They conducted analyses for the 32 countries that had over 100 COVID-19 cases as of March 13, 2020. They calculated Pcrit with the formula Pcrit = 1 - (1/Rt). Another reason for using Rt is that some individuals are already immune to the coronavirus.   
 
Results | All of the Pcrit values are shown in table 1. The Pcrit values range from 5.66 in Kuwait to 85 in Bahrain. Here are the Pcrit values from some of the countries with the highest amount of cases:Spain - 80.7The United States - 69.6Germany - 69.6Switzerland - 69.3France - 67.6Italy - 59.0Iran - 50.0Korea - 30.1   
 
Conclusion |Some people may have partial immunity to SARS-CoV-2. They may have antibodies against common seasonal viruses, such as OC43, 229E, NL63, and HKU1. These people seem to have milder symptoms or are asymptomatic if infected. Finally, a problem is that many people may die as a population achieves herd immunity. Fatality rates vary between 0.25-3.0 of a population.  
 
 
Introduction | The novel coronavirus, SARS-CoV-2, is causing the COVID-19 pandemic. Many of the common symptoms of the coronavirus include cough, fever, headache, soreness, and more. In Spain, dermatologists have been treating patients virtually. The researchers noted an increasing number of cases of lesions that resemble chilblains. Chilblains are skin sores that show up when small blood vessels become inflamed from the cold. The majority of patients were children or young adults. They initially had red lesions like chilblains. About a week later, the lesions began to appear as purple spots and were flatter. There was some discomfort and pain if one touched the lesions. Most patients had mild symptoms or no symptoms of the coronavirus. Most patients had no respiratory conditions. 
 
Aims | The researchers aim to make dermatologists aware of a possible symptom of the coronavirus. Particularly, skin lesions may form. 
 
Cases | The researchers presented six case studies. All of them had skin lesions in the toes, heels, and/or toes. All of them presented with some indication of the coronavirus, either through symptoms or an X-ray. However, not all of them could be tested for the virus. A summary of the results are in Table 1. 
 
Discussion | The researchers cannot confirm that the lesions are due to the coronavirus. However, these lesions are rare, and there are a large number of consultations on these lesions. Furthermore, these patients are in Spain, where there are a large number of cases. Thus, it is highly possible that there is a correlation between the lesions and the coronavirus. Other countries, including Italy and France have also reported similar symptoms in patients.	The researchers hypothesize that the lesions may be a late indication of COVID-19. At the time that lesions were reported, Spain was several weeks after the peak number of cases. Also, patients often reported contacts with COVID-19 several weeks before noticing the lesions. The negative PCR test in some patients can be due to no infection, a false negative, or that the patient has already largely recovered.	Dermatologists are not sure if the lesions are due to vasculitis (the inflammation of blood vessels) or microthrombi (small clots). They indicate that the lesions are different from various forms of ischemia (low blood flow). At this time, dermatologists are not able to biopsy the lesions.	Researchers still need to confirm this hypothesis. Meanwhile, the lesions may help diagnose patients who are asymptomatic. When the opportunity arises, a reverse transcription polymerase chain reaction (RT-PCR) test and IgM - IgG serological tests need to be done on the patients. 
 
 
Significance / Abstract | Invasive species are species that are not native to a certain area. When they enter a new area, they can harm the area's environment, plants, and animals. This article is concerned with invasive species' potential to harm global agriculture. The authors of the article aim to determine which countries are hit the hardest by invasive species and which produce the most invasive species threat. 
 
Introduction | Invasive species cause crop loss, reducing food supplies and agricultural profits. With more countries trading crops with each other in the modern day, invasive species have more chances to travel and cause harm. The researchers in this article measure this harm with a value called invasion threat. Invasion threat represents the chance that an invasive species arrives and successfully inhabits a new area. For each country they studied, the researchers calculated chance of arrival by examining how often the country imports crops. To calculate how likely a species would thrive in a country, they examined the types of environments each species is most suited for. For each country, they summed up the invasion threat of all species that could be expected to enter it. This gave them an idea of a country's overall threat of invasion. They also examined each country's most important crops and whether they could be hosts for invasive species. All this information was then used to calculate the total amount a country would expect to lose in crops lost to invasion.The researchers also looked at the invasive species threat that each country generates for the rest of the world. They did this by examining how often each country exports food, as well as measuring the amount / variety of invasive species that live in the country. 
 
Results | Countries that are high agricultural producers also suffer the greatest financial losses from invasive species. These include countries like China, the US, Brazil, and India. However, developing countries suffer the greatest losses relative to the sizes of their economies. These include several countries in sub-Saharan Africa.China and the U.S. are the greatest sources of invasive species. Countries that are great sources of such species often suffer great losses due to invasion. 
 
Discussion | It is difficult to find a clear pattern of invasion among countries across the globe. This shows that there are many complex factors that dictate the impact invasive species can have on a country. Countries that import crops at high volumes don't necessarily lose the most due to invasion.Developing countries are the most impacted by invasive species because their economies are so dependent on agriculture. Many of such countries are in sub-Saharan Africa. Even though richer countries have more agricultural losses overall, agriculture is a much smaller part of their economies.The US and China are the greatest sources of invasive species in the world. This is because of their extensive trade as well as the high numbers and variety of invasive species in the two countries.There are several uncertainties in the study that the authors discuss. It is difficult to examine invasion threat in countries that have little to no history of invasion. The study also doesn't account for complex invasion processes. For example, there are processes in which there is a delay between arrival in a new area and invasion. There are also instances of arrivals that aren't followed by invasion. Moreover, it is hard to tell whether a species will affect one area differently than another. However, even when accounting for these uncertainties, the results of the study don't change much.From all this insight gained, the article calls for the formation of an international body to handle invasive species. Such a body should offer countries info and resources to reduce the spread of invasive species.This may be the first study to examine global invasive species threat on a country-by-country basis. 
 
Materials and Methods | Data on different invasive species and countries were collected from various databases. Statistical and other mathematical methods were used to draw insight from this data. 
 
 
Abstract | Since SARS-CoV-2 is thought to have originated from bats, it is of significant importance that we observe the susceptibility of other animals as a potential transmission route. In this study the researchers investigate how susceptible ferrets and other animals that are in close contact with humans are to SARS-CoV-2. The researchers found that SARS-CoV-2 replicates poorly in dogs, pigs, chickens, and ducks. However ferrets and cats are not as resistant to infection as the other animals studied. Specifically, cats appear to be susceptible to airborne infection. 
 
Background | SARS-CoV-2 is very similar to the coronavirus RaTG13 detected in horseshoe bats. This raises the question if other animals can participate in a cross-species infection. If they are able to be infected, then animals could serve as a potential stockpile of the virus. The symptoms that appear in humans vary wildly, therefore efforts for vaccine trials must use an animal model that responds to the virus in a similar fashion to a human. 
 
Methods | FerretsTo test ferrets as potential animal models they took pairs of ferrets and infected them with two different viruses. One was collected from the environment of the proposed animal market origin in Wuhan china (F13-E) and the other from a patient (CTan-H). After 4 days the ferrets were euthanized and all portions of their bodies were analyzed using PCR. This test was repeated with several more pairs of ferrets measuring RNA, temperatures and other symptoms. Viral Samples were collected via a nasal swab.CatsTo test cats the researchers infected them using the (CTan-H) virus isolated from a human patient. The researchers also tested for the difference that age might have on infection location and intensity. The same methods were used on both sub adult cats (6-9 months) and juvenile cats (70-100 days). Viral RNA was measured from the fecal matter as nasal samples posed a danger to the researchers. Uninfected cats were also placed within the same incubator chamber as an infected cat. The infected and purposefully not infected cats could not physically interact, but they were breathing the same air.DogsTo test dogs the researchers used five 3-month old beagles that were infected with (CTan-H) and housed with two purposefully uninfected beagles. Mouth and rectal tests were collected every two days for 14 days. Serum (portion of the blood) was collected from all the dogs on the 14th day. 
 
Results | FerretsOnly the respiratory tract showed any viral RNA for ferrets. All other portions of the ferret were either immune to infection or were simply undetectable via PCR. After doing some assay tests the researchers concluded that SARS-CoV-2 was able to bind and replicate inside the ferret's tonsils, nose, and soft palate. No virus was found within the lungs.CatsBoth sub adult and juvenile cat groups showed infection that was present in the tonsils, lungs, small intestine, nasal passage, soft palate, and trachea, but no other organs. Specifically the juvenile cats had significant scarring of lung tissue. This led to the death of some juvenile cats within 4 days. Generally, older cats seemed to fare better than younger cats. The purposefully uninfected cats that were kept within the same incubator also showed viral RNA within their fecal matter after 4 days. Which indicates that cats are susceptible to airborne infection.DogsOnly 2 of the infected dogs produced antibodies. All of the purposefully uninfected dogs did not produce any antibodies in their blood. These results show that dogs have low susceptibility to SARS-CoV-2. 
 
Discussion | Generally the researchers found that ferrets and cats are highly susceptible to SARS-CoV-2. Dogs have a low susceptibility, and other livestock including pigs, chickens, and ducks are not susceptible to the virus. Ferrets are commonly used as an animal model for the study of human respiratory diseases. Therefore, It is vital that the infection found in either humans or ferrets be incredibly similar. SARS-CoV-2 replicates in both the upper and lower respiratory tract in humans. However in ferrets it is exclusively confined to the nose, soft palate, and tonsils. It has also been noted with decreased frequency to replicate in the digestive tract, as viral RNA was found in the rectal swabs of the virus infected ferrets. However, no virus was found in any of the lung tissue in any ferret. Several studies report that SARS-CoV-2 uses a receptor known as angiotensin converting enzyme 2 (ACE2) to gain access to the cell. Cats and Ferrets have a two amino acid difference in the virus contacting regions of ACE2. Therefore, the mechanism that prevents replication of SARS-CoV-2 in the lower respiratory tract of ferrets still needs to be investigated. However, ferrets still remain a suitable animal model to test antiviral drugs or vaccines because SARS-CoV-2 is able to replicate efficiently in the upper respiratory tract.  
 
 
Abstract	 | 	SARS-CoV-2 has been found in stool, gastrointestinal tract, saliva, and urine samples in the past. This study is the first to conduct research on the virus’s presence in semen. It should be noted that the study is limited in its sample size (only 32 semen samples from different individuals) and the extent of its data (no study of fetal development). With this being said, the paper states that semen may carry SARS-CoV-2, even in recovering patients. 
 
Introduction | 	A strong comprehension of a virus’s means of transmission is essential in preventing or controlling its spread. While COVID-19 is mainly passed from person to person via respiratory droplets, there are numerous other potential paths it may take. This study focuses on its presence in semen, paving the way for future studies on its sexual transmission and potential impact on fetal development. 
 
Methods | 	This study began with 50 males (15 years and older) with lab confirmed COVID-19. Only 38 samples were ultimately collected due to issues like erectile dysfunction or death. Data such as time since onset of symptoms, time since hospitalization, time since recovery (where applicable), presence of urogenital (relating to urinary and gential organs) disease, and comorbidities was gathered. Semen samples were tested in a lab for COVID-19.Of 38 patients who ended up supplying a sample, 23 (60.5) had recovered prior to the study and 15 (39.5) were at the acute stage of their infection. 
 
Results | 	6 patients (15.8) had semen samples which tested positive for SARS-CoV-2. A significant finding is that 2 of 23 (8.7) patients who were recovering had samples which tested positive. The data mentioned above (age, urogenital disease history, etc) had no significant effect on test results. 
 
Discussion | 	The fact that some recovering patients had positive semen samples suggests sexual transmission may play a role in the spread of SARS-CoV-2 (future research required). Additionally, SARS-CoV-2 found in the male reproductive tract (due to imperfections barriers in male reproductive parts paired with local inflammation) may result in “privileged immunity of testes.” This study emphasizes its limited scope, but it poses many significant questions (some of which affect viruses previously deemed nonsexually transmitted).  
 
 
Abstract  |  Remdesivir is a nucleoside analog. Which means that its chemical structure imitates the chemical structure of a nucleotide. Nucleotides are how we store and transmit genetic information. SARS-CoV-2 uses this genetic language as well. To test Remdesivir it was given on a compassionate-use basis to patients hospitalized with confirmed COVID-19. A 9 day trial was conducted and the clinic data was collected for a one month period. This trial included severe cases of COVID-19 infection and compassionate-use of Remdesivir showed clinical improvements in 36 of the 53 patients (68). Measurement of its efficacy requires future randomized, placebo controlled trials.  
 
Background  | Older patients and those with preexisting respiratory or cardiovascular related conditions appear to be at the greatest risk. Remdesivir is a prodrug of a nucleotide analogue. This means that Remdesivir is metabolized by the body into the active form of the chemical. This imitates a molecule called adenosine triphosphate. This will in turn inhibit viral RNA polymerases which are responsible for the eventual creation of viral proteins.  
 
Methods  | Patients accepted into the trial were required to have met several requirements. They needed to be confirmed positive, needed to have blood oxygen saturation of less than 94, and several other blood tests. Blood tests, important patient values, and all adverse events were recorded daily. 
 
Results | Interestingly, 75 of patients were men and the age range was 23 to 82 years, while the median age was 62 years. At baseline (before treatment) a majority of patients (64) were receiving invasive ventilation.  In comparison to patients receiving noninvasive ventilation, those receiving invasive ventilation tended to be older, were likely to be male, and a higher prevalence of coexisting conditions. After a median of 18 days after the first treatment, 68 of patients showed an improvement in the level of oxygen support required. It is notable that 75 of patients undergoing ECMO stopped receiving it. By day 28 after therapy the total number of patients showing clinical improvement was nearly 84. A total of 32 patients (60) reported adverse events during the therapy. Generally, adverse events were more common in patients who initially were receiving invasive ventilation. A total of 23 of patients had serious adverse events such as multiple organ system dysfunction, septic shock, acute kidney injury, and hypotension. 8 of patients discontinued use due to worsening of preexisting issues. Discussion To date no therapy has demonstrated efficacy for patients with COVID-19. This is purely a preliminary report that describes clinical outcomes with a small group of individuals, 53 patients total. Currently the researchers trials show the best preliminary results out of all therapies tested. The authors specifically note lopinavir-ritonavir. However, the researchers study took on much more serious condition patients and thus comparing the studies is largely unfounded. Kidney issues were observed during this short term therapy, but no clear evidence shows kidney toxicity as of yet. There are many shortcomings of this trial such as: small sample size, short follow up duration, missing data, lack of certain molecular info, or a randomized control group. This study suggests that remdesivir may have clinical benefit in patient with severe COVID-19.         
 
 
Abstract: | The virus that originated in China, SARS-CoV-2, that led to Coronavirus Disease (COVID-19) at the end of 2019 has spread to 28 countries/regions infecting a confirmed 43,000 people. The virus is spread between humans through direct contact or through droplets. The incubation period is 6.4 days and has a reproduction number of 2.24-3.58 (i.e. it is expected that one case will give rise to 2.24-3.58 cases). The most common symptoms of COVID-19 are fever followed by cough. The drug remdesivir showed promising results in a COVID-19 patient in the USA and is now undergoing clinical trials in China. 
 
1. Introduction: | In February of 2020, the disease resulting from the novel coronavirus was named coronavirus disease or COVID-19. The virus itself was given the name severe acute respiratory syndrome coronavirus-2 or SARS-CoV-2.The primary suspect for the virus’s jump from animals to humans is a local fish and animal market. The human-to-human transmission, however, is far more dangerous. The virus can spread between humans through droplets or direct contact. Additionally, crowded hospitals, asymptomatic carriers, and the current prevalence of domestic and global travel make the virus so widespread. 
 
2. SARS-CoV-2 and COVID-19: | SARS-CoV-2 is very closely related to two bat-derived coronaviruses, bat-SL-CoVZC45 and bat-SL-CoVZXC21. Further RNA-based analysis found that SARS-CoV-2 has 98.7 nucleotide similarity to the coronavirus in horseshoe bats. Further evolutionary analysis of the virus suggests that it is likely a novel coronavirus independently introduced from animals to humans. With all the acquired findings, the best theory is that the virus started in an animal market in Wuhan and more specifically in a bat. 
 
3. Epidemiology: | Early trends in the outbreak demonstrates exponential growth with a basic reproduction range between 2.24 and 3.58. Further, early data suggests that the epidemic doubling time is between 5.8 days and 7.1 days. The mean incubation period for the virus is 6.4 days.The number of total cases of COVID-19 has been steadily increasing around the globe. However, within China, the number of new COVID-19 cases per day is declining. As of February 11, China leads the world in the number of COVID-19 cases by over 40,000. Nevertheless, 28 countries/regions have confirmed cases of COVID-19. At this time, the continent with no cases is Africa. The mortality rate of the virus is estimated to be 2.5 with 45,167 confirmed cases worldwide. 
 
4. Clinical Manifestations: | In a sample of 278 patients from different studies conducted during the early stages of the pandemic there were two main findings. The first finding was that all of the patients were older than 18 years of age. The second finding was that males comprised 61.9 of the patients in the sample population.The number of pediatric cases is relatively small. A study in Beijing reported that ~15 of the patients with SARS-CoV-2 pneumonia were children between the ages of 2-15 years.The study of the 278 patients showed that the most common underlying diseases for COVID-19 in adult patients were cardiovascular disease and hypertension. The most common symptoms (in order from most common to least common) were fever, cough, dyspnoea (difficulty breathing), myalgia (muscle pain), headache, diarrhoea. Fever was far more common than the other symptoms with nearly every patient in the study experiencing fever whereas the cough and dyspnoea being experienced in about ⅔ and ⅓ patients respectively. 
 
5. Imaging: | Two different studies on the radiological finding of patients with SARS-CoV-2 showed similar findings. Both studies showed the prevalence of ground glass opacity (GGO) and the studies also showed the prevalence of bilateral lung involvement and multilobe involvement.GGO is a broad term. One of the studies on the radiological findings of the patients showed prevalence of pure GGO, GGO with reticular and/or interlobular septal thickening, GGO with consolidation and pure consolidation. 
 
6. Potential treatment options: | Most of the patients received antiviral agents (such as oseltamivir, ganciclovir, lopinavir, or ritonavir) or antibiotics. A minority of patients (~15) received antifungal agents.Unfortunately, there has been no effective treatment of COVID-19. However, there are potential drug candidates such as antiviral agents, different inhibitors, chloroquine, and traditional Chinese medicines. Chloroquine has shown promising results in in vitro viral studies including HIV. Remdesivir has also shown promising results in controlling the coronavirus when used with chloroquine. Further controlled clinical studies can help verify these drugs’ efficacy. 
 
7. Outcomes: | Of the 278 patients mentioned earlier, amongst other findings, 25.9 required ICU admission, 20.1 developed acute respiratory distress syndrome, 8.3 required invasive mechanical ventilation, and 3.2 required extracorporeal membrane oxygenation for refractory hypoxemia. In addition, shock, acute kidney injury, continuous renal replacement therapy, and acute cardiac injury was observed in patients. There is dispute over the mortality rate of SARS-CoV-2, however, a recent study showed a mortality rate of 4.3. Nevertheless, the estimated real-world mortality rate may be lower than 4.3. 
 
8. Infection control and prevention: | The primary concern regarding the virus is stopping/limiting the spread of the virus across the globe. In order to reduce the chances of the virus spreading, the WHO recommends limiting/avoiding contact with people suffering from acute respiratory infections, frequently washing hands, and limiting contact with domesticated or wild animals. General hygiene etiquette can also help prevent the spread of the virus.Within the United States, the CDC has given guidelines to help slow the spread of the virus across the country. This includes assessing which individuals may have the virus and potential contacts that may subsequently have the virus. Additionally, assessment of people arriving from mainland China to the United States is required to slow the spread of the virus. Slowing the spread of the virus helps healthcare professionals and the general public prepare for the pandemic.In addition to the government helping slow the spread of the virus, the government should help limit the spread of misinformation regarding the virus. Given how easy it is to spread information, fake news regarding the virus may spread, which can be very dangerous. 
 
9. Unresolved issues: | There are many unanswered questions regarding COVID-19 and there is evidence that SARS-CoV-2 works differently than other coronaviruses. The virus has been found in some patients’ stool. However, it is currently under question whether SARS-CoV-2 can be transmitted through the faecal-oral route. Additionally, unlike other coronaviruses, there has been no evidence of SARS-CoV-2 being present in the environment. Another difference between SARS-CoV-2 and other coronaviruses is the efficacy of typical disinfectants. I.e. typical disinfectants are not very effective in killing SARS-CoV-2 in comparison to other coronaviruses. A third mystery about COVID-19 is regarding the spread. It is currently unclear whether or not travel bans positively impact the spread of the virus. Overall, there is not enough data to make general conclusions. 
 
10: Conclusions: | COVID-19 has threatened the globe and unfortunately, there is limited information regarding the virus. However, implementing infection control measures and monitoring the virus can lead to positive outcomes. 
 
 
Abstract  | This study looks at how effective social distancing is in a mid sized city. 20 of deaths were avoided in real cities that carried out social distancing.When the social distancing ended these rates went back up. This study suggests that social distancing allows hospitals to increase their capacity. It is necessary to have enough testing and self isolation to slow the spread of the virus. 
 
Introduction | On January 21st, Washington had the first confirmed case of COVID-19 in the US. On March 12th, the first set of social restrictions began in Washington. By March 25th, a stay at home order was put into place for 6 weeks. Researchers used Seattle, Washington as a model. This study predicts cases, hospitalizations rate, deaths prevented, and how effective social distancing is. 
 
Methods | This study used a model that separated their population into age groups. In each age group, there were several subcategories: susceptible, exposed, infectious, and removed. Susceptible people could get the virus. Exposed people had come into contact with the virus but were asymptomatic. Infectious were people who were positive for the virus. Removed people were those who had recovered or died. This study found that only 20 of cases were discovered, because 80 of cases were mild. This prevented those patients from being tested.In Washington, there were six weeks of time for SARS-CoV-2 to circulate between the first and second positive case. Then the social distancing period started. This reduced the contact rate for three age groups: less than 19, 20 to 59, and 60 or more. There were four models of social distancing used. Model 1 - Only adults over 60 years of age reduced social contact by 95. This model was used in some countries. When people tried to protect the elderly from harm. Model 2 - Adults over 60 reduced their contact by 95 and children both reduced their contact by 85. This model represents social distancing of the elderly and of school closures. As most contact for a child is done during the school day.Model 3 - Adults over 60 reduced their contact by 95. Adults 20 to 59 have either 25, 75, or 95 reduced contact. The child contact is not reduced. This model represents the elderly are social distancing. The adults have mixeddistancing. As this model accounts for the essential frontline workers and people who are able to work from home. However, some countries did not close their schools. This model accounts for this by having the children not social distance. Model 4 - Adults over 60 reduced their contact by 95. Adults 20 to 59 have either 25, 75, or 95 less contact. Children have 85 less contact. This model is similar to the US. As The elderly social distance the most, the adults are medium, and the schools are closed.  
 
Results | Infection PeriodFirst the infectious period of this model was set to only 5 days. In this case, the epidemic peaked after 85 days. When the infectious period increased to 8 days, the epidemic took 110 days to peak. Raising the infectious period lowers the infectious rate. Decreasing the infectious rate early on delays the peak. However, it fails to change the size of the pandemic.Models 1-4The study then looks at models 1 through 4 mentioned in the methods section, for an 8 day infectious period. Model 1 delayed the peak by 5 days. Model 2 delayed the peak by 23 days. Model 3 delayed the peak by 24 days. Model 4 delayed the peak by over 40 days. This study looked at other lengths of infectious periods. When the infectious period was shorter, social distancing was more effective. But still, this did not impact the height of the peak.ExecutionNext, they looked at how long social distancing was executed after the first case was identified. When social distancing started at day 50, the epidemic was delayed under every percent isolation condition. But the height of the curve did not change. When the social distancing was executed mid pandemic at day 80, all models did somewhat flatten the curve.              Hospitalization and Fatality Rates Here, the children group had the most impact by reducing hospitalizations by 75 and the total death rate by 80. This is because children might not need to be hospitalized. Despite this, the viruswill spreadto people 60 or older. Model 2 averted 87 of cases and model 1 averted 77 of cases, but models 1 and 2 still had similar hospitalizations and fatalities to each other. No matter the social distancing put into place, every model suggested that the epidemic would spike again after the social distancing orders were lifted.         
 
Discussion |      Many people are familiar with the term “flatten the curve” and this study addresses that. This study concludes several things about social distancing. Such as:1) Social distancing too soon after the first case will delay the pandemic, not flatten the curve. In order to flatten the curve social distancing must be executed during the “growth” phase of the pandemic.2) The effectiveness of social distancing is reliant on the ratio of susceptible, infected, and recovered people at the very start of the intervention. To predict the effects of social distancing accurate data on these factors is necessary3) As of April 2nd, the US was testing less people per million for COVID-19 than some other countries, like Italy.The future of social distancing relies on expanded testing.4) It is still unclear how long immunity to COVID-19 lasts after having the virus.This will continue to play a role in social distancing regulations in the US. If we have long term immunity, recovered people can go back work.If the immunity is lasting for a couple of weeks, they should continue to social distance.  These results should be handled with caution because this model is simplified. Social distancing can give communities vital time to prepare for the pandemic. And it can avert deaths for a small period of time. But it will likely not decrease the number of cases long term. Social distancing is also not helping economically or socially, and therefore not sustainable long term. So, it would be best to not rely entirely on social distancing. Rather implement a collection of methods to combat the pandemic. Interventions should be made globally because any imported cases could lead to a new outbreak. More aggressive measures should be taken to decrease as many deaths as possible.The limitations of this study include mathematics and information about COVID-19. Current research estimates of the infectious period of COVID range from 5 to 20. This is a wide range and leads to different results in the models of this study. Secondly, we cannot confirm that people of the same age group have the same ability to infect others. This study considered all all age groups had the same ability to infect others. Different countries have different population structures and health care systems. This could change the results in some countries. Finally, probability and mathematics can predict well, but also have the opportunity to over or under predict some factors in this study.                 
 
 
Abstract | Scientists have found that the COVID-19 virus binds to the angiotensin-converting enzyme 2 (ACE2) receptor to enter the cell. This study looks at how much ACE2 receptor is contained in the Central Nervous System (CNS) tissue. The ACE2 receptors in the CNS show if COVID-19 damages nervous tissue. 
 
Background | COVID-19 and GeneticsThe entire genome analysis of COVID-19 showed it was an RNA virus. This test also showed that COVID-19 was found before in bats in China.ACE2 Tissue ExpressionACE2 receptors are found at high levels in the lungs, heart, kidneys, intestines, brain, and testicles. This makes these organs targets for COVID-19. Researchers also want to know the effect of COVID-19 on nervous tissue since this has not been studied as much as the other tissues listed. ACE2 Receptors in the BrainIn other studies, SARS-CoV has caused nervous tissue death in mice when it entered through the nose. This has not been found in COVID-19, but the virus has been found in spinal fluid of deceased COVID-19 patients. Some COVID-19 patients lost their ability to breathe on their own, which may be caused by nervous tissue damage. This is all evidence that COVID-19 may interact with ACE2 receptors in the brain. 
 
Results | How COVID-19 uses ACE2 ReceptorsCOVID-19 and other types of coronaviruses used a protein called the spike protein (S1). S1 allows the virus to attach to the cell membrane and uses ACE2 receptors in the process. All of the S1 proteins are very similar in their genetics, but do have some differences. The differences allow the COVID-19 S1 to bind to the human ACE2 receptor better than the other coronaviruses do. The similarities show that these coronaviruses are related in structure and evolutionary background.How COVID-19 Enters the BrainSince COVID-19 can travel through the blood in humans, it is likely that the virus also has the potential to penetrate the blood brain barrier. The blood moves slower around the brain than in the rest of the body, which could give COVID-19 more time to find the ACE2 receptors and bind to them. If the blood vessels near the brain get damaged from the virus, the virus has an easier time getting to the brain. If there is vessel damage, there will be bleeding around the brain. This can be fatal before the virus has had time to cause any damage to the nervous tissue. Once the virus is in the brain, it can interact with the ACE2 receptors of neurons and cause damage. COVID-19 may reach the brain through the nose before it is able to get through the blood brain barrier. This may cause damage to the CNS and may explain the loss of sense of smell in a COVID-19 patient 
 
Conclusions |Though COVID-19 could cause fatal nervous tissue damage, the cause of most fatalities are from damage to the lungs, heart, or kidneys. But, understanding the role of COVID-19 in the nervous system could help improve treatment plans.       
 
 
Abstract | Famotidine is a drug commonly used for gastric acid suppression. Some researchers have pointed to it possibly stopping SARS-CoV-2 replication. This study tested whether famotidine use is associated with better outcomes in COVID-19 patients. These patients were hospitalized in a non-intensive care setting. They were exposed to famotidine within 24 hours of hospital admittance. The study found that famotidine use was associated with a reduced risk for death or intubation, and for death alone. Proton pump inhibitors, a similar group of medications that suppress gastric acid, did not have this association of reduced risk. Further trials are needed to investigate the effects of famotidine therapy on hospitalized COVID-19 patients. 
 
Introduction | Famotidine stops gastric acid production. It is often prescribed for stress ulcer prophylaxis, which tends to cause gastrointestinal bleeding without abdominal pain. In vitro (i.e., test tube), famotidine has displayed antiviral capabilities by preventing HIV replication. Famotidine may inhibit 3CLpro, which is essential to SARS-Cov-2 replication. 
 
Methods | This study included adults admitted to Columbia University Irving Medical Center or the Allen Pavillion from February 25th to April 13, 2020. These patients tested positive for SARS-CoV-2 upon presentation or within 72 hours following admission. Patients surviving less than 48 hours after admission or requiring intubation within 48 hours after admission were excluded from the study. 
 
Results | Famotidine use was independently associated with risk for death or intubation (Table 2, adjusted hazard ratio (aHR) 0.42, 95 CI 0.21-0.85). Age was also an independent predictor of poor outcomes in this study. 
 
Conclusions | In patients with COVID-19 who did not require urgent or semi-urgent intubation, famotidine use was associated with a significantly reduced risk of death or intubation. These results were specific for famotidine and COVID-19. The results also support the idea that famotidine use may decrease cytokine release during COVID-19 infection. These findings do not mean that famotidine has a protective effect in patients hospitalized with COVID-19. 
 
 
Abstract | 	Researchers looked for vaccine targets against COVID-19 by investigating genetic similarities between SARS-CoV-2, the virus that causes COVID-19, and SARS-CoV, which caused a major outbreak in 2003. The researchers identified B cell and T cell epitopes in the S and N proteins that are identical between the two viruses. For T cell epitopes, the researchers also calculated the percentage of the global and Chinese population that could be covered by vaccines that target these epitopes. The researchers proposed a final set of epitopes that could guide studies about vaccine development against SARS-CoV-2. 
 
Aims | 	The researchers wanted to find epitopes (the part of an antigen that an antibody targets in the immune response) that were identical between SARS-CoV and SARS-CoV-2. These epitopes are associated with known immune responses against SARS-CoV that could also be produced in SARS-CoV-2. These epitopes could be targeted in a vaccine against SARS-CoV-2. 
 
Introduction | 	There have been several recent coronavirus outbreaks, including Severe Acute Respiratory Syndrome (SARS) in 2003 and Middle East Respiratory Syndrome (MERS) in 2012. SARS-CoV-2 belongs to the same family as SARS-CoV and MERS-CoV, which cause SARS and MERS. There is a lack of understanding about immune responses against SARS-CoV-2, which makes it difficult to develop a vaccine. However, studies suggest SARS-CoV and SARS-CoV-2 are very similar, which means immune responses against these two viruses could also be similar.	Previous studies suggest that SARS-CoV is targeted by both humoral and cell-mediated immune responses. However, cell-mediated (T cell and B cell) responses have provided the most long-term and efficient protection. In addition, T cell responses against the spike (S) and nucleocapsid (N) proteins were the most effective.	The researchers analyzed SARS-CoV B cell and T cell epitopes. They compared these epitopes with SARS-CoV-2 sequences and selected ones that were identical. Because they were identical, immune responses against them could protect against both SARS and COVID-19. The researchers focused on S and N proteins since they have been found to provide effective and long-term immune responses in SARS. For T cell epitopes, the researchers also looked at their associated major historompatibility complex (MHC) alleles. The MHC is part of the genome that codes proteins essential for the adaptive immune system. Different MHC alleles are present in different individuals, so the researchers wanted to look for epitopes associated with MHC alleles that were present in a greater percentage of the population. This would increase the number of people who could be protected by a potential vaccine against that epitope. 
 
Results | Structural Proteins of SARS-CoV-2 are genetically similar to SARS-CoV, but not MERS-CoV	SARS-CoV-2 is more genetically close to SARS-CoV than MERS-CoV based on comparing their genomes. This is also true at the level of individual structural proteins. The membrane (M), N, and envelope (E) proteins of SARS-CoV-2 and SARS-CoV have over 90 genetic similarity, while the S protein has a lower but still high similarity. The similarity between SARS-CoV-2 and MERS-CoV was substantially lower for all proteins. The researchers decided to focus on S and N proteins as they produce long-term, strong immune against SARS-CoV.Mapping the SARS-CoV-Derived T Cell Epitopes That Are Identical in SARS-CoV-2, and Determining Those with Greatest Estimated Population Coverage	By using positive T cell assays, 115 SARS-CoV T cell epitopes were found and compared with SARS-CoV-2 protein sequences. 27 were identical between viruses and all were present in the N or S proteins. 19 of these epitopes were associated with 5 MHC alleles, and population coverage calculated from these alleles was low (59.76 for the global population, 32.36 for China). The MHC alleles for the remaining 8 epitopes were unknown and population coverage could not be calculated.	To identify T cell epitopes that could cover more of the population, the researchers considered epitopes that were found from positive MHC binding assays. They found 229 T cell epitopes that were identical between viruses, with 102 found in S and N proteins. Multiple T cell epitopes provided a global population coverage of 96.2, and 88.11 in China.Mapping the SARS-CoV-Derived B cell Epitopes that are Identical in SARS-CoV-2	The researchers used a similar approach in finding T cell epitopes for B cell epitopes. They found two kinds of epitopes: linear B cell epitopes and discontinuous B cell epitopes. Of 298 linear B cell epitopes, 49 sequences were identical between the viruses. 45 of these were found in the S or N proteins. The researchers also found 6 discontinuous B cell epitopes, all in the S protein. None were identical between viruses, but three of them were partially identical between viruses.	The researchers also found that many of the identical B cell epitopes associated with two subunits of the S protein, S1 and S2. 20 of the 23 linear epitopes in the S protein were found in the S2 subunit. Antibodies targeting these epitopes could protect against both SARS-CoV and SARS-CoV-2. The S2 subunit is less exposed and could be more difficult to target than S1. The 3 discontinuous epitopes were found in the S1 unit. However, these epitopes are not fully identical between viruses and vaccines targeting these epitopes might not be effective. 
 
Discussion | 	The T-cell epitopes found in SARS-CoV that are identical in SARS-CoV-2 are expected to cover a large population.	The B-cell epitopes found are in agreement with recent studies. The study suggests that vaccines targeting the S1 subunit in the SARS-CoV-2 S protein may not be effective. The S2 subunit may be more promising for vaccine development and should be explored further.	Overall, the proposed SARS-CoV epitopes are identical to SARS-CoV-2 and are potential candidates to guide vaccine development efforts. Further experiments must be done to confirm the potential of the proposed epitopes as vaccine targets. 
 
Methods | 	Whole genome sequences of SARS-CoV-2 were downloaded from GISAID. These sequences were aligned to a GenBank reference sequence and translated into amino acids. The amino acid sequences were then aligned using MAFFT. Reference protein sequences for SARS-CoV and MERS-CoV were also obtained from GenBank.SARS-CoV B cell and T cell epitopes were searched for on the NIAD Virus Pathogen Database and Analysis Resource. The researchers limited their search to epitopes that were experimentally confirmed.Population coverage for T cell epitopes were computed using the Immune Epitope Database (IEDB). This tool uses the distribution of MHC alleles within a population to estimate population coverage, which is the percentage of individuals that would elicit an immune response to a specific epitope.The researchers used a software called PASTA to construct a phylogenetic tree of each structural protein using their sequences for SARS-CoV, SARS-CoV-2, and MERS-CoV. 
 
 
Abstract | This study aims to see how nonpharmaceutical interventions impacted the 1918-1919 influenza pandemic in 43 US cities. They looked at the excess death rate compared to different interventions taken. The cities that took quick and consistent interventions had the least excess deaths. Those who layered different types of interventions also had lower excess deaths. We can use this data to help plan effective nonpharmaceutical interventions in addition to developing pharmaceutical interventions. 
 
Introduction | The influenza pandemic in 1981-1919 killed about 40 million people worldwide and 550,000 people in the US. Many pandemic planners think that nonpharmaceutical interventions, like social distancing and business closure, will not prevent the pandemic. But, nonpharmaceutical interventions may lower the total number of cases, lower the peak of cases, and lower the death count. This study uses data from 43 US cities to see if specific nonpharmaceutical interventions of each city were more effective during the three pandemic peaks. 
 
Methods | The researchers used the US Census Bureau's Weekly Health Index to assess 43 cities, all over 100,000 population size. They chose cities with most complete data. They also used all of the public health documents on nonpharmaceutical interventions of each city that were available. 
 
Data Analysis | The study covers September 8, 1918 through February 22, 1919. 23 million people died from the 43 cities in this study, 22 of the total US population. They assumed that each person contracted the flu 10 days before they died. The three main categories of nonpharmaceutical interventions were school closure, public gathering bans, and isolation/quarantine. The final category considered other changes like different work schedules, transportation restrictions, and mask wearing. But this category was hard to keep track of so it was not always included in the data analysis. Based on newspapers and records, this study classified cities as either activated (on) or deactivated (off) for nonpharmaceutical interventions on a given day. Cities were classified as activated when these interventions were enforced by law. This study measured weekly excessive death rates (EDR) for each city, based on the city having death rates about the nation’s average that week. The three main things they looked for were 1) the difference in time it took for the national average first peak and the city’s EDR peak, 2) the magnitude of the first EDR peak, and 3) the accumulative EDR over the entire 24 week period. They also looked at the public health response time (PHRT). 
 
Results | There were 115,340 total excess deaths in the 43 cities after 24 weeks. The most common interventions taken were combining school closure and public gathering bans. Layering the interventions was more effective in preventing excess deaths. Cities that had a faster public health response time had lower mortality rates. If the interventions were longer, this also showed lower mortality rates. This pandemic had three waves. The researchers found that the interventions taken over the first wave had nothing to do with the mortality rates of the second wave, and the same for the second to the third wave. The second and third wave had much higher mortality rates across the nation. None of they city’s size, density, sex distribution, or age distribution changed the mortality rates. 
 
Comment | Time of activation, duration, and combination of nonpharmaceutical interventions were important in lowering the mortality rate of the 1918-1919 influenza pandemic. The US Centers for Disease Control and Prevention recommend implementing nonpharmaceutical interventions when the first case is confirmed in an area. Since growth of a pandemic is exponential, it is important to act quickly when implementing interventions. For example, New York City took quick and drastic measures, and ended up having the lowest mortality rates on the East Coast. Pittsburgh, however, had a couple week delay before implementing interventions, and they experienced the highest excess mortalities. The three peaks seen in the pandemic were often seen after the city loosened its nonpharmaceutical interventions. In fact, no city experienced a second peak until after the nonpharmaceutical interventions were lifted.History cannot tell us exactly what is going to happen, but we can study the 1918-1919 pandemic in hopes to be more effective against the current pandemic. The society of the 1918-1919 pandemic has some similarities to ours now, but things are still very different. Public support and compliance with medical guidelines has drastically increased in the past 100 years. People now have much better access to information and have been more educated about the pandemic. We have significant advances in medical technology that have also helped us.Still, this study of the past reflects modern models of the pandemic, which only reaffirms that nonpharmaceutical interventions taken quickly and consistently have better outcomes. This study breaks successful interventions into 9 ideas: strength, consistency, specificity, temporality, dose response, biological plausibility, coherence, analogy, and experiment. 
 
 
Abstract | This was a retrospective study about the effect of hydroxychloroquine (with or without azithromycin) on in-hospital mortality and abnormal electrocardiogram findings. The study focused on adverse effects of this drug, opposed to its efficacy as a COVID-19 therapeutic. Records from 25 NY metropolitan region hospitals (representing 88.2 of COVID-19 patients in the area) were collected. Four groups were examined: patients receiving hydroxychloroquine and azithromycin, hydroxychloroquine alone, azithromycin alone, and neither drug. 
 
Introduction | 	As COVID-19 vaccines are still in development and testing phases, many healthcare professionals are experimenting with therapeutic agents as immediate treatment. Hydroxychloroquine (often in combination with azithromycin) has become a top candidate amongst these agents. Despite its popularity, few studies about the drug’s adverse effects have been conducted. This study aims to understand hydroxychloroquine and azithromycin prescription patterns, as well as their connection to in-hospital mortality and cardiac abnormalities (such as arrhythmia or QT prolongation). 
 
Methods | 	The medical records of 1438 lab verified COVID-19 patients (59.7 male, median age 63) from 25 hospitals were collected and analyzed. A two week sampling period was used to ensure complete complete discharge and sufficient patient follow up. 51.1 of patients received both hydroxychloroquine and azithromycin, 18.8 received only hydroxychloroquine, 14.7 received azithromycin alone and 15.4 received neither medication. Patient demographics, vital signs, and lab results were collected within 24 hours of hospitalization and for the duration of their hospital stay. 
 
Results | Based on chest imaging, O2 saturation measurements, AST, alanine, and aminotransferase tests, patients in the hydroxychloroquine with azithromycin group generally presented more severe illness. 95 of hydroxychloroquine with azithromycin presented abnormal initial chest imaging results (such as air space opacity, lung infiltrate, and pneumonia). 	Patients receiving both hydroxychloroquine with azithromycin had higher levels of ICU admission versus those on hydroxychloroquine alone or azithromycin alone (30.7 vs 19.2 vs 10.9 respectively). Hydroxychloroquine with azithromycin patients were also more likely to need mechanical ventilation.Adjusted results for in-hospital mortality showed no significant difference between any of the groups. Estimated mortality during the trial window was: 22.5 for hydroxychloroquine with azithromycin, 18.9 for hydroxychloroquine alone, 10.9 for azithromycin alone, and 17.8 for neither drug.Between all groups, arrhythmia and other abnormal electrocardiogram results were the most commonly reported adverse effects. Patients taking hydroxychloroquine in combination with azithromycin were more likely to experience such cardiac problems. Cardiac arrest was also more common in patients receiving both medications. 27.1 of patients receiving both medications together exhibited abnormal ekg findings and 15.5 experienced cardiac arrest (vs 14.0 and 6.8 respectively in the control group). 
 
Discussion | Results of this study suggest that hydroxychloroquine (with or without azithromycin) does not result in significantly increased in-hospital mortality. Patients receiving hydroxychloroquine combined with azithromycin were, however, more likely to experience cardiac arrest, arrhythmia, or other cardiac abnormalities. This statistic could, however, be affected by increased medical attention (more frequent screening) as patients taking both drugs generally exhibited more severe illness. 
 
 
Abstract | The transmission of SARS-CoV-2 through droplets is clear, but whether it can be transmitted through aerosols (airborne transmission) is not. This study investigated whether SARS-CoV-2 is transmitted through aerosols by measuring viral RNA in two Wuhan hospitals during the COVID-19 outbreak. The researchers found that levels of SARS-CoV-2 RNA in isolation wards and vented patient rooms was low, but higher in patients' toilet areas. SARS-CoV-2 levels were undetectable except in two areas prone to crowding. Some medical staff areas had high concentrations of SARS-CoV-2 RNA, but they decreased after strict sanitation measures were put into place. Although the infective potential of airborne SARS-CoV-2 is unclear, the researchers suggest that SARS-CoV-2 may be transmitted through aerosols. The findings suggest that room ventilation, open space, sanitation of protective wear, and disinfection of toilet areas can limit the concentration of SARS-CoV-2 RNA in aerosols. More work is necessary to understand infectivity of SARS-CoV-2 in aerosols. 
 
Aims | The researchers wanted to understand whether SARS-CoV-2 could be transmitted through aerosols by measuring viral RNA in two wuhan hospitals. 
 
Introduction | Transmission pathways of SARS-CoV-2 include inhalation of droplets, close contact with infected people, and contact with surfaces on which SARS-CoV-2 is present. Many respiratory diseases are spread airborne, including tuberculosis, measles, and possible SARS. The potential for airborne transmission of SARS-CoV-2 is not well-understood. 
 
Methods | In this study, the authors sampled airborne SARS-CoV-2 at 30 sites in two hospitals and public areas in Wuhan. They quantified the number of SARS-CoV-2 in these samples using droplet digital PCR-based detection (ddPCR). The two hospitals were used exclusively for COVID-19 patient treatment. Renmin Hospital was designated for treating severe symptoms of COVID-19, while Fangcang hospital was a makeshift field hospital that treated patients with mild symptoms.There were three categories of sample locations: patient areas, coronary care units and patient ward rooms in Renmin Hospital, medical staff areas, and public areas.In these locations, three kinds of samples were collected: aerosol samples of total suspended particles; aerodynamic size-segregated aerosol samples to determine the size distribution (a curve that determines the amount of particles present in a sample according to size) of SARS-CoV-2; and aerosol deposition samples to determine the deposition rate (the rate at which particles attach to surfaces) of SARS-CoV-2. 
 
Results | In general, very low or non-detectable concentrations of airborne SARS-CoV-2 were found in Renmin Hospital. This suggests that the negatively pressurized isolation units and good ventilation in the hospital were effective in limiting airborne transmission of the virus.The highest concentration of SARS-CoV-2 observed in patient areas was in the Fangcang hospital mobile toilet room. This is a small, temporary single toilet room without ventilation. In this setting, airborne SARS-CoV-2 may come from the patient's breath or from the patient's feces or urine.In public areas outside hospitals, a majority of the sites had little to undetectable concentrations of SARS-CoV-2 aerosol. Exceptions were a crowd-gathering site outside of a department store, and an area next to Renmin hospital where the public and outpatients passed through. These results suggest overall low risk of SARS-CoV-2 transmission in well-ventilated and open public areas, but also reinforce the importance of avoiding large gatherings of people.Inside the Renmin Hospital ICU rooms, two aerosol deposition samples tested positive for SARS-CoV-2. One had a higher deposition rate than the other. The sample with the higher deposition rate was placed in a corner of the room without any blockage, while the sample with the lower deposition rate was blocked by medical equipment. This suggests that aerosol deposition may play a role in surface contamination and the infection of people touching those surfaces.Medical staff areas had higher concentrations of SARS-CoV-2 aerosol compared to patient areas. In Fangcang Hospital, aerosol concentrations decreased after the implementation of rigorous sanitation procedures. This confirms the importance of sanitation in reducing airborne SARS-CoV-2.There are two size regions of SARS-CoV-2 aerosol, the sub-micron region (smaller) and the supermicron region (larger). The sub-micron region was dominant in protective apparel removal rooms in Fangcang hospital. The researchers hypothesize that this is because the aerosol on protective apparel of medical staff is resuspended and becomes smaller while they are being removed. This aerosol may originally come from patients' respiratory droplets, airborne SARS-CoV-2, or SARS-CoV-2 deposited onto the floor. 
 
Discussion | The findings of this study provide the first investigation into the airborne properties of SARS-CoV-2 in Wuhan. They suggest that toilet use by and crowd-gathering with COVID-19-infected individuals are important sources of airborne SARS-CoV-2. They also suggest that there is a pathway of SARS-CoV-2 transmission involving the deposition and resuspension of SARS-CoV-2 aerosols during the removal of protective apparel by medical staff. The researchers call for particular public health attention on the ventilation and sterilization of toilets, personal protection measures for the general public and avoiding busy crowds, sanitation of high-risk areas in hospitals, the effectiveness of ventilation in field hospitals, the surface sanitation of protective apparel before they are removed. 
 
 
Abstract | Based on genetics, SARS-CoV-2 is similar to SARS-related coronaviruses seen in horseshoe bats. This study tests small live tissue samples, called organoids, in horseshoe bats. The organoids in this study were made to mimic the intestines. These organoids can be infected with SARS-CoV-2. This shows that COVID-19 can affect the digestive system, not the respiratory system alone. This study compared stool samples and intestinal organoids from bats and humans, and found live virus in both. This suggests that SARS-CoV-2 can be spread through stool, not respiratory droplets alone. 
 
Introduction | It is common for bats to carry RNA viruses that cause severe disease in humans and other animals. Even though the outbreak of SARS-CoV in 2003 has increased our knowledge of coronaviruses in bats, many of the viruses we know about have not been studied well. This is because it is hard to study live bats in the wild. So, researchers can use stem cells to grow miniature tissues that mimic whole organs. These are called organoids. This is the first study to create successful bat organoids. Most organoid studies are done with human tissue. 
 
Methods | The research team used stem cells from the intestines of bats to grow the organoids. To grow them, they incubated the samples in different shaped containers and cell mediums to get the right shape and cell types. Medium is a liquid mix of different nutrients that help the cells grow. The researchers let the human and bat organoids mature. Thenthey were infected using a nasal swab from a COVID-19 positive patient. The researchers used PCR to see if their organoids were infected. 
 
Results | The intestinal organoids of humans and bats were both infected by SARS-CoV-2. The researchers then looked at how the different coronaviruses typically enter cells, and tested three of those potential methods. The three methods of cell entry they looked at were angiotensin-converting enzyme 2 (ACE2), transmembrane cellular protease human (TMPRSS2), and human endosomal protease cathepsin L (CTSL). They found ACE2 and TMPRSS2 at high levels in the organoids. CTSL was at lower levels than usual, which was expected for this test. The CTSL method is usually used by SARS-CoV and MERS-CoV, not SARS-CoV-2.Then the researchers look at how fast SARS-CoV-2 infected the organoids. In the bat small intestine organoid, infection rate was slower than the human small intestine organoid. The researchers also tested a human organoid that mimicked the large intestine, and this had the fastest rate of infection.The researchers also found that the cells called enterocytes had the highest level of infection. Enterocytes are the cells in the small intestine that line the inside of the intestine and absorb food. There was a test done to see which inflammation causing molecules were present in the organoids, but more research is needed to understand this data.The researchers isolated the virus from a COVID-19 positive stool sample to see if the virus in the stool still had the ability to infect other people. Live virus was found, suggesting that stool can infect people with SARS-CoV-2. 
 
Discussion | This study was able to make the first stable small intestine organoids of bats. This may make it easier to study other bat viruses in the future. Even though digestive issues are not the most common symptoms of COVID-19, they are still present. Some stool samples have contained live virus, even after the respiratory tests have come back negative and the patient was feeling better. Based on the results of this study, COVID-19 is more than a respiratory illness. It can also infect the digestive system and spread through stool.   
 
 
Introduction | This study aims to discover the tropism of SARS-CoV-2 to other organs. Viral tropism refers to the ability of a virus to infect other cells. SARS-CoV-2 mainly infects the cells of the lungs and respiratory system. The respiratory tropism can explain why we see respiratory symptoms in COVID-19 patients. But, the virus does interact with other organ systems as well. In this study, 27 COVID-19 positive patient autopsies were done to see which other organs SARS-CoV-2 can infect. Most of the patients had more than 2 other coexisting conditions. More coexisting conditions are linked with higher levels of SARS-CoV-2 in the kidneys. 
 
Methods | This study used PCR, immunohistochemistry, and confocal microscopy to assess the tissue samples. 
 
Results/Discussion | The respiratory system still had the highest number of SARS-CoV-2 virus per cell, therefore the highest tropism. But the kidneys, liver, heart, brain, and blood also had virus present. The kidneys were a target of SARS-CoV-2. The virus seemed to target the glomerular cells of the kidney, which make up the glomerulus. Since kidneys were a target for SARS-CoV-2, the researchers tested the RNA in these cells. There were high RNA levels of angiotensin-converting enzyme 2 (ACE2), transmembrane serine protease 2 (TMPRSS2), and cathepsin L (CTSL) in the kidney tissue. These are all molecules that help SARS-CoV-2 enter the cell. This may be why there is increased tropism in the kidney tissue compared to some other organs. The high tropism of the kidney tissue could explain why kidney damage can be seen in COVID-19 patients. Some COVID-19 patients who do not have severe respiratory symptoms can still have injury to their kidneys. 
 
 
Introduction | Even though more than six million people worldwide are in need of an organ transplant, only about 150,000 people get transplants in a year. One third of the patients who need an organ in the US get one per year. 7,600 people die each year on the organ transplant waiting list.Many individuals in the health care world have concerns about organ donation and transplantation during the COVID-19 pandemic. Patients receiving the organs may be more likely to get an infection or virus. The next concern is that hospitals will not have enough resources to support transplant patients Oftentimes, patients will need care from doctors in many specialties. This study looks at the effect of COVID-19 on organ transplantation in France and the US. 
 
Methods | The researchers used information from Public Health France, Center for System Science and Engineering, National Organ Procurement Agency, and United Network for Organ Sharing to compare COVID-19 cases with organ donation and transplantation.  
 
Results | The rate of organ transplantation in France decreased by 90.6. The rate in the USA decreased by 51.1. Kidney transplantation decreased the most. Heart, lung, and liver transplants were also decreased. In areas with few COVID-19 cases, organ transplantation was still decreased. 
 
Discussion | As the COVID-19 pandemic spreads around the world, medical resources will continue to decrease Officials will have to make tough decisions about how to distribute medical resources. This could mean less transplants are being done. Organ transplantation is a well structured and necessary medical field. So, the reduction in transplantation shows that any field in medicine can suffer due to COVID-19. With careful monitoring of the situation, organ transplantation can resume as soon as possible.               
 
 
Summary | In the past month, there was an outbreak of Kawasaki disease﻿﻿ in the Bergamo province. Researchers compared past cases of Kawasaki disease before and after the SARS-CoV-2 pandemic.19 patients had Kawasaki disease from 2015 to Feb 17th 2020. There have been 10 cases of Kawasaki disease from Feb 18th to April 20th, 2020. The rate of Kawasaki disease incidence has increased by 30 times. A similar increased rate is expected in other countries affected by the SARS-CoV-2 outbreak. 
 
Introduction | Bergamo has had the highest rate of cases and deaths from SARS-CoV-2 in Italy. In adults, severe cases cause pneumonia and inflammation. Children usually don’t have severe respiratory complications. But, the cytokine storm caused by our own immune system can be very damaging to all age groups. Kawasaki disease is caused by inflammation to medium and large sized vessels in children. Some complications are Kawasaki disease shock syndrome (KDSS) and macrophage activation syndrome (MAS). The cause of this disease is unknown, but was thought to occur after an infection that would trigger the disease. 
 
Methods | Past cases of Kawasaki disease were reviewed from records of Hospital Papa Giovanni XXIII in Bergamo, Italy. Diagnostic criteria of Kawasaki disease includes: fever for more than 5 days; with non liquidy eye redness; changes of lips and mouth; swollen lymph nodes; rash; reddening of the palms and feet; and thickening and hardening of the hands and feet. They also looked at low red blood cells count, high platelet count, low albumin, high liver enzymes, high white blood cell count, white blood cells in the urine, aortic aneurysm, or other cardiac dysfunction. KDSS occurs when there is a drop in blood pressure and the body cannot get enough oxygen.The hospital records showed the blood work, EKG results, and whether the patient had come into contact with a COVID-19 positive person. The patients and their caregivers were tested by nasal swab and RT-PCR for SARS-CoV-2. Some of the more recent patients were tested for IgG/IgM antibodies for COVID-19.Patients were given aspirin, intravenous immunoglobulin, and methylprednisolone. This is the typical treatment for Kawasaki disease. 
 
Results | Group 2 consists of those who were diagnosed with Kawasaki disease from Feb 18th to April 20th, 2020. Group 2 has ten members between ages 2 and 16. 5 of the children had complete Kawasaki disease, meaning they had more of the symptoms. 5 of them had incomplete Kawasaki disease. Various patients met different criteria of the disease at different severities. 8 out of the 10 patients tested positive for SARS-CoV-2 or COVID-19 through nasal swab, RT-PCR, or IgG/IgM antibody tests.Group 1 consists of patients who were diagnosed with Kawasaki disease before the COVID-19 outbreak. There were 19 patients diagnosed since Jan 1, 2015. On average, there are 0.3 patients diagnosed a month in Group 1. But Group 2 showed an incidence of 10 per month. The average age of Group 1 diagnosis was 3 years, but the average age of Group 2 diagnosis was 7.5 years. Group 2 had lower white blood cell and platelet counts than Group 1. In addition, Group 2 had more severe effects of Kawasaki disease than Group 1. 60 of Group 2 has irregular heart rhythms, but only 10 of Group 1 saw this complication. Steroid treatment was required for 80 of Group 2, but only for 16 of Group 1. 
 
Discussion | The first cases of Kawasaki disease have been documented over 50 years ago, but there is still no known cause. The main possible cause is a rare immune response to some type of disease. Previous studies have been done to identify other coronaviruses as the cause of Kawasaki disease as early as 2005 in New Haven, CT. But these studies have shown mixed results compared to Japanese studies, which is where Kawasaki disease was first identified.Since the COVID-19 related outbreak of Kawasaki disease has more severe and slightly different presentations, the researchers have decided to call this “Kawasaki like disease.” Compared to Group 1 Kawasaki disease patients, Group 2 Kawasaki-like disease patients is they were older and had lung issues, digestive issues, and heart issues. The kawasaki-like disease is overall a more severe disease, so the patients were given steroids.Since Kawasaki disease occurs weeks after the initial infection, this may explain why no trigger has been linked directly to the disease. Testing for IgG/IgM antibodies is a better way to look for triggers of Kawasaki and Kawasaki-like diseases than RT-PCR and the nasal swab.This study recommends physicians to consider steroid treatment for Kawasaki-like disease patients with a positive SARS-CoV-2 IgG/IgM antibody test or another positive COVID-19 test. 
 
 
Abstract  | The purpose of this study is to discuss the effect of COVID-19 on the central nervous system (CNS). Databases were searched for relevant articles. Very little information is currently available. However, two studies provide documented data. The involvement of the central nervous system in COVOID-19 infections is largely unexplored and understudied. However, it is very likely that there is neurological involvement in severe patients.  
 
Introduction | Coronavirus primarily targets the respiratory systems, but it can invade the central nervous system as well. The symptoms of coronavirus appear in roughly 5 days. Mild patients have symptoms of headaches, cough, fever, and fatigue. In the most severe cases, patients can have pneumonia, multiorgan failure, and severe respiratory or cardiac issues. However, coronavirus infections are associated with neurological issues as well. Seizures, encephalitis, and changes in mental status have all been reported. Once the virus enters the body via the olfactory bulb it causes inflammation and demyelination. Demyelination causes the loss of a protective fatty layer that covers neurons.  
 
Methods |  Databases were systematically searched for related articles. In various databases certain search words were used to acquire better results. 
 
Results |  Two articles were discovered that observed the involvement of COVID-19 with the central nervous system. One study found neurological conditions in 25 of patients. However, no specific tests were executed to further study the observation.  
 
Discussion  | Data on the evidence of central nervous system involvement is scarce and low quality. Only one study reported 25 of patients with a central nervous system issue. It is possible that patients becoming severe is a result of increased central nervous system infection. COVID-19 is similar to other coronaviruses in their viral structure and method of infection. It is possible that the mechanism the other coronaviruses use can mirror what COVID-19 may do. For instance SARS-CoV has been associated with neurological issues. So, it is likely that there are neurological issues in SARS-CoV-2. They must be carefully observed and investigated.  
 
Conclusion | Neurological involvement has not been studied appropriately yet. Despite this it remains to be highly likely that COVID-19 could infect and cause more severe symptoms. Further data collection is required.    
 
 
Abstract | This goal of this study is to see if levels of Vitamin D affects case rate and mortality rate of COVID-19 in European countries. It was found that with higher levels of Vitamin D, the case rate and mortality rate were lower. 
 
Background | In many other respiratory tract infections, Vitamin D helps to prevent more serious complications. But COVID-19 may be different because the virus interacts with ACE2 to enter the cell. Calcitriol, which is a form of Vitamin D, increases the amount of ACE2. So, higher amounts of Vitamin D might suggest a higher risk of COVID-19 infection. Stil, the researchers think that Vitamin D will protect against COVID-19 since it has that effect in other respiratory infections. 
 
Methods and Results | This study compared average Vitamin D levels with cases of COVID-19 and deaths caused by COVID-19 in European countries. High Vitamin D levels are associated with low case rate and low death rate. 
 
Discussion | Vitamin D deficiency is defined by a level lower than 30nmol/L. The average values for the elderly population in Spain, Switzerland, and Italy are all under 30nmol/L. These countries have a high death rate in their elderly populations. Anyone worldwide can have a Vitamin D deficiency, but the levels naturally lower with age. Lifestyle and genetics also play a role in Vitamin D deficiency. This is why low Vitamin D trends are seen in different countries who eat different foods, have different activities, and have different genetics.To confirm that Vitamin D is protective against COVID-19, we can look at this relationship in other respiratory diseases. Though Vitamin D can increase ACE2 levels and could potentially increase the infection rate of COVID-19, Vitamin D plays a big role in the immune system. Vitamin D is necessary for some white blood cells to mature. It also plays a role in the body’s ability to detect infected cells. Finally, Vitamin D helps create some of the enzymes that are toxic and can help kill diseases.Even though SARS-CoV-2 uses ACE2 to enter the cells, studies have shown that higher levels of ACE2 actually protects against serious COVID-19 issues. In studies done on rodents, ACE2 has decreased rapidly in elderly rats compared to young and middle aged rats. ACE2 also decreased more in male rats than female rats.The data used in this study is limited because there are many other variables involved for every country like access to testing and social distancing measures. Future studies should be done to confirm that Vitamin D is protective against COVID-19. 
 
 
Abstract | It is important to understand how SARS-CoV-2 infects the cells so that medications and vaccines can be safely developed. This study looks at angiotensin-converting enzyme 2 (ACE2) and Ang 2 receptor-1 (AT1-R). Some treatments involving ACE2 and AT1-R are recombinant ACE2, ACE inhibitors, AR1-R blockers, Ang 1-7 peptides, and Janus kinase-signal transducer inhibitor (JAKinibs). 
 
Background | SARS-CoV-2 causes a wide range of symptoms and severity. It has a high infectivity and mortality rate. Therefore it is vital to understand how the virus works. This is instrumental in the process of developing antiviral medications or vaccines. 
 
Angiotensin-Converting Enzyme 2 | ACE2 has been highlighted because SARS-CoV-2 uses it to enter the target cell. ACE2 helps to maintain blood pressure, so it is found in the heart, lungs, kidneys, brain, testes, liver, and small intestines. In normal cells, ACE2 inactivates angiotensin 2 (Ang 2) by cutting it and turning in into Ang 1-7. Ang 2 increases blood pressure, so ACE2 lowers blood pressure when it cuts Ang 2. SARS-CoV-2 finds ACE2 on the outside of a cell and binds to it, which causes a process called endocytosis. In this process, SARS-CoV-2 and ACE2 enter the cell. This causes Ang 2 levels to rise, which will lead to acute respiratory distress syndrome (ARDS). ARDS is fatal for many patients.One medication strategy could be a medication that binds to ACE2 better than SARS-CoV-2, so the virus can never even enter the cell. There can be issues with this option though-- like the dosing, method of ingestion, and possible side effects. This medication could be effective if it was taken very early on in the course of the viral infection. 
 
Angiotensin 2 Receptors | Ang 2 interacts with a receptor called Ang 2 type 1 receptor (AT1-R) that deals with a lot of cardiovascular and renal functions. AT1-R blockers (ARBs) have been looked at as a possible treatment for COVID-19, but there are conflicting results of these studies. One study has shown that elderly patients already taking ARBs for high blood pressure may be less likely to have a severe COVID-19 case. ARBS and other medications like recombinant ACE2, ACE inhibitors, and Ang 1-7 peptides may prevent cardiac or lung damage from COVID-19. But, it may be harmful to stop these medications. So, people who are already taking these medications for their underlying health conditions should continue use advised by their health care provider.ATI-R and Cytokine Signaling through the Janus Kinase-Signal Transducer and Activator of Transcription Pathway in COVID-19The Janus kinase-signal transducer and activator of transcription (JAK-STAT) is the name of the pathway that Ang 2 uses to function. JAK-STAT is also the pathway that coordinates the different components of the immune system. As Ang 2 levels increase, immune function and inflammation increase in the same area. There are two proposed explanations for this relationship. First, AT1-R activates the JAK-STAT system. The second explanation is for patients with a severe COVID-19 case and is called a cytokine storm, which means a large amount of inflammation causing factors are released by immune cells. Then, the immune system has a bad reaction to all of the inflammation, and causes organ failure. 
 
JAK inhibitors | JAK inhibitors are currently used to treat rheumatoid arthritis. Compared to other JAK inhibitors, Baricitinib may be the most effective against COVID-19. Baricitinib would stop SARS-CoV-2 from assembling and would reduce inflammation in patients with ARDS. Baricitinib can also stop the virus from entering the cell. JAK inhibitors may not be perfect though because they can weaken the immune response too much and affect red blood cell levels. But, antiviral medication like remdesivir coupled with a JAK inhibitor may be very effective. Many other JAK inhibitor medications are going through trials for different immune diseases, with varied results and side effects. JAK is recommended to be given only to those who are hospitalized with severe cases of COVID-19 since 80 of patients can heal with their immune response alone. More studies must be done to confirm JAK inhibitors as a method of treatment for COVID-19. 
 
JAKinib Monotherapy or Combination Therapy with MTX | Methotrexate (MTX) is currently used to treat autoimmune diseases and some cancers. It works through the JAK-STAT pathway to reduce inflammation. MTX is being studied to see if it would be more beneficial when paired with a JAK inhibitor. Some specific JAK inhibitors do show some improvement when taken with MTX, but some studies contradict these trials. These medications cannot tell healthy cells from diseased ones, so researchers and physicians must proceed with caution in pairing these medications. 
 
Conclusion | Targeting ACE2 and AT1-R for the treatment of COVID-19 is promising. However, more studies need to be done on recombinant ACE2, ACE inhibitors, ARBs, and Ang 1-7 peptides as use of COVID-19 treatment. JAK inhibitors may be successful in treating COVID-19 because they reduce lung, heart, and kidney damage while also reducing some inflammation in ARDS patients. The combination of baricitinib and MTX may be the most effective against COVID-19. But, MTX is only needed in a small dose to be effective, so it may be a cheaper and safer option to use alone, without JAK inhibitors. JAK inhibitors tend to be more expensive and have more side effects.     
 
 
Abstract  | The outbreak of coronavirus has created concern for transmission from mother to fetus. Databases were searched for all relevant academic articles. A review of 13 final articles published has revealed that COVID-19 can cause fetal distress, miscarriage, respiratory distress, and preterm delivery. However, it does not infect newborns. There is no documented transmission from mother to baby. Pregnant women experience the same symptoms as non-pregnant women. It is important to document women before and after delivery to get more data. 
 
Introduction | Coronavirus continues to spread in nearly every country. At the time of this studythe exact method of transmission is to be determined. It is now known that the virus travels in respiratory droplets like the flu. Viral pneumonia is the leading cause of pregnancy deaths worldwide. Since COVID-19 can cause pneumonia it is vital to understand how it may affect mothers.  
 
Methods |  
 
This is a narrative review done on all relevant information. Various databases were searched using strategic keywords and phrases.  |  
 
Results | No original research on COVID-19 has been done on this subject. However, there were five case studies, and other correspondence, commentaries, or letters available.Analysis of the reportsThis report studied a total of 37 pregnant mothers and 38 newborns. The age range of mothers was 23-40. Of these, 29 had cesarean delivery and 8 had normal. Of the 37 mothers, 6 had preterm labor, 6 has premature rupture of the membrane, 2 had abnormal amniotic fluid, and 2 had abnormal umbilical cords. The most common finding is lymphocytopenia. Lymphocytopenia indicates a higher susceptibility to infection because the white blood cell count is low. All neonates with COVID-19 were infected after birth from the cough of the mother or other relative. The most common symptoms of infected neonates were tachypnea, milk regurgitation, vomiting, cough, fever, pneumothorax, liver disorders, and pulmonary changes in chest CT scans. Formula was fed to all neonates.  
 
Discussion | There is no original research exploring the transmission of COVID-19 from mother to fetus. According to the studies reviewed mothers should refrain from breastfeeding until they are confirmed to be non-infectious. Similarly, all neonates and mothers should be taken care of in isolated rooms to avoid transmission. Mothers with confirmed COVID-19 should be treated with antibiotics and antiviral drugs after childbirth. Infection during pregnancy can cause complications for both the mother and the fetus. Infected newborns and mothers should be isolated. Due to lack of evidence researchers could not confirm transmission of COVID-19 infection from placenta, during delivery, or breast milk. Some research shows that neither cesarean or vaginal birth makes any difference in the possibility of infection. Generally, the review of available literature shows that there are less harmful effects of infection by SARS-CoV-2 than if by SARS-CoV-1. This study's results should be taken with precaution because the sample size was small. More research is needed. 
 
 
Abstract | It is necessary to understand the protective immunity (how antibodies created against a primary infection respond to secondary infection) of SARS-CoV-2 to develop vaccine and health strategies to end the pandemic. An important question that has not been answered is whether SARS-CoV-2 infection results in protective immunity during a secondary infection. In this study, the researchers developed a rhesus macaque (a kind of monkey) model of SARS-CoV-2 infection. They found that the monkeys had a large amount of virus in the respiratory tract, humoral and cell-mediated immune responses, and evidence of pneumonia. After the virus was cleared from the monkeys’ systems, the researchers infected them again. They found that the amount of virus present in the respiratory system and mucus lining of the nose decreased. The immune response against secondary infection was mediated by the adaptive immune response. The results show that SARS-CoV-2 induces protective immunity during secondary infection in monkeys. 
 
Aims | The researchers wanted to determine if SARS-CoV-2 infection would provide protective immunity against a secondary SARS-CoV-2 infection in rhesus macaques. 
 
Introduction | The rapid spread of COVID-19 has made the development of vaccine and health strategies a global priority. However, understanding of immune responses against SARS-CoV-2 is limited. It is unknown whether primary SARS-CoV-2 infection provides protective immunity against re-exposure in humans. This information is important for vaccine development, modeling of disease transmission, and public health strategies. In this study, the researchers develop a rhesus macaque model of SARS-CoV-2 infection and try to understand various features of infection and assess whether protective immunity is created or not. 
 
Results | Virology and immunology of SARS-CoV-2 infection in rhesus macaquesAfter primary infection, the monkeys showed high levels of viral RNA in the lower respiratory system and in the mucus lining of the nose. Viral RNA increased over time, suggesting replication of the virus. The monkeys showed decreased appetite and responsiveness, suggesting a mild form of the disease. Extreme symptoms such as death and respiratory distress were not observed.All monkeys developed antibodies against SARS-CoV-2 structural proteins and neutralizing antibodies, indicating activity in the humoral immune response. All monkeys also developed a cell-mediated immune response.SARS-CoV-2 infection induces acute viral interstitial pneumonia in rhesus macaquesThe researchers also assessed the pathologic (related to the cause and effects of diseases) characteristics of SARS-CoV-2 infection. They autopsied multiple regions of the body, and found high levels of viral RNA in the mucus lining of the nose, pharynx, trachea, and lung tissues. They found lower levels of viral RNA in the gastrointestinal tract, liver, and kidney.The researchers found that multiple regions of the body showed evidence of inflammation and viral pneumonia. Virus-infected cells were found in the lungs, randomly dispersed, and were suggested to replicate. They were also associated with inflammatory particles in the lungs.These results suggest that SARS-CoV-2 induced acute inflammation and viral pneumonia in many areas of the body that involved multiple cell types.Protective efficacy against rechallenge with SARS-CoV-2Upon secondary infection, the researchers observed very limited viral RNA on day 1 of reinfection and no viral RNA after. In controls, high levels of viral RNA was observed. Viral RNA was higher in the mucus lining of the nose than in the respiratory tract, but the researchers suggested that this was because the monkeys were infected through the nose. Little clinical disease was observed in the monkeys after reinfection.After reinfection, the monkeys showed fast response by the adaptive immune system. All monkeys developed adaptive antibody responses following reinfection. The researchers suggest that the protective immunity against reinfection was mediated by rapid response of the adaptive immune system. 
 
Discussion | Some viruses do not generate protective immunity for reinfection, such as HIV. There is no data about whether people who have recovered from COVID-19 have protective immunity against SARS-CoV-2. In this study, the researchers demonstrate that rhesus macaques generate protective immunity against SARS-CoV-2 and are protected from reinfection.The researchers developed a monkey model of SARS-CoV-2 infection that mimics human infection by the virus, including high levels of viruses in the respiratory tract and viral pneumonia. This suggests the potential of rhesus macaques as model organisms for immunological research and testing vaccines and therapeutics. However, no monkey models have led to respiratory failure or mortality. More research is necessary to create a monkey model of severe COVID-19 disease.SARS-CoV-2 infection led to humoral and cell-mediated immune responses that provided protection against reinfection. However, because of the near-complete protection observed in the monkeys, the researchers were unable to determine the immune correlates (measurable signs that the monkeys are immune) of protection. The importance of neutralizing antibodies, other antibodies, cellular immunity, and innate immunity in protection must be determined. Additional research is necessary to understand the longevity of adaptive immune responses against SARS-CoV-2.The results of this study suggest that immunological approaches to the prevention and treatment of COVID-19 is possible. However, because monkey models are so different from humans, clinical studies are necessary to determine whether SARS-CoV-2 infection provides protection against reinfection in humans. 
 
Methods | Evaluating immune response against primary infectionThe researchers infected 9 monkeys with various amounts of the SARS-CoV-2 virus through the nose and trachea. After infection, they quantified the virus by assessing viral RNA levels using PCR.To distinguish viruses used for infection and replicated virus, the researchers assessed E gene subgenomic mRNA (sgmRNA) using PCR. E gene subgenomic mRNA is only found in replicated viruses.The researchers evaluated the humoral immune response in infected monkeys using ELISA, a pseudovirus neutralization assay, and a live virus neutralization assay. They evaluated the cell-mediated immune response using intracellular cytokine staining assays.Evaluating pathologic characteristicsThe researchers infected 4 monkeys with SARS-CoV-2 and autopsied them on day 2 of infection.The researchers fixed tissue from the mucus lining of the upper airway, the trachea, and the lungs with formaldehyde and “froze” them in paraffin to understand the inflammatory response and diagnose pneumonia.Immunohistochemistry and RNAscope were used to detect clusters of virus-infected cells in the lungs.Cyclic immunofluorescence (CyCIF) was used to further characterize infected tissues.Evaluating immune response against secondary infection35 days after primary infection, the researchers re-infected the monkeys. They also infected 3 monkeys who did not undergo primary infection to serve as controls. 
 
 
﻿Abstract |  
 
Vaccine and therapeutic research is essential to curb the spread of SARS-CoV-2. The SARS-CoV-2 Spike (S) glycoprotein helps viruses enter cells. It is the main target of neutralizing antibodies, which bind to structures on viruses and prevent them from interacting with cells. In this study, the researchers describe multiple monoclonal antibodies, which are made by identical immune cells that are clones of a unique parent cell. These antibodies target SARS-CoV-2 and were identified from memory B cells of an individual who was infected with SARS-CoV in 2003. SARS-CoV is the virus that causes SARS, which had a major outbreak in 2003 and is related to SARS-CoV-2. One antibody found called S309 effectively neutralizes SARS-CoV-2 and SARS-CoV by engaging the S receptor-binding domain. The researchers used cryo-electron microscopy and binding assays to show that S309 recognizes an antigen that is conserved within sarbecoviruses, a family of coronaviruses that includes SARS-CoV and SARS-CoV-2. Combining different antibodies with S309 enhanced SARS-CoV-2 neutralization, and could limit the emergence of resistant mutants. The results suggest that S309 and combinations of other antibodies with S309 could be used to prevent SARS-CoV-2 infection or used after exposure to limit or treat severe COVID-19.Aims | The researchers wanted to identify neutralizing monoclonal antibodies against the SARS-CoV-2 S protein. They also wanted to test the efficacy of these antibodies in neutralizing SARS-CoV-2 infection. 
 
﻿Introduction |  
 
Coronavirus entry into cells is aided by the spike (S) protein. It is comprised of two functional subunits, S1 and S2. S1 is responsible for binding to the cell, while S2 promotes fusion of viral and cellular membranes. SARS-CoV and SARS-CoV-2 share 80 of S protein amino acid sequence. Previous research has shown that human-angiotensin converting enzyme 2 (hACE2) is a receptor for SARS-CoV-2 and SARS-CoV. The S1 subunit binds tightly with hACE2, which could contribute to the current rapid transmission of SARS-CoV.The S protein has been the main target for neutralizing antibodies and vaccine/therapeutic design efforts. Using monoclonal antibodies (mAb) could provide immediate protection against SARS-CoV-2. mAb therapy has been successful in other infectious disease outbreaks, such as Ebola. Previous research has identified and isolated neutralizing mAbs in people infected with SARS-CoV and MERS-CoV, both of which are related to SARS-CoV-2.﻿ResultsIdentification of a potent SARS-CoV-2 neutralizing mAb from a SARS survivorPreviously, the researchers identified a set of SARS-CoV neutralizing mAbs from a SARS survivor. The researchers wanted to determine the potential cross-reactivity of these mAbs against SARS-CoV-2. They found 19 mAbs in a blood draw from the survivor in 2004, and 6 mAbs from a blood draw in 2013. mAbs were evaluated for binding to SARS-CoV-2 and SARS-CoV S domains. The mAbs did not bind to S domains in other coronaviruses (OC43 and MERS), suggesting there is a lack of cross-reactivity of the mAbs outside of sarbecoviruses. mAbs S303, S304, S309, and S315 bound to SARS-CoV-2 and SARS-CoV bound to S domains particularly well.To evaluate the neutralization efficacy of the SARS-CoV-2 cross-reactive MAbs, the researchers performed pseudovirus neutralization assays. S309 was the strongest neutralizing antibody, followed by S303, S304, and S315.Structural basis of S309 cross-neutralization of SARS-CoV-2 and SARS-CoVThe researchers studied the mechanism of S309-mediated neutralization using cryoEM. They found that S309 recognizes an antigen of SARS-CoV SB, a subunit of the S1 protein. They also found that the SB subunit has an open and closed state. Both open and closed states are accessible to the S309 protein.The structural data from cryoEM explains the cross-reactivity of S309 in both SARS-CoV-2 and SARS-CoV. 17 of 22 residues on the antigen that S309 recognizes are identical between the two viruses. This suggests that S309 could neutralize virtually all SARS-CoV-2 isolates and strains, as well as other sarbecoviruses.Mechanism of S309-mediated neutralization of SARS-CoV-2 and SARS-CoVAntibody-dependent cell cytotoxicity (ADCC), is an immune mechanism through which cells can recognize and kill antibody-coated target cells. ADCC can contribute to viral control in infected individuals. The researchers observed efficient S309-mediated ADCC of SARS-CoV-2 infected cells. These results demonstrate that in addition to neutralization, S309 could aid in additional protective mechanisms against SARS-CoV-2. However, this possibility needs to be assessed in clinical trials for antibodies and/or vaccines.mAb cocktails enhance SARS-CoV-2 neutralizationThe researchers also mapped other antibody binding sites on SARS-CoV and SARS-CoV-2 SB domains to see if other sites could be recognized by the mAbs they found. They identified 4 antigens that could be targeted by mAbs. They evaluated the neutralization efficacy of different combinations of mAbs with S309. They found that two antibodies, S315 and S304, enhanced neutralization efficacy when used with S309. This suggests that mAbs could be used in combination to prevent or control SARS-CoV-2.﻿DiscussionS309 is a mAb with broad neutralizing against sarbecoviruses, including SARS-CoV-2. S309 neutralizes SARS-CoV-2 by recognizing a highly conserved antigen in the SB domain. In addition, S309 can contribute to ADCC and its neutralization efficacy is boosted by other neutralizing antibodies. The results indicate the potential to discover neutralizing mAbs, define antigens to target in vaccine design, and support preparedness for future sarbecovirus outbreaks. S309 may be an effective measure against SARS-CoV-2. |  
 
 |  
 
 |  
 
 |  
 
 
Abstract | It is important to understand how non-medical interventions impact COVID-19 transmission, especially to plan future measures to combat the ongoing pandemic. In this study, the researchers used data from American counties of reported infections and deaths along with data about how people move from place to place and a mathematical transmission model. Combining these three things, the researchers quantified changes in COVID-19 transmission in the U.S from March 2020 to May 2020. They found that the basic reproduction number (R0), which is the number of susceptible people who will be infected by one infected person, was reduced in major metropolitan areas when they used social distancing and other control measures. Mathematical simulations of what would’ve happened if these measures had been implemented 1-2 weeks earlier showed that a substantial number of deaths and infections would have been avoided. Specifically, 56.5 of reported infections and 54.0 of reported deaths would have been avoided if interventions were implemented 1 week earlier. The researchers also examined what would happen if there were delays in re-implementing social distancing after relaxing control measures. They found that a longer response time would result in a stronger rebound of infections and death. The results of the study show the importance of early intervention and against response in controlling COVID-19. 
 
Aims | The researchers wanted to understand how non-medical interventions, such as social distancing, impacted the transmission of COVID-19. They also wanted to see what would’ve happened if these interventions were implemented 1-2 weeks earlier. Finally, they wanted to see what would happen if re-implementation of social distancing was delayed after current control measures are relaxed. 
 
Introduction | COVID-19 has quickly spread in the United States after its first case in January 2020. Beginning in mid-March, control measures enforcing social distancing were implemented across the U.S. In other countries, these measures successfully controlled the spread of COVID-19. However, in the U.S the efficacy of these control measures has been less evident. It is important that changes in COVID-19 transmission by implementation of non-medical control measures be quantified in the U.S, so that the effects of earlier interventions on cases and deaths can be evaluated. 
 
Methods | The researchers used human mobility data (data about how people travel across the country) to inform a dynamic metapopulation model. This model represented SARS-CoV-2 transmission in 3142 U.S counties, and simulates documented and undocumented infections with separate transmission rates. They defined a separate transmission rate for counties with greater than 400 cumulative cases to reflect heterogeneity in transmission rates between counties. They also included the following parameters: ascertainment rate (the fraction of infections documented as confirmed cases), the latency period (the time that passes between being exposed to SARS-CoV-2 and having symptoms of COVID-19), the average duration of infection, and a parameter for how travel impacts transmission. 
 
Results | In six metropolitan areas (New York, New Orleans, Los Angeles, Chicago, Boston, and Miami), the basic reproduction number decreased after March 15th after social-distancing politics and practices were implemented, and continue to decrease. The ascertainment rate slowly increased in all six areas after April 5. These results indicate that non-medical interventions adopted in the U.S effectively reduced COVID-19 transmission in metropolitan areas.During the initial growth of a pandemic, infections increase exponentially. This means that a fast response and early intervention are important to limit infections and deaths. The researchers quantified the effect of earlier intervention in the U.S on infections and deaths. They performed two simulations in which the interventions were pushed back 1 and 2 weeks. The researchers found that if measures were implemented 1 week earlier, the U.S would have avoided 56.5 of cases and 54.0 of deaths nationwide. In New York, the pandemic epicenter of the U.S, 83.3 of cases and 85.6 of deaths would have been avoided. These percentages increased if implementations happened 2 weeks earlier. These dramatic reductions show the need for early response to the COVID-19 pandemic.Rapid response is also essential to avoiding rebounds in infections and deaths in locations that are reopening. The researchers quantified the effects of response time after reopening on infections and deaths using more simulations. They assume that control measures are relaxed beginning May 4, 2020 in all counties, resulting in an increased basic reproductive number. They used a response time of 2 and 3 weeks with a 25 weekly reduction in transmission rates. They found that for both 2 and 3 weeks, the number of daily confirmed cases declined for almost 2 weeks after easing control measures. This decreasing trend, along with a lab between actual infection and confirming infection, communicates a false sense of security that COVID-19 is under control. However, the researchers found a large rebound in cases and deaths peaking in early- and mid-June even after the implementation of control measures. A one-week delay in re-implementation of these measures resulted in 32,379 additional deaths by July 1, 2020. 
 
Discussion | Modeling of disease transmission is based on hypothetical assumptions, and does not reflect the real-world complexities of implementing public health interventions. However, countries with early responses to the viruses have seen a sharp decline in infections and deaths. This study found that if control measures were implemented in the U.S at a similar time, a dramatic decrease in infections and deaths could have been observed. The findings emphasize the need for continued caution after reopenings in various areas of the country. It is vital to balance the economic need for reopening and the health consequences it could cause. Many countries have achieved this balance. The strategies in these countries could be used to guide politics in the U.S, including broader testing and contact tracing. 
 
 
Abstract | Drosophila is a genus of flies that is commonly used as a model organism to study a variety of biological processes. The eyeless gene in Drosophila encodes a transcription factor. It is homologous (has a similar structure) to the Pax-6 gene and Aniridia gene in mice and humans respectively. Aniridia, Pax-6, and eyeless are all expressed during eye development. Loss-of-function mutations in these genes result in eye structures becoming smaller or being lost all together, suggesting that these genes are important in eye development. In this study, the researchers were able to target eyeless expression in imaginal disc primordia (a part of insect larva that gives rise to the outside of an adult insect). This resulted in the appearance of eye structures in places where eyes wouldn’t normally appear, including wings, legs, and antennae. These eyes were normal and even had fully developed ommatidia (units that make up compound eyes in insects) and photoreceptor cells, which aid in vision. These results show that eyeless is the master control gene for eye development. 
 
Aims | The researchers wanted to see if they induced the expression of eyeless where it is not usually expressed, what would happen. They also wanted to understand whether eyeless was the master control gene for eye development. 
 
Introduction | Mutations in eyeless result inpartial or complete absence of eyes. Sequencing of eyeless has shown that it encodes a transcription factor. Eyeless is homologous to Pax-6 in mice and Aniridia in humans, sharing over 90 of their sequence identities. In addition, several splice sites are conserved, indicating that these genes evolved from a common ancestor.Both Pax-6 and eyeless have similar expression patterns during development. In mice, Pax-6 expression is observed in the spinal cord, some regions of the brain, and the eyes. It is expressed in the eyes from the beginning to the end of eye development. In Drosophila, eyeless is expressed in the ventral nerve cord (analogous to the spinal cord) and in the brain. Later, it is expressed in structures that give rise to the eyes. It continues to be expressed throughout eye development.Because mutations in eyeless and Pax-6 result in the reduction or complete absence of eye structures, it has been suggested that they are the master control genes in eye development. Mutations in other genes associated with eye development do not affect the expression of eyeless, indicating that eyeless is expressed upstream of these other genes.Master control genes can be detected by their mutant phenotype (the set of observable characteristics resulting from genetic expression). Mutations in homeotic genes (genes that give rise to particular body segments or structures) have identified master control genes. These genes are characterized by a DNA sequence called a homeobox. Loss- and gain-of-function mutations result in opposite phenotypes. In addition, ectopic expression of these genes result in ectopic phenotypes. For example, ectopic expression of a gene called Antp has induced the formation of legs where antennae should be.Eyeless is different from homeotic genes in that loss-of-function mutations result in the loss of eye structures rather than a transformation. This shows that eyeless is required for eye development. If eyeless is the master control gene for eye development, ectopic expression of eyeless should induce the formation of eye structures on other parts of the body. To test this hypothesis, the researchers used the GAL4 system, a biochemical method used to study gene expression and function, to ectopically express eyeless. 
 
Results | Induction of ectopic eye structuresEctopic eye structures were induced in wings, legs, antennae, and halteres in Drosophila. The eye structures bulged out of the tissue in which they were induced, which could have resulted from minimizing contact surface between the eye tissue and non-eye tissue types. In some cases, ectopic eye development interfered with the differentiation of surrounding cells, resulting in less-developed eye structures. Well-developed eyes were most frequently observed on antennae and wings, but in some cases there were defects. Eye structures on the legs were smaller, but were relatively normal.Photoreceptors in the ectopic eyesAnalysis of the ectopic eye structures showed identical cells and structures in normal eyes. The researchers were able to distinguish various structures in the eye required for vision, including photoreceptor cells. The researchers analyzed nerve cell differentiation in these photoreceptors. The sequence of differentiation was the same in the ectopic eyes and normal eyes. This suggests the development of these ectopic eyes proceeds normally. Taken together, these observations show that eyeless can induce the formation of complete and developmentally normal eyes. It is unknown whether these eyes are functional.Role of eyeless in eye morphogenesisThe findings above indicate that eyeless is the master control gene for eye development, since it can induce ectopic eye structures. Eyeless is expressed first and controls a set of subordinate genes in eye development in a regulatory cascade. Eyeless may control later steps in eye development as well, being reused in different steps of eye development. This is supported by the fact that eyeless controls other functions besides eye development in the nervous system, and loss-of-function mutations in eyeless are lethal. The loss of eye structures alone is not the cause of lethality, so the lack of development in other structures controlled by eyeless must contribute to this lethality.The transformation of antennal, leg, and wing tissue into eye structures by eyeless expression suggests that eyeless is a homeotic gene. 
 
Discussion | The high degree of conservation between Pax-6, Aniridia, and eyeless in their genetic sequences, phenotypes, and expression patterns suggest that eyeless is a master control gene for eye development in invertebrates and vertebrates. This suggests that genetic control mechanisms of development are much more universal than previously thought. The researchers call for more research comparing the regulatory cascade in Drosophila eye development with that in mice to find out what the differences are and how new genes have been incorporated over the course of evolution. 
 
Methods | The GAL4 system was used to ectopically express eyeless. GAL4 can activate transcription of any gene if it is preceded by GAL4 binding sites.  
 
 
Abstract | The relationship between biodiversity and latitude is controversial. Research that includes immigration and not just origin or extinction support the “out of the tropics” model. This model indicates that taxa prefer to originate from the tropics. Then, they migrate to the poles while remaining in the tropics. Thus, the tropics are a cradle and a museum. 
 
Introduction | The latitudinal diversity gradient (LDG) is the phenomenon that as one moves from the poles to the equator (tropics), there is an increase in the number of species. LDG occurs in all different biomes. However, many researchers have disagreed over why and what led to the differences in variation at different latitudes. 
 
Cradles and Museums | Biodiversity of an area depends mainly on three factors. These factors are origination rates (O), extinction rates (E), and immigration rates (I). Thus, diversity in the tropics (DT) can be defined as OT - ET + IT (origination and immigration minus extinction). The diversity is analogous to the number of species. The diversity of the tropics is greater than the diversity of the extratropics (DE). The extratropics are areas that are outside of the tropics.The most basic model for LDG is when there is no immigration (IT = IE = 0). Thus, a greater diversity in the tropics is due to a higher rate of new species appearing or a lower extinction rate in the tropics compared to the extratropics. Or, the origination rate can be very high in the tropics to compensate for a higher extinction rate in the tropics.These models for biodiversity in the tropics are referred to as a cradle or a museum. In a cradle, the biodiversity is due to the high origination of new species in the tropics compared to the extratropics. The extinction rates and the immigration rates are the same. In a museum, the extinction rate of the tropics is less than the extinction of the extratropics, contributing to tropical biodiversity. The origination rates and the immigration rates are the same. To distinguish the two, one must look at the origination and extinction rates separately (Figure 1). Typically, areas that have a high rate of diversification are cradles. 
 
Rate Differences and Range Shifts | Besides the simple models of a cradle or museum, the researchers considered that that taxa may change geographic locations throughout time because of climate change. Another factor is that many taxa occupy both tropical regions and extratropical regions. Thus, it is necessary to consider the whole spatial distribution of taxa across time to understand LDG. 
 
Out of the Tropics: A Dynamic Model | The researchers suggest the “out of the tropics” (OTT) model, which indicates that the tropics are both a cradle and a museum. This means that there is a higher origination rate in the tropics and lower extinction rate in the tropics. But, there is an increased immigration rate to the extratropics (Figure 1). 
 
Testing the OTT Model | The researchers use the marine Bivalvia to study the OTT model. Bivalves clearly show LDG, and they currently live in all latitudes. Furthermore, there is a very rich fossil record of bivalves, which provide evidence of when and where bivalves appear.To test that OT &gt; OE, the researchers looked at the fossil record to find where and when a particular species first originated. The researchers took into account the proportion of living taxa within a bivalve family to overcome sampling bias. They find that the origination rate of species in the tropics is much greater than the extratropics origination rate of species.Testing that ET is less than or equal to EE, the researchers find that there is more bivalve extinction at higher latitudes. But, more data is needed to confirm this.To test that IT &lt; IE, the researchers compared where species originated and where they are now. They find that over 75 of species that originated in the tropics are now in extratropical areas. This indicates a very high immigration rate to extratropical regions. 
 
Insights from Modern Biogeography | Species are not as unique to a particular geographic location as the latitude decreases. Furthermore, species are older at higher latitudes, and the tropics contain both old and new species. Both are consistent with the OTT model, although more research and modeling needs to be done. 
 
Conclusion | The tropics are both a cradle and a museum. Species tend to originate in the tropics and then immigrate to areas towards the poles. Since the tropics are such a large source of new species globally, species at higher latitudes will be tremendously impacted if the tropics are ever in a crisis. 
 
 
Abstract | This study investigated the long-term mental health effects and their risk factors in Middle East Respiratory Syndrome (MERS) survivors. The researchers followed a group of MERS survivors for 12 months after the outbreak. They assessed PTSD and depression using the Impact of Event Scale-Revised Korean version (IES-R-K) and the Patient Health Questionnaire-9 (PHQ-9) respectively. The study found that 42.9 of survivors reported PTSD and 27.0 reported depression. Anxiety and stigma in the survivors when they had MERS were predictors of PTSD. Having a family member who died from MERS was a predictor of depression. This study finds that psychological and social factors influenced the mental health of survivors over a long period of time. Mental health support and efforts to reduce stigma may improve recovery. 
 
Aims | The researchers wanted to understand the long-term mental health effects and their risk factors in South Korean MERS survivors. 
 
Introduction | The MERS outbreak lasted from May to December 2015. Outbreaks of infectious disease affect both physical and psychological well being. Few studies have investigated the psychological impact of the MERS outbreak. This study explores mental health issues and related risk factors in MERS survivors 12 months after the outbreak to determine long-term psychological consequences. 
 
Results | 54 of subjects had at least one symptom of PTSD, depression, suicidality, or insomnia that was above the threshold for diagnosis. 42.9 of the participants had significant PTSD, and 27 had depression. 22.9 showed at least a moderate degree of suicidal risk. 28 reported significant insomnia. During MERS and 1 year after MERS, PTSD, anxiety, and depression were more severe and quality of life was worse in survivors with PTSD or depression. Survivors with PTSD reported higher scores for negative coping strategies.Previous psychiatric history, having a family member who died from MERS, depression and anxiety when infected with MERS, stigma, and negative coping strategies were factors associated with PTSD.Gender, previous psychiatric history, anxiety before MERS, having a family member who died from MERS, and depression, anxiety, and stigma when infected with MERS were associated with depression.Previous psychiatric history, anxiety, and stigma were predictors of PTSD 1 year after MERS. Previous psychiatric history and having a family member who died from MERS were predictors of depression 1 year after MERS. 
 
Discussion | The study confirmed a high prevalence of mental health issues in MERS survivors after the outbreak. Infectious diseases are not only serious medical illnesses but also psychologically traumatic experiences that can result in long-term psychological issues.The study found that psychological outcomes associated with infectious disease are affected by factors during the outbreak period, rather than 1 year later. This means that psychological factors and social factors may play an important role in psychological outcomes of MERS survivors rather than medical factors.The findings of this study suggest a need for appropriate psychological and social support during infectious disease outbreaks to reduce psychological distress in patients. Particular attention should be paid towards stigma, since it is the only risk factor found in the study that can be changed. 
 
 
Abstract  | Individuals with underlying medical conditions display a worse outcome after SARS-CoV-2 infection. This study looks at several underlying medical conditions and its effect on COvID-19 infections. Studies show that obese individuals are more likely to develop infections. The fat tissue serves as aviral reservoir, which makes it harder to control the infection. infection. Diabetic individuals show a higher rate of inflammatory conditions. Hypertensive individuals are treated with drugs to reduce blood pressure. These drugs often work through ACE2 and ARB receptors and are often inhibitors of ACE2 and ARB receptors. Use of these drugs can lead to increased production of ACE2 which is what SARS-CoV-2 uses for entry into the cell.People with obesity, diabetes, or hypertension have an uncontrolled release of pro-inflammatory cytokines. Cytokines are a small and broad class of proteins involved with cellular signaling. This can lead to what is known as the cytokine-storm phenomenon. As there are no currently approved SARS-CoV-2 antiviral therapy, efforts should be placed upon controlling the inflammatory response.  
 
Introduction | Diabetes, hypertension, and other cardiovascular disease (CVD) are strongly related to higher risks of mortality and severity with COVID-19 infection. The fat cells in obese patients increased pro-inflammatory cytokines and proteins. This can generate chronic alterations in body chemistry. It is thought that SARS-CoV-2, SARS-CoV, and MERS-CoV suppress antiviral IFN-gamma immune responses. In the late stages of infection this suppression causes a rapid increase in white blood cells. Neutrophils and monocytes/macrophages flood the body and release pro-inflammatory cytokines that can damage lung tissue.  According to genome sequencing, the human SARS-CoV-2 is 89 identical to bat SARS-like-CoVVZXC21. Analysis of all coronaviruses shows that bats acted as the primary transmission route of SARS-CoV-2 to humans. SARS-CoV-2 enters the cell in a similar way to SARS-CoV. Therefore, it is suggested that both use ACE2 receptors found in the lung tissue to gain entry to the cell.  
 
Methods  | The researchers searched databases such as PubMed up until April 23, 2020 using strategic keywords. The results were then cross referenced.  
 
Results  | ( 1 ) Metabolic Disease Around 25 of adults 40-49 years old have metabolic syndrome (MS). This percentage increases to 40 at age 60. When present, metabolic syndromes double the mortality of patients with diabetes. Metabolic syndromes also triple the mortality of those with cardiovascular diseases (CVD). Metabolic Syndrome can be controlled with action through the renin-angiotensin-aldosterone system (RAAS), which is a hormone system involved with blood pressure regulation.( 2 ) Obesity Obesity causes inflammation which results in metabolic changes that can cause other comorbidities. The over production of inflammatory adipokines (cytokines in fat tissue) from gut fat can affect the immune response, impair movement of white blood cells, and change the specificity of macrophages. This will prevent the right type of white blood cell from being produced, and prevent its movement to the proper site of infection. This can help to explain the cytokine storm that we observe in severely infected COVID-19 patients. This chronic inflammation is a result of insulin resistance. The increase in oxidative stress on the fat participates in the misregulation of the pro-inflammatory cytokines. This can produce metabolic syndrome. ( 3 ) Diabetes mellitus Diabetes mellitus (DM) is a major risk factor for severity and mortality for individuals infected with SARS-CoV-2. Studies have shown that diabetes mellitus is associated with increased inflammation of the lungs. The risk of diabetics cannot be eliminated. It can be reduced by controlling blood sugar. Diabetes was seen as an important risk factor in pandemic influenza (H1N1) in 2009, SARS-CoV, and MERS-SCoV. The human immune system used sugar polymers in a variety of host-pathogen and host-host interactions. The receptor that recognizes these sugars for the immune system is known as a C type lectin receptor (CLRs). These C type lectin receptors can also be activated via excessive blood sugar, which will lead to an uncontrolled pro-inflammatory immune response. Excessive glucose concentrations in the body could lead to possible changes in the way Spike protein of the virus binds to human cells. This could lead to changes in immune response and intensity of infection. ( 4 ) Hypertension Angiotensin converting enzyme (ACE2) is what SARS-CoV-2 uses to gain entry to the cell. ACE2 belongs to a class of receptors known as ACE receptors. ACEi are inhibitors of ACE receptors, including ACE2. ACE receptors are a part ofthe Renin Angiotensin System which is asystem made to help regulate blood pressure. When ACE inhibitors are used, it causes increased production of the ACE2 protein. This could be a risk factor as this could give SARS-CoV-2 more chances to gain cellular entry. However, a study has shown that patients using ACE inhibitors had a reduced inflammation response when infected with SARS-CoV-2. Thus, the group of patients using these ACE inhibitors had better clinical outcomes due to decreased inflammation. There is currently no evidence that ACE inhibitors cause increased production of ACE2 proteins. ( 5 ) Cytokine stormPatients with severe COVID-19 infections often have what is known as the cytokine storm (CS) phenomenon. This is an uncontrolled release of pro-inflammatory cytokines. This cytokine storm can be triggered by infectious diseases. The cytokine storm can result in systemic inflammation, multiple organ failure, vascular leakage, alveolar edema, and impaired T-cell response.  A review of studies shows that more severe patients with COVID-19 have higher levels of pro-inflammatory cytokines. When researchers used antibodies that would bind to these pro-inflammatory cytokines the patients had better clinical outcomes. ( 6 ) Vitamin D and immune responseVitamin D stands out as a potential immune system regulator. It becomes activated inside the body and turns into activated vitamin D (VD3) which can bind to its receptor VDR. The VDR receptor is produced in immune cells. When activated VDR can alter the production of other genes such as angiotensin converting enzyme (ACE) and VDR. According to a study reviewed by the researchers individuals with critical respiratory infections had reduced levels of VD3. When VD3 was given to these patients they observed a reduction of pro-inflammatory cytokines which resulted in better clinical outcomes. Vitamin D also plays an important role in the regulation of many metabolic pathways. It is vital for regulation of insulin and regulating blood pressure by regulating the ACE receptor production.  
 
Conclusion  | Individuals with cardiac or metabolic diseases are more susceptible to SARS-CoV-2 infection. The dysregulation of inflammation leads to a cytokine storm which causes damage to healthy cells. The role of medications used by those with diabetes, hypertension, or other cardiovascular diseases is debatable since they often lead to increased ACE2 expression. This receptor is associated with SARS-CoV-2 entry into the cell and thus increases the risk of infection. To lessen the immune systems dysregulation active vitamin D (VD3) shows promise as a regulator. It has shown that active vitamin D (VD3) can lessen the immune response and reduce associated complications.  
 
 
Abstract | This study provides the first evidence of mental distress and its predictors in Brazil during the COVID-19 epidemic. The researchers conducted a survey of 638 adults in Brazil one month after the first confirmed case of COVID-19 in Sao Paulo, the epicenter of the Brazilian outbreak. They found that 52 of the sampled adults experienced moderate distress, and 18.8 suffered severe distress. Female, younger, more educated adults reported higher levels of distress. The distance from Sao Paulo, age, and workplace attendance predicted levels of distress. The “typhoon eye effect,” in which people closer to the epicenter experience less distress, was stronger for older people or people who went to their workplace less. Adults most vulnerable to distress were far from the epicenter and did not go to work a week before the survey. Identifying these predictors may help mental health services to find and help vulnerable adults during the ongoing COVID-19 crisis. 
 
Aims | The researchers wanted to provide the first evidence of mental distress and its predictors in adults during the ongoing COVID-19 crisis in Brazil. 
 
Introduction | COVID-19 has quickly spread across Brazil starting in February 2020. Research has suggested that large-scale mental health issues have the potential to break out during the crisis. Early evidence from China suggests a higher prevalence of mental health issues during the COVID-19 outbreak. This study explores several predictors of distress that have been reported in other countries, especially distance from the epicenter of the epidemic. Identifying these predictors could help mental health professionals locate mentally vulnerable individuals and provide assistance online or over the phone. 
 
Results | Descriptive FindingsOf the participants, 57.7 were female and 42.3 were male. 78.7 reported negative for COVID-19, 0.9 reported positive, and 20.4 were unsure. 57.5 had not exercised in the past week, while 21.9, 6.9, 5.2, and 4.1 of the participants reported exercising 1, 2, 3, and 5+ hours per day respectively. 60.0 did not attend their workplace at all in the past week, 28.5 were in the office for fewer than five days, 7.9 went to the office for five days, and 3.3 went for six or seven days.The average COVID-19 Peritraumatic Stress Index (CPDI) score was 37.64, which was higher than China (23.65) and lower than Iran (34.54). Based on cut-off values of distress in CPDI, 52.0 experienced mild to moderate distress, and 18.8 experienced severe distress compared to 47.0 and 14.1 in Iran and 29.3 and 5.1 in China respectively.Predictors of individuals’ COVID-19 Peritraumatic Stress Index (CPDI)	Females experienced more distress than males. Younger people reported a higher level of distress. Adults who were more educated and exercised less reported a higher level of distress. Family size and workplace attendance did not directly predict CPDI.	The researchers analyzed the relationship between individuals’ distance from Sao Paulo and CPDI, and how this relationship related to age and workplace attendance. A “typhoon eye effect” was observed, such that mental health issues increased with increased distance from the epicenter. This effect was stronger in older adults, and the relationship between the distance from the epicenter and distress was positive. This relationship also depended on workplace attendance, and was significantly positive for adults who did not go to their workplace at all. This relationship was negative for those who went to their workplace every single day, showing a “ripple” effect in which distress decreased with increased distance from the epicenter.Predicted scores of individuals’ COVID-19 Peritraumatic Distress Index (CPDI)	In general, predicted values for CPDI in many groups were higher than the cutoff value for moderate distress.	CPDI was also predicted based on the interaction between age and distance from the epicenter. Individuals aged 18-25 years who were in the epicenter had the highest level of distress. Individuals aged 65 and above who were 3,300 km from the epicenter reported the second highest level. The least distressed group was people older than 65 in the epicenter.	CPDI was also predicted based on the interaction between workplace attendance and distance from the epicenter. Individuals far from the epicenter and did not go to their workplace in the past week had the highest level of distress. Distress was lowest among people who lived 3,300km from the epicenter and went to their workplace every day during the past week. 
 
Discussion | The study shows a high amount of distress in adults during the early stage of the COVID-19 outbreak in Brazil. Mean CPDI was worse than China and Iran. Individuals who were female, younger, more educated, or exercised less had more distress.Studies concerning the role of distance from the epicenter as a predictor of mental health are emerging. This study found that this distance’s effect on mental health depended on age and workplace attendance. The “typhoon eye” effect was only significant in age groups of 46 years and above, which could be because mortality by COVID-19 varies by age. This effect seemed to become a “ripple” effect for those who attended their workplace every day in the last week. Possible explanations could include fulfillment associated with work, social interactions at work, and less time online and on social media.The study also found that gender, age, education, exercise, and distance predicted distress in adults in Brazil during the COVID-19 epidemic.The researchers hope that this study helps mental health professionals and encourages more research on mental health conditions and predictors during the COVID-19 crisis worldwide. 
 
 
Abstract | In this study, the researchers wanted to understand if there were differences in the placentas of pregnant women with and without COVID-19. They identified pregnant women with COVID-19 and examined their placentas. The researchers compared these placentas with controls and with placentas of women with a history of melanoma (skin cancer). They found that placentas of women with COVID-19 were more likely to show signs of maternal vascular malperfusion (MVM), a form of placental injury related to altered blood flow that can cause maternal and fetal complications. 
 
Aims | The researchers wanted to describe tissue-related changes in the placentas of pregnant women with COVID-19. 
 
Introduction | There is a growing interest in how COVID-19 affects pregnant women and their infants. SARS, MERS, and COVID-19 are all related coronaviruses. In the 2003 SARS epidemic, around 100 pregnant women were infected and some had higher risk of severe infection, maternal death, and loss of pregnancy. MERS infection in pregnant women was also associated with poor maternal and perinatal (immediately after birth) outcomes. The effect of COVID-19 on mothers and infants is still unknown.Examining the placental tissue can give people information about the health of mothers and their infants. There is little information about the relationship between coronavirus infection and changes in placental tissue. In this report, the researchers present what they found in the placentas of 16 women with COVID-19 during pregnancy. 
 
Results | 16 placentas from women with COVID-19 were examined. 14 patients delivered at term, 1 delivered pre-term, and 1 lost her pregnancy. Fifteen cases were compared with 2 control populations. Symptoms of MVM were present in 12 patients, significantly higher than the controls. In addition, rates of insufficient supply of oxygen and nutrition to the placenta, arterial disease in the lining of the uterus, vascular lesions and cell death, and enlargement of blood vessels were higher in women with COVID-19. 
 
Discussion | The most significant finding was that pregnant women with COVID-19 had an increase in symptoms of MVM. MVM is associated with many fetal complications before and during birth. Of these symptoms, arterial disease in the lining of the uterus was most strongly related to COVID-19.Pregnant women with COVID-19 also showed an increase in the formation of blood clots in the space between villi (projections from the outer surface of the placenta) containing the vessels of the mother and infant. This may be in response to the virus.There was also an increase in chorangiosis, an increase in the number of blood vessels in the placenta, which is associated with decreased oxygen levels in the mother. However, it is difficult to draw any conclusions between COVID-19 and chorangiosis.One patient in the study lost her pregnancy. This may have been caused by acute inflammation from COVID-19. More research is necessary to define this relationship.No infants showed infection after birth, which agrees with existing evidence that COVID-19 transmission from mother to child is rare.These findings suggests that it may be necessary to keep a close eye on pregnant women diagnosed with COVID-19 and their infants. 
 
Methods | Pregnant women with COVID-19 were tested and identified.The researchers used historical controls, which means they used data from pregnant women who were examined in the past. Patients with a history of melanoma were also used, since their condition is unrelated to pregnancy complications.Placentas were examined using routine clinical examination.The researchers made comparisons between placentas of women with COVID-19 and historical controls as well as between placentas of women with COVID-19 and placentas of women with a history of melanoma. 
 
 
Abstract | This study tested the hypothesis that the recreational use of tobacco helps defend against parasites, namely helminths or parasitic worms. They investigated this relationship among the Aka, a remote population of foragers in Central Africa. They found that tobacco use was associated with lower worm burden (adverse health outcomes from parasites). They also found that populations who metabolized nicotine more slowly had lower burdens that those who metabolized them faster. The results support the hypothesis that substance use may help defend against parasites. 
 
Introduction | There is a history of plants and herbivores using plant neurotoxins to defend against parasites. Plants have toxins to deter or poison parasites. Herbivores self-medicate by eating neurotoxic plants to expel intestinal parasites. Similarly, humans have a long history of using plants for medicinal purposes such as protection against parasites. So, it is possible that the recreational use of psychoactive plant drugs can be partly attributable to their antiparasitic properties. 
 
Study | The impact of tobacco use on human helminthiasis, an infestation of parasitic worms, has never been investigated. Approximately one billion people are infected by one or more helminths. Nicotine, an anthelmintic that destroys parasites, is extensively used by the global population via smoking. Investigating the relationship between parasitic worms and smoking could be critical to the history of helminth diseases and the increase in smoking in the developing world. The researchers chose the Aka because they had locally available nicotine and a high prevalence of helminthiasis. 
 
Methods | The sample was comprised of 206 men and 44 women. Saliva samples were used to measure nicotine exposure. Stool samples were used to measure parasitic worm burden. 
 
Results | 97.9 of the total sample tested positive for at least 1 species of helminth infection. They found that high levels of nicotine were strongly negatively correlated with worm burden. This aligned with their hypothesis. Their results supported the idea that nicotine exposure was regulated in response to worm infection. Other causal mechanisms cannot be ruled out, of course. Smokers with slow-metabolizing CYP2A6 alleles (breaking down nicotine more slowly) should have higher nicotine exposure. This meant that they had lower worm burdens than those with normal or fast-metabolizing alleles. 
 
Discussion &amp; limitations | Tobacco use motivated, in part, by therapeutic benefits imply that signaling pathways exist between the immune and nervous systems that might be exploited to reduce smoking. Limitations and uncertainty about the mechanisms of this study must be kept in mind, of course. The project provides a new model system to test evolutionary theories of self-medication by humans and other primates. These results are the first to suggest an important relationship between smoking and helminthiasis, two of the world's most pressing health problems. 
 
 
Abstract | The study sought to clarify the role of boldness in defining psychopathy and distinguish psychopathy from antisocial personality disorder (ASPD). They used the triarchic model of psychopathy, which describes the disorder along the dimensions of disinhibition, meanness, and boldness, to achieve this. This study evaluated the degree to which aspects of the triarchic model are represented in the Psychopathy Checklist-Revised (PCL-R), in comparison with antisocial personality disorder (ASPD) as defined by DSM-IV criteria. The findings suggest that boldness is central to diagnostic conceptions of psychopathy and distinguishes psychopathy from the more prevalent diagnosis of ASPD. 
 
Introduction | The triarchic model of psychopathy proposed by Patrick et al. tries to reconcile alternative approaches to conceptualizing psychopathy. The triarchic model proposes that alternative conceptions of psychopathy differ in the relative emphasis placed on three distinguishable phenotypic features: disinhibition, meanness, and boldness. Disinhibition can be seen as an inability to regulate impulses and negative emotions. Meanness can be seen as intentional cruelty towards others. Boldness can be viewed as immunity to stress and being socially dominant (like a leader).PsychopathyPsychopathy is characterized by distinctive emotional and interpersonal features often in the context of chronic antisocial behavior marked by poor impulse control. Such emotional and interpersonal features include lack of empathy/remorse, shallow emotions, conning/deceptiveness, grandiosity, and glibness.ASPDASPD, as defined by DSM-IV-TR, includes a persistent behavior of breaking the law and/or hurting others as well as being impulsive, remorseless, deceitful, and aggressive. This usually begins in adolescence and continues into adulthood. 
 
Method | The study recruited adult male offenders from two distinct settings (n=157 and 169). 
 
Results | Unlike meanness and disinhibition, in no case did boldness add significantly to the prediction of ASPD. The results supported the hypothesis that the diagnostic criteria for DSM-IV ASPD reflect externalizing facets of the triarchic model (i.e. disinhibition and meanness) but, in contrast with PCL-R psychopathy, are unrelated to boldness. 
 
Discussion | Their findings fit with the idea that boldness is integral to definitions of psychopathy as a condition entailing severe behavioral sickness hidden by an outward facade of psychological health. Moreover, the interpersonal features of psychopathy (i.e. boldness) are what differentiate it most clearly from the more common diagnosis of ASPD. These findings provide support for a role of boldness in the definition of psychopathy as described in the triarchic model.  
 
 
Abstract |  Coronaviruses are a group of viruses that cause severe respiratory symptoms. Lipid membranes envelop the viral RNA. Viruses enter the cell through the endocytic pathway. Controlling this pathway has potential for developing treatments against coronaviruses.  
 
Aims |   The author writes to compare data that looks into the effectiveness of controlling the endocytic pathway as a treatment for coronaviruses. The author also presents possible treatments.  
 
Introduction  |   Autophagy and the Endocytic Pathway     A diverse range of organisms take part in autophagy. Autophagy is the process where a cell envelopes and breaks down material in a vesicle. An autophagosome refers to the vesicle and what is inside. The autophagosome binds with a lysosome that breaks down what is inside. The acidic material then breaks down what is inside the autophagosome. A similar process called the endocytic pathway takes in material outside the cell. The material taken in as well as the membrane surrounding it is called an endosome. This material is either broken down by a lysosome or sent elsewhere for recyclying. Figure 1  draws out both of these processes.      Implication of Autophagy in Coronaviruses' Infection     Data collected by researchers on Mouse Hepatitis Virus (MHV) implies the involvement of autophagy in copying the virus's DNA. ﻿This copying of the DNA is how a virus reproduces and spreads to other cells in the body. The structure that envelopes the DNA looks like an autophagosome. This then attracts proteins that will copy the viral genome. Data shows that coronaviruses are involved in this process.      Despite the evidence collected in the findings above, other researchers have found evidence to go against these conclusions. ﻿Snijder et al failed to show that the proteins related to autophagosomes present near the viral genome in the cell. ﻿This would mean that there may be other processes that control the copying of viral DNA. Table 1 illustrates this. It shows the data from several viruses and what the findings were.    Involvement of the Endocytic Pathway in CoVs Infection     The endocytic pathway is one of the main ways a coronavirus enters a cell. Data in Table 2 supports this claim. This table organizes each row by the virus tested and pairs it with the endocytic process studied.The inhibitors refer to what stopped the endocytic pathway from happening. Then "Main Findings" summarizes the results of inhibiting the "machinery" in that row.   
 
Discussion |    While autophagy's importance to the virus's infection is debatable, there is a large amount of support and evidence to suggest the endocytic pathway has great potential for finding treatments to coronaviruses.         
 
 
Abstract |  
 
 COVID-19 is also known as SARS-CoV-2 and 2019-nCoV. This coronavirus can cause mild to severe upper respiratory disease, including pneumonia, acute respiratory distress, and death. For some reason children, babies, and adolescents have not contracted the disease as much as other adults. |  
 
Aims |  
 
 The author of this paper looks to provide an overview of COVID-19, its origins, and those it infects. The paper discusses knowledge related to the infection of children and infants. |  
 
Introduction |  
 
  There are six coronaviruses known to be able to infect humans prior to COVID-19. These viruses cause cold symptoms in healthy patients, but can be dangerous to compromised people. Researchers have traced the beginning of the 2020 coronavirus pandemic back to a seafood market in Wuhan, Hubei, China. The virus COVID-19 has come to spread across the world and infect millions because of how contagious it is. The virus was officially named a pandemic in March of 2020.   Researchers observe that the elderly are especially in danger of developing severe symptoms from COVID-19. Children seem to develop milder forms of the virus, but its effect on young babies is largely unknown. Numbers suggest that infants may be at a larger risk than older children. |  
 
Methods |  
 
         The research gathered in this paper was internet based and mainly used PubMed and Google. The research used included papers published up until April 7th, 2020. Studies not in English or Italian were not included.   SARS, Coronavirus, and Children       COVID-19 belongs to thegenusbetacoronavirus and is a single strand ofRNA. Researchers think that this virus passed from an animal to humans through feces, contaminated food, or other material around the area of Wuhan. Other coronaviruses related to COVID-19 also have a history of not being deadly to children. However the reason for children being in less danger is still unknown. Children are normally prone to viral infection after infancy. Otto et al showed that vaccinations early in life may cause future viruses to have less of an effect on children.         Researchers also believe that theenzymeACE2in the lungs is a possible reason why children are less vulnerable to the virus COVID-19. ACE2 is in the membrane of cells. Research shows that ACE2 allows viruses to attach to it to infect a cell. Researchers hypothesize that children may have less of this enzyme ACE2 in their bodies. Having less of the enzyme in their bodies means that the virus may have a harder time infecting cells in their lungs.         Besides the hypothesis with ACE2, it is also possible that cases of children with the virus are not reported or diagnosed. Many children have mild symptoms such as congestion, cough, diarrhea, or fever. This means that some children who actually have the virus will never be diagnosed because of their mild symptoms. There are still certain groups of children who have developed low oxygen levels in their blood or mild respiratory failure.    Diagnosis             Patients who do not show symptoms of having COVID-19 can still infect other people with the virus. RT-PCR can detect the virus in samples of infected people. Health professionals use chest CT and x-ray to find damaged lung tissue. Using these tests on infants can be misleading because infants often develop symptoms of respiratory failure for many other reasons. Research suggests that health professionals should treat infants for COVID-19 if they came in contact with an infected person, the mother had COVID-19 during pregnancy and labor, and show normal lung images.   Maternal-Fetal Transmission and Breastfeeding   Clinical Features in Newborns and Infants   Infection Control and Treatment        Scientists do not know if breast milk can transmit COVID-19. There is also conflicting data on whether or not a pregnant mother can pass on COVID-19 to her unborn child. Neither is it obvious whether or not vaginal birth may expose a child to the virus as opposed to caesarian section. However, severe symptoms in the mother can still cause distress in the fetus, including premature delivery.       Infants with COVID-19 may have non-specific symptoms, including acute respiratory distress, an unstable temperature, and problems with their digestive and cardiovascular systems. According to research done by Zhu et al, newborns born to mothers with COVID-19 had symptoms including shortness of breath,cyanosis,vomiting, increased heart rate, and rashes. However none of the newborns tested positive for COVID-19. Research done by other scientists had newborns that passed away, required ventilation, and even none to mild symptoms.Table 2provides data on infants with confirmed cases of COVID-19 up to 6 months of age.        Experts advise health professionals working in operating rooms and delivery rooms to prepare for COVID-19 positive mothers. Newborns with infected mothers should be moved to specific area for newborns possibly exposed to COVID-19. If the newborn does not show symptoms of COVID-19 after birth and the mother's test comes back negative, it may stay with the mother. Health professionals should take precaution if the mother's test is positive. Newborns with symptoms of COVID-19 should be moved to the NICU. |  
 
Conclusions |  
 
    This review attempts to organize a large amount of information for the safety and handling of infants and newborns exposed to COVID-19. Pediatricians should continue research into the topic to help better understand how COVID-19 affects these infants. |   
 
 
Abstract | Vessel formation (angiogenesis) and inflammation are closely related. A protein on the vessel cells called Endoglin (CD105) is involved in angiogenesis. So this study aims to see if CD105 is also involved in inflammation. They used antibody staining to look at CD105 levels during inflammation and angiogenesis. CD105 was found in low levels in most of the tissue throughout the body. But, it was found at high levels in capillaries near hair follicles, alveoli, and lymph nodes. During wound healing, inflammation and angiogenesis both occur. CD105 levels increase during wound healing. CD105 also moves white blood cells across the vessel membrane and into the target tissue, called leukocyte extravasation. This process happens during wound healing because the body is trying to fight off any infection from entering the broken skin. 
 
Introduction | Many inflammatory diseases also have high levels of angiogenesis. CD105 is responsible for helping form new vessels. Then, it helps smooth muscle form around some of the larger vessels like arterioles. CD105 works with transforming growth factor beta 1 (TGF beta-1) and 2 (TGF beta-2) to help the smooth muscle form around the vessel. Mutations causing low levels of CD105 are usually fatal before birth in mammals. High levels of CD105 can lead to atherosclerosis, nephritis, psoriasis, and tumors. 
 
Materials and Methods | Skin, lung, and liver tissue were studied because these commonly have disease in the vessels. The volunteers in this study each had a small biopsy taken from their buttock region. They were monitored for the next 28 days.Antibody staining (immunohistochemisty) was used to look at wound healing. They looked for CD105, macrophages, T cells, and proliferation markers. Proliferation markers tell us if the cells are rapidly growing. 
 
Results | Inflamed Tissue - CD105 in InflammationThis study did not detect CD105 in most normal, healthy tissue. The only normal tissue with high levels of CD105 were in capillaries around hair follicles, alveoli, and lymph nodes. The expression of CD105 is very high in inflamed tissue. A lot of inflammation is caused by white blood cells rushing to the target tissue, and CD105 is the protein that allows the white blood cells to cross the membrane.Wound Healing - Cd105 in AngiogenesisThe researchers took biopsies of wounds in the process of healing at 0, 1, 4, 7, 14, and 28 days after the wound. CD105 increased by 3 to 8 times between day 0 and day 7. The increase began at day 1 or 2 and stayed at a high level until they began dropping on day 28. Activated and proliferating vessel cells were both present in the biopsy and assessed for CD105 levels. Activated cells are cells that were present during the wound. Proliferating cells are cells that have grown after the wound first occurred. High levels of CD105 were found in both activated and proliferating vessel cells. CD105 was not found in white blood cells or smooth muscle. But, higher levels of CD105 were found in a cell called a myofibroblast. Myofibroblasts help to repair muscle in wounds. The CD105 RNA was increased similar to the protein levels. 
 
Discussion | This study showed that CD105 levels are high in both inflammation and angiogenesis conditions. CD105 levels are high during extravasation, where many white blood cells need to cross the vessel walls into the tissue. This suggests that CD105 facilitates this process.Myofibroblasts were found to have high levels of CD105 in wounds. Myofibroblasts interact with TGF-beta1, which is known to work with CD105. In wound healing, CD105 is at a maximum level when angiogenesis and white blood cell extravasation are both happening. CD105 protein and RNA levels are both increased during wound healing. This tells us that CD105 is not a byproduct of wound healing and the body wants more of it to help the wound heal faster.TGF-beta1 normally slows the growth of vessels. CD105 increases the growth of vessels. High levels of TGF-beta1 cause CD105 levels to increase too. This shows us that these two work together to balance the growth of vessels. If TGF-beta1 levels get too high, CD105 will increase and counter TGF-beta1’s effects on blood vessel growth.CD105 may be a great target in the treatment of chronic wounds, inflammatory diseases, and tumors. 
 
 
Abstract | 3D tissue scaffolds make better models for research and clinical use. In this study, the researchers decellularized apple slices. They grow NIH3T3 fibroblasts, mouse C2C12 muscle myoblasts, and human HeLa epithelial cells into the scaffolds. The cells can grow and live for over 12 weeks. The cells were as dense as other popular scaffold materials. Since apples are cheap and renewable, this may be a great option for scaffolding. 
 
 |  
 
Introduction |  
 
2D cell cultures are not as good of a model for research as 3D models. Cells grown in 2D conditions will get flatter as time goes on, but can return to their original shape if they are grown in 3D conditions. Cellulose is the main reason scaffolds are possible. Cellulose is the carbohydrate that makes up the cell walls of plants. It is not easily digestible, and has shown to be useful in medicine. Cellulose can be used as dialysis tubing. 3D cell cultures have better cell to cell connections through gap junctions. Apple tissue is a good choice because it has lots of pores, so the cells will be able to transport nutrients easily. The apple must be decellularized, which means removing all proteins, lipids, and nucleic acids to leave a pure cellulose scaffold. This study looks at mouse NIH3T3 fibroblasts, mouse C2C12 myoblasts, and human HeLa epithelial cells in the apple scaffold. They looked at the structure, chemical properties, and mechanical properties of the scaffolds. |  
 
Materials and Methods |  
 
Apple Tissue Preparation, Decellularization, and StorageMcIntosh Red apples were used for this study. The apples were sliced, sanitized, and submerged in sodium dodecyl sulphate (SDS). SDS is a detergent that will dissolve everything except for the cellulose, effectively decellularizing the apples. The scaffolds were treated with antibiotics and a buffer. | Post-decellularization TreatmentsThe scaffolds were either treated with nothing, collagen, or glutaraldehyde. The three types created were called native, collagen coated, or cross-linked. 
 
 | Cell CultureC2C12 mouse myoblasts, NIH3T3 mouse fibroblasts, and HeLa human epithelial cells were separately given to different scaffold types. The media used for this study was standard mammalian media (DMEM) supplemented with 10 fetal bovine serum, antibiotics, and buffer. 
 
 | In Vitro Culture in Cellulose ScaffoldsThe scaffolds were placed into a 24-well tissue culture plates and a droplet containing 6,000,000 cells was given to each scaffold. They were grown in cell media for the next 12 weeks. 
 
 | Immunofluorescence StainingImmunohistochemistry techniques were used to stain the cells. 
 
 | MicroscopyConfocal Microscopy, Scanning Electron Microscopy, and Atomic Force Microscopy were all used to image the samples. 
 
 |  
 
Results | Preparation of Cellulose ScaffoldsThe apple tissue made for a very porous sponge-like structure after decellularization. The other plant cells, proteins, and nucleic acids were successfully removed because only the cellulose scaffold was visible on Scanning Electron Microscopy. 
 
 | Mechanical Properties of Native and Modified Cellulose ScaffoldsThe scaffolds were treated with collagen or glutaraldehyde to make samples called collagen and cross-linked scaffolds. They used Atomic Force Microscopy to measure the elasticity of four samples: the untreated apple tissue, native decellularized scaffold, collagen scaffold, and cross-linked scaffold. The elasticity of the collagen scaffold and cross-linked scaffold was much higher than the other two samples. This shows that apple scaffolds could mimic mammalian tissues after treatment with certain agents. 
 
 | Mammalian Cell Culture in Native, Collagen Functionalized, and Chemically Cross Linked Cellulose ScaffoldsThe C2C12 myoblast. NIH3t3 fibroblast, and HeLa epithelial cells were all grown separately in the native, cellulose, and cross-linked scaffolds. All cells grew at a rapid rate, called proliferation. The cells were growing all throughout the scaffold, from the surface to deep within the cellulose. The different combinations were also tested for actin stress fibers. They all tested positive for actin stress fibers. This means the the cells were strongly attached to the scaffold, not just physically enclosed in the scaffold. 
 
 | Proliferation and ViabilityTo see how long the cells could live in the scaffold, the researchers took imaging at 1, 8, and 12 weeks. The HeLs and C2C12 cells grew two times faster than the NIH3T3. Then, the researchers stained all of the dying or dead cells a different color from all of the healthy cells. About 98 of the cells were living and healthy after 12 weeks, showing that this scaffold could be maintained long term. 
 
 |  
 
Discussion |  
 
Cells grown in 3D have a lot of differences than those grown on a 2D surface. 3D scaffolds allow cells to have proper shape, communication, and growth. Two types of scaffolds exist: artificial and decellularized scaffolds. Artificial scaffolds allow the research team to have more control over the shape, size and other properties of the scaffold because they can synthesize it from scratch. Decellularization can produce a natural and cheap scaffold that is much easier to make. Apple tissue is a great option for decellularization. Apple tissue is naturally porous and easily decellularized. All cell types in this study could easily adhere to the scaffold and grow. Nutrients could be exchanged all the way to the middle of the scaffold in still standing culture media, so no current was needed to penetrate the scaffold. Some cell types grow better in certain elasticity conditions, so tuning the cellulose scaffold with collagen or glutaraldehyde is a great way to make cellulose a favorable scaffolding material for several cell types. This is also supported by the stress actin fibers that formed, showing good levels of adhesion to the scaffold for all cell types. The amount of dying cells was very small in the 3D scaffold as well. Porous scaffolds have benefits and challenges. Cells will not adhere as well to a scaffold with too many holes. This was the case in the apple scaffold, so only 2,000,000 of the 6,000,000 cells they seeded actually attached to the scaffold. A porous scaffold does allow dead cells to be washed out easily. Finally, nutrients and cell communication is present in a porous scaffold. Combined with the cheap price and easy decellularization process, apple scaffolds may prove to be very effective for research and clinical treatment options. |   
 
 
Abstract |  Minority ethnic and black individuals appear to be disproportionately affected by low vitamin D levels and COVID-19 infection. This study aims to establish if blood levels of vitamin D are associated with COVID-19 infection risk. UK biobank recruited 502,624 participants aged 37-73 years. Exposure data and blood vitamin D levels were acquired. The data was then cross referenced. Complete data was available for 348,598 UK Biobank participants. Only 449 participants had confirmed COVID-19 infection. Once all variables were accounted for the data did not show any association between blood vitamin D levels or the effect of ethnicity on infection risk. The results do not support a link between blood vitamin D concentrations and risk of COVID-19 infection. The results also fail to observe ethnic differences in infection risk as a result of blood vitamin D levels. 
 
Introduction | COVID-19 has led to a pandemic of pneumonia-related illness. The researchers predict the case fatality to be 1. According to the Intensive Care National Audit and Research Centre roughly one third of all reported cases are non-white. There is growing evidence that COVID-19 disproportionately affects minority ethnic and black individuals. The US has seen similar patterns of infection. Therefore, it is critical that we understand the relationship between COVID-19 and ethnic minorities. Several factors could lead to this trend. UK government statistics show that black or minority ethnic individuals tend to live in more socioeconomically deprived areas of England. Similarly, these groups tend to experience higher levels of underlying medical issues.One potential reason for this could be that ethnic minorities and black individuals tend to have lower levels of vitamin D. Vitamin D is produced in the skin and is a result of exposure to UV radiation. However, the melanin in darker skin will absorb less UV radiation. This results in less vitamin D production. This study hypothesized that blood vitamin D concentrations were associated with COVID-19 risk among UK Biobank participants. 
 
Materials and Methods | Biological baselines were taken and touch screen questionnaires were given to every participant. Ethnicity was self reported as white, black, South Asian, or other. Various factors such as socioeconomic status (SES), smoking habits, and general health were all self reported. All variables were accounted for to make sure a valid baseline could be achieved before comparison. This essentially means that various factors such as health, race, BMI, and SES were taken into account when analyzing the data. This prevented distortion of the results. 
 
Results | The median blood vitamin D concentration was lower in patients who had confirmed infection than those without infection. However, after adjusting for various other factors such as SES, health, BMI, and race there was no relation between vitamin D concentration and COVID-19 infection. There was no statistically significant interaction between vitamin D and ethnicity. Median blood concentrations of vitamin D were highest in white individuals and lowest in South Asian participants There is higher risk found for males and individuals who BMI classifies them as obese.  
 
Discussion | This study was consistent with others in showing a higher infection risk to black and ethnic minority groups. No association was found between blood vitamin D concentration and COVID-19 infection as adjusting for variables. Blood vitamin D concentrations were lower in black and minority ethnic individuals. Despite this, there is no evidence it causes a higher risk to COVID-19 infection. Further studies are required to determine potential biological mechanisms that may vary between ethnic and black individuals. The difference in infection risk could be social factors or cardiometabolic conditions.This study failed to find an association between blood pressure and infection risk. Similarly, there was no observed risk for smokers. However, the literature on the effects of smoking is still mixed at this current time. This study was large, but not representative of the general population. This study finds no link between blood vitamin D concentration and COVID-19 infection risk. Similarly, the results of this study suggest that vitamin D supplements are unlikely to provide assistance in prevention. 
 
Conclusion | The results of this study do not provide evidence to support a role regarding blood vitamin D concentration on COVID-19 infection. Nor, does blood vitamin D concentration explain differences between ethnic groups.  
 
 
Abstract |  Studies show that microplastic has a negative impact on the wildlife. Thus the presence of microplastic in marine species that humans consume presents a health risk to humans. This study reviews the potential health effects of microplastic in marine species on human food security and human health. Knowledge on this subject is very limited and this study pushes the boundary of our knowledge. Additional research in this area is needed to ensure human health and food security. 
 
Background |  Plastics are found worldwide in the marine environments, with estimates predicting more than 5 trillion plastic debris afloat at seas. Plastic enters the sea via indirectly from industrial, urban effluents, or runoff from beaches and fields. Microplastic is any piece of plastic that is less than five millimeters in size with no lower limit in place. Microplastic in the marine environment can come from broken pieces of larger plastic and be introduced to the environment already small as plastic pellets. These pellets are used to create a variety of products and can even be found in facial cleaners, bath gels, and toothpaste. It is believed that microplastics ingestion by marine life is how it mainly enters the marine ecosystem. Once they enter the organism it is possible that they enter the cardiovascular system and deposit in certain tissues. The microplastic could cause physical damage or the organism could have a reaction to the chemicals found on the pellet. The presence of microplastic has been found in fish, crustaceans, or other animals. When a human eats these animals the microplastic present in them is transferred to the human body. However, information on the potential harmful effects on the human body are available. This area of research requires further investigation.(1) Evidence of microplastics presenceSeafoodAccording to a study done 11 out of the 25 most fished species contained microplastic. Microplastics have been found in varying concentrations in mussels, shrimp, bivalves, and in several shellfish species. One study found that in 9 of the US and 28 of Indonesian sold fish where microplastic was present in the gastrointestinal tract. Simple gutting of the fish does not solve the issue either. It is still present in a large variety of shellfish. Recently a study has shown that microplastic was found in the muscle of the imported fish.Other products consumed as food by humans or used in human food preparationResearch has shown that microplastic is found in a wide variety of foods. Including but not limited to canned sardines, sprats, beer, honey, sugar, drinking water in plastic bottles, beverage cartons, and tap water in some countries. Information on this subject is still limited to certain geographic locations. More quantitative and qualitative research is required to expand upon these early results. A standard system for the measurement must be put in place in order to achieve comparable data.(2) Implications for the environment and human food security Uncertainty and variability in data is the main issue. A proper assessment of data is difficult as there is a severe lack of available data. It has been shown that micro/nano-plastic particles can interact with toxic chemicals found in the environment. Then these chemicals leach out into the body of the animal who ingested the plastic particle. Recent studies have also shown that micro and nano-plastic are transmitted in different food webs. This leads to the amplification of plastic accumulation the higher up you go on the food chain. Experiments with microplastic in marine life have shown varying adverse effects. Exposure to microplastic has shown higher rates of mortality, reduced feeding rate, reduced body mass, reduced metabolic rate, reduced growth, and changes in behavior responses and reduced swimming performance, decreased fertilization and abnormalities in the larva. Similarly, neurotoxicity due to acetylcholinesterase inhibition and oxidative stress, intestinal damage, and several other adverse side effects. To properly assess risk more studies on the effects of microplastics are needed with particular focus on long-term exposure.(3) Implications for human food safety Marine animals may act as vehicles for the transmission of various chemicals that are attached to microplastics. There are a variety of chemicals that are used during production that are incredibly toxic to animals and humans. These pollutants, carcinogens, or neurotoxins could be transferred to humans through consumption of tainted marine wildlife. Microplastics could disrupt cellular functioning, and could accumulate and magnify in certain food webs. This magnification and accumulation poses a higher toxicity risk to animals at the top of the food chain. Microplastics have also been shown to absorb heavy metals such as mercury. This is highly toxic to humans and animals and poses an enormous health risk. Recently studies have shown that these plastics have specific chemicals, microbes, and other organisms present. This “plastisphere” is of enormous concern regarding the transmission of certain pathogens and invasive species. This could potentially destroy biodiversity. However the research regarding pathogen transmission is still speculative. Research regarding the subject of transmission is very scarce. Additional studies are needed to expand upon this subject. Especially studies highlighting the contribution that microplastics play to the addition of toxic chemicals to the human diet. Global climate change may also change the interactions between plastic and the chemicals ability to latch on. Additional research is required in this area as well.(4) Implications for human health There is evidence showing the presence of microplastic in our food, but there is little evidence on the effects after ingestion. The adverse effects on human health have yet to be explored. Scientists speculate microplastics larger than 150 µm are unlikely to be absorbed. Microplastics smaller than 150 µm may be absorbed by the lymph system and circulatory systems leading to systematic exposure. Only microplastics smaller than 20 µm would be able to penetrate the organs, while it would have to be smaller than 10 µm to access all cell membranes including the blood brain barrier and the placenta. Recently a study tested the effects of 10 µm microplastic on the brain, and epithelial cells. They observed toxic effects at the cellular level. There is little data in this area and more is advised to have a comprehensive understanding of the absorption of these varying plastic sizes. A proper assessment of risk is improbable as there is not enough data currently. Little is known about the effect of size, shape, type of plastic, surface area, additionl pollutants, and other factors effects on absorption and human health. Microplastic found in the air must also be further studied. Therefore health effects in humans should be regarded with caution as the field is still in its infancy.  
 
Conclusion |  The pollution of the ocean by microplastics has negative effects on wildlife while also potentially contaminating our food supply. In order to understand the risk to human health more data is required. The effect of microplastic on human health and the routes of absorption need to be thoroughly understood. This should be explored in the future.   
 
 
AbstractScientists consider the process of long-term potentiation (LTP) as one of the main things controlling memory formation. LTP takes two neurons that fire together and strengthens the relationship between them. Evidence shows that transcription factor CREB causes changes in the cell. This makes that neuron’s synapse more reactive. It is unclear if CREB and LTP happen together or are separate processes.IntroductionThe Role of the Transcription Factor CREB in Memory Interest in CREB started after discovering that CREB becomes activated in the vertebrate hippocampus after LTP. When CREB is disrupted in a lab, memory gets worse. Similarly, increasing the amount of CREB causes memory to get better. Increasing the amount of CREB also increases the likelihood that these neurons will be incorporated into memory trace cells.Evidence that CREB Modulates Excitability One theory suggests that CREB makes the neuron more likely to fire and makes it more excitable by increasing conductance of potassium. These neurons would then form a group of neurons tied to that memory.Functions of the Cell-Wide Increase in Excitability In the “allocate-to-link” hypothesis, changes between links in memory can happen within hours. At first, learning causes a burst of CREB in these memory neurons. These neurons remain excited for hours and easily associate with each other. This makes it easier to form memories during this time. Now these two memories encode together in these groups of neurons. Consolidation is an important part of the “assembly consolidation” hypothesis. Consolidation happens after initial learning and association of neurons to make the association permanent. It causes the neurons to “replay” the memory as seen in the “sharp wave ripples” that show the neuron activity. Disrupting these sharp wave ripples disrupts the formation of the memory. This allows the researchers to conclude that CREB increasing the excitability also helps enhance consolidation. Mechanisms and Selectivity of CREB Activation Due to chemical factors, LTP and action potentials alone do not always mean that learning or memory formation is happening in that neuron. Research suggests that CREB activation only happens when LTP occurs and a neuron fires. Since neurons have many branches, or dendrites and axons, CREB activation must require the activation of multiple of these branches in order to begin encoding learning and memory.Discussion Evidence provided and brought together in this paper shows that models for memory must both include changes at the individual neuron level as well as larger changes among groups of neurons. Researchers acknowledge that these theories with CREB do not account for long-term memory transcriptional changes. |            
 
 
Summary | Working memory is the immediate memory of outside information, such as listening to someone speak or performing a task. It is a very conscious form of memory and is characterized by non-stop neuron spikes. Researchers analyzed the local field potential in the prefrontal cortex in monkeys’ brains during a task. Gamma and beta oscillations are types of brain waves. Both of these waves appeared during the tasks in neurons that were encoding or decoding memory to do the task. They showed up as intermittent spikes rather than continuous spikes. This data means that working memory is from this discrete spiking rather than a sustained firing. 
 
Introduction | Working memory has to be able to keep information available for the organism to be able to do the task. If the information is not kept “online,” then the organism will not be able to do the task. The neurons that hold that information will keep spiking and firing until the information is needed. If the firing is disrupted, the information is lost. Some theories suggest that the information is held in the synapse rather than the firing. This would mean that the neuron’s firing can be disrupted and the information would not be lost. 
 
Results | Researchers had monkeys watch a screen for this experiment. Each trial had either two or three colored squares appear in a specific order and place. There would then be a delay of 1.2 or .6 seconds. After the delay, the same sequence would play again. However, the researchers would change one of the squares. Monkeys had to move their eyes (this is called a saccade) towards the square that changed to receive a reward.Prediction 1: Gamma Oscillations Are Tied to Neural Encoding Information Gamma oscillations should only occur when a neuron is conveying outside/sensory information. Therefore, this model predicts that a neuron without gamma spiking is not informative for this research. Despite this prediction, neurons tested did not show a meaningful increase in gamma spikes when stimulated. Rather, beta oscillations were consistently there. Next, researchers analyzed the spiking of all the neurons. Researchers found that neurons that conveyed working memory information were scattered among neurons that did not convey the same information.Prediction 2: Gamma and Beta Occur in Brief, Narrow-Band Bursts This model says that gamma and beta spikes increase in short, erratic bursts. These bursts are supposed to increase the capability of working memory, meaning that more can be remembered. Researchers used statistical methods to define what is a “burst,” saying an oscillation must be two standard deviations above the mean power and last for three cycles. Researchers separated gamma bursts into two bands to analyze frequency and spike rate separately. Researchers found that high spike rates were associated with higher frequency gamma bursts. Researchers were able to establish that the power of these gamma bursts were due to skewed data from the spike rates.Prediction 3: Beta and Gamma Underlie Different Network States This model predicts that beta and gamma bursts should be anti-correlated. This is because beta bursts happen during a resting/default state in the neuron while gamma bursts happen while the neuron is coding a stimulus. Data collected supports this notion in figure 4C, figure S7, and figure 2D. However, there is nothing in the data that indicates there is no correlation on a single trial level. The overall picture in the data collected shows that there is a negative correlation, however you cannot predict the state of a single gamma burst based on a single beta burst or vice versa.Prediction 4: Gamma Bursts Are Not Periodic Evidence shows that slower frequency oscillations are related to gamma power. This low frequency control comes from the consistency of the duration of these gamma bursts, rather than the periodic occurrence of the gamma bursts. Data in figure 5A and figure 4C support this.Prediction 5: Gamma Bursts Are Associated with Stimulus Decoding Data suggests that gamma bursts are not only involved in recording information into memory, but also “replaying” memory. These gamma bursts coincide with pauses in the beta bursts during this replaying, meaning they do not happen at the same time. Figure 2C, figure 4C, and figure S7C show that the rate of gamma bursts increased late in the memory delays (*Recall: in the experiment, trials were separated by a 1.2 or .6 second delay). Beta bursts also decreased during this time. To verify this prediction, researchers designed a new experiment. This time there were seven trials. Six of the seven had a delay of 750 milliseconds and one of the seven had a delay of 1500 milliseconds. Figure 8B outlines this data and supports the prediction. Increases in gamma bursts and decreases in beta bursts were seen from 750 milliseconds to the end of the 1500 millisecond interval. Therefore, researchers concluded that gamma bursts increase as an animal anticipates using (decoding) the information in working memory. 
 
Discussion |  The data discussed in this research has implications for other cortical areas. Just as gamma and beta bursts have implications in encoding/decoding and maintenance of information, Funahashi et al demonstrated these bursts are involved in motor planning in a similar way. Therefore, the data suggests that gamma and beta bursts are a reoccurring phenomena in the cortex of the brain.  
 
 
Abstract | The very contagious COVID-19 has had an immense impact on the world and killed an unprecedented amount of people across the globe. This especially applies to ethnic and racial minorities. Many minority groups have already been pushed into a societally disadvantaged position, making them even more vulnerable to the COVID-19 pandemic. In the United States, this especially applies to Black Americans. For example, the idea of “Black Immunity” gives some Black Americans the false idea that COVID-19 is not as much of a danger to them. This undermines health officials’ efforts to promote preventative measures as well as targets the health and wellbeing of Black Americans. The research in this paper presents data on COVID-19 cases in the state of Connecticut reviewed by other experts in this field. Researchers also use this data as a call to action for the National Commission on COVID-19 Racial and Ethnic Health Disparities. 
 
The Black Immunity Myth | In modern day America, widespread systemic racism rooted in this nation’s history disproportionately affects Black Americans, such as with poverty, mass incarceration, and negative effects on health. The illusion of “Black Immunity” is thought to have come from anecdotal evidence claiming that peoples of African descent are genetically different, or that melanin somehow protects people from COVID-19. These false claims bring with them a variety of consequences. The HIV epidemic is another example of a time when “Black Immunity” caused Black Americans to be disproportionately affected by a virus. These kinds of ideas cause minority groups to be even more vulnerable during a crisis like the COVID-19 pandemic, in addition to the pre-existing social disadvantages. 
 
An Emerging Trend | Many people have racialized and disregarded COVID-19 from the beginning. People, especially in the United States, began calling it the “Chinese Virus.” This disregard of the virus eventually led to the US becoming the epicenter of the pandemic. Trends show the rapid spread of the disease in cities whose populations have a large proportion of Black people, including Boston (25.3), Chicago (30.1), Detroit (78.6), New Orleans (59.7), and Philadelphia (47.4). The percentage of Americans who live in a city is only 13. These numbers reflect the idea that Black Americans have been pushed into close, concentrated communities, especially in cities. These communities also tend to have limited access to health care and less jobs that allow a person to work from home. These factors contribute to Black Americans’ vulnerability during this pandemic. 
 
The State of Connecticut Experience | Black Connecticut residents are mainly concentrated in a select few cities and towns, even though Connecticut has over 150 cities and towns. Counties across the state are missing data on race and ethnicity for COVID-19 cases (55 of cases). Table 1 and Table 2 have what information is available on race and ethnicity for Connecticut COVID-19 cases. 
 
A Request for Data | Many believe that the COVID-19 pandemic has exposed the flaws and racial biases of the American health system. As of March 2020, democrats have asked for data on racial disparities during the pandemic to be released. 
 
A Call to Action | Authors of this paper hope that the US will use the data on racial and ethnic groups during the COVID-19 pandemic to resolve and prevent these racial disparities of the disease. Researchers call for the establishment of a National Commission on COVID-19 Racial and Ethnic Disparities to manage the effects of this virus on racial minorities. 
 
Conclusion | Data in this paper debunks “Black Immunity” and shows that Black Americans are more likely to face infection and death during this pandemic. Missing data is the main limiting factor of this research. 
 
Added in Proof | The racial and ethnic data that was missing is now displayed in Figure 1.  
 
 
Abstract | The 2020 COVID-19 pandemic has been affecting discriminated and marginalized peoples more than others. Crises like this pandemic cause social inequality to be exaggerated, especially when economic troubles are involved. This writing looks to explain and expand upon how COVID-19 has affected these groups of people. These researchers would like to outline research plans and models for professionals to follow. This would help experts analyze and study how COVID-19 is affecting vulnerable populations. Certain people see COVID-19 as an “equalizer” even though there is evidence to suggest it affects certain groups more than others. This paper looks into four topics: 1) relatively lower amounts of representation for low-income and racial minorities. 2) The lack of good work opportunities for low-income LatinX workers. 3) The rise in discrimination of Asian Americans. 4) Struggles of working women without access to childcare. 
 
Disproportionate Representation in Sectors Most Affected by COVID-19 |  The COVID-19 pandemic has largely affected businesses in the restaurant, travel, retail, manufacturing, and entertainment sectors. These businesses also have a larger amount of women, Black,LatinX, and Native American employees. This means a large amount of people of color and women have been out of work during the COVID-19 pandemic. Data collected before the pandemic shows that Black and LatinX people already had higher unemployment rates and lower wages compared to white employees. The pandemic now adds onto those issues by mainly affecting businesses with majority Black and LatinX employees. Additionally, the jobs least affected by the COVID-19 pandemic are those that allow employees to work from home. These jobs tend to bewhite collarand professional with health benefits, paid sick leave, and higher wages. These jobs are also are also known for lacking representation of Black, Native American, and LatinX people. These factors combined lead researchers to think that these groups may be more affected by this pandemic than the white, upper, middle-class Americans. More research is needed to investigate the consequences of the pandemic on people of color. 
 
Decent Work | Authors of this paper define “decent work” as a job that is fair, safe, secure, has good benefits, and protects the rights of its employees. COVID-19 has shown that there aren’t as many “decent” jobs for essential employees in the US. This includes workers not being provided with properPPEor support on handling their work during this pandemic. Workers report feeling as though they must choose between their health or their ability to make money. This increase in stress for them has caused some workers to quit their jobs or not show up to work. These jobs often do not offer access to benefits, health care, sick leave, nor living-wages. LatinX people form a large percentage of people in these jobs compared to the number of LatinX employees overall in the US. These numbers mean that LatinX people are more likely to have these jobs than other groups. This makes these issues something that have been affecting LatinX people more than others. 
 
Asian American Discrimination |  Experts consider Wuhan, Hubei, China the origin of the COVID-19 pandemic. This has brought a dramatic increase in discrimination against Asians and Asian Americans because people seem to think that the COVID-19 pandemic is their fault and that they are carriers of disease. Certain political leaders have played a role in this mindset, such as Donald Trump labeling COVID-19 as the “Chinese virus.” Data collected from polls and reports since the beginning of this pandemic indicate that a large amount (30) of Americans blame Chinese people for the virus and that the first eight weeks after COVID-19 emerged saw 1,497 reports of discrimination against Asian Americans. It’s worth noting that 57 of these cases came from New York and California, which are two of the states most affected by COVID-19. On top of this, research has shown that Asian Americans were already vulnerable to work discrimination before the COVID-19 pandemic. Similar to patterns discussed before in the article, researchers suggest that the pandemic has now exaggerated the discrimination faced for Asian Americans in the workplace. Research lacks in how these forms of discrimination have affected Asian Americans, how they are managing the stress of it, and the long-term consequences of it. 
 
Multiple Role Conflict for Women | “Multiple Role Conflict” means what happens when a person struggles to balance the different parts of their life. This paper examines how the COVID-19 pandemic has affected women specifically. Women (84) tend to take on more household responsibilities when compared to men (69). Studies also show that women (2.6 hours) spend more time on household chores per day than men (2.0 hours) and spend double the amount of time taking care of children in the home. Many schools and daycares have closed down since the beginning of the COVID-19 pandemic. This presents unique issues to households with two working parents and ones with single, working mothers. Research suggest that women in these situations may be taking a larger burden in terms of balancing a full-time job and taking care of children. This is because data shows that women tend to take on more responsibility and time with children in the home. This may increase multiple role conflict in these women. Due to these issues and women being given lower wages, the COVID-19 pandemic may be causing a larger amount of strain on women than men in these situations. This issue applies to all working women, but especially those that are essential employees. The authors of this paper urge more research into the long-term consequences to these topics. Specifically, whether or not these issues cause women to be less satisfied overall at home and at work, and whether or not this is forcing women to leave their work and careers. 
 
Conclusion |  COVID-19 has shown us inequality in the home as well as in the workforce for women and racial/ethnic minorities. Many of the people unable to work from home are part of groups that were already vulnerable to these inequalities and discrimination. Authors of this paper hope that researchers will carry out the calls for research outlined in this paper. The goal of this is to work towards equality and equity for workers in the US.  
 
 
Abstract | Understanding the origin of SARS-CoV-2 is important for drug development, vaccine development, and future virus prevention. This study shows high sequence conservation around the receptor binding motif (RBM) in the Spike gene in human, bat, and pangolin coronaviruses. Understanding the recombination that led to SARS-CoV-2 could explain how new human coronaviruses emerge. 
 
Introduction | COVID-19 has spread since December 2019 and is now a global pandemic declared by the World Health Organization. SARS-CoV-2 is the virus that causes the disease COVID-19, and was identified as a betacoronavirus. SARS and MERS are both betacoronaviruses, but SARS-CoV-2 is most similar to the coronavirus RaTG13 found in a bat. However, other similar coronaviruses were found in Malasian pangolins called Pan_SL-CoV_GD and PAN_SL-Cov_GX. Recombination can lead to the evolution of viruses, and understanding these could help us understand and prevent other viral outbreaks. SARS and MERS had nearly identical sequences to viruses found in camels, but no such similar virus has been identified for SARS-CoV-2. 
 
Materials and Methods | Genome sequences are from GenBank and GISAID for the sequence analysis. For recombination analysis, the researchers used SimPlot 3.5.15 and the LANL database tool RIP. For selection analysis, they used the LANL database tool SNAP. To do structure modeling of receptor binding, they used several softwares to generate the best model, rated by a confidence score. 
 
Results | Acquisition of receptor binding motif through recombination43 complete genome sequences from 3 different clades were compared and RaTG13 is overall the most similar to SARS-CoV-2. The pangolin virus Pan_SL-CoV-GD is the next most similar, then Pan_SL-CoV-GX. The very first SARS-CoV-2 sequence identified was named Wuhan-Hu-1. The researchers compared Wuhan-Hu-1 to the bat viruses, SARS-CoV, and the pangolin sequences. Still, RaTG13 is the most similar to Wuhan-Hu-1. Using phylogeny, the researchers found a distinctive change of the genome due to recombination before and after the ACE2 binding site arose. This means that the bat and pangolin viruses probably had a recombination event in the development of SARS-CoV-2. Because there are certain pangolin virus genes that are very different from SARS-CoV-2, we can look to other animals to see if recombination had occurred in those sites. The S gene, for example, is very similar in pangolin virus and SARS-CoV-2. The S gene is how SARS-CoV-2 enters the human cell. SARS-CoV and SARS-CoV-2 both have very similar S genes so they can both enter human cells, but the RaTG13 does not have the S gene similarity. If RaTG13 had undergone recombination with a pangolin virus, that could have made a hybrid that could more likely infect humans.Strong purifying selection among SARS-CoV-2 and closely related virusesSARS-CoV-2, RATG13, and the pangolin viruses all had identical or nearly identical sites. The sites found before and after receptor binding motif RBM, and after the furin cleavage site. These sites are likely conserved because they allow for binding to ACE2 and allow the virus to actually fuse with the host’s cell membrane. Out of the hundreds of mutated SARS-CoV-2 sequences that are added to the database daily, only eight sequences in the database had a mutation in these sites.Frequent recombination between SARS-CoVs and bat_SL-CoVsA previous study suggested that SARS-CoV-2 was from many recombination events from several different bat coronaviruses. This is supported because small portions of the SARS-CoV-2 genome do match many different portions of different bat coronaviruses. Four significant breakpoints have been found, suggesting that what is now SARS-CoV-2 had gone through multiple recombination events. This study has shown that SARS-CoV-2 shares recombinant history with at least three different bat coronaviruses. Recombination may allow for transmission across species of SARS-CoV-2 by allowing it to acquire the human ACE2 binding site. The ORF8 gene is highly variable in many of the coronaviruses that were studied, so this location could be a site of recombination. 
 
Discussion | Three important aspects of betacoronaviruses should be carefully considered when creating a phylogenetic map. 1) a traditional phylogenetic map is difficult because there is a high amount of recombination between viruses. 2) distant virus relatives can acquire the same mutation, but this does not mean that the two distant viruses are closely related. This can make it difficult to distinguish from a random similar mutation in distant relatives, or if they are close relatives. 3) there are different selective pressures that can affect the recombination of different lineages.The pangolin viruses seem too divergent to be closely related to SARS-CoV-2, but the similar RBM means it can most likely bind to human ACE2. RaTG13 is the most similar to SARS-CoV-2, but does not have a similar RBM. It is likely that RaTG13 had a recombination event with the pangolin virus to obtain the S gene is SARS-CoV-2, but there are other possibilities. There could be many mutations or unidentified viruses that we do not yet know about. Either way, recombination must occur for a virus to jump between species. Reducing direct human contact with wild animals will help prevent new zoonotic viruses in the future. 
 
 
Abstract | Diabetes has become known as a major comorbid (occurring at the same time) condition for COVID-19 severity. This is an observational study with people with diabetes hospitalized for COVID-19 in 53 French centers from March 10th-31st, 2020. The measured outcome combined tracheal intubation for ventilation and/or death within 7 days of hospital admission. BMI was positively and independently associated with the measured outcome. 
 
Introduction | Diabetes is known to worsen the health outcomes for COVID-19 patients. Specifically, it increases the risk of death and the need for intensive care. Data regarding diabetes characteristics in hospitalized patients with COVID-19, however, are still lacking. An investigation into the relationship between diabetes-related phenotypes and COVID-19 severity is imperative. 
 
Methods | This study was launched in volunteering French hospitals with COVID-19 patients with diabetes. It aimed to describe the expressions of diabetes and prognosis (course of the disease) of these patients. 
 
Results | There were a total of 1317 participants. 88.5 of the cases had type 2 diabetes, while 3 had type 1 and 5.4 had other conditions causing diabetes. Of these participants, 382 required intubation and/or died. 410 patients required intensive care within 7 days of being admitted, 267 of whom needed intubation for ventilation. On day 7, 140 patients died while 237 were discharged. The study found BMI to be the only factor independently associated with an outcome of intubation and/or death. Age, a history of blood vessel complications and sleep apnea were also found to be associated with an increased risk of death on day 7 of the study. 
 
Discussion | BMI turned out to be the only variable (before admission) independently associated with the measured outcome, which is mainly driven by tracheal intubation. Many of the patients suffered from respiratory symptoms (i.e., coughing). Some participants suffered from digestive disorders (i.e., Hemorrhoids). People with diabetes may also need the management of metabolic disorders when suffering from COVID-19. It is worth noting that this study focuses only on short-term outcomes, so the possibility that diabetes characteristics could be associated with severe, long-term COVID-19 outcomes can not be excluded. 
 
 
Abstract |  Brain-machine interfaces (BMI) show promise to restore lost sensory or motor function. Similarly, they offer a potential treatment for a variety of neurological disorders. According to the researchers, BMI's have not been utilized by the populus. This is due to limitations in their physical design and ability to transmit information. This paper details Neuralinks first attempt at scalable high-bandwidth BMI. The researchers have built an array that uses small threads with at most 3072 electrodes per array across 96 threads. Each thread is inserted individually with submicron precision to avoid vasculature and enable targeting of regions in the brain. The electrode array is packaged into a small implantable device. The package is 23x18.5x2 mm3 and utilizes a single USB type C cable to provide full-bandwidth data streaming. The array is also capable of simultaneous recording and analysis of all 3072 electrodes. This system also achieved a spiking yield of up to 70 in long-term implanted electrodes. This approach to a BMI is unprecedented in its packaging density and scalability for clinical applications. 
 
Introduction  |  Brain-machine interfaces show promise in helping people with a variety of clinical disorders. BMI’s with 256 electrodes have been used to allow control of a computer cursor, robotic limbs, and speech synthesizers. These demonstrate a proof of concept, but they are limited by an inability to record a large amount of neural input simultaneously. Noninvasive electrodes placed on the outside of the skull provide distorted results. They are only capable of averaging the activity of millions of neurons which makes them incredibly non-specific. Similarly, invasive electrodes placed on the skull can only measure the activity of thousands of neurons. They are also incapable of reading deeper brain activity.Microelectrodes are the standard technology for recording action potentials from neurons. No large-scale systems exist for implantation. This requires a system with high biocompatibility, safety, and longevity. Such a system would also need to be compact and low power to allow wireless operation. Current systems use rigid metals or semiconductors. Such a design permits deeper penetration into the brain, but can accelerate an immune response. It also limits its potential applications as certain portions of the brain can not be accessed due to vasculature.Here Neuralink uses an alternative approach. Flexible polymer probes have 32 electrodes per probe. Their greater flexibility and smaller size offer great biocompatibility. However, the increased flexibility creates issues with their insertion. The researchers used a robot to insert a large number of probes efficiently and independently across varying brain regions. Neuralinks system increased the amount of channels by a factor of 10. This system has three main portions: 1) ultra-fine polymer probes, 2) a neurosurgical robot, 3) and a custom high density electronic array. This system is designed for long-term implantation. It also permits full broadband streaming of the neuronal information. A proprietary neuronal spike-detection software was developed for high accuracy, low latency detection. 
 
Threads |  A custom process was devised to fabricate such delicate threads. The developed microfabrication process allows for easy and fast production of these threads. Each of the 96 threads contain 32 independent electrodes. The researchers have developed over 20 different types of threads each with three layers of insulation and two layers of conductors. 
 
Robot |  The insertion head contains six light modules each capable of illuminations with 405nm, 525nm, 650nm, or white light. The 405nm module allows the robot to visualize for alignment. The 525nm light in conjunction with stereoscopic cameras and specialized software allow for estimation of the surface of the brain surface. This complex setup allows for the robot to implant electrodes around previously identified microvasculature. This system has demonstrated an 87.1 insertion success rate over 19 surgeries. Small manual adjustments were made. This resulted in an unprecedented insertion rate of 29.6 electrodes per minute. 
 
Electronics |  The custom chip produced by Neuralink provides unparalleled signal amplification and digitization within an impressively small package. Their system rejects background noise, and digitizes the amplified signals to be streamed out of the unit for real time-processing. This system uses minimal power and takes up a fraction of the size of other systems. The researchers currently have two configurations. System A has better overall performance measures, but less channels for communication. System B has more channels but slightly worse performance. The data is then streamed to a computer for live data analysis. 
 
Electrophysiology |  System A and B were implanted into Long-Evans rats. System A was able to record 1344 of 1536 channels simultaneously. The exact channels can be changed according to what is desired. System B was able to record from all 3072 channels simultaneously. The use of the researchers custom online spike-detection software was instrumental in decreasing their systems energy usage, latency, size, and accuracy. 
 
Discussion | The systems developed in this experiment serve two main purposes. First it is a research platform for use in rodents. Secondly it serves as a prototype of a human version used in clinical applications. The system is easily implantable and allows for rapid refinement. The next step is to modulate neuronal activity. This could potentially give the sense of touch back or allow movement of paralyzed individuals. The researchers system was designed to allow electrical stimulation through every channel, but it was not demonstrated in this paper. The researchers system offers distinct advantages over previous approaches. The size and composition of the probes is unparalleled in size and biocompatibility. Similarly, the ability to choose where the probes are placed allows greater flexibility and avoidance of vasculature. Finally, the system allows very high channel counts with a low power consumption and small packaging. In theory multiple systems could be readily implanted onto a human to interface with more neurons. Various technological improvements must be made before practical. This offers an unparalleled scalable prototype from which to move forward. This system shows the potential to offer paralyzed patients the ability to control a digital mouse or keyboard. Additionally it could feasibly be used to restore motor function.  
 
 
Abstract |  Attention-deficit hyperactive disorder (ADHD) is one of the most common psychiatric disorders in children and adults. Research shows that ADHD patients have symptoms of abnormal circadian rhythms. A person’s circadian rhythm is how their body changes as night and day pass. In other words, it is their sleep-wake cycle. A mutation in a protein involved in this cycle, per1b, causes zebrafish to display ADHD-like symptoms. These symptoms include hyperactivity, bad impulse control, decreased attention, and lower levels of dopamine. In short, dopamine is involved with movement, reward, emotion, and attention. Research found that the circadian rhythm controls the dopamine-related genes formonoamine oxidase and dopamine beta hydroxylase. This control is important in the zebrafish brain for deciding how many neurons there will be that make dopamine in that part of the brain (ventral diencephalic posterior tuberculum). Mice with mutations in per1b also show lower dopamine and other ADHD symptoms. Since mice and zebrafish are far apart evolution-wise, this may suggest thatper1b’s role may be similar among many organisms and thatthis research may be applicable to humans. 
 
Introduction | The circadian rhythm causes changes in someone’s body and in the way they act. Researchers have linked errors in this cycle to other psychiatric disorders, such as bipolar disorder and mania. ADHD is a very common disorder. ADHD’s symptoms include hyperactivity, inattention, and impulsivity. These symptoms make it especially hard for children to form good school and social habits, which can lead to other issues in adulthood such as defiance and drug abuse. The hyperactivity in ADHD can cause sleep deprivation. Researchers did genome-wide association studies (GWAS) to look for a direct connection between ADHD and this sleep deprivation. A GWAS means that researchers compared the DNA of many ADHD patients and looked for mutations they had in common. They found that many ADHD patients had errors in genes related to the circadian rhythm. It is still unknown how these genes lead to ADHD.The zebrafish over time has become a well-accepted model for studying behaviors and behavioral disorders. This paper wants to show that zebrafish with mutated per1b genes have an altered circadian rhythm and causes ADHD-like symptoms. This research also attempts to establish that errors in the dopamine (DA) system play a role in ADHD. 
 
Materials and Methods | The paper notes that Soochow University Animal Care and Use Committee approved the procedures outlined in this section. They were also under the government guidelines of China.Fish Husbandry and Embryo Production The zebrafish per1 mutants and the normal zebrafish were raised at the researchers’ facility. These fish bred in pairs and larvae hatched in total dark conditions. Researchers manipulated the lighting to activate the fishes’ circadian cycles. Researchers collected RNA from the embryos. In situ hybridization and immunofluorescence staining called for fixing the cells in place with PFA with PBS buffer. Researchers stored them in this solution either for 3 hours at room temperature or overnight at -4 C. Researchers washed them and stored at -20 C until use.Mutant Generation and Identification Researchers inserted the mutant per1b gene into the zebrafish with a retrovirus. A retrovirus is a virus that inserts its genetic material into the host DNA. Researchers used PCR to identify mutant DNA.Quantitative Real-Time PCR Invitrogen TRIzol reagent extracted RNAs from the researchers’ treatments. Researchers turned the RNA extracted into DNA by using cDNA. Researchers tested samples in triplets and measured the amount of DNA in each with qPCR.Luciferase Reporter Assays Researchers attached a luciferase protein to fragments of the genes for monamine oxidase or a fragment of the dopamine beta hydroxylase in the zebrafish. The luciferase inserts in the promoter region of these genes. Researchers then cloned these samples.Real-time Bioluminescence Monitoring in Transgenic Fish The samples from the luciferase assays insert into the one-cell zebrafish embryos. Researchers then observed luminescence in these embryos from the luciferase.Cell Culture and Cotransfectors Researchers used mouse fibroblast cells for cotransfection studies. Cotransfection studies allow researchers to be sure that the DNA that they insert into their samples is stable.Antibodies and Chromatin Immunoprecipitation Researchers used Invitrogen assays for this part of the experiment. A short 13 amino acid peptide, which make up proteins, were used to make antibodies in a rabbit. Researchers also made a 10 amino acid peptide from Per1 and Per2 genes. These antibodies were successfully used in ChIP assays, immunofluorescence stainings, and Western blot experiments.Whole-mount in situ Hybridization Researchers used dyes and an RNA probe to detect larvae suspended in a buffer.Western Blotting Analysis Zebrafish larvae were lysed, or broken up, and protein samples were separated. The primary and secondary antibodies then detected HRP substrate, which is a label used in this experiment.Immunofluorescence Staining with Tyrosine Hydroxylase Antibody This form of staining allowed researchers to see how many neurons were making dopamine in the mouse and zebrafish brain.HPLC Analysis The concentrations of various neurotransmitters in the brain were measured, including DOPAC, norepinephrine, dopamine, HVA, and 5-HIAA.Zebrafish Behavioral Analysis Researchers used several measurements for these observations. The measurements attempt to quantify typical ADHD symptoms. These measurements involve the zebrafish’s movements, time spent learning, impulsivity, the mirror-image attack test, environmental sensitivity, and drug treatments.Mouse Behavioral Analysis The tests to look at mouse behavior was the same as with the zebrafish. 
 
Results | Researchers found Per1 protein and TH in normal mouse brain neurons that make dopamine, but could not find it in zebrafish dopamine neurons. However, mutant per1b zebrafish larvae showed much more movement than normal ones under complete darkness (DD). This shows that Per1b is needed for zebrafish to regulate their circadian rhythms. In a normal fish, the darkness should promote resting behavior.Based on movements during day and night time, adult fish and larvae with mutant per1b genes were hyperactive. These mutant fish also showed more exploratory behavior and less anxiety by spending more time near the edges of the tank. Researchers concluded that the per1b mutation was responsible for these changes because a mutant larva displayed normal behavior when researchers put the correct gene back in.per1b mutant fish had a harder time learning than normal fish. The zebrafish prefer dark areas. However, when researchers apply an electric shock to the dark side of the tank, it took per1b mutant fish twice as long to move to the other side than the normal fish. This pattern only happened in the daytime. At night, researchers observed no significant difference.Researchers were able to observe that per1b mutants had lower impulse control/attention span. Researchers caused fish to associate a green-lit area with food. Mutant and normal fish were able to form this association. However, when researchers applied a four-minute wait period after the light turned on, per1b mutant fish were much more likely to leave the area when food was not there. Researchers also showed that per1b mutants were much more agitated by environmental changes. Rapid changes in light and dark increased their movement and agitation.HPLC showed that per1b mutant fish had much lower amounts of dopamine in their brain, during the larva and adult stage.Research has shown that dopamine regulates complex behaviors in zebrafish similar to humans. Researchers observed a much lower amount of dopamine-making neurons in per1b mutant fish. Researchers did follow up experiments and concluded that the decrease in lphn3.1 for the per1b mutants may have something to do with this.The per1b mutant fish show decreased levels of dopamine as well as commonly identified ADHD symptoms. Experiments show that using drugs that treat ADHD (Ritalin, Selegiline) on the mutant fish reduce the symptoms of these fish to around the levels of the normal fish. These drugs helped restore normal amounts of dopamine in these fish’s brains. 
 
Discussion | The mutant fish have altered circadian rhythms, hyperactivity, a harder time learning, and impulsivity. These are like the symptoms of ADHD. Per1b protein is required to rescue mutant larva. This research proposes that these per1b mutant zebrafish be used for studying the basis of ADHD. There is no research yet on the role of Per1a in ADHD. 
 
 
Abstract | 	This paper shares details about Mitsubishi’s development of a TiAl alloy designed specifically for turbocharger applications (turbine wheels). While some information is dated, the research and development of this alloy was a significant step towards designing modern turbochargers. 
 
Introduction | 	A turbocharger is a device used by many gasoline and diesel power vehicles. It recycles pressurized gases coming from a vehicle’s exhaust manifold, using them to spin a turbine and create positive pressure (under load) in a motor. Engines utilizing this technology are more fuel efficient and environmentally friendly (a smaller displacement turbocharged motor can produce more power than a larger naturally aspirated motor). Due to increasing environmental regulations, optimization of turbocharger has been and continues to be a priority for many companies. This paper shares one of the first breakthroughs reducing the weight of rotating parts within a turbo: the easiest method of improving efficiency and turbo response. The breakthrough involves a TiAl alloy which is light, able to be precisely shaped, and able to handle the extreme temperatures within a turbo. 
 
Development | 	The TiAl turbine was constructed with a precision casting technique (LEVICAST) developed by Daido Steel Co. Ltd.. Hot isostatic pressing (combination of high heat and pressure applied at the same time) was used to ensure there were no casting defects. The result was a fully lamellar structure (thin, alternating layers of the two materials) ideal for the high temperatures experienced by the turbine.	The new alloy demonstrated a lower specific gravity (relative density) value than other materials traditionally used for such a high temperature application. The low relative density translates to good resistance to centrifugal stress (turbine spins at very high rpm). Strength attributes of the alloy are possibly connected to high Nb content. Another benefit of the new alloy was increased resistance to oxidation (corrosion) compared to previous TiAl alloys.	When it comes to assembling the turbo, consideration was taken about the differing expansion between the TiAl turbine and the steel shaft it connects to. Repeated heat cycles would compromise the joint without special measures. These measures included using a joining material with expansion properties similar to the TiAl turbine. Electron beam welding and brazing were used to assemble the unit. A stress free ultrasonic inspection system was used as a quality control check for the final assembly. 
 
Results | 	A 0.2 second improvement was seen in the time the new turbo took to accomplish a 50kPa pressure. The value seems small, but the acceleration difference can easily be felt by the vehicle’s operator. Tests conducted at 1000 degrees C (operating turbo temperatures are around 900 degrees C) demonstrated the new alloy’s temperature specific strength. Rigorous endurance tests were also performed, with no notable deformations or failures. 
 
Discussion | 	Traditional fabrication methods can continue to be used with this new alloy. It spans the previously problematic gap between heat resistant metal components and ceramic materials (great with heat but difficult to shape). While this particular paper looks at the development of a TD05 turbo from Mitsubishi, the strengths of this alloy make it ideal for many rotational applications.  
 
 
Abstract | Pain comes from sensory input as well as situational context from the brain. Research has associated pain with neuronal oscillations (brain waves) at different frequencies. This paper looks to compile information on how the different frequencies of these oscillations and prediction come together to make the experience of pain. 
 
Trends |  In chronic pain, the brains ability to consider both the physical sensation and emotional/contextual information is interrupted. The large range of frequencies and experience of pain may show that the brain is flexible in how it transports this information. Observing and measuring these factors in pain may allow for better understanding of chronic pain. 
 
How Can the Study of Brain Rhythms Advance Our Understanding of Pain? | This paper looks into the curiosities of pain and how it is processed in the brain. Evidence on how brain waves and oscillations are involved in pain integration and processing. This research hopes to gain insight on how these processes create pain and where research goes in the future. 
 
Pain | Pain’s unpleasant experience encourages behavior that protects the organism. Nociception is the perception of physical pain, for example, physically feeling something sharp cut you. These nociceptors combine with contextual information to create pain. For example, a child in pain can be soothed, and placebo effects can be used in pain therapy. This process is dynamic and changes how information is integrated in day-to-day life. Chronic pain refers to when an organism continues to experience pain even though there is no outside threat. 20 of adults in the Western world experience chronic pain. This pain implies that nociception and the experience of pain are no longer entirely related. This is supported by evidence showing that there are psychological factors in the development of chronic pain. 
 
Pain and the Brain | Pain activates several brain areas, including somatosensory (feelings from your body), the insula, cingulate, prefrontal cortices, the thalamus, subcortical areas, and the brainstem. These systems are not unique to pain. Since you cannot induce pain by activating any one of these areas, pain must be integrated by all of the neuron activity from these regions. Researchers hypothesize that the way these regions are connected and how they change over time influence pain integration. Factors that determine pain also are affected by time. The frequency of these brain waves can affect the experience of pain in different conditions. There is still no all-encompassing model for this system. 
 
Neuronal Oscillations and Synchrony | Brain rhythms can be observed on electroencephalogram (EEG), local field potentials (LFP), and magnetoenchalography (MEG). These waves can form from the synchronization of multiple neurons firing at once (multiple action potentials). These brain waves occur in single brain areas as well as between them.Anatomical differences exist in neurons for feedforward and feedback systems in the visual system. Feedforward systems start in supragranular layers and terminate in layer four. Feedback systems start in the infragranular layers and terminate in layers other than layer four. These “layers” refer to the organized neuron layers of cortex in the cerebrum. These pathways are not only different in location, but tend to exhibit waves at differing frequencies when transmitting information. Alpha and beta oscillations are stronger in feedback signals, while gamma oscillations are stronger in feedforward signals. This research regarding these systems in vision can be applied to the processing of pain. 
 
Neuronal Oscillations and the Experience of Pain | There is more research on quick, acute pain than there is long-term pain. The acute pain quickly signals for protection in the individual. Phasic pain is quick, short term pain, while tonic pain is long or recurrent.Phasic Pain Quick stimulation causes a complex spatial and temporal reaction in multiple regions of the brain. Initial pain causes an increase in neural activity below 10 Hz immediately after. These come from the sensorimotor cortex, the insula, the secondary somatosensory cortex, and the cingulate cortex. The phasic pain then suppresses alpha and beta frequencies in the sensorimotor and occipital areas. Then, gamma frequencies increase in the sensorimotor cortex.Data shows that with random changes in pain, such as with music, and repetitive painful stimulation, gamma oscillations are more closely related to pain intensity. When the expectation of pain is variable, such as with placebos or falsely saying something will hurt, alpha suppressions are more closely related to pain. This data is not perfectly predictive of pain integration, however.Intracranial recordings in epilepsy patients show that the anticipation of pain can change how certain brain regions are connected. This experiment must be replicated to solidify its findings.Tonic Pain Studies show that pain on a longer scale of minutes associate with suppression of alpha oscillations. The effect of this suppression is unclear because many mental processes also do this. Some studies say that the suppression of alpha and beta oscillations is supposed to replicate the physical pain stimulation (nociception) after it is gone. This means the suppression may be more about cognition than perception. Gamma oscillations also appear to encode pain instead of nociception. This activity was not reflected in the sensorimotor areas as the phasic pain was. This data indicates that duration also affects pain information on top of context.Chronic Pain    There are not as many studies and data on chronic pain as much as tonic and phasic pain. Data has shown that chronic pain patients show an abnormal increase in theta oscillations. Experts say this is because of abnormalities in communication between the thalamus and the cerebrum/cortex. The thalamus acts as a sort of “phone operator” for the brain, relaying information from the body to where it needs to go into the brain. Other data suggests that chronic pain may involve the increase of theta and beta oscillations in the frontal brain areas. 
 
Concluding Remarks and Future Perspectives |  The oscillation changes are important in the brain’s dynamic integration of pain-information. Further assessment of these processes may allow professionals to better understand and treat the processes going into a patient’s pain in disease and injury. 
 
 
Abstract | The researchers hypothesize that militarization will lead to increased police violence. They studied the 1033 program, which is a U.S. Department of Defense program. It gives excess military equipment to law enforcement agencies (LEA). The researchers looked at the correlation between the amount of equipment transfers and violence. Violence was measured using civilian casualties, change in civilian casualties, and the deaths of dogs. There is a positive and statistically significant correlation between the number of transfers and violence. 
 
Introduction | Many protests against the shooting of Michael Brown occurred in the summer of 2014. Police officers had armored vehicles, gas masks, and other military equipment. Many people criticized the militarized response. The federal government created Executive Order 13688 (EO). The EO aimed to investigate the 1033 program. Also, the EO limited the type and amount of equipment that the military could give LEAs. Many politicians were against EO, claiming that there is no evidence that militarization caused unnecessary harm to citizens.Delehanty et al. argue that militarization of LEAs will result in more violence. The large military equipment access will be conducive to a culture of militarization. The militarization will cause more officers to resort to more violent measures when perhaps other solutions are available.MilitarizationMilitarization is the appropriate use of force to solve problems. There are four components of militarization: material, cultural, organizational, and operational (Kraska, 2007). These four aspects affect one another. The receipt of equipment automatically increases the material part of militarization. This can lead to more training with the military equipment. Thus, more officers will rely on violence since they are trained to do so. The 1033 program has given out most military equipment to LEAs since 1997.1033 Program and MilitarizationPresident Bill Clinton signed the National Defense Authorization Act for Fiscal Year 1997. The bill included the 1033 program. The 1033 program provided equipment worth over $1.5 billion between 2006 and April 2014. Eighty percent of counties obtained equipment. 
 
Methods | The authors examine public data from counties in Connecticut, Maine, Nevada, and New Hampshire. They looked at 1033 receipts of equipment transfers. They use regressions to analyze possible correlations with civilian casualties and annual change in civilian casualties. They control for confounding variables, such as wealth, drug use, and demographics. They also try to establish a possible causal relationship by looking at LEA requests for military equipment. The other variable they look at is civilian dogs killed by LEAs. 
 
Results | In Nevada, counties that did not have 1033 transfers had no LEA killing (Figure 1).Increased receipt of military equipment corresponded to increased civilian casualties (Figure 2). A county that receives the maximum amount of equipment is expected to have 129 more civilian casualties than a county that receives no military equipment. Furthermore, the increased receipt corresponded to an increase in predicted change in civilian deaths (Figure 3).Alternative dependent variable: dog casualtiesA LEA may correctly anticipate problems with civilians and request more military equipment. Thus, looking at civilian casualties may give a biased result. Thus, the researchers used civilian dog casualties for another analysis. They do not expect that LEAs will consider pet casualties when requesting equipment. LEAs that request more equipment have much more dog casualties. 
 
Conclusion | This evidence-based study aims to help analyze the 1033 program. But, more research is needed due to the lack of public data on police violence. Also, no research can prove a causal effect. So, this paper uses multiple dependent variables.The Executive Order may help save lives by taking away military equipment. Other studies suggest that militarization also results in increased violence towards police. So, demilitarization may save both police and civilians. More research is needed on how the other components of militarization may decrease violence. This paper studied the militarization effect on the organization level. Another remaining question is the effect of military equipment on the individual level. 
 
 
Abstract | Trauma manifests in many behavioral and psychological disturbances in children and adults alike. These manifestations, however, do not always allow for a diagnosis of PTSD by clinicians. Of particular interest are the problems that result from early traumatic experiences with relationships. Such experiences can lead to disturbances in how one interprets social information, defines oneself, emotions, and memory. They can also result in the manifestation of physical symptoms without traceable cause(s). This raises important considerations into the nature of diagnostic criteria for PTSD. 
 
Introduction | PTSD as a diagnosable disorder (in the DSM-III) emerged out of Vietnam War Veterans’ struggles after the war, so its diagnostic criteria largely surrounded war-related trauma. The fact that most of the trauma experienced by women has to do with sexual and interpersonal trauma, most of which occurs during childhood, presented problems for PTSD diagnosis. Childhood trauma does not necessarily lead to PTSD. However, it can result in a myriad of other psychological and physical disorders and issues. Many of these issues resulting from interpersonal trauma have been viewed as being separate from PTSD, generating many problems with treatment, research, and conceptualizations of the disorder.The DSM-IV field trial for PTSD was employed to clarify whether these problems of childhood abuse were better accounted for by a diagnosis of PTSD or Disorders of Extreme Stress Not Otherwise Specified (DESNOS). 
 
Methods | A list of 27 symptoms of trauma that came up often, but were not captured by DSM-III criteria was categorized for DESNOS symptom criteria. Structured interviews including one that mirrored DSM-III criteria and the High Magnitude Stressor Events Structured Interview were used on participants. 
 
Results | Only a very small sample of participants qualified as having DESNOS without PTSD, showing that it is rare for people showing symptoms of DESNOS to not suffer from PTSD. There is no statistically significant evidence that the age of onset for trauma (childhood or later in life) or the kind of trauma (i.e., sexual abuse vs. natural disaster) result in a pathology distinct from PTSD. Also, an earlier traumatic experience is tied to more symptoms (including a combination of DESNOS and PTSD symptoms) than a later traumatic experience. Similarly, the longer someone is exposed to trauma, the more likely they are to develop both PTSD and DESNOS. 
 
Discussion | Interpersonal trauma that is prolonged during childhood will result in problematic symptoms that go beyond ‘just’ PTSD, which are captured under the DESNOS construct. This does not mean that these symptoms are separate from PTSD; instead, they add to it. The designation of DESNOS symptoms under PTSD, and not as a separate co-occurring condition, will allow clinicians to formulate more comprehensive treatments for patients. DESNOS as a construct functions to clarify the multifaceted and devastating nature of trauma. DESNOS is important for treating PTSD as it is a sign of a worse outcome for traumatized patients. Furthermore, patients showing DESNOS symptoms need particular attention to problems of dissociation (i.e., depersonalization) and emotional regulation as they result in more pressing problems of functioning in daily life. In short, attention should be directed to patients who have suffered from trauma that was interpersonal in nature (i.e., sexual abuse) and occurred during early childhood for a prolonged period of time. 
 
 
Abstract | The aim of this article is to review the prognosis and existing treatments for co-occurring PTSD and Substance-Use Disorder (i.e., Alcohol Use Disorder). PTSD and substance-use disorder (SUD) often occur together (25-50 in clinical populations), spelling out worse outcomes for patients and more challenges for clinicians. 
 
Introduction | The prevalence of PTSD varies by sample, but there is a strong co-occurrence between the two disorders. People with lifetime PTSD have much higher chances of also having lifetime SUD. There is also an elevated association between ‘harder’ substance-use disorder (i.e., amphetamine) and PTSD than ‘softer’ substance-use disorder (i.e., alcohol). Many explanations exist for the relationship and high co-occurrence of PTSD/SUD, but the one receiving the most support is that PTSD has a strong influence over developing a substance-use disorder. This does not mean that their relationship is not highly complex and that both disorders act on each other. Patients with PTSD/SUD have worse physical and psychiatric symptoms than those with only one disorder. For example, PTSD/SUD patients are more likely to also have major depression and anxiety disorders. Thus, these patients experience many other psychological issues that make them complex to treat. 
 
Psychotherapy Treatment | Only treatments with at least one published study and tailored specifically to PTSD/SUD patients were assessed.Seeking SafetySo far, this is the only model shown to be effective. It focuses on the present, providing 25 topics to teach coping skills for both disorders.Concurrent treatment of PTSD and cocaine dependenceThis is a 16-session therapy that combines effective treatments for PTSD and SUD. An example would be combining Cognitive Behavioral Therapy (CBT) and Exposure Therapy for SUD and PTSD, respectively.TranscendThis is a 12-week program in which veterans are partially hospitalized together and go through CBT, 12-step models, constructivist (learning through experience), and psychodynamic therapies (focusing on unconscious processes).Substance dependence PTSD therapyThis is also known as assisted recovery from trauma and substances (ARTS) and employs the same strategies as concurrent treatment of PTSD and cocaine dependence, but is instead 40 sessions.Collaborative CareThis is a prevention model aimed at those affected by trauma that resulted in medical injury. It functions to prevent at-risk individuals from developing PTSD and SUD. 
 
Pharmacological Treatment | Few studies have examined pharmacological treatments for PTSD/SUD. One study suggests that naltrexone and disulfiram are safe medications that can be clinically applicable to patients suffering from PTSD and alcohol dependence. 
 
Conclusion | PTSD and substance-use disorder frequently co-occur, having devastating effects on patients. More research is needed on treatments for this as well as how the two disorders influence each other. 
 
 
Abstract |  COVID-19 is only one of the life-threatening outbreaks that took place in the last decade. Experts believe that the COVID-19 virus originated in Wuhan, Hubei, China. The emergence of coronaviruses like this may be a big threat to people’s health across the world. Research on SARS-CoV may help scientists understand COVID-19 since the two viruses have many similarities epidemiologically. In this paper, researchers look into using monoclonal antibodies to help treat SARS-CoV and MERS-CoV. 
 
Introduction | Coronaviruses are a diverse family of viruses that affects mammals, birds, and humans. These viruses have an envelope membrane that contain a single strand of RNA inside. SARS-CoV, MERS-CoV, and COVID-19 are all coronaviruses. The exact origin of COVID-19 may be from bats, the dynamics of how it spread is not known.COVID-19 produces a wide range of symptoms, sometimes resulting in death. These symptoms usually take about 2-14 days after catching the virus to appear. Experts warn that COVID-19 spreads through direct contact and droplets that come from the lungs and throat. Up to this point, research has focused on finding and making molecules that can target the virus’s spike protein. The spike protein is what helps the virus enter and infect cells. If researchers can find and use a molecule to inhibit the spike protein from working, the virus will not be able to infect.Therapeutic Intervention for COVID-19 There is currently no approved vaccine or treatment for COVID-19 or other coronaviruses. This is why quickly discovering and making new treatments is very important. One possible approach has been to use the antibodies of infected patients to prevent future infections and neutralizing the virus. This new therapy would have many challenges, including finding donors, understanding the virus, and how the virus is infecting a specific person. The use of immunotherapy and monoclonal antibodies can help overcome these challenges. These antibodies are very effective and very specific to their target. COVID-19 infects the cells by having its spike protein interact with proteins on the cell’s surface membrane. This makes the spike protein a good target for developing drugs and antibodies to prevent infection. Similar to SARS-CoV, COVID-19 relies on the host cell’s ACE2 receptors to bind and infect the cell, which is why SARS-CoV treatments may be able to also treat COVID-19. Monoclonal antibodies can specifically target these receptors to prevent infection. When monoclonal antibodies target and bind to a receptor, it prevents that receptor from working and binding to its intended target. Figures 3, 4, and 5 show how this would work. Preliminary experiments show promising results that monoclonal antibodies may be a useful therapy (table 1 and table 2). The use of different kind of monoclonal antibodies to target multiple structures and proteins seems to be a promising anti-viral therapy in the future. 
 
Concluding Remarks |  Even though the use of monoclonal antibodies as a therapy has shown to be a promising therapy, there are not any fully developed and marketable products yet. Hopefully, prior research on SARS-CoV and MERS-CoV will push researchers to develop this much needed treatment. 
 
 
Abstract: | In late 2019, the pneumonia causing virus, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), that originated in Wuhan spread rapidly throughout China. The relatively strong transmission capacity of SARS-CoV-2 in comparison to the SARS outbreak of 2003 leads to a rapid increase in confirmed cases. Therefore, prevention and control of the subsequent disease, COVID-19, is crucial.Though the primary symptoms of COVID-19 are respiratory, some patients experience cardiovascular symptoms as well. Patients with underlying cardiovascular conditions have a higher risk of death from COVID-19. This is why understanding the connection between SARS-CoV-2 and cardiovascular health is very important. 
 
SARS-CoV-2 and ACE2: | Angiotensin-converting enzyme 2 (ACE2) plays a crucial role in heart function. Additionally, ACE2 has been identified as a functional receptor for SARS-CoV-2 and other coronaviruses. SARS-CoV-2 binds to ACE2 thereby triggering the SARS-CoV-2 infection. ACE2 is highly expressed in both the heart and lungs. ACE2 is secreted more in patients with cardiovascular disease (CVD) as compared to healthy individuals. This can, in-turn, lead to respiratory symptoms. Because increase in ACE2 levels can lead to the fatal respiratory symptoms seen in COVID-19, ACE inhibitors may show positive outcomes and should be considered as a therapy. 
 
Acute cardiac injury: | A coronavirus with similar pathogenicity to SARS-CoV-2, Middle East respiratory syndrome-related coronavirus (MERS-CoV), can cause acute myocarditis and heart failure. Of the first 41 patients with SARS-CoV-2 in Wuhan, 5 had myocardial injury. Of the 5 patients that experienced myocardial injury, 4 were admitted into the ICU. This indicates the prevalence of myocardial injury in COVID-19. In another sample of 138 patients in Wuhan, 36 patients were admitted into the ICU. The levels of biomarkers of myocardial injury were higher in these 36 patients as compared to the other COVID-19 patients. This indicates a correlation between myocardial injury and serious symptoms.Many of the patients first went to see doctors about their cardiovascular symptoms such as heart palpitations and chest tightness. These patients were later diagnosed with COVID-19. Even people who died from COVID-19 without underlying CVD showed significant heart damage. This shows that patients with COVID-19 are likely to experience cardiovascular symptoms caused by COVID-19 progression. 
 
Chronic cardiovascular damage: | A 12-year follow-up survey of 25 patients who had recovered from SARS-CoV showed that 68 had hyperlipidemia, 60 had glucose metabolism disorders, and 44 had cardiovascular system abnormalities. Additionally, metabolomics analysis showed that patients with a history of SARS-CoV had lipid metabolism dysregulation. The mechanism by which SARS-CoV infection leads to glucose and lipid metabolism disorders is unclear. However, because SARS-CoV-2 and SARS-CoV have similar structures, healthcare professionals should give attention to cardiovascular protection in COVID-19 patients. 
 
Patients with pre-existing CVD: | A meta-analysis showed that patients with underlying CVD were at a higher risk for MERS-CoV infection. In patients with MERS-CoV and severe symptoms many had hypertension, diabetes, and heart disease. Regarding SARS-CoV-2, elderly people with hypertension, coronary heart disease, or diabetes were more likely to be infected. Among patients with severe symptoms from COVID-19, many had hypertension, heart disease, and arrhythmia.In addition to preexisting CVD, healthcare professionals should be aware of the cardiovascular effects of treatments given to COVID-19 patients. Most patients with COVID-19 were given antiviral drugs, however, these drugs can cause cardiovascular disorders. 
 
Conclusions: | SARS-CoV-2 likely infects cells through ACE2 to cause COVID-19. Though the primary manifestation of COVID-19 is respiratory related, there is strong evidence linking COVID-19 and cardiovascular disorders. Additionally, patients with underlying CVD are at a higher risk of developing severe symptoms. 
 
 
Abstract | Much research on COVID-19 is needed to understand its nature (i.e., how it spreads) and to come up with more targets for vaccines and medication. This study discusses what is currently known about the structure and qualities of SARS-CoV-2, including how it spreads and where it comes from. 
 
Introduction | SARS-CoV-2 belongs to the Betacoronavirus (β-CoVs) genera of the Orthocoronavirinae subfamily, making it known to infect mammals and similar to the previous SARS-CoV and MERS-CoV. COVID-19 has spread to 72 countries and affected hundreds of thousands of people worldwide, designating it as an international health concern. There are currently no existing cures, vaccines, or specific medications for it, so research and an accurate understanding of the virus are crucial. 
 
Structure of SARS-CoV-2 | The SARS-CoV-2 genome (the complete set of genes in a cell) encodes a polyprotein that is then cleaved and broken down into amino acids via enzymes, creating, among other proteins, the spike (S) surface glycoprotein -a structural protein. This protein is important in the attachment of SARS-CoV-2 to host cells. Thus, comprehending the structure and function of this protein may help in generating antibody drugs that ultimately contribute to developing future vaccines. 
 
Etiology and pathogenesis of SARS-CoV-2 | SARS-CoV-2, like SARS-CoV and MERS-CoV, causes atypical pneumonia, which can be explained by humans having dipeptidyl peptidase 4 (DPP4) and angiotensin-converting enzyme 2 (ACE2) receptors in the respiratory tract. The SARS-CoV-2 surface spike (S) glycoprotein binds to these receptors well. Moreover, unlike SARS-COV, SARS-CoV-2 spike proteins bind to human ACE2 receptors 10-20x better, allowing it to spread easier. Once in the lungs, SARS-CoV-2 reproduces quickly, triggering a powerful immune response that can result in cytokine storms and lung tissue damage. Cytokine storms are key causes of acute respiratory distress syndrome (ARDS) and multiple organ failure, making it part of an especially poor presentation of COVID-19 infection. Furthermore, after SARS-CoV-2 infection patients are left with fewer and weaker T-cells, which contribute to weakened and lessened immune function. All of these contribute to lung/breathing failure in SARS-CoV-2 patients. 
 
Epidemiological characteristics of SARS-CoV-2 | Origins of SARS-CoV-2Many studies suggest that bats may be the natural host and pangolins may be the intermediate host for SARS-CoV-2. The first source of and whether the virus is transmitted directly from bats or via pangolin still needs to be investigated. Finding out the source will help to understand how the virus spreads and help stymie the outbreak.Transmission route of SARS-CoV-2SARS-CoV-2 is transmitted between people by respiratory droplets that come into contact with one’s eyes, mouth, or nose. It may also be transmitted through aerosol in closed environments with little airflow. Some studies have suggested that it may travel through the digestive tract. Whether SARS-CoV-2 can be transmitted to babies via breastfeeding requires more research.Susceptible populationThere is an overall general susceptibility to catching COVID-19, but populations of particular concern are the elderly, those with weakened immune systems, pregnant women, and newborns.Incubation periodThe average incubation period for SARS-CoV-2 patients is 3-7 days, revealing a substantial time period in which the disease can be transmitted. Asymptomatic patients can also spread the disease. Research supports the recommendation of surveilling patients for 14 days.Basic reproduction number (R0) of SARS-COV-2Reproduction number represented as R0, or R naught, is a measure of how many susceptible people an infected patient will likely infect (i.e., R0 of measles=15). The average R0 of SARS-CoV-2 is about 3.28.Clinical presentationThe main early symptoms of COVID-19 are fever, fatigue, dry cough, muscle pain, and labored breathing. Other less common symptoms include headache, runny nose, sore throat, stuffy nose, vomiting, and diarrhea. Particularly bad patients usually showcase labored breathing and/or particularly low levels of oxygen in their blood after a week of infection. After this would come septic shock (organ failure and severely low blood pressure), acute respiratory syndrome, an over-accumulation of acid in the body, and problems with the body dealing with blood clotting.Pathological characteristicsPathological characteristics of SARS-CoV-2 were found to be related to acute respiratory syndrome as well as very similar to those seen in SARS-CoV and MERS-CoV.Computed tomography (CT) imaging characteristicsCT is helpful when patients present with a persistent cough, fever, and fatigue. CT imaging also supports the devastating effects SARS-CoV-2 has on the lungs.Detection of SARS-CoV-2Using reverse transcription-quantitative PCR (RT-qPCR) or viral gene sequencing of nasopharyngeal swabs, stool, or blood samples, scientists are able to detect the nucleic acid of SARS-CoV-2. Studies have shown that saliva samples may be effective and less invasive to collect for SARS-CoV-2 detection. CRISPR-based SHERLOCK (Specific High-sensitivity Enzymatic Reporter UnLOCKing) technique uses synthetic SARS-CoV-2 RNA fragments for COVID-19 detection. This technique is quicker and more accurate than RT-qPCR, so it will likely be used with clinical patients. 
 
Treatments | General treatmentsPatients should be in a safe and comfortable environment in which food and water are not an issue, and vital signs are actively monitored. They should also be kept away from others to keep the disease from spreading.Antiviral therapyInterferon-alpha (IFNα) has been shown to directly interfere with and inhibit viral replication as well as help immune responses. Lopinavir/ritonavir (Kaletra) has been shown to help severe patients of SARS or MERS by improving acute respiratory syndrome. It may also inhibit the protein synthesis of SARS-CoV-2. Ribavirin can thwart RNA and DNA replication of viruses by stopping inosine monophosphate dehydrogenase activity. Chloroquine is a cheap and safe drug that has been shown to effectively stop SARS-CoV-2 in vitro. Arbidol is shown to similarly stop the reproduction of COVID-19 in vitro. Remdesivir has been reported to obstruct SARS-CoV and MERS-CoV in vivo (in a living organism).Cellular therapyHuman Natural Killer (NK) cells are immune cells that break down the membrane of antibody-coated virus-infected cells by the process of antibody-dependent cellular cytotoxicity (ADCC). NK cell therapy can enhance immunity and is currently viewed as a viable strategy for treating and preventing pneumonia from SARS-CoV-2.Mesenchymal stem cells (MSCs) have been shown to effectively treat acute respiratory syndrome and reduce lung fibrosis, designating it as a favorable therapy for COVID-19 patients.ImmunotherapyConvalescent plasma (plasma removed from the blood of a recovered patient) therapy has been used for previous infection diseases like Ebola and may effectively treat SARS-CoV-2 patients. Monoclonal antibodies may be important to SARS-COV-2 remission. The monoclonal antibody CR3022 targets the 193-amino acid receptor binding domain (RBD) of the spike protein of SARS-CoV-2 without overlapping with the ACE2 binding site. Thus, this monoclonal antibody has potential for treating COVID-19 pneumonia by itself or with other monoclonal antibodies.Chinese medicineGlycyrrhizin, hesperetin, baicalin, and quercetin are Chinese medicines that may help with preventing and treating COVID-19 pneumonia. 
 
Conclusion &amp; future directions | COVID-19 affects the lungs, liver, gastrointestinal organs (i.e., small intestine), esophagus, testis, and kidney. Its characteristics and ease with which it infects humans make designing therapies, drugs, and vaccines imperative. Research may have to focus on establishing animal models that summarize various aspects of human disease and vaccines. 
 
 
Abstract | The coronavirus spike protein (S) allows the virus to begin infecting a cell. The S protein is made of two parts: the S1 and S2 domains. S1 is responsible for letting the virus bind to receptors on the surface of the cell. S2 helps the viral membrane fuse with the cell’s membrane. In certain cases, there are proteins that can cut these two pieces apart. Research has shown that viral entry into the cell requires this proteolysis by cathepsin L, but treatment with trypsin also allows the virus to enter. It is still unclear how the proteolysis of the SARS-CoV S protein works exactly. A mutation at site R797 on the S protein made the virus unable to fuse with the cell after trypsin treatment. Researchers also inserted cleavage site for a protein called furin. This allowed for cellular fusion even without trypsin. It was noted that the addition of a second cleavage site increased this cell-to-cell fusion. This data suggests that these two cleavage sites may work together to allow the virus to fuse with the cell.There are three kinds of S proteins. The type discussed in this paper is a class 1 fusion protein. Class 1 fusion proteins require proteolytic cleavage to activate. This activation can also occur with a low pH, receptor binding, or a combination of these two. This activation causes a shape change that exposes the part of the protein that can insert itself into the cell membrane.Coronaviruses have continued to be a threat since SARS-CoV first emerged in 2003. The SARS-CoV S protein displays many characteristics of a class 1 fusion protein. The cleavage of S1 and S2 can be enhanced by increasing the expression of furin enzymes.Research on SARS-CoV has shown that acidifying the inside of the viral endosome and the protease cathepsin L are important steps in viral infection. Proteins besides cathepsin L have been shown to be able to cleave the S protein as well. Other research has also shown that expression of factor Xa and other proteases like trypsin, thermolysin, and elastase can induce and enhance SARS-CoV infection. These proteases seem to cleave the S protein along the S1/S2 boundary. The use of trypsin identified position R667 as a cleavage site. This suggests there may be an entry route into the cell for SARS-CoV that doesn’t require fusion and the formation of an endosome. 
 
Results | Role of the S1-S2 Boundary in Trypsin-Mediated Activation of SARS-CoV S Membrane Fusion Researchers did experiments to understand the role of S1/S2 cleavage in allowing S protein fusion. A normal SARS-CoV S protein was cleaved at the S1/S2 boundary by trypsin. However, a mutant SARS-CoV S protein (mutated at position R667) was not able to be cleaved by trypsin. Using cells referred to as Vero E6, researchers used immunofluorescence microscopy to observe the fusion. Researchers inserted the genes for SARS-CoV S protein into these Vero E6 cells. When these two cells fuse into one, the cell with now two nuclei is called syncytia. Both cells with a normal SARS-CoV S protein gene and ones with a mutated S protein gene showed normal syncytia formation with immunofluorescence microscopy. To exactly measure these two groups, researchers used a luciferase assay. Researchers used another cell line (BHK cells) for this part of the experiment. They found that more trypsin caused more fusion in cells with a normal S protein. Mutant cells were able to fuse, but not as efficiently. This suggests that S protein cleavage is likely not the most important during fusion for SARS-CoV. Identification of Additional Cleavage Sites within the Coronavirus S Protein Researchers used a ProP 1.0 server to look for other cleavage sites in classes 1, 2, and 3 coronaviruses. Researchers by default looked for site that furin enzymes can cleave. Researchers found a cleavage site in the S2 domain of the IBV (infectious bronchitis virus) strain called Beaudette. The Beaudette strain is the only IBV strain with a cleavage site in S2. Researchers named this cleavage site S2’. Researchers used a Western blot analysis to verify that S2’ is a cleavage site. The antibodies were specific to the S2 domain of the S protein. The results showed the S protein was cleaved at the S1/S2 boundary as well as at S2’. Further analysis showed that SARS-CoV may also have this S2’ cleavage site. Introduction of a Furin Site at S2’ Induces SARS-CoV-Mediated Membrane Fusion Researchers inserted furin cleavage recognition sites at the S1/S2 boundary and at S2’ of the SARS-CoV S protein, specifically 667 and 797. The furin cleavage recognition sites allow for the furin to identify these sites as where it is supposed to cut. Researchers did this by making specific mutations in the S protein. Researchers used Vero E6 cells again for these experiments. 797 mutants showed much more fusion than 667 mutants. Cells with 667 and 797 mutations had even more fusion than 797 (&gt;95). This was measured using a luciferase assay.Data additionally shows that S1/S2 cleavage facilitates cleavage at S2’ and the subsequent S2’-activated fusion.Mutation of R797 at SARS-CoV S2’ Inhibits Trypsin-Induced Membrane Fusion Researchers mutated K796 and R797 to further investigate the role of the S2’ position in membrane fusion. These became K796A and R797N. They had three cell groups: a K796A mutant group, an R797N mutant group, and a group with both mutations. Cells with both mutations had lower amounts of the S protein in their membrane, however, incubating the cells at 32 C rescued them. Researchers used immunofluorescence microscopy to look at syncytia formation. Using trypsin and Vero E6 cells with normal SARS-CoV S protein led to many syncytia. Cells with both positions mutated had almost undetectable amounts of syncytia formation. Mutant K796A cells still were able to efficiently fuse with trypsin treatment. A luciferase assay supported what researchers found with the microscopy experiments. The double mutation strongly inhibited trypsin-induced membrane fusion and that K796A mutations only partially affected the fusion.SARS-CoV S-Mediated Virus Entry Is Dependent on Cleavage at S2’, as well as at the S1-S2 Boundary To analyze the S1/S2 and S2’ cleavage sitesin vivo, researchers used a mouse leukemia virus (MLV) system that makes particles to activate luciferase expression. Researchers are now using viruses to try and infect cells, instead of looking at two cells fusing like in prior experiments. In this experiment, luciferase expression would mean the virus has infected the cell. Cells were treated with NH4Cl, which will prevent viral infection through the endosomal pathway. Researchers activated the fusion using a short trypsin treatment. The K796A and R797N mutations completely inhibited trypsin activation and infection. This suggests that these positions may play a significant role in infection. K796A mutations had a very weak effect, nearing the same levels of fusion as normal cells. R797N mutants had barely any fusion. Even though the R667N mutation decreased cell-to-cell fusion by trypsin, this in vivo experiment showed that these mutants could not be recovered by trypsin treatment. This suggests that cleavage at the S1/S2 boundary (the R667 position) has a more important role for viral infection than it does when two cells are fusing. When researchers took away the NH4Cl and trypsin, R797N mutant viruses were still able to easily infect the cell, suggesting that the R797 position is not important for the endosomal route of SARS-CoV entry. 
 
Discussion | The data from these experiments suggests that SARS-CoV S protein cleavage at the S1/S2 position triggers cleavage at the S2’ position and then membrane fusion. The S2’ position was found when research used bioinformatics to search for another possible cleavage position on the S protein that is involved in viral entry. Both mutations discussed in these experiments seemed to have no effect on virus entry if there was no endosomal acidification or cathepsin L inhibitors. This may be because cathepsin L recognition sites are not as specific as furin and trypsin sites. Therefore, cathepsin L may not be involved in S2’ cleavage, or there are other “satellite” sites around S2’ that are cathepsin recognition sites. Future experiments on these spike protein cleavage sites may have implications on viral host range or pathogenesis. 
 
Methods and Materials | Cell-Cell Fusion Assays Vero E6 cells were grown on 24-well plates. Invitrogen Lipofectamine 2000 was used to transfect them with the S proteins. Cells were then placed in serum-free media with trypsin. These cells were then transferred to a media with 10 FBS, incubated, and fixed in place. Immunofluorescence was used to observe the fixed cells. For syncytia formation, cells were fixed without protease treatment. Researchers then counted the number of cells with two or more nuclei. For quantitative assays, BHK cells were also grown in 24-well plates. Researchers then transfected them with plasmids having either normal or mutant SARS-CoV S protein and a plasmid with luciferase controlled by a T7 promoter. BHK cells were then incubated the same way that Vero E6 cells were and incubated for 6 hours before lysis. Luciferase activity was then measuredProduction of Pseudotyped Virions Researchers used plasmids to produce pseudovirions. The transduction of the pseudoparticles involved cotrasnfecting BHK cells with plasmid DNA. Following preparation and periods of incubation, luciferase activity was measured. 
 
 
Abstract | Venous leg ulcers (VLU) are a growing issue in healthcare. Transforming growth factor-beta (TGF-beta) and Endoglin (CD105) help to regulate wound healing and inflammation. CD105 can be cleaved off of its normal site on the cell membrane, called soluble CD105 (sCD105). Then the sCD105 can bind to and lower TGF-beta’s signal. This will increase angiogenesis. This study looks at the presence of TGF-beta and sCD105 in wound fluid. They tested the effect of sulodexide on healing VLU. The increase of TGF-beta 3 found shows that it has a negative effect on wound healing. High levels of sCD105 reduce inflammation by affecting how white blood cells move across vessel walls, called leukocyte adhesion and transmigration. This favors wound healing. Glycosaminoglycan sulodexide increases the amount of sCD105 released, so it may accelerate wound healing. 
 
Introduction | Venous leg ulcer (VLU) is a complication of chronic venous disease (CVeD). The cause of VLU is not well understood. We need to find out how to heal wounds that are hard-to-heal. Wound healing is usually divided into four stages: hemostasis, inflammation, granulation, and remodeling. Ulcers or wounds that do not heal in 6 months are stuck in inflammatory conditions, so they cannot progress through the four stages. This study looks at the microenvironment of the would bed, specifically wound fluid (WF). Right now, there is no biomarker to tell is if a wound is in the process of healing, or if it is not progressing. This study looks at TGF-beta isoforms and sCD105 because of their role in vascular inflammation and wound healing.TGF-beta 1 and TGF-beta 2 are well understood, and both respond to injury and help in wound healing. TGF-beta 3 is not well understood. CD105 is an auxiliary receptor to TGF-beta type II receptor. CD105 controls inflammation related leukocyte adhesion and transmigration. Matrix metalloproteinase (MMP)-14 cleaves CD105 and creates soluble CD105 (sCD105). sCD105 downregulates TGF-beta. Creating sCD105 may change the shape of the endothelial cells, which is seen in CVeD. CD105 has a high expression level on vessel wall cells and activated macrophages. CD105 is found highly upregulated during wound healing, but has not been studied in VLU wound fluid.This study looks at the three TGF-beta isoforms and sCD105 in healing and non healing VLU. This study also looks at the release of TGF-beta isoforms and sCD105 from wound fluid stimulated monocytes, with and without glycosaminoglycan sulodexide. Sulodexide had anti-inflammatory effects in CVeD. 
 
Methods | 30 patients with VLU were chosen for the study. Human monocyte THP-1 cell line was used for the cell culture. Magnetic Multiplex Immunoassay was performed to determine the TGF-beta isoforms and sCD105 levels in the wound fluid. 
 
Results | This study looked at 30 VLU patients. Based on how much the patient had healed, the tissues samples were divided into two groups: inflammatory (Infl) and granulating (Gran). The average timespan of the ulcer was 41.6 months. The average size was 10.7cm. The Infl patients had higher pain than the Gran patients. TGF-beta 1 and 2 were not at different levels for the Infl and Gran patients. But TGF-beta 3 was significantly increased in Infl patients compared to Gran patients. sCD105 was decreased in Infl compared to Gran patients, which tells us that sCD105 may change during the healing process.Human macrophage cells were treated with the inflammatory wound fluid and sulodexide. The sulodexide alone did not change the TGF-beta or sCD105 levels. But, sulodexide plus either Infl or Gran wound fluid increased the level of sCD105. This means that sulodexide interacting with biomolecules in wound fluid will lead to the shedding of sCD105. 
 
Discussion | Specific cell types and extracellular matrix components have a strictly coordinated sequence of events to allow wound healing to occur. This study revealed that TGF-beta 3 is elevated in Infl wound fluid compared to Gran wound fluid. This suggests that TGF-beta 3 downregulates TGF-beta 1 and 2, and promotes the release of pro-inflammatory cytokines. TGF-beta 3 may be part of the cause of chronic VLU. This is supported because neutrophils are known to release TGF-beta 3 and neutrophils have been identified in the ulcer bed of patients with VLU.sCD105 competes with membrane bound CD105 for leukocyte integrin binding. sCD105 can outcompete membrane bound CD105, which reduces the leukocyte transmigration and therefore reduces inflammation. sCD105 will work against the membrane CD105, so it decreases angiogenesis, capillary formation and sprouting but increases the permeability of vessels. Sulodexide increases the sCD105, which affects TGF-beta and leukocyte adhesion and transmigration. Although membrane bound CD105 plays an important role in angiogenesis, soluble CD105 may increase wound closure and therefore would be the first successful treatment in patients with a venous leg ulcer resulting from chronic venous disease.*Eng stands for membrane bound CD105 and sEng stands for soluble CD105 
 
 
Abstract: | Oxidative stress can lead to Alzheimer’s disease (AD), among other disorders. Oxidative stress is when there is a buildup of highly reactive free-radicals in the body. These free-radicals can lead to cell death through apoptosis. Carnosic Acid (CA) is a chemical found in rosemary and sage that can combat oxidative stress in its active form. The active form of CA stimulates the Nrf2/Keap1 pathway. The Nrf2/Keap1 pathway produces antioxidants which can neutralize the free radicals which, in-turn, prevents cell death.Both in vivo and in vitro studies were conducted. Mouse models of AD were treated with CA transnasally twice weekly for 3 months and tested on their neuronal capacity. The in vitro studies were done on rat neurons. Both studies showed positive results in response to the CA treatment. 
 
Main: | AD is an increasingly prevalent disease among the elderly population. The loss of synapses accompanied by neuronal loss leads to cognitive decline in AD patients. This neuronal damage is caused primarily by oxidative and nitrosative stress. Oxidative stress is caused by reactive oxygen species (ROS) and nitrosative stress is caused by reactive nitrogen species (RNS).Many studies have shown the potential of the Nrf2/Keap1 pathway in combating oxidative and nitrosative stress especially in neurodegenerative diseases. This study tested the efficacy of a known Nrf2/Keap1 pathway activator in AD mouse models.Electrophilic compounds react with the Keap1 leading to the Nrf2 to be released into the cytoplasm. The Nrf2 then moves to the nucleus of the cell where it binds to the antioxidant response element (ARE) promoter region. The problem with electrophilic drugs is that they may have reverse effects. The antioxidants that are produced by the electrophilic drugs may be used to combat the electrophilic drug instead of the target reactive species. The use of pro-electrophilic drugs is a strategy to overcome the previously stated obstacle. Pro-electrophiles are activated in environments of oxidative stress. This makes pro-electrophiles innocuous in normal environments. Carnosic acid is a naturally occurring pro-electrophile. 
 
Results: | 1. CA treatment ameliorates amyloid-beta-induced spine loss in cultured rat cortical neurons:For in vitro study, dendritic spines of rat embryos were treated with amyloid-beta (AB) to simulate AD. Treatment with AB showed a significant decrease in dendritic spine density when compared to the control. However, CA treatment along with the AB exposure reduced the damage to the dendritic spines.2. CA treatment rescues deficits in spatial learning in hAPP-J20 AD mice:The mice were also tested for their spatial learning. A Morris water maze was used to evaluate the mice’s spatial learning ability. The hAPP-J20 mice (the mice modeling AD) took a significantly longer time in the maze as compared to the wild type mice. On the first day of training, the hAPP-J20 mice with CA treatment took a significantly longer time than the wild type mice. However, on the third day of training, these mice took a similar amount of time as compared to the wild type mice.3. CA Treatment rescues dendritic loss in hAPP-J20 mouse brain, as reflected by the number of MAP2-positive cells:The next evaluation involved four groups: wild-type control, wild-type CA, J20-control, and J20-CA. In this evaluation, the level of MAP2 signaling was tested. MAP2 signaling is correlated with dendritic loss in mice. Both the wild-type control and the wild-type CA showed robust MAP2 signaling whereas the J20-control lacked MAP2 signaling. J20-CA showed similar MAP2 signaling as both the wild-type groups. This indicates that CA treatment can rescue dendritic loss in hAPP-J20 mice.4. CA Treatment rescues synaptic loss in hAPP-J20 mouse brain, as reflected by synaptophysin staining:To evaluate how CA impacts synaptic levels in hAPP-J20 mice, quantitative confocal immunohistochemistry by the synaptophysin antibody was performed. The J20-control mice showed significantly lower synaptic activity as compared to the wild-type mice. The J20-CA mice, on the other hand, showed similar synaptic activity as the wild-type mice. This shows that synaptic loss in hAPP-J20 mice can be rescued by CA treatment.5. CA Treatment decreases astrocytosis in hAPP-J20 mouse brain, as reflected by the number of GFAP-positive cells:A similar approach as the previous experiment was used to test the effect of CA treatment on gliosis in hAPP-J20 mice. Gliosis is when the body creates an abnormal amount of glial cells (cells that support nerve cells). This can lead to scars developing in the brain. This experiment found that treatment with CA can prevent gliosis in the hippocampus of hAPP-J20 mice.6. CA Treatment reduces amyloid accumulation in hAPP-J20 mouse brain, as reflected by AB immunohistochemistry:In vitro studies have demonstrated the efficacy of CA in the presence of AB. However, this study is the first to prove similar efficacy in vivo. Similar to the last two experiments mentioned, immunohistochemistry was performed to evaluate the AB levels in each group. Both wild-type groups showed undetectable levels of AB whereas the J20-control group showed high levels of AB. The J20-CA group showed significantly reduced levels of AB demonstrating CA’s efficacy in suppressing AB in vivo.7. Effects of CA treatment on 3xTg AD mouse brain:3xTg is another mouse model for AD. Similar experiments were performed on the 3xTg mice as the hAPP-J20 mice to generalize the results. The findings from the 3xTg mice were similar to those of the hAPP-J20 mice. Additionally, 3xTg mice have been reported to have increased levels of p-tau. CA treatment reduced the p-tau levels in 3xTg mice. The results from the hAPP-J20 mice combined with the results from the 3xTg mice demonstrates the general efficacy of CA in AD. 
 
Discussion: | There is strong potential for pro-electrophilic drugs (PEDs) like CA in neurodegeneration recovery. PEDs activate the Nrf2/Keap1 pathway without depleting antioxidants. Additionally, CA crosses the blood-brain barrier in neuroprotective concentrations making delivery of the drug much easier.This study has demonstrated the effectiveness of PEDs in in vivo models of AD, unlike any previous study. This study, with the use of immunohistochemistry, showed that CA improves histological damage in the hippocampus of two different AD mouse models.Though CA has been shown to activate numerous transcriptional pathways, there is strong evidence supporting the role of Nrf2 activation in the protection seen in this study. 
 
Methods and Materials: | The AB peptide was prepared at a concentration similar to what is found in a brain affected by AD. Primary cortical cultures were prepared from embryonic rat pups and, ~2 weeks later, the neurons from the cultures were exposed to the AB peptides. The neurons were then treated with CA or a vehicle for 4 days.Regarding the in vivo studies, all AD transgenic mice were obtained and performed on according to IACUC protocol. The CA treatment was administered transnasally to maximize CNS levels while minimizing systemic delivery. Morris water maze test and brain immunohistochemistry was performed to test the efficacy of CA. Finally, statistical analysis was performed. 
 
 
Abstract | In this study, researchers examined the blood types of Wuhan patients infected with SARS-CoV-2 with the blood types of healthy citizens in the surrounding area. They found that COVID-19 infections were more common among people with type A blood and less frequent in people with type O blood. This is an early study. Regardless, it should encourage more researchers to study the link between blood type and COVID-19 infection rate. 
 
Introduction | Past studies have shown that traits such as age, gender, and health conditions may affect how likely a person is to contract COVID-19. However, there is currently no known component in the human body that can be used to reliably predict how susceptible a person is to COVID-19. Other viruses like Hepatitis B are known to infect people with specific blood types more often. Blood types are distinguished by the different antigens that blood cells of different types have. In this study, researchers wanted to see if there are specific blood types that affect the risk of contracting COVID-19. 
 
Methods | Typed blood samples were collected from living and dead COVID-19 patients from the cities of Wuhan and Shenzhen in China. These COVID-19 cases were confirmed using reverse PCR tests. Surveys were also sent out to healthy citizens in Wuhan and Shenzhen asking them to provide their blood types. The blood types of infected and healthy citizens were compared using statistical methods. 
 
Results | A significantly higher proportion of infected people, living and dead, had the A blood type. Meanwhile, a significantly higher proportion of healthy people had the O blood type. The percentage of people with blood types B and AB were similar between the two groups. These percentages remained constant even when the researchers compared different age and sex groups. 
 
Discussion | The data suggests that different blood types confer different levels of risk for COVID-19 infections. Type A blood is associated with greater risk while type O blood is associated with lower risk. Future studies should aim to investigate the mechanisms driving these different levels of risk. 
 
Limitations | The number of people examined in the study was small. Some of the people also had unknown ages, sexes, and chronic medical conditions. 
 
Conclusions | This study provides the first reported link between blood type and COVID-19 risk. However, it should be verified with future studies that examine more people. If verified, the study's results could change how we handle the pandemic. People with type A blood may be given more personal protection against infection. Infected people with type A blood may need to receive more aggressive treatment. Blood types may receive higher consideration inCOVID-19 management efforts. 
 
 
Abstract | The purpose of this article is to investigate the effects of ACEI/ARB on COVID-19 patients. Theoretically, ACEI/ARB should help COVID-19 patients similarly to SARS-CoV patients, but many major cardiology scientific associations have denied this. This study concludes that an association between ACEI/ARB and positive effects on COVID-19 patients is not supported. This may change in the future, however. 
 
Introduction | SARS-CoV-2 is similar to SARS-CoV and MERS. Studies show the virus binding to angiotensin-converting enzyme 2 (ACE2) receptors, allowing it to replicate and transport through the lungs. Angiotensin-converting enzyme inhibitors (ACEI) are medicines that block ACE2 receptors, protecting against infection. 
 
Background | ACE2 receptors act to counter-regulate renin-angiotensin-aldosterone system (RAAS) activation. RAAS is a hormone system involved in regulating blood pressure and fluid and electrolyte balance. The RAAS system has a major role in people suffering from diabetes, hypertension, or heart failure. ACEI and ARB (angiotensin II receptor blocker) drugs are often used to help with these conditions (i.e., hypertension and heart failure).	 
 
COVID-19 and Comorbidity | Hypertension and diabetes are major risk factors for infection and poorer outcomes of COVID-19. Studies have not combined ACEI use with COVID-19 patients showcasing hypertension and/or diabetes. ACEI use has not been shown to affect COVID-19 outcomes. SARS-CoV-2, SARS-CoV, and MERS all show a common association with damaging cardiac events. 
 
Pros and Cons of ACE Inhibition | ACE2 receptors may be involved with cardiac events associated with SARS-CoV-2. Drugs that increase activity at ACE2 receptors may increase the risk of infection and worse outcomes in COVID-19 patients. ACEI may inadvertently lead to ACE2 upregulation, which would allow SARS-CoV-2 to bind to more sites and increase infection. This has been seen with COVID-19 patients taking ACEI or ARB drugs for hypertension or diabetes. Other investigators have argued that using ACEI actually disrupts ACE2 pathways, then decreasing ACE2 production and decreasing the likelihood of SARS-CoV-2 infection. However, no causal relationship between ACEI use and decreased risk for death has been established. Cardiology associations have urged those using ACEI/ARB medications to continue using them while infected with COVID-19. 
 
Conclusions | More research is needed regarding the relationship between ACEI use and COVID-19 outcomes. There is not enough evidence to support halting ACEI use as they still help with hypertension and diabetes, so COVID-19 patients already using them should continue to do so.  
 
 
Abstract: | SARS-CoV2 is the virus that causes coronavirus disease (COVID-19). COVID-19 is a potentially fatal disease that could impact the entire globe. Because many of the infected people were exposed to the wet animal market in Wuhan City, China, many researchers theorized that the animal market is the origin of the virus. The reduction of person-to-person contact has been limited to slow the spread of SARS-CoV2. This review highlights the current concerns regarding the virus and steps to take to help control the spread of the virus. 
 
Introduction: | The primary target for coronaviruses is the respiratory tract. There have been numerous outbreaks of different coronaviruses, notably severe acute respiratory syndrome and Middle East respiratory syndrome. Numerous patients were admitted to hospitals for pneumonia. A common factor between these patients was their exposure to the Wuhan wet animal market. This cluster of patients led to the prediction of a coronavirus outbreak. The estimated reproduction rate for the virus was between 2.24 and 3.58.The likely reason for the rapid spread of the virus was the exposure of people in hospitals to the few people with SARS-CoV2. By January 22, 2020, there were 571 confirmed cases. There were likely many more cases, however, only clinically sick patients were tested. By January 30, 2020, there were 7734 confirmed cases in China and 90 cases in other countries with a fatality rate of ~2.2. By February 16, 2020 there had been 1666 deaths from COVID-19 in China and the first few confirmed cases in the United States. 
 
Symptoms: | Symptoms of COVID-19 begin after an incubation period of about 5 days. Depending on the age and immune system health of the patient, the incubation period can vary. The incubation period is shorter in elderly patients (&gt;70 years of age).The most common symptoms of COVID-19 are fever, cough, and fatigue. Chest CT scans showed that patients had pneumonia in both lungs as well as numerous abnormal features. Some of these abnormalities could be fatal.Unlike other coronaviruses, SARS-CoV2 targets the lower airway. Additionally, some cases, the virus was present in the upper lobe of the lung leading to difficulty breathing. COVID-19 is also unique in that many patients experienced gastrointestinal symptoms. 
 
Pathogenesis: | Since the start of the epidemic (now a pandemic), the number of new cases and deaths per day from COVID-19 has been rising rapidly. As the virus incubated, patients would develop severe pneumonia in addition to ground-glass opacities in CT scans and cardiac injury. Patients developed significantly high levels of cytokines. 
 
Phylogenetic analysis: | 99.8-99.9 nucleotide identity in isolates from 5 patients provides evidence of a new beta-CoV strain. When compared to SARS-CoV, COVID-19 showed &gt;80 identity and when compared to MERS-CoV, COVID-19 showed 50 identity. This phylogenetic analysis shows that SARS-CoV2 belongs to the betacoronavirus genus. 
 
Therapeutic/treatment options: | There are no drugs that treat COVID-19 nor are there any vaccines to protect against COVID-19. However, broad antiviral drugs can help slow down the virus until a more precise drug becomes available. Remdesivir and chloroquine have shown positive results in vitro. Additionally, these drugs have been used in human patients. Though the results are promising for these drugs, further research must be done to confirm their efficacy. 
 
Future directions to control the spread of the disease: | Reducing person-to-person contact is crucial to slow the spread of this virus. Additionally, basic hand washing etiquette and regular disinfecting can make a large impact on the spread of the virus.There is evidence that the virus can be transmitted through many tracts including the faecal tract. It is crucial that countries monitor the spread and development of the virus on a biological and epidemiological scale. 
 
 
Abstract | Understanding the physiological cause of mental illnesses has greatly increased. This knowledge combined with the discovery of the microbiome and psychoneuroimmunology has created a new way to study mental health: psychobiotics. The microbiome we have today is much different than past humans, due to our diet, medications, and other environmental factors. The ability of our diets and microbiomes to affect our mental health is a very complex and poorly understood discovery. The potential of psychobiotics to alleviate mental illnesses makes understanding the science very important. 
 
Main Text | Affective disorders, anxiety disorders, and psychotic disorders are more than simple stressors, they involve the whole body inflammation and immune health. The microbiome consists of over 100 trillion organisms that affect our bodies. The microbiome can affect diseases of the gut, autoimmune disease, obesity, and alcohol metabolism. Every single person’s microbiome is unique, but healthy people have a lot of the microbiome in common.The idea that the gut microbiome and brain are connected is based on the hypothalamic-adrenal-pituitary axis. The microbiome may influence the axis in a similar way to stress, which can create inflammatory cascades and an increase in sympathetic nervous activation. Probiotics and antiinflammatories can lessen the inflammation and sympathetic activation. Medication that includes healthy microbes can potentially be used for anti-inflammation, anti-anxiety, or anti-depression medication with much lower side effects than traditional medications.Studies have shown that rodents' moods can be influenced by probiotics, prebiotics, and fecal transplants. Prebiotics refer to types of fiber that the microbiome can eat. Humans have showed a decrease in negative and obsessive thoughts after a month of probiotic treatment. Prebiotics and pseudocommensals have decreased anxiety in humans. Pseudocommensals are microbes that live in soil and water that can be healthy for human diets, but do not live in the GI tract long term.In another study, rates of ADHD and autistic spectrum disorders in teenagers were found to decrease if they were given probiotics as infants. The addition of antibiotics with antidepressant medications were more beneficial to the patient than antidepressants alone, found in another study. Differences in the microbiome have been found in people with schizophrenia and anorexia as well.Though the links between the microbiome and mental health are clear, there are challenges in generating reliable data. For example, a general probiotic supplement may not work well to treat different patients, where it would be more helpful to test them and see which specific microbes their microbiome is missing.Food intake is highly variable between people, which can also alter the microbiome. Whole food diets that contain vitamins, minerals, and fatty acids also happen to be higher in fibers and prebiotics. This may explain why whole food diets can be helpful for those with mental illnesses.One additional area of study includes helminths, which are parasitic worms that live in the gut. Helminths have been studied in some disorders, and may be applicable here due to the role of the helminths in preserving the microbiome. 
 
Conclusions | More collaborative research should be done in the field of psychobiotics. 
 
 
Abstract | 	This paper discusses information from several previously conducted studies on the potentially negative effects of chloroquine and hydroxychloroquine on pregnant women. It discusses the potential risks which arise from the medications’ long half lives and prolonged exposure to them. Risks coming from eye, ear, and adrenal accumulation are mentioned. Overall findings are reassuring, suggesting that the risk for developmental issues, premature birth, or low birth weight do not increase from either drug. 
 
Introduction | 	Hydroxychloroquine and chloroquine’s half lives can reach up to two months, meaning patient exposure to either drug can continue long after stopping its intake. Considering these half lives and recent widespread discussion about the two medications’ use as a COVID therapeutic, this study draws attention to potential risks they may pose for pregnant women. Negative side effects, such as ocular damage (sometimes irreversible), have been reported in the past. The question is whether such problems can arise in utero. 
 
Methods | 	The first experiment which is referenced addresses potential ocular, aural, and adrenal problems caused by chloroquine. Tests were conducted on mice, rats, and monkeys, administering very high doses (greater than 250mg/kg).	Next, three studies on groups of 169, 130, and 774 women were referenced. These groups were exposed to chloroquine during their first trimester of pregnancy. The 169 patient group involved 300mg of chloroquine being administered once a week as a malaria chemo suppressant. The other two studies involved a 25mg/kg dose over the course of three days followed by 300mg of chloroquine given weekly. This section also mentions studies from 2015 and 2018 about teratogenicity (developmental abornmalities) and premature birth in relation to hydroxychloroquine.	Lastly several studies analyzing potential retinal degeneration due to in utero exposure to chloroquine are cited. A 2011 case involved a child prenatally exposed to methotrexate and chloroquine. Other cases looked at ocular damage occurring in groups of 588 and 246 children, with data being gathered about drug dose and duration of use. 
 
Results | 	The experiments conducted on the animals mentioned above present several potential side effects of chloroquine. High dosage (greater than 250mg/kg) was associated with microphthalmia and anophthalmia (infant born with one or two abnormally small eyes or with one or both eyes being missing). Additionally, other in vitro and in vivo tests linked chloroquine to genetic mutations and chromosomal damage.The human studies on first trimester pregnant women did not connect chloroquine to a heightened risk of congenital abnormalities, utero death, or low birth weight. The studies about hydroxychloroquine did not suggest that it causes a larger risk of teratogenicity, pregnancy termination, or premature birth. Additionally, no significant risk of child eye abnormalities due to either drug was found. 
 
Discussion | 	The clinical data for both drugs suggests that they do not pose serious risk for pregnant women and their children. With this being said, many of the studies referenced discuss the need for further follow up and the need for larger sampling groups. The long half life of the drugs is significant, as side effects may develop well after their intake is terminated. The paper urges that the medications be administered only when their benefit is clear and that frequent screening and precautions be taken. 
 
 
﻿Abstract | Whether hydroxychloroquine can prevent infection after exposure to SARS-CoV-2 is unknown. In this study, the researchers conducted a randomized, double-blind, placebo-controlled trial in the U.S. and Canada. They tested hydroxychloroquine’s ability to prevent infection after exposure to SARS-CoV-2. Participants in the study were adults who had exposure to someone with COVID-19 at a distance of less than 6 feet for more than 10 minutes with little protection. After exposure, participants received a placebo or hydroxychloroquine. The researchers assessed whether the participants developed laboratory-confirmed COVID-19 or illness that indicated COVID-19 within 14 days. The researchers found that the incidence of COVID-19 did not differ significantly between participants receiving hydroxychloroquine and participants receiving placebo. Side effects were also more common with hydroxychloroquine than placebo. In conclusion, hydroxychloroquine did not prevent COVID-19 after exposure. 
 
﻿Aims | The researchers wanted to understand whether hydroxychloroquine can prevent infection after exposure to the SARS-CoV-2 virus. 
 
﻿Aims | SARS-CoV-2 is the virus that causes COVID-19. While there are public health strategies to decrease its transmission, there is no medication that prevents SARS-CoV-2 transmission and infection.Hydroxychloroquine has in vitro (outside of a living organism, such as a test tube) activity against SARS-CoV and SARS-CoV-2. It is thought to impair activity of the angiotensin-converting-enzyme 2 (ACE2) receptor. This prevents binding of viruses to host cells.Clinical studies of hydroxychloroquine for COVID-19 have focused on treating hospitalized patients. However, it is also important to prevent transmission to inhibit the spread of the pandemic. Previous research suggested that hydroxyquinolone use could reduce or even eliminate the risk of transmission. In this study, the researchers hypothesize that hydroxyquinolone could be used to prevent infections after exposure to SARS-CoV-2. 
 
﻿Methods | The researchers conducted a randomized, double-blind, placebo-controlled trial. They randomly assigned participants to receive either hydroxychloroquine or placebo. Participants had known exposure to SARS-CoV-2.The researchers included participants who had household or occupational exposure to a person with confirmed COVID-19 at a distance of less than 6 feet for more than 10 minutes with little protection (no face mask, or face mask but no eye shield).Recruitment of participants was done by social media outreach and other media platforms.Hydroxychloroquine sulfate or placebo was dispensed and delivered to participants. The dosing for hydroxychloroquine was 800mg once, then 600mg 6-8 hours later, and 600mg daily for 4 more days. Placebo tablets were similar in appearance to hydroxychloroquine tablets and were prescribed in an identical manner.The primary outcome studied was laboratory-confirmed COVID-19 or COVID-19-related symptoms if testing was unavailable. Secondary outcomes included hospitalization for COVID-19 or death, PCR-confirmed SARS-CoV-2 infection, discontinuation of medication, and severity of symptoms. Data about side effects were also collected.Statistics were used to calculate ideal sample size and assess the incidence of COVID-19 disease. 
 
﻿Results | ParticipantsThe researchers recruited 821 asymptomatic adult participants. 414 were assigned to the hydroxychloroquine group and 407 were assigned to the placebo group. Overall, 719 participants had high-risk exposures to SARS-CoV-2. Of these, 365 received hydroxychloroquine, and 354 received placebo.Primary outcomeOverall, COVID-19 developed in 107 of 821 participants. The incidence of COVID-19 did not differ between those receiving hydroxychloroquine (49 out of 414) and those receiving placebo (58 of 407).Adherence and safetyAdherence to medication in the trial participants was moderate. 75.4 of participants in the hydroxychloroquine group and 82.6 of those in the placebo group took all prescribed medication. The most common reason that participants stopped taking medication in the hydroxychloroquine group was side effects. Side effects were more common with hydroxychloroquine than placebo.Blinding was well-maintained in the absence of side-effects. Participants who reported any side effect were likely to believe they received hydroxychloroquine. 
 
﻿Results | In this study, the researchers investigated the efficacy of hydroxychloroquine in preventing symptomatic infection of SARS-CoV-2.The researchers’ approach using internet-based self-referral and online follow-up surveys allowed recruitment across the U.S and Canada, indicating broad geographic participation and high generalizability to the general population. It also minimized risk of infection to researchers and lowered the burden of research participation. A result of this approach was that participants were generally younger and healthier than those more at-risk for severe COVID-19.In addition, while PCR or serologic testing for asymptomatic infection would have strengthened the study, it was not possible. Thus, more research should be done to investigate the effect of hydroxychloroquine on mild or asymptomatic infections. However, the risks associated with hydroxychloroquine may increase in more at-risk populations and could negate any benefits.The researchers acknowledge that this trial has limitations. Reproduction of the researchers’ results in other, ongoing trials is necessary to confirm their findings. 
 
 
﻿Basic Concepts of Herd Immunity | Acquired immunity is achieved when an individual is infected with a pathogen or is vaccinated, and their immune responses “learn” a response against that pathogen. Herd immunity is essentially the acquired immunity of the population. It refers to the protection of susceptible individuals (i.e., children and the immunocompromised), with no acquired immunity when a sufficiently large proportion of immune individuals exist in the population. The goal of vaccination is to produce herd immunity.The amount of people immune to a pathogen impacts disease transmission. This is because transmission stops with people who are immune, and they cannot transmit the pathogen to other people. If there are too few susceptible people in a population, the pathogen cannot successfully spread and its prevalence will decrease. The point at which the number of susceptible people falls below the number of susceptible people necessary for transmission is called the herd immunity threshold. Above this threshold, herd immunity begins to take effect and susceptible people are protected from infection.Important parameters for herd immunity are R0, the basic reproduction number, and Re, the effective reproduction number. Re is the average number of infections a single infected person can generate in a population with both susceptible and non-susceptible populations. R0 differs from Re in that it only deals with a completely susceptible population. The larger the R0, the more transmissible the pathogen, so a larger proportion of the population must be immune. Re changes dynamically as an outbreak unfolds and more people are infected and gained acquired immunity. The goal of vaccination programs is to bring the value of Re below 1, where the pathogen will not continue to spread, and its prevalence in the population declines. 
 
﻿Establishing Herd Immunity within Populations | In real-world situations, assumptions of equal population density and that all infected individuals acquire complete immunity are not met. The magnitude of protection by herd immunity depends on variations of these assumptions.R0 depends on the pathogen and the population in which it is transmitted. A single pathogen will have different R0 values based on the characteristics of a population experiencing an outbreak. These characteristics include population density and structure, differences in contact rates across demographic groups, among others. This means different populations have different herd-immunity thresholds.To establish herd immunity in a population, vaccination must prevent onward transmission, not just disease. For example, with SARS-CoV-2, asymptomatic hosts can be highly infectious even though they don’t have clinically diagnosable COVID-19. Even after herd immunity is established, the efficacy of herd immunity depends on the strength and duration of the acquired immunity. For pathogens such as measles, lifelong immunity is generated, such that herd immunity is highly effective. This is rare. For many other infectious diseases, immunity wanes over time, such that herd immunity is less effective and outbreaks can still occur. 
 
﻿Herd Immunity and SARS-CoV-2 | The SARS-CoV-2 pandemic has caused over 3.5 million clinically confirmed cases and over 250,000 deaths worldwide. Trials to evaluate vaccines and therapeutics are ongoing. However, it is unknown whether these trials will produce effective interventions.Various studies have estimated R0 for SARS-CoV-2 to fall in the range of 2-6. This wide range reflects the difficulty of estimating R0 during a pandemic. These values most likely do not indicate a complete picture of transmission in all countries.Assuming an R0 estimate of 3 for SARS-CoV-2, the herd immunity threshold is approximately 67. This means that the incidence of infection will decline once 67 of the population acquires immunity to SARS-CoV-2. Again, this model relies on simple assumptions. But, it can give us a basic idea of the number of individuals that would be needed to be infected in the absence of a vaccine to achieve herd immunity naturally. 
 
﻿Consequences of Reaching the SARS-CoV-2 Herd Immunity Threshold in the Absence of a Vaccine | An important measure to evaluate the impact of SARS-CoV-2 spread is the case fatality rate (CFR). CFR is the proportion of deaths attributed to a certain disease among all cases of that disease. There is significant uncertainty in the CFR for COVID-19, and it is also sensitive to the age structure and distribution of comorbidities in a population. Current estimates of CFR point to 1.38.A more relevant measure to evaluate the impact of SARS-CoV-2 spread is infection fatality rate (IFR). IFR is the proportion of deaths caused by a disease among all infected individuals. IFR differs from CFR in that it attempts to account for asymptomatic and undiagnosed infections. IFR is always lower than CFR because some cases will not be reported. The number of deaths resulting from combining IFR with meeting the herd immunity threshold can be calculated with caution, assuming an unchanging IFR across countries and does not consider factors such as access to healthcare that change IFR. The worldwide number of deaths is estimated to exceed 30 million people worldwide if herd immunity is to be naturally achieved.In reality, CFRs and IFRs vary dramatically across different countries. Factors that contribute to this variability include testing biases, age demographics, and strain on healthcare systems. Especially important is the strain on healthcare systems, as achieving herd immunity in the absence of a vaccine requires a large proportion of the population to become infected. Depletions in healthcare resources lead to both elevated COVID-19 mortality and overall mortality. These depletions would be especially devastating for countries with limited public health infrastructure and in vulnerable communities such as prison and homeless populations. 
 
﻿Epidemiological Considerations for SARS-CoV-2 Herd Immunity | The above analysis is limited since the transmission and infection dynamics of SARS-CoV-2 are not well-characterized. Complexities in viral spread and infectivity, variations in R0, variable infection rates in different demographic groups, among others are important epidemiological factors in herd immunity. However, they are difficult to estimate given the limited data available.The assumption of a uniform R0 is unrealistic. R0 is also complicated by superspreading events when favorable circumstances for high rates of transmission arise.Factors that influence individual susceptibility, pathology, and disease outcome are not well-understood. Further studies are necessary to understand determinants of COVID-19 susceptibility and severity. 
 
﻿Immunological Considerations for SARS-CoV-2 Herd Immunity | The ability to establish herd immunity against SARS-CoV-2 is based on the assumption that infection generates sufficient, protective immunity. Currently, it is unclear whether humans are able to generate sterilizing immunity to SARS-CoV-2. While there are promising findings, it is important to consider whether antibodies generated against the virus wane over time and how long acquired immunity will last. Previous studies of other coronaviruses showed that antibodies decreased after 1-2 years after infection. If this is also true for SARS-CoV-2, herd immunity may not be achieved in the absence of recurring vaccination. 
 
﻿Recap | Herd immunity provides protection to susceptible individuals by minimizing transmission between a susceptible individual and an infected person. In its simplest form, herd immunity will begin to take effect when a population reaches the herd immunity threshold (proportion of immune individuals crosses 1-1/R0). However, in real-world populations, the situation is much more complex. Epidemiological and immunological factors, such as population structure, variations in transmissibility, and waning immunity lead to variation in herd immunity and herd immunity threshold for different populations. These factors need to be taken into account when discussing herd immunity in populations. There are two approaches to build herd immunity against SARS-CoV-2: (1), a mass vaccination campaign, or (2) natural immunization by infection. However, the consequences of (2) are severe. A large fraction of the global population would need to become infected, causing millions of deaths. In the absence of a vaccination program, establishing herd immunity should not be the ultimate goal. Instead, policies that protect vulnerable groups should be enacted in hopes that herd immunity will be achieved as a byproduct of such policies. 
 
 
Challenges in treating COVID-19 |  Coronavirus was first discovered in December 2019. The largest issue will be the rapid increase in critically ill patients. As of March 16th, there is no vaccine or drug available and current provisions focus on supportive care: oxygenation, ventilation, and fluid management. Currently, herbal treatments, anti-malarial, and anti-viral medications show potential promise as an effective treatment. 
 
Convalescent plasma: one of the forgotten immunologically based strategies |  Using plasma from recovered patients showed to cause a significant reduction in mortality and viral load. This was demonstrated with SARS-CoV and MERS-COV. No adverse side effects were noted. This therapy requires more research. New studies from China National Biotec Group Co have claimed similar reductions in viral load, inflammation, and symptoms after infusion of plasma. 
 
Potential Risks and ethical considerations |  Currently there is evidence that demonstrates a higher risk same-day thrombotic (clot-forming event) after infusion with human plasma. Given the lack of knowledge on SARS-CoV-2 it is advised to refrain from its use at this current moment. Similarly there is a lack of high-quality studies on this subject. Ethical acquisition of human plasma must be ensured. 
 
Conclusion |  No treatment plans are in place as of yet. It is too soon to see what will prove to have efficacy, but some preliminary results show promise, specifically the use of serum from recovered COVID-19 patients. 
 
 
Abstract | 	This is a paper published during the exponential rise of COVID-19 cases in Italy, before the country experienced its peak. It uses statistical models and information gathered from Hubei, China to predict the exponential growth in the number of COVID-19 in Italy. The time frame of the predictions is over, but the methods shared remain valuable and they may be used in other regions. The data presented in the paper anticipated a spike in cases which would overwhelm the country’s intensive care capacity. It urged the government to move in over 20,000 doctors and 5000 ventilators in preparation for this spike. 
 
Introduction | 	China’s early, relative to the rest of the world, spike and decline in COVID-19 cases made it a source of outbreak statistics for many other nations. This paper makes use of the data available from Hubei, China to anticipate the progression of the virus in Italy. The European nation took many steps, such as internal travel restrictions, to try and contain the virus, but numbers continued to rise. With only 5200 hospital beds available and a survival time of 1-2 weeks for nonsurvivors of COVID-19, this study warns the government of the virus’s likelihood to overwhelm the nation’s healthcare system. 
 
Statistics/Results | 	The number of COVID-19 patients in Italy was published every day starting on Feb 21, 2020. Using this data, the researchers constructed an exponential model with the value of the exponent being r=0.225 (1 per day). This growth pattern was consistent with reported infected patient numbers until 17 days after the start of the model.The trend following this 17 day period suggested that more than 30,000 patients would be infected by March 15. With infection duration between 15 and 20 days, a basic reproductive number found was 2.76-3.25 (similar to that in Wuhan). The model predicted that the Italian healthcare network would reach full capacity within a few days. Hospitals would reach their capacity by March 14, 2020, assuming half of the 5200 ICU beds in the nation were open to COVID-19 patients.The paper also compared the curve of Hubei (population 50 million) to the data gathered in Italy (population 60 million) so far. A divergence in the Chinese region’s predicted vs recorded patient numbers was noted.If Italy experienced a similar divergence, the paper predicts the number of newly infected patients could decrease within 3 or 4 days from March 11.	 
 
Discussion | 	While most of the modeling in this paper is based on data from Hubei, China, it is noted that a comparison between Italy and this Chinese region is difficult. The draconic measures taken in China to reduce infection are likely impossible in Italy. Additionally, genetic differences and differences in the percentage of the population with diabetes, heart conditions, or other comorbidities are hard to take into account. Lastly, the use of antiviral drugs or other pharmaceutical measures to reduce infection were different in both nations and were not taken into account in the models presented.	Regardless, the paper clearly states that it is addressing government officials, imploring them to prepare for an inevitable spike in cases.  
 
 
Abstract | 	This study uses ANSYS workbench 16.0 (modeling software) to conduct thermal structure analysis: to observe the thermal stresses and heat fluxes of brake rotors using different materials and designs. It uses this type of analysis to evaluate rotor performance under extreme braking conditions (when heat related issues are most prevalent). 
 
Introduction | 	Modern braking systems involve a rotor and caliper design. A rotor attached to a hub spins along with a vehicle’s wheel and a caliper applies pressure to this moving rotor (via brake pad) to slow it down. Rotor slotting and drilling are common techniques used to improve cooling and prevent heat related issues and failures. This paper’s goal is to analyze the effectiveness of these techniques and to determine the optimal materials for designing a brake rotor. 
 
Methods | 	The first step was to review the issues experienced by rotors under harsh braking. These are: hot spots resulting in thermal judder (violent shaking), uneven wear along the rotor’s surface, and rotor deformation and oscillation. Lack of effective and even cooling can result in thermal buckling and warping, pad imprinting (brake pads cooling at different rates than rotors they come in contact with) and material failure. Lastly, high temperatures in a braking system can lead to friction loss (friction between pad and rotor is what slows a vehicle) and can lead to ineffective braking known as brake fade.	The next step in the study was software tests. Disc brakes were first modeled using Solidworks 2016. Next, computer programs were used to simulate hard braking and gather temperature and deformation data. The test assumed all kinetic energy was lost to the brake discs (tires not considered) and that the heat transfer was uniform. The tests performed were to simulate repeated hard braking and do not predict the longevity of the discs. 
 
	Results | 	Several simulation images using color coding for temperature were presented. Slotted discs experienced redzones (peak temp) at the outer edge of the rotor. This redzone developed from the friction force applied by the brake caliper. Drilled and slotted rotors showed superior heat convection and their max temperature was lower than just slotted rotors. Stainless steel max temperature was 947.4 degrees C vs 630.18 degrees C for cast iron. Cast iron discs showed a 33 reduction in temperature and a 75 reduction in thermal deformation compared to stainless steel.	 
 
Discussion | 	While some performance vehicles use carbon ceramic materials in their braking systems, such designs can be expensive and impractical in daily driving (brakes are grabby until they reach operating temperature). This study clearly presents that a slotted and drilled set up using cast iron is most effect in dissipating heat and in preventing deformation or other structural issues. It is important to note that no considerations were made about rotor longevity or about the effect of slotting and drilling on pad life. 
 
 
Abstract | 	This paper analyzes the effect New Jersey’s decline in horse racing has on the state’s veterinarians. More specifically, the study looks on several veterinarian practices’ revenue and staff size over the last five years. The data gathered suggests that only veterinarians involved in racehorse breeding (vs those in horse racing) were negatively impacted by the industry’s decline. 
 
Introduction | 	New Jersey’s share in the $122 billion dollar equine industry was estimated at $1.1 billion in 2007 (largely from horse racing). Despite the industry’s evident importance to the state economy, horse racing and racehorse breeding both experienced an overall decline in New Jersey over the last five years. This study looks at veterinarians, a group closely linked to the equine industry, hypothesizing that the industry’s decline has a negative effect on their business. 
 
Methods | 	A survey was sent out in October 2018, distributed online with the help of the New Jersey Association of Equine Practitioners (sent to its members via email). Several follow up emails were sent to ensure a sufficient number of responses were received. The survey consisted of ten multiple choice questions about veterinary practices' involvement in horse racing/racehorse breeding and revenue associated with them. 
 
Results | 	51 out of 105 licensed equine veterinarians responded to the survey. 48 of practices reported a decrease in revenue over the past five years due to changes in horse racing. 22 reported no change and 30 reported an increase in revenue over this period. 44 of practices reported a decrease in their staff size, 17 reported no change, and 39 reported an increase in staff. Of practices reporting a loss in revenue, 42 reported decreases between 31 and 40. Of practices reporting an increase in revenue, 33 reported an increase between 0 and 10.	52 of the veterinarians which responded were not involved in racehorse breeding. Of the 52 which were, 91 reported a decrease in revenue over the past five years (with 9 experiencing an 81 to 90 decrease in revenue).	The data clearly suggests that veterinarians directly involved in racehorse breeding were hit hardest by NJ’s equine industry decline. 
 
Discussion	 | 	The study expresses surprise at the fact that veterinarians involved in only horse racing (not breeding) did not demonstrate a significant loss in revenue or staff. This suggests that horse veterinary treatment in the state is still in demand even if the horses are not racing in-state. The paper notes that NJ’s geographical location creates the possibility that racehorses may be housed in the state and raced outside its borders.	 
 
 
Abstract | The COVID-19 pandemic caused by the novel coronavirus SARS-CoV-2 has affected over 52,000 individuals in California as of May 4, 2020. This study intends to investigate the different strains of SARS-CoV-2. The findings support the need for contact tracing, social distancing and travel restrictions to limit further spread of the pandemic. 
 
Introduction | An exponential growth in the number of cases has overburdened clinical care facilities and threatens to overwhelm the medical workforce. The authors have developedmethod called MSSPE (Metagenomic Sequencing with Spiked Primer Enrichment) to identify the origins and characteristics of viral genome samples obtained from affected patients.  
 
Methods | The researchers screened 62 respiratory swab samples from 54 COVID-19 patients from various hospitals and clinics in Northern California (table S1). The 36 infected patients for whom viral genomes were obtained were collected from January 29 to March 20, 2020 and spanned 9 counties in Northern California (Fig. 1B and table S2). MSSPE yields 34 SARS-CoV-2 genomes with enough coverage ( &gt;65 of the total genome sequenced) and these were included in the study.  
 
Results | A large outbreak was associated with travel on the US Grand Princess cruise ship. There were at least 78 confirmed positive cases out of 469 tested as of March 26. The WA1 strain identified from cruise ship passengers have 3 sites on the viral genome sequence that identify this strain. The timing and classification of the viral sequences suggests that the virus on the Grand Princess likely came from Washington State, although the cases may also have originated from a different region in which the WA1 strain is circulating.Growing evidence indicates that WA1 is now an established lineage of SARS-CoV-2 in the US. Residents of several Northern California counties hadviruses in the WA1 lineage from Grand Princess cruise ship passengers. In addition, WA1 lineage viruses found in COVID-19 cases come from many states including Minnesota, Connecticut, Utah, Virginia, and New York. 
 
Discussion | The variety of introductions of SARS-CoV-2 into California appear to give rise to the diversity of virus lineages. No single predominant lineagewas observed. There is not enough current sampling to confidently estimate the dates of when transmission first started. Most samples analyzed were from public health laboratories and thus may not be representative of the general population. 
 
Conclusion | The authors' data suggest concerning trends of an established lineage. This is shown in community-acquired COVID-19 cases with the WA1 lineage in several counties of Northern California. Social distancing interventions may help stop the spread of the virus between communities.   
 
 
AbstractRecent brain imaging studies suggest that the insula may become a future focus of research because of its use in understanding the structure and function of the brain as well as its use in clinical research. This paper looks to summarize the insula on a structural and cellular level. The researchers then discuss how the insula’s involvement in psychiatric and neurological disorders may be underestimated. They then suggest how research on the insula can be done in the future.Introduction: It Is Time to Pay Attention to the InsulaSince its discovery, the insula has not been a large focus of research. Antonio Damasio’s “somatic marker hypothesis” claims that rational thought comes from feelings and emotions. Research has implied that the insula plays a role in emotionality and cognition. Neuroimaging studies also seem to suggest that the insula plays an important role in many brain disorders.Anatomy and PhysiologyThe insula is located underneath the top layer of the brain’s cortex. Even though it is not on the surface of the brain, the insula is made of cortex as well. The insula is bilateral (has two sides) and a front and back (anterior and posterior sides). Sensory information travels up to the posterior region of the insula. The information then moves to the anterior insula, which has connections to many brain regions involved in emotion.The anterior insula has strong connections to the anterior cingulate cortex. These connections are thought to be between sensory (insula) and motor (cingulate cortex) information in the limbic system. The anterior insula has many large spindle-shaped neurons called von Economo neurons, which are similar in structure to the anterior cingulate cell structure. Even though the exact function these neurons are doing, evidence suggests that they may be involved in integrating long-range information.Physiological Functions of the Human InsulaResearchers understand the insula and its many sensory functions through interoception. Interoception refers to the brain’s sense of what is happening in the body and homeostasis. This is relevant in that researchers attempt to map out what regions of the brain are responsible for sensing and responding to these bodily states. Regarding the insula, researchers hypothesize that information passes through the insula from the back (posterior) to the front (anterior). The posterior part of the insula receives signals from the body, processes them, and passes it along towards the anterior region of the insula. Other parts of the brain communicate with the anterior insula to integrate emotional and cognitive information.Parts of the posterior insula are related to certain interoceptive signals from the body, similar to how sensory information is mapped on the sensory cortex. Researchers propose that the anterior insula may contribute to someone’s sense of “selfhood” because of how the physical information from the body seems to be turned into subjective feeling here.The insula also seems to be involved in cognition. The feelings that arise from the insula may act to “mark” certain stimuli from the body. This plays a role in how individuals learn to pay attention and remember certain feelings and how they are associated with our emotions and beliefs.The insula also plays a role in behavior and motivation. The insula can label different stimuli as either good or bad. This label from the insula then can encourage an individual to take a specific action if associated with pleasure, or avoid a certain action if it is associated with pain/discomfort.Regions of the brain connected to the anterior insula support the idea that it is involved in feelings and cognition, especially its connections with the dorsolateral prefrontal cortex (DPC) and the ventromedial prefrontal cortex (VPC). The DPC collects information marked as important by the anterior insula. The DPC then uses this information to influence what to pay attention to or try to actively remember (working memory). The anterior insula takes the outcomes and feelings of past behaviors and sends them to the VPC. The VPC uses this contextual information to influence the decisions on future actions.The insula shares similar functions to how the amygdala works in the brain. The amygdala is involved in initiating automatic responses related to fear and aversion. The main difference is that the insula does not cause an automatic response, rather subjective experiences.Pathological Roles of the Insula in Psychiatric and Neurological DisordersRecent findings suggest that many psychiatric disorders are caused by multiple genes and not just one source. It is becoming more important to recognize the multi-dimensional nature of psychiatric disorders rather than trying to categorize them. Disrupting the insula’s roles in cognitive, emotional, and motivational functions lend to many different psychiatric disorders.Recent neuroimaging studies have connected the insula to abnormal feeling states and mental disorders, such as major depressive disorder. fMRI studies reveal that the insula is too active when processing emotion, and much less active than normal in a resting-state for patients with major depressive disorder. The insula has also been connected to bipolar disorder, anxiety disorders, schizophrenia (impaired affective processing), anorexia (distorted feelings of one’s body), and others. Besides these psychiatric disorders, the insula is connected to neurological conditions as well, such as Huntington’s disease, multiple sclerosis (impaired processing of facial emotions), and Alzheimer’s disease (loss of sense of self).The insula’s role in labeling emotions or beliefs for working memory or fixation also contributes to multiple disorders. This abnormal and excessive fixation on belief has been connected to schizophrenia, autism, and delusion.Motivation derived from the insula’s processing of emotional states may have a role in addiction. Outside and interoceptive cues processed in the insula affect decision making and may be behind drug use in those with a history of substance abuse. Molecularly, changes in dopamine levels have been linked to varying degrees of effort used for rewards in humans.Towards a Better Understanding of the Physiological and Pathological Roles of the InsulaUsing neuroimaging studies makes it hard to say the insula directly causes any of these things. Neuroimaging studies limit researchers in how much of the brain they can observe at once as well as the timing of brain activity. Authors of this paper encourage research to head in the direction of finding statistical and computational ways around these limitations.Animals are a good way of getting around these limitations in human brain imaging. These studies allow researchers to conduct invasive experiments in rodent brains and compare the structures to those in human brains. Using animals also opens up the opportunity for researchers to explore genetic experiments.Next-generation genetic sequencing and single-cell studies may allow researchers to do advanced research in disease and pathology to find molecular mechanisms behind them. The authors of this paper propose translational and back-translational research to gain a better understanding of the insula.  |  
 
 
Abstract | Knowledge on masks and their ability to slow the spread of COVID-19 is constantly developing. Public officials need info on how masks can best be used by the public to fight the COVID-19 pandemic. COVID-19 is spread by droplets in infected people's lungs. These droplets are released outside the body through sneezing and coughing. Healthy people can contract COVID-19 if these infected droplets enter their bodies. Masks slow virus spread by limiting the movement of these droplets through the air. This article examines many other articles on mask-wearing to see if public mask-wearing is appropriate. The authors of this article urge public officials to encourage people to wear masks. Cloth masks are acceptable if medical masks are not available. 
 
1. Components to Evaluate for Public Mask Wearing | Before encouraging the public to wear masks, we should answer these questions:- Can symptom-less people infect healthy people?- Does mask-wearing prevent infected people from infecting healthy people?- Are there masks that can be made without hurting the supply of medical masks?- Will mask-wearing prevent the wearer from being infected?- What are the overall effects of public mask-wearing? 
 
2. Transmission Characteristics of COVID-19 | COVID-19 is highly contagious, and is mainly spread through coughing, sneezing, and talking. A lot of people with COVID-19 show no symptoms. Almost all COVID-19 patients go through an initial stage where the virus replicates inside their bodies but they show no symptoms. This stage usually lasts 2 to 15 days. People are most infectious during the first few days after they are infected - when there are mild or no symptoms. Any public policies created to limit COVID-19 spread must consider people who can spread the virus while showing no symptoms. 
 
3. Ingress: Filtering Capability of Masks | The designs and materials that make up face masks can affect how well they can block droplets from the wearer and how well they can reduce the wearer's risk of viral infection. One study showed that hospital workers with surgical masks were less likely to be infected by rhinovirus than workers with cloth masks. However, it is uncertain if the study's results can be applied to coronavirus. Another study shows that N95 respirators can filter virus particles better than surgical masks. However, people wearing N95 respirators and surgical masks were equally likely to contract influenza. 
 
4. Egress: Masks for Source Control | When people cough, speak, and breathe, droplets are most of what comes out of their mouths. A small portion of these droplets come out in an evaporated form, or aerosols. Over time, emitted droplets evaporate to become aerosols. Masks catch droplets and prevent this from happening. Studies with virus-infected patients show that masks are effective in limiting both the amount of virus particles in aerosols released from the mouth and the distance they travel. Studies also show that homemade masks are less effective, but they still work to some extent. 
 
5. Evaluating Masks as an Intervention | This section details studies on interventions used during past virus outbreaks. These studies found that mask-wearing is an effective means of slowing public spread of viruses. The studies recommend combining mask-wearing with hand washing and physical distancing. Mask-wearing should begin at early stages of a pandemic. The section also details a report about a man with COVID-19 who wore a mask during a flight. Nobody near him contracted COVID-19 during the flight. This furthers the case for using masks as an intervention against COVID-19 spread. 
 
6. Sociological Considerations | There are other issues with public mask-wearing aside from its effectiveness that officials should think over. People may think that masks are so effective, they can afford to ignore other measures meant to limit disease spread. However, studies suggest this is not a large concern. People may not wear masks because they don't want to be identified as sick. Employers may forbid their employees from wearing masks so they don't scare customers. Also, it can be hard to get all sick people to wear masks when some people don't know if they're sick or not. But if more people wear masks and if more places require people to wear masks, these issues may be lessened. People would be reminded of disease threat and feel a sense of unity from collectively wearing masks. Some of this can be seen in Hong Kong, where community activists banded together to increase mask-wearing. 
 
7. Implementation Considerations | When enforcing public mask-wearing, there are several factors to consider. Different countries have different levels of access to resources. Some countries may have to consider whether public mask-wearing may limit the number of masks available to medical workers. In this case, citizens may be asks to wear medical mask alternatives. The public may not see a disease outbreak as a major threat. The amounts of mask-wearing people may change depending on whether mask-wearing is made mandatory. However, studies suggest that mandatory mask-wearing is effective at increasing public mask-wearing. Also, mask-wearing can defend against both current pandemics and other pandemics that can occur alongside them. 
 
8. Estimating COVID-19 Impacts | This section discusses models that were made to predict COVID-19 spread with little, moderate, and high public mask-wearing. The effectiveness of mask-wearing is dictated by how well masks are made and how many people wear them. We measure infectivity of diseases with basic reproduction number, R0. COVID-19 has an R0 of 2.4, meaning that on average, an infected person spreads the virus to 2.4 other people. Good quality masks combined with high public mask-wearing can cut this number by almost half. The infection rate of a disease after interventions are made are measured with effective reproduction number, Re. Policy measures can shape public levels of mask-wearing and thus greatly impact Re. Models show that mask-wearing lowers infection rates at least somewhat, even when quality of masks and levels of mask-wearing are low. 
 
9. Discussions and Recommendations | The evidence examined throughout this article suggest that public-mask wearing is vital to slowing COVID-19 spread. Public officials should decide on interventions based on their cost and how well they can slow infection. Infections and economic impacts of COVID-19 decrease the more people wear masks in public. Clearer guidelines on mask-wearing can help slow and eventually stop the spread of COVID-19. 
 
Materials and Methods | Researchers from different fields worked together to collect and examine papers for this review. 
 
 
Abstract | About 100,000 people in the United States are in need of a kidney transplant, and 400,000 people are on dialysis. This study aims to discover more about the ability to create a transplantable kidney graft. They decellularized a rat, pig, and human kidney in this study, and recellularized the rat kidney with epithelial and endothelial cells. The grafts made urine in the lab setting. Some grafts were transplanted into the rat, and also produced urine after transplantation. 
 
Introduction | Dialysis can increase the survival of patients with end-stage renal disease, but a kidney transplant is the only way to cure end stage renal disease. Only 18,000 kidneys are available for transplant each year, leaving 100,000 people waiting on the donor list each year. The wait time is over 3 years for a kidney, and even then, the kidney can be rejected. Other options have been considered for getting those on the waiting list the treatment they need, but are all still in clinical development. This research team has previously made scaffolds from hearts and lungs. A benefit to successfully decellularizing the whole kidney is that the vascularm glomerular, and tubular components are structurally intact. 
 
Results | Perfusion decellularization of cadaveric kidneysThe rat kidney was decellularized with sodium dodecyl sulfate (SDS) until all of the cellular components were removed. The extracellular matrix (ECM) was kept intact since they used a technique called perfusion decellularization, and this is necessary to have proper kidney function. The elastic fibers of the arterioles remained in the parenchyma. Laminin and collagen IV remained as well. In general, what is called the microarchitecture of the kidney remained intact. The SDS and Triton X-100 was able to lower the DNA content of the scaffold to less than 10. The scaffold was washed with a buffer until there was no more SDS present. The total level of collagen and glycosaminoglycan were similar to that of a normal kidney. They used Krebs-Henseleit solution under normal pressure conditions to see if the decellularized kidney scaffolds would produce any filtered urine. The output of this had high protein, glucose, and electrolytes. This can tell us that some filtration was occurring across the glomerulus and the tubular basement membranes, but there was no active reabsorption. The glomerular diameter, Bowman's space, and glomerular capillary surface area were the same between normal kidneys and the decellularized scaffolds.Recellularization of acellular kidney scaffoldsThe rat kidney scaffold was repopulated with endothelial cells through the renal eatery and epithelial cells through the ureter. The kidney scaffold was repopulated better when the seeding chamber was pressurized to create a pressure gradient across the scaffold. Without the pressure gradient, the cells were not reaching the glomerulus. The ideal pressure to avoid damage was 40 cm H20. After 3 to 5 days in a perfusion bioreactor, the scaffold was then seeded with more cells, but this time the cells were a mixture of all kidney cell types. The scaffold was grown until the cells were all attached, then perfused to give oxygen, nutrients, and stimulate function. They used glucocorticoids and catecholamines to mature the kidney scaffold. All of the cell types seeded in the appropriate anatomical locations. There were some non-site specific cells, but overall, the kidney scaffold was cellularized in a similar fashion to a normal kidney. There were about 70 of the functional glomeruli in the kidney scaffold compared to a normal kidney.In vitro function of acellular regenerated kidneysHere, they tested if the regenerated kidneys could properly function. The regenerated kidneys produced steady, but less urine than the normal kidneys. The glomerular filtration was decreased in the regenerated kidney. Vascular resistance was higher in the generated kidney compared to the normal kidney. Albumin retention is morally 89.9, but was only 46.9 in the regenerated kidneys. Glucose reabsorption is usually 91.7 in normal kidneys, but was 47.4 in the regenerated kidneys. The electrolyte reabsorption for the regenerated kidney was about 50 of the normal kidney’s reabsorption.Orthotopic transplantation and in vivo function of regenerated kidneysSince urine was produced in the lab setting, the researchers thought the kidney could be transplanted into a rate and also produce urine. An orthotopic transplant was done, meaning the original kidney was removed and the regenerated kidney was placed in its spot. The kidney graft successfully used the body’s blood supply and began making urine immediately. The urine output was high in glucose and albumin, but low in urea and creatine. The urine output was less, and there was no clot formation or bleeding detected. 
 
Discussion | A bioengineered kidney using a patient’s own cells could be an alternate treatment for a patient with end stage renal failure. Although there is a lot more research that needs to be done, this study presents three important factors. They were able to 1) generate a 3D kidney scaffold from rat, human, and pig kidneys. 2) they were able to repopulate the scaffolds in a way that was anatomically correct. 3) The kidneys did produce rudimentary urine in the lab setting and in a living organism.The kidney could be decellularized without altering the microarchitecture of the vessels, glomerulus, and tubules. Recellularizing a more simple organ or tissue like muscle or the lungs is easier than recellularizing a complex organ like the kidney. This is because surface attachment or injection of cells can recellularize the simple tissue or organ. The research team took advantage of the renal artery and ureter to seed the cells deeper inside the organ. More research will need to be done on recellularizing a larger, human sized kidney and where to obtain the cell types for this process. Bioengineered kidneys may eventually become a viable treatment for patients with end stage renal failure. 
 
 
Main: | Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is the virus that causes COVID-19. This virus, which originated from China, has spread to over 200 countries. Public health interventions in China have stopped the spread of the virus in China. However, the rest of the world is still in their first wave of the COVID-19 epidemic.One study of the virus assessed provinces outside Hubei, the virus’s province of origin. The study found that the non-pharmaceutical health interventions taken were effective in controlling the spread of the virus. The virus’s spread was controlled both locally and between provinces. Unfortunately, other countries were not well prepared for the virus. These countries showed rapid increases in the number of COVID-19 cases. The question remains, would earlier implementation of interventions such as social distancing have helped.In addition to lack of early intervention, early relaxation of interventions must be looked at. Models show that early relaxation of interventions could lead to a second wave of infections. At the time this paper was written, there was not much focus on which interventions were effective. A study identifying the effective interventions is strongly needed.There are many unanswered questions regarding the COVID-19 pandemic: what drugs can be used against the virus; what is the fatality rate of the virus; how will this impact global economies. The list goes on. Obtaining data and continuing to monitor the virus is crucial for containment of the virus and for preventing a second wave of infections. 
 
 
Abstract | Black American communities are suffering tremendously from the COVID-19 pandemic. Underlying health and social problems make the issues from the pandemic worse. The syndemic theory can help to understand what is happening. A syndemic is when multiple diseases concentrate in a particular community. The co-occurence of the diseases worsen the outcomes of the diseases. The syndemic often coincides with the social problems of that community. Social factors and history have especially caused this syndemic. Some factors include but are not limited to racism, discrimination in the work field, and health care disparities. Policies need to be implemented to combat structural racism, which is the root of the racial disparities. 
 
Main | Massive racial disparities are present in the COVID-19 pandemic. Black Americans make up a disproportionately high number of COVID-19 cases and deaths. Primary reasons are due to the higher number of underlying health conditions. These chronic diseases include diabetes, obesity, and hypertension. Other reasons include social factors, such as the greater lack of healthcare insurance. To understand this disparity, one needs to consider the historical and current factors that led to this syndemic.Social and political factors have more impact on healthcare than an individual’s decision. Policies from history have caused the disparities. Researchers looked at the 677 counties that were disproportionately black with greater than or equal to 13 of black Americans. 91 of these counties are in the southern regions of the United States. Black Americans in these counties also have higher rates of unemployment and uninsurance. These counties also have high rates of people with underlying health conditions. All of these disparities worsened the situation when COVID-19 hit.Many of the poor do not have insurance because of the lack of access to insurance. Many southern state governments refuse to allow for Medicaid expansion as part of the Affordable Care Act (ACA). Thus, the uninsured are likely to seek treatment too late because of the high costs of healthcare.There are also racial disparities in COVID-19 testing. Wealthier communities have a higher testing rate. But, poorer black communities have a higher rate of positive tests. The “drive-by” testing also assumes that one owns a private car. Medical providers often have racial bias. Some hospitals have refused to treat black Americans that have symptoms of COVID-19.Black Americans consist of a large percentage of low-wage workers in the healthcare field. The jobs include sanitation, nursing house workers, and laundry. Many of these jobs do not come with insurance or other benefits. Furthermore, black Americans are more likely to live in crowded public housing. Thus, many cannot practice social distancing. The jobs and living environment predispose many black Americans to COVID-19. These outcomes are due to the structural violence from racism. Black Americans are more at risk for disability or death from COVID-19, which has become a norm.Politics contribute to these healthcare disparities. Counties that primarily voted for Trump in 2016 are less likely to practice social distancing. These counties often have more residents that dismiss climate change. The rejection of science has led to governors in these states to reopen the economy too early. As a result, black Americans are disproportionately affected by COVID-19 due to the aforementioned healthcare and social disparities. For example, in Dougherty County in Georgia, 69 of the population is black. But, black Americans consist of 81 of the COVID-19 deaths.More data and tracking would give more precise information about racial disparities. But, the inequality is clear. The researchers urge people to act. At the very least, employers must offer insurance to healthcare workers and a living wage. Workers should also receive proper PPE and have a chance to be tested. Otherwise, the racial inequality will only continue on top of the syndemic.Everyone does not have the same risk for COVID-19. Rather, racial health disparities often determine the outcome. The inequity stems from structural racism from past and present policies. The researchers urge readers to be aware of racism and to advocate for change. 
 
 
Abstract | Using psychiatric signs or symptoms, symptom severity, diagnoses based on ICD-10, DSM-IV, or the Chinese Classification of Mental Disorders (third edition), quality of life, and employment as outcome variables in this systematic review and meta-analysis, the researchers examined the psychiatric and neuropsychiatric (i.e., delirium) displays of SARS, MERS, and COVID-19. If SARS-CoV-2 follows a similar course to SARS-CoV or MERS, most patients will likely recover without experiencing a mental illness. A significant proportion of patients may suffer from delirium in the acute stage of SARS-CoV-2. Clinicians should be attentive of depression, anxiety, fatigue, PTSD, and certain neuropsychiatric syndromes in the longer term following COVID-19 infection. 
 
 Introduction | There is a widespread understanding of the psychiatric implications of COVID-19 that may affect infected and non-infected populations for reasons including widespread anxiety, illness-related stigma, and governmental response. Neuropsychiatric consequences (mental disorders attributable to nervous system disorders) can emerge directly or indirectly from infection (i.e., via medical therapy). Severe neuropsychiatric consequences may be proportionally rare, but given the reach of the pandemic, a significant population would be affected. The previous coronavirus epidemics were assessed to ascertain the possible psychiatric and neuropsychiatric consequences of COVID-19. 
 
Methods | The authors searched MEDLINE, Embase, PsycINFO, and the Cumulative Index to Nursing and Allied Health Literature databases for relevant studies or abstracts.  
 
Results | In the acute illness stage, common symptoms among hospitalized SARS or MERS patients were confusion, depressed mood, anxiety, impaired memory, and insomnia. Along with the aforementioned symptoms, irritability, fatigue, and in one study traumatic memories and sleep disorders were among patients in the post-illness stage. In this stage, the point prevalence of PTSD was 32.2, depression 14.9, and anxiety disorders 14.8. There was evidence for delirium in COVID-19 patients. There was much variability in the quality of the studies.  
 
Discussion | Relevant data on COVID-19 and the higher mortality rate of SARS and MERS that may be correlated with poorer psychiatric consequences make establishing conclusions with caution important. Confusion is common in the acute stage of SARS and MERS so delirium may become a significant problem of COVID-19. Depression, anxiety, PTSD, and fatigue may have a high prevalence post-COVID-19, but this data is early or unpublished at the moment with regard to COVID-19. The seemingly high prevalence of common symptoms like depression may have been a consequence of selection bias. This review suggests that most people will not suffer from a mental illness after coronavirus infection and that there is little evidence to suggest neuropsychiatric consequences beyond short-term delirium following infection.  
 
 
Abstract | Acute respiratory distress syndrome (ARDS) occurs when inflammation of the lungs leads to respiratory failure without cardiac failure. The mortality of patients with ARDS is still high despite efforts to develop treatments. Identifying biomarkers of ARDS will help decrease mortality. This study looks at soluble advanced glycation end-products, soluble tumor necrosis factor-receptor 1, interleukin-6, interleukin8, and plasminogen activator inhibitor-1 for ARDS treatment by a soluble inhibitor. 
 
Introduction | Biomarkers are helpful in the diagnosis and treatment of a patient. Several biomarkers have been identified for ARDS, but the death rate of ARDS patients remains high. ARDS has 2 phases: exudative and fibroproliferative. Exudative phase is due to inflammation, which injures the alveoli and releases proteins into the blood and alveolar compartment. Fibroproliferative phase is due to an imbalance of profibrotic and antifibrotic mediators. This study attempts to identify a soluble inhibitor that will be effective against the biomarkers of ARDS. The biomarkers discussed are soluble advanced glycation end-products, soluble tumor necrosis factor-receptor 1, interleukin-6, interleukin8, and plasminogen activator inhibitor-1. 
 
Soluble receptor for advanced glycation and end-products (RAGE) | The soluble receptor for advanced glycation and end-products (RAGE) is a cell surface immunoglobulin. RAGE can interact with multiple ligands. RAGE is highly expressed on alveolar type 1 cells. RAGE activates innate immune and inflammation, leading to activation of the transcription factor NF-kB. RAGE can be measured as soluble (sRAGE) or endogenous secretory (esRAGE). High levels of sRAGE indicate alveolar type 1 cells damage and low oxygen levels. sRAGE can also lead to the build up of inflammatory cells in the alveoli. Based on this study, sRAGE can be used to diagnose ARDS or an ARDS risk factor. There is conflicting data whether sRAGE levels can be used to determine the severity of a patient or if they are responding well to treatment. 
 
Interleukin-6 | Interleukin-6 (IL-6) is a complex cytokine that has pro and anti-inflammatory properties. IL-6 is usually present before the onset of ARDS because there is usually inflammation or an infection before ARDS begins. IL-6 becomes severely elevated during ARDS. Il-6 is known to recruit inflammatory cells, like neutrophils, to the alveoli. The neutrophil entering the alveoli will cause the lung tissue to express vascular cell adhesion molecule (VCAM-1) and intercellular adhesion molecule (ICAM-1). IL-6 is associated with worse patient outcomes. IL-6 in addition to other biomarkers may be helpful in diagnosing ARDS in patients with other conditions like sepsis. 
 
Interleukin-8 | Interleukin-8 (IL-8) is a pro-inflammatory cytokine that recruits neutrophils in response to inflammation.High levels of IL-8 are associated with severe cases and death. IL-8 alone may be able to identify high risk patients for severe ARDS, and may be able to determine a prognosis of ARDS. 
 
Soluble Tumor Necrosis Factor-Receptor 1 | Tumor necrosis factor-receptor 1 (TNFR-1) is a receptor with transmembrane, extracellular, and intracellular domains. TNFR-1 is associated with inflammation, tissue death, and neutrophil apoptosis. During inflammation, soluble TNFR-1 (sTNFR-1) is shed and binds to TNF-alpha. sTNFR-1 is associated with higher mortality rates. 
 
Coagulation and Fibrinolysis | Plasminogen activator inhibitor-1 (PAI-1) regulates coagulation and fibrinolysis. PAI-1 helps convert plasminogen to plasmin by binding to different plasminogen activators. PAI-1 promotes inflammation because fibrin accumulates, which activates pro-inflammatory mediators and vascular permeability. There is varying data whether PAI-1 can predict ARDS mortality. 
 
Conclusion | More studies need to be done on the biomarkers of ARDS, but it is clear that sRAGE, IL-6, IL-8, sTNFR-1, and PAI-1 will be helpful in the diagnosis and prognosis of ARDS. 
 
 
Abstract | The authors compared patients with borderline personality disorder (BPD) with a healthy control group about childhood traumatic life events, parental attitudes, family history of mental illness, and birth risk factors. BPD patients reported more severe traumatic events and childhood traumatic experiences (i.e., sexual abuse, violence, separation from parents). Attitudes towards parents were significantly more negative in BPD patients. BPD patients also reported higher rates of mental illness in their families (i.e., anxiety disorders, depression, suicidality). More reports of premature birth were seen in BPD patients. Familial mental illness, childhood sexual abuse, separation from parents, and poor nurturing styles by parents appeared to be possible factors causing BPD.  
 
Introduction | Developmental trauma (i.e., incestual childhood sexual abuse, neglect) has consistently been reported at high rates in patients with both BPD and “childhood” BPD. Among various psychological disorders, BPD was most frequently associated with sexual abuse. Family and twin studies support the presence of genetic underpinnings to the disorder. Fetal, peri- or post-natal brain damage may also result in susceptibility to BPD. Brain abnormalities and neuropsychological deficits have been shown in patients with BPD.  
 
Methods | The researchers used a DSM-IV structured clinical interview on 66 outpatients with BPD. Patients with severe medical illness and a history of schizophrenia or bipolar disorder were excluded. 109 people without mental illness were used as controls matched with patients for age and sex.  
 
Results | Traumatic childhood events1. Separation from mother during childhoodHospitalization of the mother, for longer periods of time, during childhood was more common in the BPD patient group.2. Separation from father during childhoodIn ~25 of the BPD patient group, fathers were imprisoned during childhood. Absence of the father for reasons outside of military service was also higher in this group. 3. Separation from both parentsSignificantly more BPD patients reported being raised by people other than their own parents (e.g., aunts) or growing up in a foster home.4. Parents' marital problems, separation, or divorceMarital problems and divorce (though not significant) were reported more in BPD patients. 5. SiblingsThe severity of illnesses of siblings was higher in the control group, but siblings were sicker for longer in the BPD patient group.6. Childhood illnessMore BPD patients reported a major illness that lasted longer during childhood than controls. More and longer-lasting hospitalizations not caused by mental illness were reported more in BPD patients.7. Physical handicapsMore BPD patients reported being physically handicapped or living with physically handicapped siblings.8. Social environmentThe average social class was higher in the control group and BPD patients reported more unemployment in mothers.9. Violence in familiesFamilial, particularly the father beating children or the mother, violence reported significantly more in the BPD patient group.10. Sexual abuseMany of the BPD patients reported being sexually molested or abused during childhood, with the average age of it beginning being 6 years old. The childhood sexual abuse (CSA) being penetrative or non-penetrative was much more frequent in the BPD patient group. Most of the sexual abuse was done by a relative or acquaintance. Non-genital CSA occurred at the same rate among men and women (73.7 and 73.9, respectively), but penetrative CSA was more frequent in women than men (66.7 v. 44). Only two BPD patients received emotional support from a parent with regard to the abuse. Age periodNo particular age periods (0-4, 6-10, or 11-15 years) revealed patterns of traumatic event occurrence. Parental attitude and rearing stylesPoor styles of nurturing as well as less care and affection from parents were shown by all BPD patients with one exception. Psychiatric disorders in the familyAnxiety disorders, depression, and suicidality were the most common of reported disorders of first degree relatives of BPD patients. 6 BPD patients also directly reported the presence of “borderline” disorders among a relative. Alcohol abuse by fathers was higher in BPD patients. Birth risk factorsBPD patients reported more premature birth than controls. There were no statistically significant differences in reports for other birth risk factors (i.e., mother’s age).  
 
Discussion | Studies comparing similar risk factors for BPD with other psychiatric disorders may result in an underestimation of the relationship between these factors with BPD. Hence, why this study used healthy controls for comparison. This study affirmed the association of BPD with disturbed family environments, as demonstrated by many other studies, but revealed startlingly high reports of childhood sexual abuse. BPD may then be a form of PTSD from sexual traumatization. The method used in this study may have overestimated the frequency of familial mental disorders as researchers used the descriptions of BPD patients who may have had a negatively skewed perspective on family members. 
 
 
Abstract | The authors reviewed the gene-environment interactions (GxE) and epigenetic factors in borderline personality disorder (BPD), mainly, as well as avoidant, schizotypal, and antisocial personality disorders. Childhood sexual and physical abuse were found to mediate the expression of susceptibility genes in borderline personality disorder. Epigenetic (i.e., environmental) alterations to brain development and genes involved with stress were found to explain the relationship between BPD and challenges early in life. The results suggest possible biological treatment targets for personality disorders, which are known to be chronic and lack any pharmacological treatments.  
 
Introduction | The present understanding of the genetic risk for BPD is that it is caused by a synthesis of many variants spread throughout the genome, each of which increases the risk for developing BPD. Environmental influences play a large role in the emergence of psychiatric disorders, even in highly heritable ones (i.e., schizophrenia, autism). The GxE approach posits that environmental influences are responsible for the genesis of disorders with genes changing individual susceptibilities to environmental factors. This is assuming that one’s genetic predispositions are expressed differently in different environments, and environmental influences are ‘felt’ differently according to one’s genetic predispositions. The main evidence for the gene-environment interaction approach is the observed heterogeneity of responses to environmental influences that cause psychiatric disorders.  
 
Borderline Personality Disorder | Genetics and Environment in BPDBPD is the most commonly diagnosed personality disorder, marked by emotional instability, dysfunctional social relationships, and self-destructive, impulsive behavior. BPD has a high mortality rate (8.3) and raised healthcare costs, so it has been pressing for researchers to find out more about it. Most studies on BPD have mistakenly viewed gene-environment interactions as being independent. Candidate genes in certain neurotransmission centers (i.e., serotoninergic) have been widely studied, but proven unsuccessful in finding associations with BPD diagnostic features. This suggests research on susceptibility should focus not on “vulnerability genes” but on plasticity genes, which are in line with the GxE approach. Moreover, genome-wide association studies (GWAS), rather than focus on candidate genes, have revealed more promising genes. Gene-Environment Interaction Studies in BPDAlthough environmental factors such as childhood sexual abuse and neglect have been established as influencing BPD, few GxE studies have been conducted. These studies assert that certain “susceptibility” genes to BPD are expressed in response to certain environmental factors or tribulations. Possible susceptibility genes are as follows: Serotonin transporter promoter (5-HTTLPR)Catechol-O-methyltransferase (COMT) Val158Met polymorphismBrain-derived neurotrophic factor (BDNF) Val66Met polymorphismTPH1 polymorphismOxytocin receptor gene (OXTR rs53576) and FKBP5 geneHPA genetic polymorphismsGene-environment correlations (rGE)Epigenetic Modifications in BPDEpigenetics describes the resulting gene expression of an interaction between a gene and the environment without changing the DNA sequence of the gene. This is a heritable alteration that is stable, but reversible and acts as an adaptive biological response to one’s environment. Implicated genes are as follows: Glucocorticoid receptor (GR) gene (NR3C1) Serotonin 3A receptor gene Brain-derived neurotrophic factor (BDNF) gene Dopamine receptor D2 gene Ribosomal DNA gene Multigene/genome-wide investigations Methylation, a biological process that can change the activity of a DNA segment without changing its sequence, of these genes revealed many associations and correlations with regard to BPD. Future directionsBPD affects 2-5.9 of the general population. The nascent evidence on the role of GxE in BPD poses new possibilities for its treatment, especially those taking into account epigenetics. This is even more pressing considering the lack of pharmacological treatments for BPD.  
 
Other personality disorders | Antisocial personality disorder ASPD, as defined by DSM-IV-TR, includes a chronic pattern (beginning in adolescence and continuing into adulthood) of law-breaking or violation of the rights of others, along with impulsivity/failure to plan ahead, irresponsibility, recklessness, deceitfulness, irritability/aggressiveness and a lack of remorse for repeated wrongdoing.The monoamine oxidase A (MAOA)-encoding gene and serotonin transporter gene promoter polymorphism (5-HTTLPR) have been identified as having associations with antisocial behaviors. Schizotypal Personality Disorder Schizotypal Personality Disorder (SPD) consists of problems with interpersonal relations that result from social detachment, psychotic personality traits (i.e., eccentricity), and confusing boundaries with others. SPD is closely related to schizophrenia, but little is known about its genetic bases. One study reported that the p250GAP gene polymorphism may be involved in the susceptibility to both schizophrenia and schizotypal personality traits.Avoidant Personality DisorderAvoidant personality disorder (AvPD) features an avoidance of many social situations that result from the combination of feelings of inferiority and sensitivity to negative evaluations by others about the self. It is viewed as being very similar to social anxiety disorder. Studies about environmental influences on the emergence of AvPD are uncommon, but preliminary evidence suggests that parental neglect and/or abuse may increase the likelihood of its development. Some polymorphisms in genes regulating serotonin and dopaminergic systems provide evidence of heritability (transmissible from parent to child) in AvPD.  
 
 Conclusions | Environmental risk factors like histories of childhood maltreatment and abuse have been shown to play a significant role in the emergence of BPD, but formal studies exploring the interaction environmental and genetic factors have only been explored fairly recently. Epigenetic changes are thought to be the intermediary mechanism linking environmental experiences to biological changes that play key roles in personality disorders. “Susceptibility genes” to personality disorders, namely BPD, or their traits may be expressed under specific conditions in response to specific challenges. Most of the GxE studies have focused on negative environmental factors such as childhood sexual abuse, so it is necessary for future studies to evaluate the impacts of positive environments on susceptibility genes in order to get a more comprehensive understanding of gene-environment interactions. Epigenetic changes are reversible, so research here invites the emergence of new treatments and medications for these personality disorders. Particular attention to childhood interactions with parents (i.e., childhood trauma) is important in preventing the emergence of these severe personality disorders. 
 
 
Abstract: | A certain chemical family known as flavonoids activate pathways that combat oxidative stress. Oxidative stress is the phenomenon in which an imbalance in oxidants and antioxidants leads to programmed cell death. The pathways that are activated are the hypoxia inducible factor (HIF) and Nrf2. It is important to note that not all flavonoids are activators of these two pathways. NDGA, a chemical similar to flavonoids, was chosen in this study due to its strong ability to activate the Nrf2 and HIF pathway as well as its bioavailability and stability. NDGA had neuroprotective effects in the animal model of Parkinson’s Disease. 
 
Main: | Flavonoid-rich diets are praised because of their incredible health benefits. These diets are correlated with lowered risk of cancer, heart attack, stroke, and age-related neurodegeneration. Scientists have attributed these benefits to flavonoids activating anti-oxidant and anti-hypoxic programs in the cell. The two most potent programs that are activated are those triggered by hypoxia inducible factor (HIF) and Nrf2.HIF:HIF is a transcription factor responsible for activating many genes involved in glucose uptake, metabolism, extracellular pH control, and programmed cell death. Under normal conditions, HIF is targeted for proteasomal degradation by prolyl hydroxylases (PHDs). However, there are certain molecules - such as flavonoids - that inhibit the PHDs thereby freeing/activating the HIF.Nrf2:Nrf2 works in a similar fashion to HIF. Nrf2 is a transcription factor that is responsible for the expression of pro-survival and cytoprotective enzymes. Under normal conditions, Nrf2 is bound to the Keap1 complex which targets Nrf2 for proteasomal degradation. When the Keap1-Nrf2 complex is in the presence of electrophiles, the Keap1 undergoes a conformational change allowing for the Nrf2 to enter the nucleus of the cell. The Nrf2 then binds to the antioxidant response element (ARE) binding site. 
 
Methods and Materials: | The first step in the study was to demonstrate that flavonoids activate the HIF and Nrf2 pathways. To do this, a luciferase assay and a real-time RT-PCR were performed.To model Parkinson’s in neuronal cultures, the researchers made a glutathione depletion model. Both the mouse model of Parkinson’s and the in vitro Parkinson’s model were both treated with NDGA and selected flavonoids.To measure cellular viability, an MTT assay was performed. 
 
Results: | In the glutathione depletion model, certain flavonoids were selected based on their luciferase activity. Most of the chosen flavonoids gave significant recovery to the neuronal culture. NDGA treatment at 2.5 micromolar concentration gave nearly full recovery.Within the mouse models of Parkinson’s, slides of the mice’s brains showed a significant decrease in the cell density. However, with NDGA treatment, there was significant recovery in cell density. 
 
Discussion: | This study showed that different flavonoids may have different effects on the two programs mentioned (HIF and Nrf2). One flavonoid may be a strong HIF activator while not being as strong an Nrf2 activator and vice versa. This is likely due to the different structural requirements for activating HIF versus Nrf2.Flavonoids, though their health benefits cannot be ignored, have lacking bioavailability in the brain. NDGA is a promising alternative as it is structurally similar to flavonoids. NDGA also has a higher bioavailability. Lastly, NDGA was proven in this study to have neuroprotective effects in Parkinson’s Disease models. 
 
Conclusion: | In addition to this study showing the promising effects of NDGA and flavonoids in Parkinson’s Disease, it also highlighted the structural requirements for activation of HIF and Nrf2. 
 
 
Abstract | Background: COVID-19 has spread around the globe. This study investigates the infectivity of asymptomatic carriers.Materials and methods: 455 contacts who were exposed to the asymptomatic COVID-19 positive virus carrier were the subjects of this study.Results: During quarantine seven members in contact with the asymptomatic individual developed new cardiovascular conditions. However, no SARS-CoV-2 infections were detectable in all 455 contacts by a nucleic acid test.Conclusion: All 455 contacts did not contract the virus and thus the researchers concluded that the infectivity of some asymptomatic SARS-CoV-2 carriers might be weak. 
 
Background | As of March 24, 2020 there have been 334981 confirmed cases and 14652 deaths globally. The basic reproduction number of SARS-COV-2 is predicted to be between two and three, which is higher than SARS-CoV. It has been previously reported that asymptomatic carriers could still transmit the virus, but this is still a controversial topic. Here we report one case of an asymptomatic SARS-CoV-2 carrier with nosocomial infection and his 455 contacts.CaseAA 22 year old female patient with a medical history of congenital heart disease. As Case A vitals stabilized she was transferred to the emergency department observation unit (EDOU). She was then tested by a nasopharyngeal swab where she tested positive for SARS-CoV-2 by real time Reverse transcription-Polymerase Chain Reaction (RT-PCR). The patient had not visited Wuhan lately and did not present with fever, sore throat, or other COVID-19 infection related symptoms. The patient's blood measurements remained within normal tolerances for white blood cells, lymphocytes, C-Reactive protein, and procalcitonin. Similarly, a chest computed tomography (CT) scan showed no COVID-19 imaging features.While in the hospital the patient received antiviral and interferon therapy and 11 days after treatment the chest CT showed no significant changes. The patient tested positive for 5 days and then on the 6th day she tested negative. She was released from quarantine on day 21 and released. Case A was diagnosed as an asymptomatic carrier. 
 
Materials and Methods | This study considers an asymptomatic carrier as one who presents without clinical symptoms, but whose SARS-CoV-2 test remains positive. All contacts, staff, family members, and associates were routinely screened for infection. 
 
Results | Patients in the EDAll abnormal CT findings were discussed by professional radiologists and confirmed to be of a non-viral origin. All patients in the EW were required to wear a mask except while eating or drinking.Family MembersNone tested positive for SARS-CoV-2 and all wore masks when in contact with Case A. The only time the mask was taken off was when eating or drinking.StaffAll staff wore proper protective equipment when interacting with Case A such as N95 respirators, isolation gowns, and goggles. 
 
Discussion | 	All developed medical issues were related to underlying or preexisting medical conditions. Combined with proper protective equipment like masks the researchers conclude that there is no need to worry about asymptomatic individuals. The limitations of this study is that there is only one case in this study. 
 
Conclusions | 	Infectivity of some asymptomatic SARS-CoV-2 might be weak. Effective prevention is helpful to prevent COVID-19 spread of asymptomatic carriers. The results may alleviate public concern of asymptomatic spread.  
 
 
Main text | The underrepresentation of Black scientists goes beyond the research team, it applies to the authors, reviewers, and advisory board. It is easy to redirect the blame and point out that any journal is a reflection of the scientific ecosystem. To hide behind statistics. It is an epidemic of denial and it is vital that everybody deny the status quo to fight the overt racism which cripples the lives of Black Americans, including Black scientists.Science has a racism problemLook at human genetics and its history. It is a field that has been repeatedly used as a rationale to support the inherent inequalities present in “races”. Supporters of Eugenics use the allele we carry as reason to support racial superiority. Race is genetic.Look at the exploitation of Black research subjects. The sheer volume of contribution and exploitation from Henrietta Lacks, to the Tuskeegee syphilis study that purposely withheld appropriate treatment to hundreds of Black men. Do not overlook the shared role of race in these violations of medical ethics.Look to the extreme disparity in clinical and genetic databases that are mostly composed of white Americans of Eurpoean descent. This lack of knowledge is deadly and can be highlighted by the current pandemic, why black women are five times more likely to die during pregnancy, or why black infants are twice as likely to die as white babies in the US. Black health has never been a priority.Science has a racism problem. The scientific discoveries and their usage, the scientific establishment, education and metrics used to define scientific success has racism inherent as well.Black Americans face a mountain of challenges built on centuries of systemic structural racism. The gatekeeping system in academia, industry, and scientific organizations was not designed to account and correct for the centuries of compounded oppression and the resulting disadvantage. It is time for renovation.We urge community members to enact change. Nobody can stem the tide of racism or rebuild and unjust society, but every action helps. Hiring committees, education, mentors, admissions committees, classmates, researchers, everybody must help.The authors of this paper Cell are committed to listening to and amplifying their voices, to educating ourselves, and finding ways to help. We the writers of Cell have the advantage of having this platform and we will put it to work.As a start, we are committing to the following actions to increase representation of Black scientists.Representation- We will feature and amplify Black and other underrepresented minority authors of Cell papers on social media. If you wish to be highlighted send us an email.Education- We pledge to purposefully highlighting Black authors and perspectives in the review and commentary that we commission and publish.Diversifying- We pledge to increase the diversity of our advisory board, reviewer pool to better represent of non-white scientists. We are currently trying to improve diversity through outreach, recruiting, and hiring efforts. If you are a black scientist interested in a career get in touch. We are eager to talk.Listening- We the editors are willing to talk. We can use this platform to help the Black scientist community. We want to hear them. Please email us if you have concrete ideas for perspectives to help us. We promise to hear you.This is just the beginning. We are learning, and will make mistakes. Silence is not, and never should have been, an option.Science has a racism problem. Scientists are problem solvers. Let’s get to it.  
 
 
Abstract | Anopheles gambiae is a mosquito that can infect humans with malaria. The doublesex gene encodes two genetic sequences, dsx-female and dsx-male that control whether a mosquito is a male or female. The female sequence contains a coding sequence called exon 5, which is highly conserved in Anopheles. In this study, the researchers found that disruption of exon 5 aimed at blocking the formation of dsx-female did not affect male development or fertility but caused females to have an intersex phenotype and be sterile. A CRISPR-Cas9 gene drive targeting this sequence spread rapidly in caged mosquitoes, and reached 100 prevalence in 7-11 generations. This caused egg production to decrease to the point of population collapse. 
 
Aims | The researchers wanted to find a gene to disrupt using CRISPR-Cas9 in Anopheles that could be used in a gene drive to collapse a lab population of the mosquito. 
 
Introduction | CRISPR-Cas9 has been used in previous studies to create gene drives in Anopheles gambiae and Anopheles stephensi with the purpose of vector control. These studies focused on suppressing the reproductive capability of mosquito populations. According to mathematical modeling, this suppression can be achieved using gene drives targeting genes related to female fertility, or introducing interruptions on the Y chromosome (called a Y-drive). Both strategies cause decreases in the number of fertile females that would eventually cause population collapse.However, these strategies have technical and scientific issues. Y-drives prove difficult because the transcription of sex chromosomes shut down during meiosis, making it difficult to pass on interruptions to the next generation. A gene drive used to disrupt fertility gene AGAP007280 initially spread through a population, but nuclease-resistant variants emerged and blocked the spread of the drive. Gene drive targets with functional or structural constraints that can prevent the development of nuclease resistance could create successful gene drives. The researchers evaluated the potential for disrupting sex determination in A. gambiae to block the formation of doublesex in females. 
 
Results | doublesex and sex differentiation in A. gambiaeIn A. gambiae, doublesex (dsx) is alternatively spliced during transcription to produce male and female transcripts (AgdsxM and AgdsxF respectively). To understand whether dsx was a good target for a gene drive suppressing reproduction, the researchers disrupted a specific portion of dsx to prevent the formation of AgdsxF while leaving AgdsxM unaffected. To do so, they injected A. gambiae embryos with Cas9 and a single-guide RNA that was designed to recognize and cleave the interruption site, while an eGFP transcription was inserted into the site using a template for homology-directed repair. Transformed mosquitos were crossed to breed homozygous and heterozygous mutants. Larvae that were heterozygous for the disruption developed normally into male and female mosquitoes. However, half of the homozygous mutants had both male and female features, and abnormalities in reproductive organs (intersex). Intersex females were unable to take blood meals and failed to produce eggs.Building a gene drive to target dsxThe researchers replaced the eGFP transcription insert with a dsxFCRISPRh gene drive construct so that the interruption could be passed onto future generations. The dsxFCRISPRh construct was able to bypass traditional inheritance and were passed on to 95.9 of heterozygous males and 99.4 of heterozygous females. dsxFCRISPRh heterozygous males had no change in fertility, while dsxFCRISPRh heterozygous females showed decreased fertility.Assessment of dsx gene drive in caged insectsUsing a mathematical model, the researchers calculated that dsxFCRISPRh could reach 100 prevalence in a mosquito population in 9-13 generations. To test this, the researchers mixed wild-type mosquitos with heterozygous dsxFCRISPRh mosquitos and monitored their progeny at each generation. They performed this in two cages. During the first 3 generations, the drive allele increased from 25 to ~69 in both cages. In one of the cages, the drive reached 100 frequency by generation 7 and population collapse was achieved at generation 8. In the other cage, 100 frequency was reached at generation 11, with population collapse at generation 12. Both of these results fell within the range of the mathematical model.Potential for resistance to dsx gene driveThere was a low frequency of mutations in this study’s gene drive. There was no evidence of positive selection, which would have caused the drive to fail. The researchers found that the guide RNA used in the gene drive construct efficiently cleaved variants of dsx, suggesting that the gene drive would be successful even in the presence of dsx mutants. However, the drive is not “resistance-proof.” 
 
Discussion | The development of a gene drive capable of collapsing mosquito populations to a level that cannot support malaria transmission is a long-sought goal. The gene drive used in this study, with the dsxFCRISPRh has features that make it suitable for field testing. The drive has high inheritance rates, fully fertile heterozygous individuals, sterile homozygous females, and no evidence of nuclease resistance. Nonetheless, the drive is not resistance-proof.The gene drive used in this study now needs to be evaluated in large confined spaces that mimic natural ecological conditions. 
 
 
Abstract | Mucosal barrier immunity in the intestine is essential for maintaining the commensal microflora (friendly gut bacteria) and fighting bacterial infection. Previously, immune and epithelial cells were thought to maintain this balance between harboring the commensal microflora and fighting infection. In this study, the researchers show that the enteric nervous system (ENS), or neurons in the gastrointestinal tract, plays an important role in this balance. The researchers found that the ENS governs the antimicrobial protein (AMP) response, which helps fight against infection. The researchers used confocal microscopy and single-molecule fluorescence in situ mRNA hybridization (smFISH) to observe that intestinal neurons produce IL-18, a cytokine. Deletion of IL-18 production from the ENS, but not from immune or epithelial cells, caused mice to be susceptible to Salmonella typhurium (S.t.) infection, indicating that IL-18 production by the ENS is essential and non-redundant. In addition, RNA sequencing and single-cell sequencing showed that IL-18 produced by the ENS is required for AMP production. Together, these results show that IL-18 produced by the ENS signals to and controls intestinal immunity, and has important implications for the mucosal barrier and fighting off infection. 
 
Aims | The researchers wanted to understand how the enteric nervous system influenced immune responses in the intestine. 
 
Introduction | The intestinal mucosal barrier protects against bacterial infection while maintaining a symbiotic relationship with commensal microflora. It is well known how immune and epithelial cells maintain this balance, but little is known about the influence of the enteric nervous system (ENS).Patients with Hirschsprung disease have an absence of nerves in the bowel. These patients are at risk of developing serious and life-threatening infection of the bowel. This infection correlates with dysregulation of intestinal mucus and imbalances in the commensal microflora, suggesting a connection between the ENS and intestinal mucosal barrier. Previous studies have concluded that ENS cells can respond to patterns associated with infection. This suggests that the ENS may play a key role in regulating mucosal barrier immunity.Interleukin 18 (IL-18) has emerged as an important cytokine in the immune response. It encourages inflammation and is required to combat invasive bacterial infections, such as Salmonella. IL-18 deficient mice have shown imbalances in the commensal microflora and decreases in antimicrobial protein (AMP) production. Understanding of this cytokine outside of immune and epithelial cells is largely unknown. In this study, the researchers found that immune and epithelial cells were redundant sources of IL-18, which drives AMP production and protection against Salmonella infection. The results demonstrate that the ENS plays a critical part in the immune response, and is essential for coordinating the balance between harboring the commensal microflora and combating infection. 
 
Results | Epithelial Cell- and Immune Cell-Derived IL-18 Does Not Protect against Enteric S.t. InfectionEpithelial cells and myeloid cells (which give rise to many kinds of immune cells) are thought to be the major sources of IL-18 production. To test this, the researchers crossed wild-type mice with mice that have IL-18 deletion in myeloid and epithelial cell lineages. Wild-type and mutant mice were subjected to Salmonella infection. Absence of IL-18 in both epithelial and myeloid cells did not affect susceptibility to infection, and mice were healthy after infection. These results suggested that epithelial- or immune-derived IL-18 are required for protection against infection.Enteric Neurons Express IL-18To investigate whether the ENS produces IL-18, the researchers used confocal microscopy for IL-18 reactivity. The researchers found a subset of neurons in the ENS that produced IL-18, indicating that enteric neurons are novel producers of IL-18 in the gastrointestinal tract.Enteric Neuronal IL-18 is Protective against S.t. infectionTo investigate the role of ENS-derived IL-18 on intestinal immunity, the researchers bred wild-type mice and mice with genes that allowed deletion of IL-18 from ENS cells. Loss of IL-18 did not affect the commensal microflora in progeny mice. The researchers then infected progeny mice with Salmonella and observed that mice without ENS-derived IL-18 became infected and sick, and showed increased prevalence of bacteria in the gastrointestinal tract. On the other hand, when wild-type mice were infected, the mice were more healthy than mice without ENS-derived IL-18. These results showed that ENS-derived IL-18 protects mice from bacterial infection.Enteric neuronal IL-18 is a Specific Driver of Goblet Cell Antimicrobial Protein ExpressionSince it was not obvious how ENS-derived IL-18 protects against Salmonella, the researchers sought to understand what kind of signaling events that occur in mice deficient in ENS-derived IL-18 compared with mice deficient in epithelial and immune cell-derived IL-18. The researchers conducted RNA-seq on colon tissue of both wild-type and mutant mice. Analysis showed that distinct genetic expression was specifically regulated by different sources of IL-19 (neuronal, epithelial, and myeloid). The researchers compared these genes and found that bactericidal and antimicrobial genes were exclusively reduced in mice lacking ENS-derived IL-19. This suggested that the source of IL-18 has significant effects on what role it has in the intestinal immune response.Analysis also showed that ENS-derived IL-18 was specifically promoting AMP production in the colon. The researchers found that these AMPs were produced by goblet cells, which secrete mucus in the intestine. These results showed that ENS-derived IL-18 drives intestinal AMP production through indirect signaling mechanisms.Neuronal IL-18-Driven AMP Expression Prevents Bacterial Infiltration and InfectionThe researchers also wanted to understand whether deficiency of ENS-derived IL-18 led to targeted loss of AMPs or if AMP loss was caused by other disturbances in the intestine. Using histological staining and immunofluorescence studies, the researchers found no major defects in the structure or immunological environment in the intestine.The researchers also investigated the impact of ENS-derived IL-18 on the commensal microflora. They observed no significant alterations. However, they did observe that in mutant mice, there was increased bacterial infiltration from the commensal microflora into the intestine. These results revealed that ENS-derived IL-18 signals AMP production that is necessary to prevent bacteria from the commensal microflora infiltrating the intestine.The researchers tested whether decreases in AMP production explained why mutant mice were more susceptible to Salmonella infection. They found that bacterial killing was significantly reduced in mutant mice compared to wild-type mice. These results demonstrate that reduction in AMPs in mice deficient in ENS-derived IL-18 causes an inability to ward off infection. 
 
Discussion | In this study, the researchers found that IL-18 produced by the ENS is necessary for protection against bacterial infection. Expression of IL-18 in the ENS non-redundantly signals for AMP production in goblet cells, which helps prevent the commensal microflora from invading the intestine and, during infection, kills bacteria. The researchers also found that epithelial and immune cell-derived IL-18 is completely unnecessary for AMP expression. The results of the study demonstrated that the source and location of IL-18 also influence its effects.Science’s understanding of how the nervous system influences intestinal immunity has grown rapidly in recent years. The findings of this study show that neuron-produced IL-18 is an important driver of the immune response. Based on these results, the researchers suggest that targeting neurons to enhance AMP production may be used to limit infection in patients suffering from deficiencies in barrier immunity. 
 
 
Abstract | 	This study looked at 25-hydroxyvitamin (25(OH)D) levels in 137 Brazilian women with breast cancer. Overall findings show that 25(OH)D deficiency was prevalent among the cancer patients. This deficiency was linked to poor prognosis parameters (reduced likelihood of recovery, chemoresistance, and metastasis. 
 
Introduction | 	Vitamin D deficiency is a common issue around the world and has been linked to type 1 diabetes, multiple sclerosis, rheumatoid arthritis, cancer, and a number of other diseases. 25-hydroxyvitamin (25(OH)D) is used as a standard to examine an individual’s vitamin D status. This paper discusses using the vitamin’s levels to predict the development and progression of breast cancer. This type of cancer is mainly related to female aging and is a heterogenous illness with various types of gene expression (different outcomes). The chronic inflammation and constant changes of breast cancer cells may make them resistant to the antitumor effects of vitamin D and its receptor (together they can regulate expression of genes related to cell growth and death).  
 
Methods | 	Between Feb 2016 and May 2017, 147 women with infiltrative ductal carcinoma were studied. Anyone undergoing vitamin D replacement or diagnosed with a different type of cancer was excluded from the study. Blood and tumor samples were collected from the 147 participants. Tumors were placed into four categories based on immunohistochemistry (antibodies used to check for certain antigens). 70 healthy women (no cancer and no vitamin D replacement) were used as a control group. Participants were between the ages of 32 and 88.	25(OH)D testing was performed and used to estimate overall vitamin D status. A chemiluminescence kit was for this step of the study. Healthy serum samples with known vitamin levels were used to determine the kits’ precision (over 90 as stated by manufacturer). 
 
Results | 	25(OH)D levels for the cancer patients ranged from 4-29.1ng/mL, with a median of 22.0ng/mL. 25(OH)D levels for the healthy control group ranged from 8.8-48.9ng/mL, with a median of 25.6ng/mL. “Plasmatic 25(OH)D was significantly reduced in breast cancer patients in relation to healthy controls…”	Patients with lymphonodal invasion of the tumor cells tended to have lower 25(OH)D levels (vs those without lymphonodal invasion). Patients who developed chemoresistance 6 months after starting chemotherapy also showed lower 25(OH)D levels. Patients with metastasis identified during later follow ups showed lower vitamin levels during diagnosis. Patients still alive after 2 years showed higher vitamin levels than those that died. Overall outcomes were observed and categories were made based on prognosis. This grouping showed that poor prognosis was linked to lower levels of 25(OD)H. 
 
Discussion | 	This study suggests that vitamin D may help prevent the development of breast cancer, which is why reduced levels may occur during its formation. Such a conclusion is consistent with the fact that groups closer to the Equator (higher vitamin D production due to sun exposure) have reported lower levels of breast cancer. Overall, chemoresistance, metastasis, and poorer prognosis (lymph node spreading and death) are all linked to low vitamin D levels.  
 
 
Abstract | This study looks at the expression of endoglin (CD105), vascular endothelial growth factor (VEGF), epidermal growth factor receptor (EGFR-1), and epidermal growth factor receptor 2 (c-erbB-2). The expression of these were all correlated with the prognosis of adenocarcinoma in the cervix. This study shows that cervical adenocarcinoma is caused by angiogenesis that is controlled by the interactions of CD0105, VEGF, EGFR-1, and c-erbB-2. 
 
Introduction | Cervical cancer has been decreasing in women overall, but cervical adenocarcinoma has been increasing in young women. Compared to cervical carcinoma which is the most common type of cervical cancer, the cervical adenocarcinoma has a worse prognosis and does not respond as well to chemotherapy. The two subtypes of cervical adenocarcinoma are endocervical (70 of cases) and endometrioid (30 of cases). The endocervical is the most common, but the endometrioid has a worse prognosis. Cervical cancer is the most common cause of cancer death worldwide, but the subtypes and their prognosis are not well understood. Studies need to be done to see the specific microenvironment of the different types of cervical cancer so better treatment can be developed.The growth and metastasis of a tumor depends on the density of vessels and angiogenesis. Endoglin (CD105) is involved in angiogenesis and microvascular density, which are both associated with a poor prognosis. Tumors can increase angiogenesis by secreting vascular endothelial growth factor (VEGF). VEGF is proven to promote tumor growth. Epidermal growth factor (EGFR) is also associated with poor prognosis. VEGF and EGFR are very closely related, and blocking both pathways can help treat tumors better. This study aims to look at the expression of CD105, VEGF, EGFR, and c-erbB-2 in different subtypes of cervical adenocarcinoma. 
 
Materials and Methods | The researchers used immunohistochemistry to test the expression of VEGF, EGFR and c-erbB-2. They assessed blood microvessel density by counting all of the CD105 positive vessels per optical field under a microscope in the center and the edges of the tumor. 
 
Results | CD105 expression and MVD assessmentIn the normal tissue, CD105 expression was low. CD105 expression was highest in the endothelial cells of the center and edges of the tumor. The highest density of the tumor microvessels were at the invasion front and the stromal areas. The microvascular density varied in all of the tissue samples, but the tumor samples had a higher density on average all throughout the tissue.VEGF expressionThe VEGF reaction was found in vascular endothelial cells, fibroblasts, and inflammatory cells. The intensity of the VEGF reaction seemed to be higher when there was a higher microvascular density, independent of which subtype of cancer was looked at.C-erbB-2 expressionThe highest c-erbB-2 reactivity correlated with the highest microvascular density, independent of which subtype of cancer was looked at.EGFR-1 expressionEGFR-1 was found in significantly lower levels than c-erbB-2. 
 
Discussion | The expression of CD105, VEGF, EGFR-1, and c-erbB-2 and their correlation with prognosis in cervical adenocarcinoma. CD105 is known to allow normal vessels to turn into activated vessels, which are found in tumors. This study showed that the highest CD105 levels of cervical adenocarcinoma were found in the areas around the tumor. The angiogenesis of the tumor was also seen with high CD105 levels. Other studies have also shown that a higher microvascular density correlates with a worse prognosis.There is conflicting data from multiple studies about the use of VEGF as a prognosis predictor. Still, VEGF plays a large role in tumor angiogenesis. Some studies find that the overexpression of VEGF is linked to angiogenic tumors and the spread of cancer to the lymph nodes. But there are other studies conflicting with this link.Most studies show EGFR to be expressed higher in squamous cell carcinoma compared to adenocarcinoma, which was supported by this study. There are mixed results on the relative expression of EGFR and c-erbB-2 in adenocarcinoma, but this study showed that c-erbB-2 was highly expressed. c-erbB-2 likely upregulates VEGF expression, which was also supposed in this study. The more we study about the microenvironment of cervical adenocarcinoma, the better we can treat this cancer. 
 
 
Abstract | Using a structured interview on an ethnically diverse sample of 394 adolescents from 2 outpatient settings, the authors tested the relationship between reported histories of childhood maltreatment, symptoms of drug (mainly alcohol) abuse and dependence, and risky sexual behavior. They found symptoms of alcohol abuse and dependence mediated relations between scores of (1) emotional neglect (2) sex with co-occurring alcohol use and (3) sexual abuse with sex with co-occurring alcohol abuse. Addressing client histories of maltreatment may be necessary to effectively treat adolescents with substance abuse problems and prevent STD transmission. 
 
Introduction | Risky sexual behaviors are of a great public health concern as they account for a significant percentage of sexually transmitted infections (i.e., HIV). Patients being treated for substance abuse report having sex earlier and with more partners with less consistent condom use than those without drug abuse problems. There is also a significant association between alcohol use and sexual risk behaviors. Environmental risk factors such as childhood abuse and neglect influence both alcohol abuse and sexual risk behaviors. Childhood maltreatment is multidimensional and has well-documented short- and long-term consequences (i.e., developing internalizing disorders). Adolescent patients being treated for alcohol abuse show extensive histories of childhood abuse and neglect. Childhood abuse tends to happen before alcohol abuse, so seeing if alcohol use mediates its relationship with sexual risk behavior has important implications for treatment and prevention programs. 
 
Methods &amp; Analysis | Data were collected from an ethnically diverse sample of sexually active adolescents receiving substance abuse treatment from 2 outpatients facilities. The 38-item Childhood Abuse and Trauma Scale (CATS) was used to assess experiences of childhood and adolescent maltreatment. A modified version of the Timeline Follow Back instrument was used to measure sexual risk behaviors. Psychiatric symptoms and disorders were diagnosed using DSM-IV criteria. Path analyses were used to assess the constructs of interest. 
 
Results | Older participants reported higher levels of alcohol abuse, unprotected sex, and sex with co-occurring drug use. On average, male participants reported more sex with co-occurring alcohol use. There were no significant associations in relation to ethnicity.Past-year drug abuse or dependence was suggested to mediate the influence of specific kinds of childhood maltreatment (i.e., sexual or emotional) on certain risky sexual behaviors. Childhood sexual abuse was positively related to past-year alcohol abuse and sex with co-occurring alcohol use. However, sexual abuse experiences were found to be negatively related to alcohol abuse and dependence. 
 
Discussion | Findings are consistent with previous research demonstrating significant associations between childhood maltreatment and sexual risk behaviors and the development of disorders including substance use disorders. This also reinforces associations between substance abuse with risky sexual behaviors. Different kinds of substance use could be coping strategies (i.e., emotional regulation) in reaction to specific types of childhood maltreatment, mediating risky sexual behaviors. Substance abuse during sex could be motivated by anxiety reduction from past sexual trauma. Sexual abuse is more likely to be associated with alcohol abuse than other drug abuse.Patients with severe patterns of substance abuse and histories of childhood maltreatment appear to be at a higher risk for engaging in risky sexual behaviors (i.e., unprotected sex). The mechanisms underlying the relations between childhood maltreatment, alcohol abuse, and risky sexual behaviors needs further investigation. Particular attention to sexual risk behaviors and histories of childhood maltreatment are supported when treating adolescents with substance use problems. 
 
 
Abstract | Using data from 30-day daily dairies, the authors investigated if self-reports of childhood trauma were associated with variability in daily wellbeing and emotional reactivity to positive and negative daily events. Childhood trauma was associated with lower overall levels of wellbeing with increased variability. They found that emotional reactivity facilitated strong increases and decreases in wellbeing in those reporting childhood traumas in reaction to positive and negative events, respectively. This suggests that mastery increases sensitivity to positive and negative events. Thus, childhood trauma may lead to poorer midlife (and later) health by disturbing perception and reaction to daily events. Mastery may also have a different meaning for those with childhood trauma. 
 
Introduction | Childhood trauma can have effects lasting into midlife or old age including lower levels of wellbeing and less emotional support. A pathway linking childhood trauma to day-to-day health in midlife of particular interest is social-emotional regulation and wellbeing. Social-emotional regulation is defined in the study as (the ability to adjust) changes in positive and negative emotions in response to daily positive and negative events. Wellbeing is defined as an individual’s level of positive or negative affect in response to a neutral day (nothing good or bad happened). Social-emotional regulation and wellbeing make up components of daily life that accumulate over the lifespan and have the potential to affect health developments.Pathways Linking Childhood Trauma to HealthThere are multiple social-emotional pathways regulating long-lasting health effects of trauma. Trauma can alter perceptions (negative appraisals of neutral events or hypersensitivity to stressors) and coping strategies of daily life events and result in less goal-directed behavior, for example. These impairments in the context of dealing with daily life can worsen over time and from poor parental relationships and early life adversity. Early life adversity can lead to increased sensitivity to both stressors and positive events, differentiating between individuals and known as “differential susceptibility”. Emotional reactivity may be able to heighten resilience in the context of positive events (i.e. completing a fulfilling project at work) as well as decrease resilience due to an increased sensitivity to adversity.Mastery as a Key Resilience Factor for Confronting Childhood TraumaMastery, or perceived control, involves a sense that one has control (agency, self-efficacy)over a situation. It has been shown to decrease emotional reactivity and to stressful events and protect wellbeing, likely from the employment of better coping strategies (i.e., turning to a support network). The authors defined mastery as a tool for those with childhood trauma to mitigate emotional reactivity from (and decrease reports of) daily negative events. Mastery could also allow for positive events to be more uplifting in those with childhood trauma. The role of mastery in childhood trauma is unclear as its protective effects could be diminished after experiencing a stressor. The production (and perception) of positive events is ultimately decided by the person as an active agent, which is amplified in the context of childhood trauma. 
 
Method | 782 participants recruited from the ASU Live Project completed self-report questionnaires about early family life, personality, and traumatic and stressful experiences. A quarter of the sample (approx. 200 people) participated in a videotaped stress-inducing experience. Another quarter of the sample completed a 30-day daily diary about positive and negative emotions and experiences. A multilevel logistic regression model was used to determine whether childhood trauma increased or decreased the likelihood of experiencing a negative or positive event over the course of a day. A multilevel linear regression model was then used to evaluate whether childhood trauma moderated emotional reactivity to daily negative and positive experiences. 
 
Results | Higher levels of childhood trauma were associated with more reports of (and more variability of) negative and positive affect and lower levels of mastery. They also predicted stronger increases and declines in positive and negative emotions from positive and negative social experiences, respectively. Mastery, in the context of trauma, increased emotional reactivity. 
 
Discussion | The results explored how social-emotional regulation (mastery, wellbeing, and emotional reactivity) may be a pathway linking childhood trauma to health consequences later in life. Patterns of disturbances in responding to daily events as mediated by trauma may explain this as they can compound over the course of one’s life. Moreover, mastery does not function to protect against negative daily stressors in those with childhood trauma, functioning to exacerbate emotional reactivity to events. Social relationship interventions and mastery interventions meant to organize what kinds of situations are (and not) within one’s control may be helpful for those suffering from childhood trauma. More research into the underpinnings of daily-life disturbances mediated from childhood trauma is needed. 
 
 
Abstract | Adverse Childhood Experiences (ACEs) are major, compounding risk factors for physical and mental disorders among children and adults. Research has pointed to the need for strategies relieving and preventing trauma. Interventions for trauma, labeled as trauma informed care (TIC), requires observation of resiliency against trauma as well as its negative impacts on health. Catching trauma early in children remains a public health crisis. This article discusses trauma informed care in light of the prevalence and nature of ACEs (i.e., traumatic toxic stress, childhood adversity).    
 
Childhood Adversity: Definition and Scope | Childhood adversity can be described as stressful events or circumstances that are outside of a child’s control, which compounded can be detrimental to his/her physiological and psychological (i.e., cognitive and behavioral functioning). The most common ACEs fall under childhood abuse, child neglect, household dysfunction, poverty, and peer relational issues (i.e., bullying, lack of friends). However, shocking events such as witnessing the death of a loved one as well as moving frequently are also among many other ACEs. Measuring the behavioral and emotional responses to ACEs in real-time can be helpful in gaining a more comprehensive understanding of their later, longer-lasting effects in adulthood.  
 
Traumatic Toxic Stress: How ACEs affect Neurological Functioning | Health professionals are becoming increasingly aware of the impact social and environmental experiences have on health. Physiological/Positive Stress, Tolerable Stress, & Traumatic Toxic StressStressors that activate a normal fight/flight response in a child that ultimately helps with personal growth can be described as positive/physiological stressors. More shocking stressors that can be overcome with appropriate parental nurture is tolerable stress. Chronic stressors without a support system can lead to traumatic toxic stress (TTS). Response to stress involves two systems, the hypothalamic-pituitary-adrenal (HPA) axis and the sympathetic nervous system (SNS). Activation of the HPA axis ultimately results in the release of cortisol, epinephrine, and norepinephrine from the adrenal cortex, which affects many organ systems (i.e., cardiovascular via increasing heart rate). The body must go back to equilibrium at some point, so there is a negative (or counteracting) response in which the levels of cortisol return to baseline when the stressor is deemed gone. In TTS, however, the HPA axis remains activated, wreaking havoc on the body (especially the immune system) with the short term outcome of abnormally high levels of cortisol and the long term of abnormally low levels (or a lack) of cortisol. Neurologic Remodeling in the Context of TTSDysregulation of the HPA axis via TTS has profound impacts on the brain with vulnerability heightened during childhood/adolescence (C/A). TTS results in epigenetic changes with regard to how the body responds to stress. These changes can occur by DNA methylation and histone acetylation that change gene expression. Some of these changes can be reworked during C/A, but others will be rooted throughout the lifetime with the possibility of being passed onto offspring. The hippocampus, amygdala, and prefrontal cortex are particularly affected by HPA axis dysregulation. The hippocampus is involved in forming new memories and learning. It goes through much change throughout adolescence when learning and memory formation proliferates. TTS suppresses hippocampal neuronal proliferation, leading to long-lasting impairments in memory and learning formation. The amygdala, part of the limbic system, and responsible for the perception of emotions such as fear is activated during stressful events. TTS can lead to over-proliferation of neurons in the amygdala, resulting in more impulsive behaviors (as a reaction to stress). The prefrontal cortex, implicated in impulse control and future planning, will be underdeveloped as a consequence of TTS. TTS transforms normal physiological responses to stress by regional brain alterations, resulting in hypersensitivity in which neutral events are experienced as shocking and life-threatening.  
 
Epidemiology of Childhood Adversity | Epidemiologic studies on ACEs are relatively new, the original study being conducted in 1998. The population prevalence of having at least one ACEs falls between 55-64. A study surveying 42,272 children from nine Balkan countries found the prevalence to fall between 65-83. Studies have shown that ACEs likely co-occur and that the prevalence of having four or more ACEs is a staggering 15.  
 
Impact of Childhood Adversity and TTS on Health | Studies on ACEs have revealed the need to shift focus from the effects of individual kinds of childhood mistreatment to those of compounded ACEs on children and adults. The negative outcomes of ACEs can be broadly divided into (1) risky behaviors (2) leading causes of death and other long-standing health problems (3) poor mental health and (4) other consequences. Health Risk BehaviorsThere is a dose-response relationship between the number of ACEs and risky behaviors. Four or more ACEs increases the rate of IV illicit substance abuse (11.3 times), severe obesity (1.6 times), sexual intercourse with more than 50 partners (3.2 times), and alcoholism (7.4 times). The adoption of these risky behaviors are likely in response to (and cope with) trauma, referred to as a “trauma organized” lifestyle. Circumstances of limited healthcare with a “trauma organized” lifestyle from neurological alterations mediated by TTS are thought to result in an increased risk of illness and death. Leading Causes of Death and Other Chronic DiseasesChildhood trauma and four or more ACEs, in particular, can lead to autoimmune diseases (from HPA axis dysregulation), heart disease, lung cancer, stroke, and other problems such as obesity and insomnia. Mental Health There is extensive evidence surrounding the relationship between the aggregate number of ACEs and mental health difficulties. Learning and behavioral problems among children are in relation to the cumulative number of ACEs. ACEs have severe implications for the mental health of adults with four or more ACEs increasing the risk of depression and suicide attempts by 4.5x and 12.2-15.3x, respectively. Those who have suffered from multiple childhood traumas and consequent emotional dysregulation may develop PTSD with dissociation and automatic hyperreactivity. This can make traditional treatments especially difficult as PTSD dissociation comes with immense difficulty in establishing relationships as a result of emotional under-engagement.  
 
Approaches to Reducing the Burden of ACEs | A complex interaction between the individual, family, and community exists in ACEs, so prevention interventions and policies can follow the general public health approach, involving primary, secondary, and tertiary preventions. Primary preventions would involve preventing ACEs so future generations of children do not experience them. Secondary preventions would involve immediate efforts after an ACE to mitigate the short- and long-term effects of it on the child. Tertiary prevention would involve treating and reducing the severity of the long-term consequences of ACEs. Psychological first aid (PFA), parent-child interaction therapy (PCIT), child-parent psychotherapy (CPP), and CBT have been shown to be effective interventions for ACEs.  
 
Trauma Informed Care  | Trauma Informed Care (TIC) is meant to be a multilevel approach to change the way organizations view and approach trauma, treating children in an informed manner to primarily avoid re-traumatization. The SAMHSA promotes the use of six broad principles for TIC:1. Making sure clients feel physically and emotionally safe.2. Organizations should be transparent and trust staff and clients.3. Peer support is an essential resource for TIC. 4. Adverse experiences can be healed by every member of a trauma-informed organization.5. Approaches that are client-focused and empower clients are important. 6. Efforts should be culturally-informed (i.e., gender and historical).There is emerging evidence on the effectiveness of TIC in improving health-care delivery. Trauma-informed organizations must be sure to properly screen for trauma and operate in tandem with the above principles to appropriately and effectively treat clientele.  
 
 
Abstract | Trauma is a known causal factor for dissociation (i.e., depersonalization). This overview updates the conception of dissociation as well as neurobiological findings. Research has illustrated neurochemical and structural and functional abnormalities of the brain resulting from trauma, especially childhood interpersonal trauma (i.e., sexual abuse). The authors begin to shed light on the neural underpinnings of dissociation present in childhood PTSD, somatoform disorder, and dissociative (or conversion) disorders. Dissociative symptoms among children and adolescents may thus be seen as complex developmental disorders prompted by environmental factors. 
 
Introduction | Dissociation in the context of psychological disorders can be expressed as disturbances in memory, consciousness, and/or identity as well as disruptions in bodily sensations and feeling (i.e., feeling numb). The prevalence of dissociative symptoms is not well understood, but studies point to a range of 19-73 among sexually abused or maltreated children. Child psychiatry has often misdiagnosed or been unaware of dissociative symptoms among children, resulting in disastrous implications for treatment. This unawareness or ignorance of dissociation can be attributed in part to Freudian psychoanalytic theory, which was repurposed to consider childhood trauma described by patients as imagined or desired, denying the alarming frequency of childhood interpersonal trauma.Interest in the importance of trauma was prompted in the 1970s after studies about the sufferings of veterans of World War II and the Vietnam War and concentration camp survivors came out. Also, active women’s movements that published works pointing to the occurrence of childhood sexual abuse helped push back psychoanalytic ideas of trauma being fantasies. Push back against dissociation, especially in debates surrounding multiple personality disorder (now known as dissociative identity disorder), involved memories of trauma being characterized as fake or imagined, perpetuated and reinforced by clinicians. New, more reliable and valid diagnostic instruments and neurobiological technologies have helped reinforce dissociative symptoms as resulting from severe trauma. 
 
Methods | Using a literature search on PubMed and PsychInfo, 309 relevant papers were rigorously studied.Concepts and terminology in the literature searchFrom a dimensional perspective, dissociation can manifest on the spectrum from the normative end of everyday daydreaming to the pathological end of depersonalization. Dissociation is a reaction to trauma, which is inherently overwhelming for both the mind and body. Thus, its defence functions to automatize behavior, compartmentalize painful memories or emotions, and/or alienate (or distance) oneself from the self (of the trauma). Dissociation protects the individual from trauma and can manifest as massive denial, identification with an (or the) aggressor, and numbing among. Dissociation can be delineated from repression in that repression involves enough processing of the repressed material (including its associated taboos), whereas completely averts any consideration of the trauma. From a categorical perspective, dissociation can only manifest as psychological symptoms (i.e., amnesia, derealization). Physical or somatoform symptoms (i.e., sensory loss) of dissociation are categorized under “conversion disorders”.Memory can broadly be categorized as implicit (non-declarative, procedural) or explicit (declarative, semantic) memory. Implicit memory involves the amygdala, basal ganglia, motor cortex, and sensory cortex. It can be seen as memory without conscious access (i.e., riding a bicycle, acquired habits). Explicit memory involves the hippocampus, parts of the medial temporal lobe, and the prefrontal cortex. It can be divided into episodic and semantic. Episodic (or autobiographical) memory refers to episodes in an individual’s life that s/he can recall and describe with a sense of self and time. It is mediated by the orbito-frontal cortex and related parts of the prefrontal cortex. Semantic memory refers to facts and other information one can recall. Implicit memory, in relation to trauma, is highly resistant to decay, and explicit memory is affected by traumatic events that result in disjointed recall. Van der Kolk proposes that the central nervous system fails to synthesize sensations related to the traumatic event into an integrated explicit memory, resulting in trauma-related sensations continuing to intrude after the traumatic event has passed.The criteria for dissociative (conversion) disorders used in this study involves severe impairment in memory, sense of self, immediate sensations, and control of bodily movements. 
 
Results | Of the 932 articles from PubMed and 87 from PsychInfo, 237 described correlates of trauma and 72 the neurobiological correlates of dissociative disorders.Traumatic correlatesMost research linking dissociation with traumatic events, address the strong association between early, chronic abuse, especially sexual abuse, and substantial dissociative symptoms. Some researchers argue that there is not enough evidence to suggest causality between early traumatic events and dissociative symptoms. Findings imply that there is likely a combination of genetic, neurological (i.e., post-concussion syndrome), and psychological vulnerability (i.e., tendency to self-blame) that lead to dissociation in the context of experiencing trauma. The most important predisposing factor to dissociative symptoms is early childhood traumatization.Neurobiological correlatesThe human brain is equipped with a stress-response system. This system involves the activation of the hypothalamic-pituitary-adrenal (HPA) axis, which broadly results in the fight-flight-freeze response from the release of epinephrine, norepinephrine, and cortisol. Brain endorphins are also released, affecting the way the stressful event is perceived. This may explain the physical and emotional sensations that accompany response to stress. High levels of cortisol are toxic for the brain, especially early in life. Impairments in memory and synaptic connections (i.e., early neuronal degeneration) are implicated here. Secure attachment with a primary caregiver (i.e., support and comfort from a parent) acts to cushion the neurotoxic effects of cortisol in infants and children. 
 
Effects of trauma on the developing brain | Severe neglect, seeing violence between parents, emotional and physical abuse during childhood are powerful sources of prolonged stress-response that can result in subsequent permanent neurochemical abnormalities as well as functional and structural abnormalities.Neurochemical abnormalitiesSevere childhood trauma can result in a permanently altered HPA-axis response in which the hypothalamus down-regulates the stress response, resulting in lowered cortisol levels in response to stress. New threats or dangerous situations no longer evoke a normal response.Traumatized children can have an overactive sympathetic nervous system from continued stress responses. This is indicated by high secretion of dopamine and norepinephrine in combination with decreased platelet adrenergic receptors and increased resting heart rate. Hyperarousal and hypersensitivity to stress and reminders of trauma result.	Children can dissociate and essentially “shut down” in response to a traumatic experience in which there is no escape. The vagus nerve gets activated by circulating norepinephrine, resulting in slowed heart rate and falling blood pressure. Brain endorphins from the dopamine system in the prefrontal cortex may be released as well.Functional abnormalitiesEEG studies involving recall of traumatic events reveal the left and right hemispheres function independently:There is striking hemispheric lateralization (brain functions specific to one side). Traumatic memories may be stored in the right hemisphere and expressed as nonverbal emotional experiences. There is increased activity in areas of emotional arousal. Dissociative patients may re-experience traumatic memories as physical and visual rather than verbal (Broca’s area is turned off). The limbic system is dysfunctional in traumatized children, with decreased activity in the left prefrontal cortex. This helps explain why traumatized children may function emotionally (increased right hemisphere activity) rather than in a problem-solving manner (decreased left hemisphere activity).Structural abnormalitiesElevated cortisol secretion may be implicated in reported reductions of brain size among traumatized children:There is reduced total cerebellar volume and corpus callosum size that are correlated with the duration and age of trauma. There are mixed results about trauma resulting in reduced hippocampal volume, so further research is needed. Reduced corpus callosum size is implicated in reported depersonalization and derealization as children are not able to function in a problem-solving manner.Dysfunctions in the developing limbic and neocortical systemsDissociation from trauma may be the result of over-stimulation of the limbic and neocortical systems, which are the last parts of the brain to mature and thus are especially vulnerable to the effects of trauma.Overstimulation of the amygdala can result in hyperarousal and poor behavioral control of anxiety, aggression, impulsivity, and sexual behavior. The neurotoxicity of cortisol (producing cell death) in the context of the hippocampus may lead to amnesia and dissociative symptoms. A reduced hippocampus can also result in misinterpretation of stimuli and hypersensitivity to threats. It may also contribute to the fragmentation of experience into an incoherent isolation of sensory information (i.e., sounds, bodily sensations). Altering the maturation of the prefrontal cortex can result in an inability to gain full adult capacities (i.e., in the dimensions of planning, judgement, and impulse control). 
 
Conclusions | There is a high proportion of dissociative symptoms among patients of child and adolescent psychiatry. Many of them have been misdiagnosed with ADHD and bipolar affective disorder, among others, leading to mistreatment and long-term suffering. Recent innovations in brain-imaging technologies have allowed for a bridging between developmental psychology and neurobiology. The central nervous system, HPA-axis, and many other brian regions are implicated in dissociation and the relationship it has with childhood trauma. Cortisol neurotoxicity offers only one explanation for some of this relationship. The study of neurobiological correlates with dissociation is still preliminary, and as most research relies on adults, more research among child populations is necessary for a better understanding of dissociation. It is worth noting that trauma is necessary for a diagnosis of a dissociative disorder, but not all traumas result in dissociation. Protective factors in children and other vulnerabilities (i.e., genetic) for dissociation in the context of trauma should be researched. 
Five Things to Know About Physician SuicideSuicide is the only cause of death to be higher in physicians than in non physicians. Male physicians are 40 more likely to commit suicide than non-physicians, and female physicians are 127 more likely to commit suicide than non-physicians.Firearms are the most common method to commit suicide. Physicians are more likely to use poisoning, which is likely due to their easier access to prescription medication.In a recent study, 11.1 of medical students had suicidal thoughts. 7.4 of students had thoughts within the past two weeks, and 24.2 of students had thoughts within the year.In a study done of 8000 physicians, it was found that suicidal thoughts increased if the physician had complaints against them. 2.5 of physicians without patient complaints had suicidal thoughts, but 9.3 in those with a recent complaint, and 13.4 in those who had past complaints.Physicians who are contemplating suicide may have trouble getting care. They may fear a lack of confidentiality, they will lose their medical license or lose other hospital privileges. This adds to the burden of facing stigma and lack of time to seek care. 
 
 
Abstract | Prior studies on gender based physician income were not thorough. This study looks at factors like total hours worked, percent of time spent with the patient, procedures, the specialty of the physician, age, years of working, race, ethnicity, and geographic location. 439 physicians from 6 states and 30 practices are included in the study. The unadjusted results of this study found that male physicians made about $95,000 more a year, worked more total hours, and spent more time doing procedures than females. After adjusting to scale, this study found that males made $27,000 more than females per year. Though the habits of male physicians can explain why they make more money on average, this does not explain why the adjusted income is still $27,000 higher for males. 
 
Introduction | Even though about half of physicians are female, there is still a difference in pay between men and women. Multiple studies have been conducted on this issue, but none have fully explained why men make more than women. The difference in pay between genders is also an issue in individuals who are masters of business administration graduates, layers, and pharmacists. In business and law, men seem to make more because they work more hours and more continuously throughout their career, so they strengthen ties with clients and in turn continue to make more money. For pharmacists, the difference in pay can be entirely attributed to a difference in hours worked as most pharmacists work hourly. This study aims to account for a variety of factors that will explain if the physician wage gap is more similar to those in business and law, or purely hourly like pharmacists. 
 
Methods | 439 physicians from 30 different specialties responded to the survey sent by this study, throughout Colorado, Massachusetts, North Carolina, Texas, Washington, and Wisconsin. The survey included a self reported income, gender, specialty, hours worked per week, weeks worked per year, composition of work hours, percent of patient care time spent providing procedures, compensation type, age, years in practice, race, and ethnicity. This study is a secondary analysis of the same survey. The original intent of the survey was to measure physician satisfaction.Seven Models were generated to see how different factors compared to income. Model 1 was gender alone. Model 2 adjusted for state and practice. Model 3 adjusted for hours worked per year. Model 4 adjusted for specialty. Model 5 adjusted for work hour compensation. Model 6 adjusted for percent of time performing procedures and compensation type. Model 7 adjusted for age, years in practice, race, and ethnicity. The researchers accounted for the non-response rate for the survey, and excluded data outside of the 95th percentile for hours worked and salary. 
 
Results | Men reported working about 400 more hours a year than females, and working 360 more patient care hours than females. Males also provided more procedures with and without anesthesia than females. Males were less likely than females to be primary care physicians, which is a specialty that tends to make less money. A majority of male respondents were white, about 40, and had been practicing for over 10 years.In each of the models described the the methods section, more factors were looked at to determine an adjusted wage difference. Unadjusted, the difference was about $91,000 for males and females. But in Model 7, which accounted for the most of the large factors, the difference was $27,000. This means that the models were able to account for 70 of the wage difference, but 30 was still unaccounted for. 
 
Discussion | The 30 of unaccounted for income difference between men and women may have an explanation outside of the parameters of this study. For example, this study did not account for which procedures were being performed and whether they were more profitable or not. Other studies have partially explained the physician wage gap, but used less factors and accounted for less than 70 of the wage gap like this study did.In all of the studies that have been done and have accounted for different factors, there still remains an amount of the wage gap that has not been attributed to anything. A long term study over a physician’s career or their salaries may be helpful in attributing the wage gap. Though there are limits to this study, more research should be conducted based on these findings to help understand the physician gender based wage gap. 
 
 
Abstract | Both disease causing and healthy angiogenesis are regulated by nucleotides and Vascular Endothelial Growth Factor (VEGF). The activated P2Y nucleotide receptors (P2YR) can interact with VEGF Receptor 2 (VEGFR2). This tells us that the P2YR may mediate VEGFR, called P2YR-VEGFR2 signaling. Inhibiting P2YR can increase angiogenesis in endothelial cells. But treating the cells with a VEGFR2 inhibitor lowered the levels of angiogenesis back to the baseline before P2YR was inhibited. The findings of this study lead researchers to believe that the P2RY-VEGFR2 signaling is important for both disease causing and healthy angiogenesis. 
 
Introduction | Nucleoside diphosphate kinase (NDPK) may have a role in cancer and tumor angiogenesis. The researchers of this lab recently published another study showing that angiogenesis could be regulated by a cancer that secreted NDPK. Activated P2YR have been shown to interact with VEGFR2. This shows that there is a direct link to nucleotide regulation outside of the cell, to the regulation of tumor angiogenesis. P2YR-VEGFR2 signaling may be important for outlining nucleotides in angiogenesis signaling, like ATP.The researchers hypothesize that P2YR activation uses VEGFR2 to increase angiogenesis, and cancer uses NDPK to exploit this pathway and obtain a blood supply.An antibody that binds to VEGF and stops its function is approved for the treatment of many types of cancer. This is due to the role of VEGF in angiogenesis. VEGFR2 regulates and increases the angiogenic effects of VEGF. Also, VEGFR2 and P2YR are known to be located on the surface of endothelial cells, meaning they are in close proximity and are likely to be involved in the same angiogenesis signaling pathway. This study provides evidence that P2YR interacts with VEGFR2 to increase endothelial capillary like tube formation, or tubulogenesis, in the lab setting. 
 
Materials and Methods | This study used a tissue culture of human cardiac endothelial cells. Tubulogenesis and angiogenesis were determined by the number of branch points, length, and cell surface area of the sample. 
 
Results and Discussion | The cells treated with the P2YR1 and P2YR1/2 inhibitors showed 1.9 and 1.5 times higher angiogenesis than the control samples. The addition of the VEGFR2 kinase inhibitor to the samples returned the angiogenesis levels back to control levels. The positive control sample had 2.4 times higher angiogenesis than the negative control.These results, combined with the results of the previous studies done by this research team, directly linking VEGFR2 signaling to cancer secreted NDPK and angiogenesis. The P2YR tubulogenesis was consistent with previous findings. These results suggest that VEGFR2 cell signaling plays a role in P2YR regulated angiogenesis.This study allows the research team to expand their previous study. Their hypothesis says that cancer cells exploit the P2YR-VEGFR2 signaling pathway by secreting NDPK and increasing angiogenesis. The P2YR-VEGFR2 signaling pathway may also help us understand angiogenesis and vessel formation in both tumors and healthy vasculature. 
 
 
Abstract | Racial and ethnic disparities in access to health care could be a result of discrimination. In this study, the researchers wanted to identify differences in the rates at which patients, based on their race, are offered primary care appointments and how long they wait for those primary care appointments. They also wanted to understand the mechanisms by which how discrimination occurs. The researchers performed a cross-sectional study using 7 simulated black, Hispanic, and white callers. The callers requested appointments from 804 randomized primary care offices in 2 urban centers of Texas. The simulated calls were done by research assistants, who randomly assigned offices to schedule an appointment supplying the same basic information. Race and ethnicity were signaled through callers’ names and voices. The main outcomes and measures were appointment offer rates, days to appointment, and questions asked during the call. Of the 7 callers, 2 identified non-Hispanic black, 3 identified as non-Hispanic white, and 2 identified as Hispanic. Of 804 simulated calls, 299 were from white callers, 215 were from black callers, and 290 were from Hispanic callers. Overall, 582 callers were offered appointments. In unadjusted analyses, black and Hispanic callers were more likely to be offered an appointment than white callers. However, after adjusting for whether insurance status was revealed, the significance of the unadjusted analysis was lost. In adjusted analyses, black callers and Hispanic callers were 44 and 25.3 more likely, respectively, to be asked about insurance status than white callers. Black and Hispanic callers received appointments further in the future than white callers. In conclusion, black and Hispanic callers were more likely to be given an appointment, but were asked more frequently about insurance status. In addition, they experienced longer wait times than white patients, indicating a barrier to timely access to primary care. 
 
Aims | The researchers wanted to understand differences in the rates at which racial/ethnic minority groups were offered primary care appointments, as well as the number of days they wait for primary care appointments. 
 
Introduction | People of color experience worse health outcomes than white people in the U.S. While there is much evidence for biological and environmental determinants of these health disparities, little is known about how the healthcare system plays a role. These disparities may result because of discrimination in access to timely services. Black and Hispanic patients wait longer than white patients to be seen by a physician and in the emergency department. These delays may contribute to poorer physical and mental health.Most primary care appointments are scheduled over the phone, and phone staffers have control over appointment times they offer. Names and voices can signal race, ethnicity, and gender. Appointments scheduled over the phone likely include racial, ethnic, and gendered signals. It is possible that biases in scheduling staff result from minority groups being turned away or given later appointments. Scheduling staff may have direct hostility toward minority patients, or draw on stereotypes to make assumptions about minority patients’ insurance status.Previous studies link racial and ethnic disparities in health to 1 of 3 determinants: self-reported discrimination, explicit bias, or implicit bias toward black and Hispanic patients by health service professionals. Explicit bias can be controlled, while implicit bias is automatic and outside of an individual’s control. Overall, research suggests that black patients report bias from healthcare professionals more frequently, healthcare professionals are more biased toward black and Hispanic patients, and that implicit bias is more common than explicit bias in healthcare professionals. While informative, these studies measure attitudes rather than behaviors. Field experiments are necessary to understand behavior, but these studies are rare in healthcare settings. A few small-scale field experiments have suggested that healthcare professionals show favoritism based on class, insurance status, race, and gender. The mechanism by which these biases occur is unclear.In this study, the researchers investigated whether the rates at which black and Hispanic patients were offered appointments, as well as the number of days they had to wait for appointments, were different from those of white patients. They also categorized the kinds of questions that schedulers asked and analyzed differences by race and ethnicity to try and understand the mechanisms by which discrimination may occur 
 
Methods | Sample SelectionThe researchers used the Texas Medical Board database of active licensed physicians to select offices to call. They selected physicians within the study’s geographic area and retained primary care physicians which included family medicine, family practice, general practice, general preventive medicine, gynecology, internal medicine, obstetrics and gynecology, sleep medicine, endocrinology, and preventive medicine. This provided the researchers with 1888 offices to choose from, and they selected a subset using simple random sampling.Data Collectors7 female callers were recruited. Each invented a fake name that signaled their gender, racial, and ethnic identity. All grew up in the U.S. with their biological relatives and lived in communities whose racial/ethnic identities matched their own.Script and ProceduresDuring each call, the caller introduced herself and asked to be scheduled for the next available appointment as a new patient. All callers used the same procedures and script to supply identical personal information. They chose to report health problems to increase plausibility that an uninsured patient would seek an appointment. The health problems were common to primary care practitioners but were not emergencies.Data CollectionCallers documented information for each primary care practice using a standardized data collection form. They recorded date and time, whether the call was answered, and the number of minutes they were on hold. They noted questions/comments by the scheduler, whether an appointment was scheduled, and the date/time of the appointment.Statistical AnalysisThe researchers assessed whether patients were treated differently during the call. They used a linear regression analysis that was controlled by variables for socioeconomic, healthcare market, and demographic characteristics as well as practice specialties and physician races.Because insurance status was the most common question, the researchers also evaluated the extent to which insurance was associated with appointment offers and days to appointment.All analysis was performed in Stata. 
 
Results | Differential Treatment Leading to an OfferOut of 1081 calls, 481 calls had complete data and were included in analysis. Black and Hispanic callers were engaged differently in their discussions with practice schedulers. 444 callers were asked about insurance status, with black and Hispanic callers more likely to be asked. Questions about insurance were the most common and where disparities were the highest. Black and Hispanic callers were 44 and 25.3 respectively more likely to be asked about insurance status.Differential Treatment in Offer and Days to OfferOverall, 582 callers were offered appointments. In unadjusted models, black and Hispanic callers were more likely to be offered appointments than white callers. The addition of controls did not change results for offer rates. Callers who were asked about insurance status were more likely to be offered an appointment, which suggests that more appointments were offered if insurance status was revealed.The mean time until offered appointments was 10.8 days. Black and Hispanic callers received later appointments compared with white callers. When restricting analysis to those who were asked about insurance, black callers were offered appointments 7.04 days later than white callers. 
 
Discussion | In this study, black and Hispanic callers seeking medical appointments were treated differently than white callers. Schedulers offered more appointments to black and Hispanic callers, such that there was no evidence of discrimination against minority patients in terms of accessing appointments. However, black and Hispanic patients waited longer on average for the appointment, suggesting that they face barriers to timely access to appointments. Black and Hispanic patients were also asked more about insurance status, and those asked were offered appointments at different rates. Schedulers may believe that race and ethnicity are associated with insurance status. Those who asked about insurance appeared to be inquiring in response to race and ethnicity signals, which would constitute discrimination.The finding that disclosing uninsured status was positively associated with an appointment offer was surprising. However, schedulers distinguished patient groups by Medicaid vs. non-Medicaid status rather than insured vs. uninsured status. Texas Medicaid disproportionately covers black and Hispanic individuals. Determining whether schedulers asked minority patients about insurance status because of a higher expectation of Medicaid was beyond the scope of this study.The study should be replicated using a nationally representative sample of primary care offices, and expand to include callers with a broader demographic range. Insurance status should also be randomized to understand its effects on being offered appointments. 
 
 
Abstract | Clinical outcomes associated with Zika virus (ZIKV), a mosquito-borne virus, in the Americas are well-documented, but other aspects such as risk factors are not well-understood. In this study, the researchers prospectively followed a cohort of 1453 urban residents in Salvador, Brazil. They used an assay that measured immunoglobulin G3 (IgG3), which function as antibodies, against ZIKV NS1 antigen. The researchers estimated that 73 of individuals in the cohort were infected with ZIKV during the 2015 outbreak. Attack rates of the virus were very different across very small areas. Preexisting antibodies against dengue virus, also a mosquito-borne virus, were associated with reduced risk of ZIKV infection and symptoms. The ZIKV immunity generated by the 2015 outbreak in this population may affect the risk for future transmission. 
 
Aims | The researchers wanted to understand how dengue and Zika viruses, which are related mosquito-borne viruses, interacted with one another in terms of immunity and susceptibility. 
 
Introduction | There is much uncertainty about the dynamics and circumstances of the Zika virus (ZIKV) outbreak in the Americas in 2015. The association of ZIKV with microcephaly (a condition where head circumference is smaller than normal, damaging the brain) makes it important to determine future dynamics of transmission.An unanswered question is how preexisting immunity to dengue virus (DENV), which is genetically and antigenically similar to ZIKV, in suppressing ZIKV transmission. Some previous studies have shown enhanced ZIKV infection in the presence of DENV antibodies, but other studies have been less clear. Immunity to DENV has been shown to protect against ZIKV infection, and thus could reduce ZIKV infection in a DENV-immune population. However, this relationship has not been evaluated in humans.It is difficult to characterize interactions between ZIKV and DENV due to asymptomatic infections and difficulties and diagnosis. Infections can only be understood by serological measures, which quantify and characterize antibodies in blood samples. Current serological tests are limited because of cross-reactivity between the two related viruses. These limitations have prevented full understanding of the American Zika epidemic and interactions between DENV and ZIKV. 
 
Results | High ZIKV attack rates in an urban populationThe researchers prospectively characterized ZIKV transmission in Pau da Lima, an urban slum community in Salvador, Brazil. Northeast Brazil has been endemic for DENV for over 30 years. It was also the epicenter of the 2016 Zika epidemic. The researchers quantified ZIKV infection rate using data from 1453 individuals. In 642 individuals for whom dengue immunity data was available, the researchers investigated the impact of DENV immunity on ZIKV susceptibility.The researchers identified ZIKV infection with an assay that measures immunoglobulin G3 (IgG3) response to ZIKV NS1 protein. They performed additional validation of the assay to ensure cross-reactivity did not affect the results.Samples collected before the 2015 ZIKV epidemic in Salvador were mostly negative for ZIKV immunity, suggesting little transmission before the epidemic. In contrast, 63 of samples collected in October 2015 were positive. Adjusting for limitations of the assay, this level of positivity corresponds to an attack rate of 73 in the population.Heterogeneity in attack rates at fine spatial scalesAlthough the attack rate was high, they were not the same across the population and differed across distances as small as 20 meters. Similar differences have been reported in DENV transmission. This variation could be due to differences in mosquito populations or in exposure of people living in different conditions.The researchers estimated that the basic reproductive number (R0) of ZIKV was 1.8, but ranged from 1.2 and 2.1 between areas of the study site. These results are within the range of previous estimates and calculations for both ZIKV and DENV.Influence of dengue immunity on ZIKV infectionThe researchers investigated potential associations between having DENV antibodies (total IgG) and susceptibility to ZIKV infection. 642 samples collected before the ZIKV epidemic were tested for antibodies against DENV. 553 samples were positive. Among individuals who had immunity to DENV, each time the amount of antibodies present against DENV was doubled, reduction in the risk of ZIKV infection rose by 9. To investigate this effect, the researchers estimated the risk of ZIKV infection among individuals with different levels of pre-outbreak immunity to DENV. Individuals with mid- to high-levels of antibody experienced a 38 to 44 reduction in ZIKV susceptibility respectively. Individuals with low to no levels of DENV antibodies were more susceptible.The researchers also investigated the relationship between a specific subset of antibodies, IgG3, against DENV and the risk of ZIKV infection. The researchers found that increased levels of IgG3 actually increased susceptibility to ZIKV infection, in contrast to total IgG. This positive association may be caused by an immune profile caused by recent DENV infection that makes individuals more susceptible to ZIKV infection.To further investigate the association between DENV exposure and susceptibility to ZIKV infection, the researchers created a mathematical model including the variables DENV total IgG, DENV IgG3, and age. Analysis showed that DENV total IgG was negatively associated with ZIKV infection. It also showed a positive association between DENV IgG3 and ZIKV infection, consistent with results above. Age was not associated with risk of ZIKV infection.Finally, the researchers investigated associations between previous DENV immunity and Zika symptoms. Among 642 individuals, 29, 206, and 11 reported experiences with skin rash, fever, or both, respectively. Pre-outbreak DENV total IgG was associated with a 47 reduction in the odds of having fever, but no reduction for rash. DENV IgG3 did not decrease odds of fever or rash. 
 
Discussion | The researchers found that individuals in Salvador, the epicenter of the Zika epidemic in Brazil, was heavily affected with an attack rate of 73. The pattern of cases is consistent with the emergence of a highly transmissible and asymptomatic pathogen, followed by reduced transmission after populations gain immunity. Differential infection rates within Pau da Lima, Salvador shows that susceptible individuals who were not infected in the 2015 epidemic may remain. Although this population could sustain some future ZIKV transmission, the high rates of immunity will present a barrier to future ZIKV infections. 
 
 
﻿Abstract | In this literature review, the researchers wanted to understand the risk of mother-to-child transmission of HIV through breastfeeding if the mother received antiretroviral therapy (ART). The researchers reviewed experimental and observational studies. Exposure was maternal HIV antiretroviral therapy and different ways of infant feeding (breastfeeding, bottle-feeding, etc.). Outcomes were defined as overall and postnatal HIV transmission rates at 6, 9, 12, and 18 months. Literature from 2005-2015 was searched in multiple databases. Papers were analyzed by narrative synthesis, meaning the review relied on the use of words and text to organize data. The data was pooled using a statistical method called random effects meta analysis. HIV transmission after birth was assessed from four to six weeks of life. The quality of the study was assessed using a modified Newcastle-Ottawa Scale (NOS) and GRADE. 11 studies were identified for the study. Overall, pooled transmission rates at 6 months for breastfed infants whose mothers were undergoing ART was 3.54 and 4.23 at 12 months. Postnatal transmission rates were 1.08 at 6 months and 2.93 at 12 months. ART was provided for prevention of mother-to-child transmission (PMTCT) and was discontinued after 6 months in these studies. In conclusion, there is evidence that maternal ART significantly decreases the risk of postnatal HIV transmission. However, transmission risk increased after ART for PMTCT was discontinued after 6 months, which supports the WHO recommendations of life-long ART for all. 
 
Aims | The researchers wanted to review literature about mother-to-child transmission of HIV in breastfed infants whose mothers received antiretroviral therapy. They did this to support the process of updated the World Health Organization infant feeding guidelines in the context of HIV and ART. 
 
Introduction | There has been significant progress in decreasing the number of new HIV infections in children. This progress is consistent with increased coverage and quality of antiretroviral treatment (ART) programs that provide prevention of mother-to-child transmission. HIV transmission from mother to child can occur during pregnancy, delivery, and breastfeeding. However, breastfeeding has substantial benefit for infant health and survival, so minimizing the risk of transmission during breastfeeding is important. The World Health Organization (WHO) recommends that breastfeeding, HIV-positive mothers should breastfeed infants under the cover of maternal or infant ART.In most African countries and some parts of India, health policy continues to advise mothers with HIV to breastfeed under the cover of maternal or infant ART. However, these recommendations are supported by limited information on the risk of postnatal HIV transmission when the infant, mother, or both are on ART to prevent mother-to-child transmission (PMTCT). In addition, there was little information on whether mixed feeding (breastfeeding and formula), which had been associated with increased risk of postnatal transmission, remained a risk in the presence of ART.In recent years, evidence has shown that PMTCT was achieved postnatally through maternal ART or infant prophylaxis. The risk of transmission when infants receive mixed feeding is of significant interest to public health. In this study, the researchers address the question of HIV transmission at 6, 9, 12, and 18 months in infants born to women who were on ART from early-mid pregnancy until 6 months after birth, and whose infants breastfed in the first 6 months of life. 
 
Methods | This literature review considered experimental and observational studies. It included HIV-positive mothers receiving ART and their breastfed children regardless of if the infant was receiving antiretroviral prophylaxis. The variables of the review were HIV antiretroviral therapy and feeding method during breast-feeding (exclusively breastfeeding, mixed breastfeeding/replacement feeding, exclusively replacement feeding). Outcome measures were overall and postnatal HIV transmission rate at 6, 9, 12, and 18 months.The researchers searched multiple databases for articles publishes between 2005 and 2015. Studies were first selected for eligibility based on their abstracts. Then, the full texts were assessed. Data was extracted from these studies. Figure 1 shows a flowchart of the screening process for these studies.To obtain more information about infant feeding, the first authors of 7 studies were contacted and questioned. 3 responded. Questions related to the type and duration of recommended feeding practice, type of infant feeding support given to mothers, collection of data on child feeding practices, and how this data was addressed in the study.The studies included in the review were assessed using a modified Newcastle-Ottawa Scale (NOS), which the authors developed. The NOS assessed the quality of studies included based on the selection of study participants and outcome assessment.The results of the review were analyzed using STATA. The researchers used random effects meta-analysis because of methodological differences between studies, so they could ascertain true transmission rates. 
 
Results | 11 studies were selected for inclusion in the review. 4 were randomized clinical trials and 7 were observational studies. In all studies, mothers started ART before or during pregnancy and continued through 6 months after birth.HIV transmissionOf 11 studies, 8 reported transmission rate at 6 months. 2 studies did not provide a confidence interval around the estimated transmission rates, so the researchers calculated it themselves. 2 studies reported the number of infections at 6 months and the number of children at risk, so the researchers also calculated transmission rate for these studies. 2 more studies reported number of transmissions but not number of children at risk. 1 study reported transmission only at 9 months but noted that all transmissions occurred during breastfeeding.Overall transmission at age six months6 studies provided overall transmission rates at 6 months. In 2 studies, ART was provided since 15 weeks of pregnancy. Of these studies, one reported an overall transmission rate of 1.4, while another reported a transmission rate of 1.9. Another study did not describe time for beginning ART, and the reported transmission rate was 0.5.Subsequent studies started ART at later stages, from 30-34 weeks of pregnancy. Studies reported transmission rates of 7.9, 5.0, 5.0, and 3.4-7.4.The pooled estimate of overall transmission at 6 months was 3.54.Postnatal transmission between four and six weeks and six months6 studies provided estimates of postnatal transmission rates. 3 studies provided ART since the first physician visit after birth. One study reported a transmission rate of 0.2, while another reported a rate of 0.6 after 4 weeks of age. Another study reported a rate of 3.1, noting that one of the infants was mixed fed.In the other 3 studies, transmission rates were reported to be 2.7, 0.80, and 0.3-2.4. The pooled transmission rate in these studies was 1.08.Rate of transmission assessed after 6 months of ageOf 7 studies providing information on transmission rates at 12 months, 5 reported overall HIV transmission rates and 2 reported postnatal transmission rates. Pooled estimates showed a 4.2 transmission rate at 12 months, and a postnatal transmission rate of 2.93.One study reported overall and postnatal transmission at 9 months of age, at 1.8 and 0.5 respectively. Another estimated overall and postnatal transmission at 5.3 and 1.2 respectively.Four studies reported a rate of transmission at 18 months, but could not be pooled due to large differences between them. Only one study reported an estimated overall rate of transmission, at 4.1. Two other studies provided overall transmission at 18 months, at 6.0 and 6.7. In both studies, mothers started ART at 34 weeks pregnant and stopped at 6 months after birth. 
 
Discussion | This review is the first synthesis of HIV transmission risk in infants with HIV-positive mothers, including mothers receiving lifelong ART. The review provides evidence that postnatal HIV transmission risk is low in the presence of maternal ART. The researchers found a pooled estimated overall transmission rate of 3.5 and postnatal transmission rate of 1.1 in women who were on ART from early-mid pregnancy and who were recommended to breastfeed their children for 6 months. The pooled estimate for postnatal transmission at 12 months of age was 3.0. Only one study provided an estimation of transmission rate at 18 months at 4.1.The results of this review show decreased rates of transmission from the pre-ART era, which ranged from 15 at six weeks and 32 at six months. This decrease highlights the efficacy of ART and the importance of early initiation and adherence to ART in pregnancy.Exclusively breastfeeding for the first 6 months of life is recommended for its positive effect on reducing infant and child mortality and long-term health outcomes. Before WHO guidelines recommending ART to reduce postnatal transmission, refraining from mixed-feeding in the first 6 months was considered important due to the risk of postnatal transmission. The rate of transmission associated with mixed feeding could not be estimated.In the included studies, women were recommended to exclusively breastfeed for 6 months according to WHO guidelines, but there was no specific support for mothers to exclusively breastfeed. Because of this, findings from this review reflect real-world situations. However, two reports included in the review suggest that support may increase adherence to breastfeeding.The WHO also recommends introducing complementary foods in addition to breastfeeding after six months. However, it also recommends that HIV-positive women are recommended to breastfeed for one year while receiving ART. Only two studies followed the latter recommendation. In other studies, there was continued transmission after six months due to continued breastfeeding without ART cover.This review highlighted clinical and methodological differences in time of ART initiation during pregnancy, recommended duration of breastfeeding, and the age at which infection in infants was assessed. The researchers also calculated transmission rates, which were not provided by all studies, which contributes to the low quality of evidence concerning risk associated with continued breastfeeding between 6 and 12 months. This review informs understanding of transmission in the postnatal period in women who receive ART. The findings of this review demonstrate a lower risk of postnatal transmission when women are on ART and breastfeeding. The quality of the evidence is low. New WHO guidelines on initiation of ART for all HIV-positive people upon diagnosis will expand ART coverage in breastfeeding women. 
 
 
Introduction | Viruses from wildlife hosts have caused emerging high-impact diseases such as severe acute respiratory syndrome (SARS), Ebola, and influenza which are major threats to public health. The emergence of these diseases occurred when an animal virus switched host into humans and was transmitted within human populations. The importance of this host switching is shown by recent, highly infectious strains of H5N1 influenza A, which spilled over from birds and caused hundreds of cases and some deaths. The emergence of influenza A should be a cause for alarm because of its potential to have efficient and pathogenic transmission between humans. Fortunately, host transfers usually only cause single infections or limited outbreaks.There are three stages in successful host switching: (1) initial single infection with no human-to-transmission, (2) spillovers that cause local epidemics (outbreaks), and (3) epidemic or endemic human-to-human transmission. There are many variables that determine the success of host switching including the type and intensity of contact between the animal and the human, barriers to infection in the host, viral factors that allow efficient infection, and how well the virus spreads in human populations. 
 
Sources of New Epidemic Viruses in Humans and Other Animals | The major sources of new human viral diseases come from animal viruses. It is likely we only know a small fraction of the viruses infecting animals. The risks of these viruses staying unrecognized are evident in the emergence of SARS coronavirus (CoV), hantaviruses, Ebola and Marburg viruses, Nipah virus, Hendra virus, and HIV, all of which resulted from host switches of established animal viruses.HIV/AIDS is an important, recent example of emerging viral disease from host switching. After switching from primates to humans 70 years ago, HIV has infected hundreds of millions of people. Even after better understanding of the virus and the development of effective antiretroviral therapies, millions of new infections still occur each year. Another recent example of host switching is the coronavirus causing SARS, which infected thousands of people in 2002 and 2003 and causing hundreds of deaths and economic disruption. Other viruses such as measles and smallpox may have emerged from host switching events in prehistoric times. These examples make it important that we understand how viruses enter and spread in new hosts. 
 
Environmental and Demographic Barriers to Host Switching | Exposures between animals and humans are an important step in host switching events, and some events may be prevented by limiting these exposures. For example, HIV has transferred to humans multiple times since 1920. A major barrier to establish host switching events in recent decades is likely the limited opportunity for primates to come into contact with humans followed by enough human-to-human contact to establish transmission. In other cases, host switching is prevented by the requirement for multiple, complex adaptive changes in the virus itself.Ecology and Contact with Alternative HostsContact between animals and humans is affected by geographical, ecological, and behavioral separation. Factors that affect the geographical distribution of animals (e.g, wildlife trade, introduction of domestic species) or that decrease behavioral separation (e.g, bush meat hunting) promote viral emergence. Changes in social and demographic factors (e.g population expansion, traveling), human behavior (IV drug use, sexual practices, farming practices) and the environment (deforestation, agricultural expansion) also affect viral emergence.Human population density is important in the establishment of transmission and epidemic potential of viruses. Human trade and travel patterns have been examined to characterize the spread of disease vectors such as mosquitos and of pathogens like SARS. In H5N1, they have been examined to predict spread of the disease through trade and bird migration. Patterns in human contact and density are important for disease emergence.Intermediate hosts between humans and animals may also play a critical role in disease emergence. For example, the emergence of Nipah virus in Malaysia was facilitated by pig farming. Fruit bats are the original source of Nipah virus. Planting of fruit orchards around pig farms attracted bats, allowing host switching of the virus from bats to pigs. This example shows how man made ecological changes can increase viral emergence. Similarly, SARS CoV originated in bats but infected humans through civet cats and other farmed animals. 
 
Host Barriers to Virus Transfer | To infect a host, a virus must be able to efficiently infect appropriate cells. This process is restricted at many levels, including receptor binding, entry or fusion, trafficking in the cell, and viral genome replication and expression. Multiple host barriers require multiple changes in the virus, making host switching more difficult. Other factors preventing host switching are antiviral responses and other responses that restrict infection.The Role of Host Genetic SeparationSpillover/epidemic infections have occurred between both closely and distantly related hosts. While evolutionary relatedness may be a factor in host switching, the rate and intensity of contact between animals and humans may be more critical. Host switches between closely related species may be limited by similar immune responses to the same pathogens, or by innate immune resistance.Host Tissue Specificity and External Barriers in Alternative HostsThe first level of protection against viruses occurs at the level of viral entry into the skin or mucosal surfaces, or in blood, lymphatic circulation, or tissues. Defenses include physical barriers to entry as well as host factors that bind to viruses and prevent infection.Receptor BindingReceptor binding by viruses is a critical role in host switching. For example, SARS-CoV derived from bats interact differently with angiotensin-converting enzyme 2 receptors of humans and carnivore hosts. Gaining the ability to bind to new receptors allows infection of new hosts, but can be a complex process requiring multiple changes in the virus.Intracellular Host Range RestrictionsPrevention of host switching can also occur after receptor binding in viral infection cycles. For example, there are several intracellular mechanisms that restrict cell infection by retroviruses, such as deaminases and TRIM5a protein which block infection into the next cell.Interferons, which are part of the immune response, protect cells against viruses and are often host-specific.Viral proteins involved in replication of viruses may show host-specific activities, and there is often a requirement for a particular combination of these proteins. Other viruses are restricted at the level of genome replication or gene expression. 
 
The Existing Host Range of a Virus as a Factor in Host Switching | Since the initial infection of humans is a key part of viral emergence, the existing range of hosts a virus can infect may influence its ability to establish infection in a new host. Viruses that infect many different hosts may increase likelihood of host switching since they can already exploit host mechanisms to infect and replicate. Viruses that infect only one or a few related hosts are more restricted by different receptors and replication mechanisms. However, both of these kinds of viruses have successfully switched hosts. 
 
Viral Evolutionary Mechanisms Leading to Emergence | Evolutionary changes are not always required for viruses to switch hosts. However, some cases of emergence require evolution of the virus for efficient infection and transmission in the new host. The evolution of viruses to adapt to new host is not well-understood. Genetic variation is important, as the greater the rate of variation the more a virus can better adapt to a new host. RNA viruses have error-prone replication mechanisms, short replication times, and large virus populations. In contrast, DNA viruses are less variable.Viral Fitness Trade-OffsMutations that benefit the virus in humans may reduce viral fitness in its original host. The nature of these fitness trade-offs and how they affect host switching is an important, but unresolved area of study. After host-switching, a combination of genetic drift and selection determine mutations that remain long-term. However, only a small proportion of viruses will exhibit increased fitness after host switching.Mode of Virus TransmissionAn important constraint of host switching is the mode of virus transmission. For example, insect vectors that feed on mammals can create cross-species viral exposures. However, levels of variation in viruses transmitted in this way are relatively constrained compared to other mechanisms. This is because viruses need to balance fitness in at least three hosts: the donor and recipient hosts, and the vector. Host switching of viruses that spread by droplet, sexual fluids, and fecal-oral routes have adaptational challenges due to host differences and variation in environmental exposure.Recombination and Reassortment in Viral Evolution Leading to Host SwitchingFor many viruses, genetic recombination allows the gaining of multiple genetic changes in a single step, producing advantageous genotypes. The potential for recombination differs between RNA and DNA viruses.Many recombinations or reassortments are likely to decrease fitness. However, they may be important for incremental adaptation after host switching has occurred.Are Viral Intermediates with Lower Fitness Involved in Host Switching?The process of host switching is rarely observed directly, but can be inferred by comparing the genomes of viral ancestors in donor hosts with viruses in recipient hosts. If several changes are required for host switching, intermediate viruses would likely be less fit in donor or recipient hosts than ancestors. Crossing this evolutionary “low-fitness valley” can be a key step for host switching, and may explain the rarity of host switching. After host switching, if the virus spreads with a reproductive number greater than 1, it could increase its fitness through mutations and become an epidemic.Early detection of viruses that do not spread efficiently could provide opportunity for epidemic control. For example, the early SARS CoV virus was inefficiently transmitted by most infected people, and early recognition of the outbreak and implementation of control measures allowed the epidemic to be stopped before the virus was fully established in human hosts. How viruses gain the ability to spread efficiently is poorly understood.During early stages of an outbreak, “superspreading” events may play a critical role in the establishment of a virus in humans after it has host switched. 
 
Posttransfer Adaptation | For many host-switching viruses, full adaptation to the new host can take months or years to complete. 
 
Summary and Implications for Prediction and Control | Much progress has been made in identifying factors that control or influence virus host switching. Studies point to common pathways of host switching and suggest preventive strategies. With better information about the origins of emerging viruses, it may be possible to identify and control emergent viruses in their original hosts. For arboviruses (viruses with a mosquito vector), vector control can limit host switching. Public health measures, such as health monitoring and quarantine, are also effective in limiting the spread of epidemics. Other strategies include reducing human-related change in infectious disease “hot spots,” as well as culling or vaccinating reservoir animals. Vaccination has been successful in raccoons/foxes in the U.S to control rabies, and wild dog rabies has been controlled in Kenya and Tanzania by vaccinating domestic dogs.New, rapidly spreading viruses can become impossible to control after a certain number of infections. Coordinated, strategic planning is critical for the confrontation of new viruses early after emergence. National and international planning is also critical.Strategies for control should include improved surveillance of regions of high likelihood of host switching events, improved detection of pathogens in reservoirs or early in outbreaks, research to clarify events that promote emergence, and modified forms of quarantine and other control measures. Human disease surveillance should be coupled with veterinary and wild-animal infection surveillance. Vaccine strategies could be used in some control programs, but presents difficulties due to the slow rate of vaccine development and approval. Antiviral drugs could also be used, but also present difficulties due to cost, logistic problems, and side effects.The emergence of new viral diseases by animal-to-human host switching will continue to be a major source of new infectious diseases. A better understanding of variables that contribute to such emergences are important for public health. 
 
 
Abstract | Before the pandemic started one out of every five college students experienced a diagnosable mental disorder worldwide. As the pandemic creates novel issues for college students it is important to explore methods to help alleviate this future and current mental strain. This article gives suggestions on how educational institutions and professionals can address this rise in mental health challenges. 
 
The impact of COVID-19 on collegiate mental health | The sudden closure of campus has resulted in isolation, frustration, loneliness, and has resulted in college students not receiving their proper therapy. This functions to amplify their psychological issues which increases suicide and substance abuse risk. The sudden closure of school resulted in worse mental health due to the routine of college life being disrupted. Similarly many students research projects and internships have been cancelled or delayed potentially indefinitely. This prevents their further academic achievements, delays graduation, and reduces competitiveness in the future job market. The sudden closure has forced many students to return back home causing more tension. Especially as students must worry about transmission of the virus to their family and elderly family members. Finally, a majority of students have lost their jobs which results in financial anxiety. This COVID-19 pandemic greatly influences students' mental health and thus calls for concern from educational institutions to support them during this trying time. 
 
Course of action | Though online classes are not perfect, they do allow students to maintain a semblance of their past academic routine. Some universities have also evacuated students from residence halls, while preventing them from retrieving their belongings due to infection risks. Some institutions report considering refunding room and board for residence halls which might help to reduce students financial anxiety. 
 
Recommendations | The transition to telecommunication is advised however faculty should consider offering virtual office hours. This will allow them to process the implications of the pandemic on their academic careers. Research advisors and internship managers should take an active role in reaching out to the affected students and working to figure out alternative options to maximize their potential experience in the program. Finally, universities need to work on novel methods to support students in their capstones and research projects so that students can achieve their graduation requirements.University counseling should set up telemental health counseling as it has been found to be effective in treating anxiety and depressive symptoms. They should also encourage students to reach out to support groups appropriate to the individual student and develop public health messaging to students and encourage them to take action for the safety of their own mental health. 
 
Conclusion | It is vital that universities give students the option and encourage them to take their mental health into their own hands. To provide them resources, coping strategies, and psychological resilience. Universities are in a fantastic position to help college students stay well in both mind and body during this pandemic and their action is required.  
 
 
Introduction | On July 7, 2016, Philando Castile was shot and killed by a police officer. The unnecessary force of this incident can be seen in the past two weeks since this publication with the death of Terence Crutcher and Keith Scott. The disproportionate use of lethal force against communities of color is not a new phenomenon. However, the production of video evidence has allowed the traumatizing experience of black Americans to be more readily seen. The cause of this force is rooted in the structural racism present in America. This structural racism is a result of practices and behaviors that has been perpetuated by institutions, culture, history, and ideology to continue inequality felt by communities of color. This is what cuts the lives of too many black Americans short.	The word racism was only found in 14 NEJM articles within the last 11 years. Most physicians are not explicitly racist and are committed to treating all patients equally, but they operate in an inherently racist system. The evidence that documents unequal health outcomes based upon race is rapidly evolving. In order to help beat the structural racism found in medicine clinicians and researchers need to take an active role in defining the root cause.	Structural racism is related to, but separate from interpersonal racism and increases deaths in colored communities. This is all too prevalent and is a threat to the physical, emotional, and social well-being of every individual that gives power “privilege” based on race. The researchers of this study offer 5 suggestions for other clinicians and researchers to help dismantle the structural racism inherent in the medical systems. 
 
Learn, understand and accept America’s racist roots | Structural racism was born from the teachings and rules of white supremacy which was invented to justify mass oppression for economic and political exploitation. This was seen through the centuries of slavery based upon race and the constitution literally said that a black life was equal to ⅗ a white life. This has led to scientific research and clinical practice to be based upon race and has led to structural racism inherent in the US healthcare system. This has led to worse health outcomes for the lives of black Americans and can be seen as an extension of the historic belief that white lives are worth more than a black life. Health care professionals should collectively and individually understand the historical roots of health inequity in order to help dismantle it now. 
 
Understand how racism has shaped the disparities narrative | Researchers and clinicians have long upheld a narrative that there are innate biological differences between the races. Recent studies of medical studies show that 50 fo white medical students still believe in certain false beliefs: black blood coagulates quickly, black skin is thicker. These implicit biases are false beliefs and we all hold them. It is vital that we observe them and understand how they contribute to health inequalities. 
 
Define and name racism | Race is defined as the “social classification of people based on phenotype” and racism is defined as “a system of structuring opportunity and assigning value based on phenotype (race) that: unfairly disadvantages some individuals and communities; undermines realization of the full potential of the whole society through the waste of human resources”. It is vital that identifying the discussion of race is separated from the racism present in our work and writing. As researchers our interactions will permit us greater depth in understanding this if we make an effort to combat it. 
 
Recognize racism, not just race | When we indicate our race in various forms for clinicians is this information acquired to indicate race or for racism? Race is often used when referencing that Black Americans have on average worse outcomes with diabetes. In order to combat this clinical research must change its focus from race to racism. 
 
Center at the margins | To provide equal medical care it is vital to shift the focus from the majority to the minority. As historical views shaped by centuries of explicitly and implicit bias bolster the experience of white Americans. Refocusing at the margins will require clinicians and researchers to redefine what is considered “normal”. Health care professionals will need to understand how they arrive at certain conclusions so as to understand any potential racial biases. This will provide better health equity to the disenfranchised and will reveal new clinical information. Health care professionals have an obligation and most importantly the power to help change this system and in doing these 5 suggestions will help to give a voice to those who are voiceless. 
 
 
Abstract | This study aims to see changes in protein expression in NIH 3T3 cells treated with virgin coconut oil (VCO) and hydrolysed virgin coconut oil (HVCO). The cells were treated with either nothing, VCO, or HVCO. Then each of those conditions were analysed to look for changes of expression in MMP-9, PDGF-BB, or TGF-beta1. Both VCO and HVCO increased the expression of all three proteins tested, with HVCO increasing the values by a higher factor. This data tells us that coconut oil is active in the wound healing process, and HVCO is more active than VCO. 
 
Introduction | The four stages of the complex wound healing process are: 1 hemostasis, when the initial clotting begins. 2 inflammation, where cytokines are secreted from fibroblasts and growth factors active the immune response. 3 and 4 proliferation and remodeling, which includes diverse processes like proliferation, differentiation, and formation of the nex extracellular matrix. Matrix metalloproteinases (MMPs) can function in wound healing, growth, migration, invasion, and angiogenesis. Matrix metalloproteinase 9 (MMP-9) is the specific MMP focused in in this study. Transforming growth factor-beta 1 (TGF-beta1) and platelet-derived growth factor-BB (PDGF-BB) are both growth factors that are function in proliferation and migration.Coconut oil is a saturated oil, made up of several medium sized fatty acid chains. Virgin coconut oil (VCO) can be isolated from a coconut at low temperatures without any refining, bleaching, or deodorizing. VCO contains lauric acid, which has antimicrobial properties. Hydrolysis of VCO (HVCO) creates free fatty acids and other molecules that have a stronger antimicrobial effect. VCO and HVCO have been studied in their effect on burn would healing, but this study aims to see if VCO or HVCO alters the expression of MMP-9, PDGF-BB, and TGF-beta1 in NIH 3T3 cells in the lab setting. 
 
Materials and Methods | The research team hydrolysed the VCO. The NIH 3T3 cells were cultured using standard techniques. The cells were treated with either VCO or HVCO and immunohistochemistry was used to determine the concentrations of MMP-9, PDGF-BB, and TGF-beta1. 
 
Results | The protein levels of MMP-9, PDGF-BB, and TGF-beta1 in VCO and HVCO conditions were compared to an untreated control sample. Percentage of MMP-9 expression was increased from 2.89 to 28.16 in VCO and 55.40 HVCO. Percentage of PDGF-BB expression was increased form 28.11 to 48.53 in VCO and 61.65 HVCO. Percentage of TGF-beta1 expression was increased from 4.19 to 18.41 in VCO and 36.35 in HVCO. 
 
Discussion | The findings of this study confirm that VCO and HVCO increase the expression of MMP-9, PDGF-BB, and TGF-beta1, which increases proliferation, migration, angiogenesis, and wound healing. VCO and HVCO can be active in the process of wound healing. Previous studies have found HVOC and VOC to be more effective than bioplacenton in wound healing, and should be further studied as would treatment due to its antimicrobial function and its upregulation of MMP-9, PDGF-BB, and TGF-beta1. 
 
 
Abstract | 	This study analyzes two methods for treating a ruptured calcaneal tendon (Achilles tendon). Various procedures, some more invasive than others, are currently used by doctors in treating acute and chronic ruptures of this tendon, but there is no consensus on which technique is ideal. This paper focuses on comparing traditional open tendon reconstruction with semitendinous (part of hamstring) grafting and less invasive tendon reinforcement.  
 
Introduction	 | 	The calcaneal, or Achilles, tendon is the strongest in the human body but is very prone to injury, especially in athletes. Injury can occur on a spectrum, from acute rupture with easy diagnosis to chronic degeneration with more difficult diagnosis. Options for tendon repair can be conservative or surgical, with varying recovery times and possibilities for injury recurrence. Surgical options include: primary repair, V-Y slip, bonding, fascia folding, etc. Other methods include transferring short fibular tendon or long flexor hallucis longus for chronic injuries. Such donor tendons cannot, however, be used if tendon loss is greater than 6cm. Without listing the overwhelming list of options, the main idea is that very common Achilles tendon problems can be addressed with many different approaches. Some of these approaches involve reinforcement that is less invasive, some involve using grafts from other parts of the body, and others involve more traditional reconstruction. Methods		A retrospective study was performed on 43 patients with calcaneal tendon rupture. Operations performed between 2008 and 2016 were analyzed (all done by the same surgeon).  Patients with diabetes mellitus were excluded and follow up time was two years on average. 16 of the 43 cases used a minimally invasive technique (short fibula tendon graft) while 27 used a conventional, open semitendinous (using part of hamstring) graft. “Age, sex, smoking, injury mechanism, affected side and bilateral cases, local skin complications, and neuromas” and other complications were all reviewed using the available records. Follow up information was analyzed, including American Orthopedic Foot and Ankle Society questionnaires about pain, ankle mobility, and other outcomes. The paper also shares a detailed explanation of “open surgical technique with semitendineous tendon reinforcement” and the following rehabilitation protocol. The procedure involves suture anchors using short fibular tendon and calcaneal tendon with nylon.   
 
Results | 	37 patients were male and 9 were female, with an average age of 45. 24 had injuries on the left side, while 19 had injuries on the right. 8 patients were smokers, with four undergoing the minimally invasive technique and four undergoing the open technique. 31 of the injuries were traumatic in nature, 12 being due to chronic degeneration. 15 injuries were related to playing soccer, 7 related to stepping on holes, and the others from miscellaneous sources. 12 males and 4 females (7 right and 9 left sided injuries) underwent the minimally invasive technique. 25 men and 2 women (12 right and 15 left sided injuries) underwent the open technique procedure. 	With an average follow up time of 2 years, the average score of the AOFAS questionnaire was 92. Complications were found in 6 of the open technique patients, with complaints in both the donor and recipient areas (necrosis, suture separation, pain, etc). One case of deep skin necrosis resulted in long term complications, ultimately leading to skin grafts. Complications were found in 3 of the minimally invasive technique patients (pinched nerve and hyper elongation due to a patient not following rehab instructions).  	 
 
Discussion | 	This paper clearly promotes tendinous reinforcement surgery, which is less invasive and strives to reduce morbidity. The data discussed promotes this tendon repair technique, even in patients with lesions exceeding 6cm (where semitendineous tendon should be used). The less invasive method (compared to open surgery) results in fewer skin complications and lower morbidity.  
 
 
Abstract | Olfactory dysfunction (issues with one’s sense of smell) is a symptom which has recently been associated with COVID-19. With this being said, there is little data on the duration of the condition or on patient recovery timelines. This paper used a series of online surveys to analyze the symptom’s relationship with COVID-19 and to gain recovery data. 
 
Introduction | 	Anosmia (loss of sense of smell) has been added to the extensive list of symptoms associated with COVID-19, alongside respiratory issues. One study showed that only 5.1 of coronavirus patients in Wuhan experienced anosmia, but over 85 of coronavirus patients in Europe experienced changes in their smelling (hyposmia or anosmia). This second statistic is inconsistent with smelling problems tied to other viruses. This discrepancy led the Brazilian Academy of Rhinology and the Brazilian Association of Otorhinolaryngology and the Cervical-Facial Surgery to conduct the following investigation. 
 
Methods | 	The organizations listed above put together an online survey which was sent out to physicians treating COVID-19 patients experiencing problems related to smell. The survey collected epidemiological information (related to the occurrence and spread) of patient anosmia and hyposmia along with associated symptoms, comorbidities, treatments used, recovery, and COVID-19 test results. The study ran between March 25 and April 30, 2020 and utilized various social media platforms. Prevalence statistics were communicated as a percent, while factors such as symptom duration and patient age were shared using medians. Further statistical methods, such as the Mann-Whitney U test, were also used. 
 
Results | A total of 253 patients from all over Brazil were part of this study (geographic distributions are provided in the paper). 149 were women and 104 were men, with an average age of 36. 212 of the patients reported sudden anosmia and 196 reported accompanying “nonspecific inflammatory symptoms” such as cough, fever, headache, myalgia, fatigue, etc. 111 patients reported nasal symptoms such as obstruction, sneezing, nasal burning, etc. Only 36 of patients reported comorbidities, the most common being mucus membrane swelling or inflammation, asthma, and systemic arterial hypertension.  	Treatment included (in order of prevalence) nasal saline irrigation, analgesics (pain relievers), topical intranasal corticosteroids, antibiotics, oral corticosteroid, hydroxychloroquine, oseltamivir, and olfactory training.Recovery information was gathered from medical records of 227 of the study participants. 121 individuals reported full recovery, 76 partial recovery, and 30 no recovery. The average time required for a full recovery was 12.5 days. Follow up time had a median of 21 days. 183 of the participants were tested for COVID-19, with 145 coming back as positive and 28 negative. Patients who weren’t tested were younger, didn’t experience as many nonspecific inflammatory symptoms, and had shorter follow up times.Further analysis was performed to compare patients who tested positive for coronavirus and those who tested negative. No epidemiological differences were noted between the two groups. Nonspecific inflammatory symptoms (listed above) appeared in COVID positive patients more frequently. Other symptoms did not show any statistical connection to one group in particular. Patients with confirmed COVID-19 tended to have a lower full recovery rate and a longer duration of olfactory dysfunction. Positive patients with hyposmia (reduced sense of smell) were more likely to fully recover compared to those with anosmia (full loss of smell). The treatments listed showed no connection to likelihood of recovery.	 
 
Discussion | 	A major finding of this study is that COVID-19 is associated with prolonged olfactory dysfunction and with reduced rates of recovery from it. Only half of COVID positive patients fully recovered, compared to over 70 of COVID negative patients. COVID positive individuals who experienced recovery took an average of 5 days longer to achieve it.	Females have experienced olfaction loss in numbers greater than men during the COVID-19 pandemic. They make up 75 of reported cases (⅔ with confirmation of coronavirus). This statistic is very interesting, as studies show that olfactory dysfunction is generally more prevalent in men. This discrepancy may be due to male inability to recognize their reduced sense of smell, or women paying more attention to their health. Another interesting finding is that anosmia is more prevalent than hyposmia in COVID-19 patients (opposite of findings for the general population).	Sudden loss of sense of smell is generally not common, with only 16 of patients showing no other symptoms. Only 5.5 of the COVID-19 patients had “isolated sudden olfactory dysfunction.” With this being said, sudden anosmia may be connected to milder cases of COVID-19. It is important to note that changes in taste were not included in this study.	Limitations in the number of participants tested for COVID-19 and in the limited follow up window are all acknowledged by the researchers. 
 
 
Abstract | 	This study explores the influence which psychological pain may have on an individual’s self-harming tendencies. 207 individuals participated, providing socio-demographic information, clinical information, and responding to the Psychache Scale (psychological pain rating method). Covariables such as drug use and patient interactions with psychiatrists were accounted for. Overall findings suggest that psychological pain “significantly contributes in predicting self-harming behaviours.” 
 
Introduction | 	According to Shneidman, suicidal behaviour develops if and only if an individual experiences extreme psychological pain (deemed psychache). Recent meta-analyses have confirmed this cause and effect relationship. With this being said, this paper focuses on the effect psychological pain has on self harming habits, as opposed to suicide. While self harming is not characterized by a desire to end one’s life, it is often considered a step along the suicide process. 
 
Methods | 	Demographic information, including sex, age, marital status, education, and employment status of 207 individuals was recorded. Chronic physical disease, prior psychological diagnosis, and drug use were also noted. Any patients responding positively to one or more of these variables were asked further follow up questions (for example, which drugs they’re taking).	Next, the Psychache Scale (13 item test, with answers on a 5 point scale, for assessing psychological pain) was used to determine the condition of patients. This scale is used in many universities and professional settings and its validity is widely accepted.	Finally, patients were asked about their self-harming habits. The questioning began with a general statement asking them if they’ve ever tried to overdose on medications, tried to burn themselves, tried to cut themselves, etc. In the case a of a positive response, further questions were asked about when the events took place and how many times they occurred. Self harm was defined as deliberate attempts to harm or injure oneself without seeking a fatal outcome. 
 
Results | 	Chronic physical disease was reported by 23.8 of participants, psychiatric diagnosis was reported in 21.8, and non-prescription drug use was reported by 53.7. The average Psychache Scale score was 32.24 and 28 (58 patients) reported self harming. 22 of these 28 reported self harming on multiple occasions. Drugs, medications, alcohol, cutting, scrubbing, and burning were noted as the most common forms of self harm.	Previous psychiatric diagnosis and drug use were the only co-variables which were associated with self-harming. “Psychological pain provided a significant contribution to self-harming behaviours,” even after factoring out these variables. The Psychache scores recorded correlated with the frequency of self harm. 
 
Discussion | 	The data presented in this study shows that psychological pain has a significant impact on the occurrence of self harm. The paper notes that the severity of self harm must be carefully analyzed and emphasizes the importance of suicide prevention measures. The transition from self harm to suicide ideation and ultimately suicidal attempts is swift and dangerous, making safety initiatives essential. The study recognizes the limitations that come from asking individuals to self report about their condition, actions, and psychological state (and having all this done online).  
 
 
Abstract | 	Racial disparities in pain management have been previously documented. Further understanding of the causes of these disparities is needed to make healthcare provision equitable.	In this study, the researchers wanted to understand racial differences in how analgesia is administered in children with appendicitis. Analgesia are drugs that relieve pain. They paid special attention to the administration of opioids.	This study was a repeated, observational study of patients less than 21 years old. The researchers calculated the frequency of opioid and non-opioid analgesia administration. They performed statistical analysis to examine racial differences in opioid and non-opioid analgesia.	0.94 million children were diagnosed with appendicitis. 56.8 of children received analgesia of any type. Black patients with moderate pain were less likely to receive any analgesia compared to white patients. Rate of analgesia administration was not significantly different by race. However, black patients received opioid analgesia significantly less than white patients.	Appendicitis pain is undertreated, and racial disparities in analgesia administration exist. Black children are less likely to receive any pain medication and to receive opioids. 
 
Aims | 	The researchers wanted to understand whether there were racial differences in analgesia administration in the emergency department. 
 
Introduction | 	There are racial disparities in many aspects of healthcare. Racial disparities have been demonstrated in the emergency department (ED), such as differences in wait time and hospital admission. Previous research has also described differences in pain management in the ED, with black and Hispanic patients having opioids prescribed less frequently than white patients. There are few studies of this nature in children.	Previous studies have shown racial disparities in ED management of abdominal pain. Appendicitis is the most common surgical cause of abdominal pain in the ED. Administering analgesia for appendicitis is encouraged. The investigation of pain management in children with appendicitis may provide a good understanding of racial differences in analgesia administration. 
 
Methods | Study DesignThe researchers conducted an observational study. They used the National Hospital Ambulatory Medical Care Survey (NHAMCS) from 2003 to 2010.Data Source and Study PopulationThe NHAMCS is a survey of visits to the EDs of hospitals in all 50 states. It is conducted by the CDC for a 4-week period each year. The population used in the study was all NHAMCS-sampled ED visits by patients 21 years or younger with a diagnosis of appendicitis.VariablesThe researchers collected data about analgesic administration (overall, nonopioid, and opioid) in each visit from the NHAMCS. Each visit was categorized as no analgesia prescribed or analgesia prescribed. They further categorized the group with analgesia prescribed as opioid or non-opioid analgesia.Independent VariablesRaces captured by the NHAMCS include white, black/African American, Asian, Native Hawaiian/Pacific Islander, American Indian/Alaska Native, or more than 1 race reported. These races are recategorized as white, black, or other. The researchers used the latter to categorize analgesia prescription.The researchers adjusted the results using variables of ethnicity, age, sex, insurance status, triage acuity level, pain score, geographic region, ED type, and survey year.Statistical AnalysisThe researchers used Stata for data analysis. They performed 2-variable regression to understand the association between race and both overall and opioid analgesia administration. They performed multivariable regression to adjust for other variables. 
 
Results | 	There were 0.94 million ED visits for appendicitis in children.	Overall, 56.8 of patients received some form of analgesia. 41.3 received opioid analgesia. In 2-variable analysis, there was no association between race and analgesia administration. However, black patients were less likely to receive opioid analgesia than white patients, at 20.7 and 43.1 respectively.	Older age and higher pain score were associated with higher rates of analgesia administration. Opioid administration was associated with higher pain score. There were no significant differences in analgesia administration by ethnicity, sex, insurance status, triage level, geographic region, or ED type.	When the results were categorized by pain score and adjusted for ethnicity, black patients with moderate pain were less likely to receive analgesia compared to white patients, at 15.7 and 58.5 respectively. Black patients with severe pain were also less likely to receive opioids than white patients, at 24.5 and 58.3 respectively. 
 
Discussion | 	The results of this study show low rates of analgesia and opioid administration overall and racial differences in opioid administration. Overall, only 56.8 of children received any analgesia, and 41.3 received opioid analgesia. These results are consistent with previous studies, demonstrating a low rate of analgesia administration for patients with appendicitis. This may result from clinicians believing that analgesia leads to diagnostic delays. But this would not explain racial disparities in analgesia administration. This failure to administer analgesia may be more present in children due to fear of adverse outcomes with opioids. Previous studies have shown that children are much less likely to receive analgesia than adults.	Eliminating racial health disparities is important for healthcare. There is growing evidence that patients of color receive a lesser quality of care compared to white patients. Stereotyping and biases by healthcare providers can contribute to these health disparities. This study exposes racial disparities in analgesia administration and allows for future efforts to minimize these disparities.	Opioid administration is a major component of pain management for appendicitis. Although there was no difference in overall analgesia administration between white and black patients, the racial disparities found opioid administration in the study are concerning. This suggests that although clinicians recognize pain equally in white and black patients, they react to the pain differently and administer different medications. These disparities in opioid analgesia found in this study are similar to other studies. 	As pain scores increased, so did analgesia administration. However, it seemed as though there was a threshold effect with analgesia administration by race. Black patients with moderate pain were less likely to receive any analgesia. Black patients with severe pain were less likely to receive opioid analgesia. This suggests there may be a higher threshold for pain score for administering analgesia to black patients.	Other studies have suggested ethnic differences in opioid administration, but this study did not find any. This may be explained by observations that Hispanic children more frequently present with appendiceal perforation rather than appendicitis. There were no differences in triage or pain score by race or ethnicity.	In conclusion, these findings show racial disparities in opioid administration to children with appendicitis. More research is necessary to understand why these disparities exist. This research could help with designing interventions to improve pain management for all. 
 
 
﻿Abstract | Leptospirosis, a widespread zoonotic disease, is an important health problem in slums. But, there is little understanding of the dynamics of Leptospira transmission in slums. In this study, the researchers sampled water in a Brazilian urban slum to study the dynamics of Leptospira. They collected surface water during dry, intermediate, and rainy seasons and quantified the number of Leptospira in these samples using qPCR. They also identified factors that explained differences in the presence and amount of Leptospira in different seasons. In 335 sewage and 250 standing water samples, Leptospira was detected in 36 and 34 of the samples respectively. The probability of finding Leptospira was higher in sewage samples in the rainy season than the dry season (47.2 and 12.5 respectively). Predictors of Leptospira being found in these samples included type of water, elevation, time of day, and season. These findings show that Leptospira are prevalent in slum communities. Seasonal increases in Leptospira may explain the timing of leptospirosis outbreaks. Public health interventions should consider these dynamics of Leptospira in water to decrease the prevalence of the disease. 
 
Aims | 	In this study, the researchers wanted to understand what kinds of factors influenced the presence of Leptospira in different kinds of water in a Brazilian urban slum. 
 
Introduction | 	Leptospirosis is a zoonotic disease that causes over 1 million cases and 50,000 deaths each year. Symptoms range from mild and flu-like to severe complications that can cause death. Leptospira, the bacteria that cause leptospirosis, infect the kidneys of several kinds of mammals and are discharged into the environment through urine. Leptospirosis is transmitted through the environment. Human infection happens through contact between contaminated water and open wounds or mucous membranes in the eyes and mouth. Little is understood about the abundance and distribution of Leptospira in surface waters that are a source of transmission. Environmental factors that influence the risk of infection are also not well-understood.	Leptospirosis is an emerging public health problem in tropical and subtropical impoverished slum communities. Inadequate sanitation promotes the presence of rodents which are major carriers of Leptospira. 865 million people reside in urban slums, a number which will increase and expose more people to leptospirosis.	Exposure to contaminated water is a major risk factor for leptospirosis. Changes in the climate leading to more exposure to water is an important factor for leptospirosis transmission. Seasonal rainfall and flooding, and extreme weather cause an increase in leptospirosis outbreaks. Another factor is how close households are to open sewers, which increases contact with sewage, flooding water, and runoff which increases risk of infection.	The abundance and distribution of Leptospira in surface waters is not well-understood. In this study, the researchers try to provide an understanding on the presence and concentration in a Brazilian slum at high-risk for leptospirosis, as well as factors influencing transmission. The researchers sampled surface waters from this Brazilian slum with high infection rates, especially during the rainy season. 585 samples were collected in dry, intermediate, and rainy seasons. Leptospira presence was quantified using qPCR. Factors that explained differences in the presence and location of Leptospira were also identified. 
 
Methods | Study Site	The study was conducted in Pau da Lima in Salvador, Brazil. This slum community has inadequate sanitation infrastructure that leads to frequent flooding during the rainy season. Salvador has a tropical rainforest climate. April to July is considered as the rainy season.Sampling design and collection	One of the valleys in the Pau da Lima community was selected for a survey of surface waters. The sampling strategy was designed to collect 672 water samples from three categories of sample sites. These sampling sites varied based on elevation (valley top, middle, and bottom) and season (rainy, intermediate, and dry). Fourteen paired sampling sites (a total of 28 sites) were selected along a section of an open sewer that flows from the top to the bottom of the valley. At each of the 28 sites, samples were collected from both the sewer and standing water close to the sewer.	Samples were collected in July 2011, November 2011, and January 2012. These months were selected based on average monthly rainfall. Within each sampling period, samples were collected at each sampling site 3 days per week in the morning and afternoon.Quantification of Leptospira DNA in surface water	DNA was extracted from the samples using centrifugation and an extraction kit. Leptospira were quantified using qPCR targeting the lipl32 gene.Data treatment	Positive qPCR samples were included in the analysis.Statistical analysis	Logistic and linear mathematical models were used to analyze the occurrence of a positive qPCR and the concentration of Leptospira respectively. Factors including sampling location, week, day within week, surface water type, season, period of the day, and elevation were accounted for in the models. Interactions between these factors were tested.Leptospirosis incidence	Severe leptospirosis infections were identified from a surveillance program at the state infectious diseases hospital. 
 
Results | Rainfall pattern and leptospirosis incidence	July 2011 was the intermediate season, November 2011 was the rainy season, and Janurary 2012 was the dry season. 101 severe leptospirosis cases were reported during the study period. The number of cases peaked in the rainy season, and less cases were reported in the dry and intermediate seasons.Specificity of Leptospira qPCR assay	The researchers verified whether the qPCR used in the analysis was detecting infectious Leptospira and nothing else. Samples with positive qPCR were randomly selected, and their DNA was sequenced. All sequenced samples showed high similarity to the targeted gene sequence, indicating that the qPCR specifically detects infectious Leptospira.Distribution and quantification of Leptospira in surface waters	585 samples (335 sewage and 250 standing water) were collected and tested by qPCR to quantify Leptospira. Among these samples, 236 were positive for Leptospira DNA, with 36 and 46 of sewage and standing water samples being positive respectively. Sewage had the most positive samples in the rainy season and the least positive samples in the dry season. More sewage samples were positive at the bottom of the valley than upper areas of the valley. The number of positive samples in standing water was more stable across seasons and elevations. Standing water was found less in the middle of the valley and during the dry season. Samples collected in the morning and afternoon had similar rates of positivity.	Overall, concentrations of Leptospira in surface water were low and did not differ between types of water, seasons, elevations, and periods of collection.Spatial and temporal predictors of Leptospira DNA presence and concentration	The probability of finding a positive sample was higher in the bottom of the valley than the middle or the top.	Two significant kinds of interactions existed between factors analyzed for their influence on Leptospira concentration: between season and type of water, and between season and period of collection. Analysis of the interaction between season and type of water showed the sewage samples in the rainy and intermediate seasons were more likely to be positive than in the dry season. In the rainy seasons, sewage samples had higher probabilities of being positive than standing water samples. In the analysis between season and period of collection, rainy season samples had higher probabilities of being positive in the morning than the afternoon. These results suggest that elevation, season, type of water, and period of collection influence the probability of finding Leptospira in surface waters in the slum.	In the rainy season, positive samples had higher concentrations of Leptospira compared to the dry season. Samples collected in the morning had higher concentrations compared to those in the afternoon. However, these differences were small. 
 
Discussion | 	The researchers found that Leptospira are prevalent in sewage and standing water, but in low concentrations. The results indicate that Leptospira prevalence differs in different locations and seasons, being more prevalent in lower areas of the valley and in the rainy season.	The probability of finding positive Leptospira samples had a seasonal pattern. More samples were positive in the rainy season than the dry season. This may be due to many factors including the washing away of Leptospira from the soil due to rain, dissolving Leptospira biofilms, or increased survival due to higher oxygen levels and diluted toxic sewage compounds. These factors need further studies. This seasonal pattern is consistent with other studies, and has been reported in other settings with heavy rainfall causing increased contact with contaminated water. This contact has been suggested as a main source of leptospirosis outbreaks.	Both sewage and standing water samples contained Leptospira. The results show that in rainy periods, sewers and overflow are drivers of infection. In the dry season, standing water samples showed more positivity than sewage. These results suggest that sewage and standing water are distinct reservoirs for Leptospira, and have different mechanisms that influence the presence of Leptospira. Previous studies have pointed to puddles, which are abundant in slums, as sources of contact with Leptospira-contamined water. Public health authorities should consider standing water, along with sewage, when designing interventions for reducing the incidence of leptospirosis.	Positivity in samples was higher at the bottom of the valley, which agrees with previous studies. This may result from lower elevations having higher flooding risk during rainfall events. Open sewers and other forms of drainage collect at the bottom of the valley, so surface water may be more contaminated at lower elevations.	The concentration of Leptospira in all samples was relatively low. However, these low concentrations contrasted with high infection rates in the community. The concentrations found in the study are far less than reported concentrations necessary for infection. The researchers suggest that there may be mechanisms where the concentration necessary for infection decreases, such as the disruption of skin barriers. More studies are necessary to confirm this hypothesis.	The study site has similar characteristics to other communities across the world. These results may help to understand geographic and seasonal differences in leptospirosis epidemics. The results of this study are important to implement efficient interventions to reduce leptospirosis worldwide. 
 
 
Abstract | This study assesses Endoglin’s (Eng) role in wound healing by comparing heterozygous Eng+/- mice and normal Eng+/+ mice. The area of the wound was higher in Eng+/- mice and took longer to heal compared to the Eng+/+ mice. The Eng+/- mice had slower growing and elongated in shape keratin cells. Decreased nitric oxide (NO) slowed the healing of normal Eng+/+ mice, but had no effect on Eng+/- mice. Increased NO caused faster wound closure in Eng+/-, but had no effect on the Eng+/+ mice. Stimulation with 12-O-tetradecanoylphrobol-13-acetate (TPA) enhanced Eng expression in tissue culture and in live mice. These results show that Eng plays an important role in wound healing and the availability of NO. 
 
Introduction | Wound healing is a very complex process that includes specific signaling pathways. Processes like reepithelialization, inflammation, connective tissue contraction, angiogenesis, and tissue remodeling are needed in wound healing. The delay of wound healing in diabetic patients is caused by poor blood flow, low oxygen levels, too much inflammation, edema, and endothelial cell dysfunction.Transforming growth factor-beta (TGF-beta) is one important factor throughout wound healing. Endoglin (CD105 or Eng) works to regulate how the cells respond to the molecules that bind to the TGF-beta family. Eng is seen in high levels in tissues that are undergoing angiogenesis. Inhibiting Eng stops angiogenesis. Genetically modified mice without any Eng do not survive through pregnancy, but heterozygous mice (Eng+/-) live full lives. Eng regulates nitric oxide synthase (NOS), and Eng+/- mice produce less nitric oxide (NO). After a wound, Eng expression increases along with inflammation. 
 
Materials and Methods | Both the NOS inhibitor and NO source were given by mouth to the mice. TPA was applied to the skin of the mice, and then a skin sample was prepared for analysis. Immunohistochemistry, western blot, and RT-PCR were used to analyze the wound tissue. 
 
Results | Temporal and Spacial Expression of Eng During RepairEng expression in normal mice was low at first, but increased, peaked, and decreased within 8 days after injury. Eng expression was highest at the edges of the wound and blood vessels near the wound.Delayed Wound Closure in Eng-deficient MiceWound healing and closure was slower in Eng+/- mice compared to normal mice by 1 or 2 days. NOS inhibition, which decreases NO levels, slowed wound healing in normal mice, but did not affect Eng+/- mice. Interestingly, increased NO levels increased wound healing in Eng+/- mice, but had no effect on normal mice. The skin near the wound is thinner and longer than normal in Eng+/- mice, even after the wound has closed.Disturbed Epidermal Proliferation in Eng-deficient MiceResearchers tested Ki67 to show rapidly growing keratin cells. In unwounded tissue, there was no difference in Ki67 for Eng+/- or normal mice. But in wounds, Ki67 was reduced in Eng+/- mice.Researchers tested K17 to see how many migrating keratin cells were present. K17 was higher in Eng+/- than normal mice.TPA is a chemical that promotes tumors. Researchers applied TPA to the skin of mice, and this area had increased Eng and Ki67. But tumor growth was lower in Eng+/- mice than in normal mice. 
 
Discussion | This study provides support that Eng plays a huge role in wound healing. Decreased Eng can cause an increase in a molecule called transforming growth factor-beta (TGF-beta). High expression of TGF-beta will cause angiogenesis to stop, so Eng and TGF-beta work together to balance angiogenesis.Nitric oxide (NO) has been shown to increase wound healing in previous studies, and this study supports those findings. This study related low NO levels with poor wound healing, and that this is the case in Eng+/- mice. Low NO levels caused by Eng+/- mice may cause low growth of keratin cells and low expression of vascular endothelial growth factor. Decreased NO can also decrease angiogenesis, which is closely regulated by Eng and TGF-beta. Even though Eng increases wound healing, high amounts are also seen in many skin diseases.  
 
 
Abstract | There is little information on exposure to sexual violence in low income urban African Americans. This study is composed on answers from 1,300 African Americans from Detroit on lifetime sexual violence and post-traumatic stress disorder (PTSD). Lifetime sexual violence was 26.3 for women and 5.1 for men, and victims reported more other traumatic events, 4 times greater unadjusted odds of PTSD, and 1.6 times greater adjusted odds of PTSD. More screening should be done in urban African American populations to decrease PTSD and sexual violence. 
 
Introduction | Sexual violence, which includes rape and sexual assault, are reported at high amounts in the United States. 40.2 of women report sexual assault, and 18.3 report rape. 4.2 of men report sexual assault and 1.4 report rape. Demographics like minority status and low socioeconomic status are correlated with higher risk for physical violence, but few studies have focused on sexual violence. Sexual violence is most likely to be done by an acquaintance, and less likely to be reported to the police, making studies about sexual violence even more important. Exposure to rape is associated with higher levels of PTSD than physical violence like assault or robbery. This study assesses sexual violence and PTSD in African American urban-dwelling adults. 
 
Methods | The 1306 participants were randomly chosen from a larger survey called the Detroit Neighborhood Health Study. Participants self identified if they had experienced sexual violence in the survey. DSM-5 criteria was used in a self assessment of the participants to determine if they qualified for PTSD. The age, sex, ethnicity, income level, education, marital status, and other traumatic events were recorded as well. Some of the participants engaged in a 40 minute phone call to further investigate trauma and psychopathology. 
 
Results | 16.4 of the sample reported sexual violence, and those who did tended to be younger, have lower income, and female. Those who had a GED or high school degree reported less sexual violence than those who did not complete high school or those who attended college. Women were more likely to report both rape and sexual assault, as well as lifetime or recent PTSD. The lifetime PTSD was 34.4 and the recent PTSD was 18.3 in sexual violence victims. In unadjusted models, PTSD was 4 times more likely in sexual violence victims. In the fully adjusted model, only lifetime PTSD was 1.6 times more likely. 
 
Discussion | Two key findings of this study are that African American women reported lower sexual violence than a recent national study, and sexual violence was associated with increased rate of lifetime PTSD. The decrease we see in lower reported sexual violence was likely due to the way the questions were asked in the study, The questions specifically asked if they had experiences sexual violence. But sexual violence can be very broad, encompassing different tactics and experiences. African American women likely have similar cases of sexual violence compared to national averages, but are simply less likely to label the same experiences as violence. The level of men who reported sexual violence in this study matched national levels.There was a previous study done in the Detroit area that assessed sexual violence in all racial groups of the area, not just African American. In the previous study, the reported sexual violence was even lower than this study. This may be because willingness to report sexual assault has increased over time, or because of ethnic and racial differences between studies. Still, both studies associate sexual violence with young, female, and low income individuals.Sexual violence is only associated with lifetime PTSD, not recent PTSD, when other traumatic events are taken into account. Still, victims of sexual violence reported having more of the other traumatic events, showing that these individuals had a higher risk for entering a cycle of traumatic event exposure. Despite the limitations of this study being self-reported, the results should be taken seriously in that sexual violence is happening, and is associated with lifetime PTSD and repeated trauma in low income urban African American women. 
 
 
Abstract | Though we are aware of the lower quality and access to healthcare of minority, rural, and impoverished individuals, the problem persists. This study discusses the gaps of knowledge and communication that keep these populations from getting healthcare. This study also recommends how to improve current healthcare access programs. 
 
Introduction | There is a known need to minimize health care disparities between majority groups and racial/ethnic minorities, rural residents, and low income adults. There is a lower level of care for these groups, notably in cardiovascular issues and cancer which are leading causes of death in the US. Even though here have been some programs put into place to provide better care to minority groups, we have not seen much improvement at the national level. This article discusses some aspects of health care disparity that existing plans do not address, and offers some programs by the Center for Population Health and Health Disparities that do account for the missing aspects. This article uses a model from Edwin Fisher to explore intervention targets and the key outcomes of the program. 
 
Interventions Targeting Disparities | There are four levels of factors that influence health care. Level 1 is individual patient factors; level 2 is family, friends, and social support factors; level 3 is provider and organizational factors; and level 4 is policy and community factors. Models that intervene at multiple levels are more likely to help the situation than models that only target one of the levels. 
 
Critical Gaps in Knowledge and Translation | Based on previous research, the study has identified 15 knowledge and translation gaps that can be categorized into the four levels mentioned earlier. Understanding these gaps could be the key to attaining health equity.All Model LevelsSome critical gaps are present between all four levels of the model. Research can be done to compare programs that may target multiple areas (like patient education, provider communication skills, and health system staffing) to programs that target one area (patient education alone). We also need to do research on the benefit of attempting to universally help under-served populations versus the benefit of targeting specific barriers of a certain under-served population. This research must be successful in real world practice as well.Specific LevelsSome gaps are between two specific levels of the model. For example, we see a critical gap between policy and community (level 4) and organization and provider (level 3): there should be a stronger link between health care systems and the communities they serve.At the organization and provider level (level 3), there are 5 critical gaps. There is a need to address the patient’s entire span of care, including prevention, primary care, specialty care, hospitalization, and post-discharge treatment. Also, the gaps of this level require us to consider how a team could benefit care, how to better use health technology, improving health worker’s communication and cultural competence skills, and to shift the focus of healthcare leaders to equity for their communities.At the friends, family, and social support level (level 2), the gap is to better understand cultural decision making and increasing social networks.At the individual patient level (level 1), there are important gaps. The needs are to study less commonly studied populations, increase access to treatments adherence and medication access, and ensure these changes to healthcare are successful long term. 
 
Addressing These Gaps and Advancing Health Equity | Reducing Disparities in Cardiovascular Disease CareThe Heart Healthy Lenoir Project was one program targeting blood pressure control. It integrated a community health coach, at home blood pressure monitoring, and on site coaching. The health care facilities were taught race specific data on blood pressure management, how to encourage regular blood pressure check ups, to medicate persistent high blood pressure, and to educate their staff members on health care disparities. This was effective in lowering the blood pressure of white and African American patients, and the program had a higher retention rate for African American individuals.Another intervention was called Reducing Disparities and Controlling Hypertension in Primary Care. This program made changes by targeting patients, providers, clinical staff members, and the health care system. Measures were taken to increase accuracy of the blood pressure readings taken in the clinic. Pharmacists and dietitians were added to the primary care team of the patients. Finally, a database was used to report the race-specific data on blood pressure management, which was intended to educate the physicians. The patients who completed all parts of the program saw a greater reduce in blood pressure, and the race disparities in systolic blood pressure was no longer present at the end of the study.Reducing Disparities in Cancer CareOne program called Fortaleza Latina showed that culturally based tactics using community education improved the rates at which Latinas got mammography screenings. The study used promotoras, which are community members who are trained to educate their community. This program involved research institutions, primary care clinics, and cancer treatment centers.Another program called Project Community Linked to Quit aimed to provide health care to smokers. The program offered outreach, motivational counseling, free nicotine replacement therapy, and access to community based resources. Information about race and income was recorded. This program was more effective than many current efforts to decrease smoking in low income and minority adults. 
 
Informing Future Interventions | This study has discovered some valuable information to health disparities. Patients prefer a holistic treatment plan that includes community classes and support groups, as opposed to disease specific treatment. Incorporating all of the people who provide care into the treatment plan creates a more successful program and can increase funding as well. Research finding and other sponsorships from the community increase the effectiveness of the programs. Universal policies, like universal health care, are important, but are not enough to rescue disparities in health care. Universal policies must be used in combination with targeted care for at-risk populations in order to see the change we need. The Delaware Cancer Treatment Program is an example of a program that used universal colorectal cancer screenings with targeted insurance coverage for those in need. This program decreased the percentage of African American disease from 79 to 40 percent, almost eliminating mortality disparities.The Affordable Care Act mainly focuses on national health overall, but also began collecting data on race, ethnicity, sex, primary language, and disability status. This information has helped physicians to use disparity interventions, target the at-risk patients, and increase health equity. In the future, we need to monitor and study health care reform to better understand how we can decrease healthcare disparities. Finally, payment model reforms are necessary to make sure disenfranchisement or penalties do not affect targeted populations or the physicians serving those populations. 
 
Conclusion | Though there is much to do when it comes to health care reforms and reaching equity, the research we are doing is helping to create better programs. We now know that networks and multiple level programs may be the best way to continue health care reform. Collaboration between levels of care, monitoring of the effects of new programs, and maintaining funding will be the key to healthcare equity. 
 
 
Abstract | Purpose: The discussion of human microplastic exposure by contaminated seafood.Recent Findings: Shellfish pose a potential exposure risk and it is presumed to be dependent on the dose, polymer type, size, surface chemistry, and hydrophobicity of the plastic polymer.Summary: Human activity has led to global use and pollution of plastic. Aquatic life ingested this plastic and there is evidence emerging that it poses a toxic threat towards aquatic life and the humans that consume it. The paper will highlight gaps in our knowledge regarding microplastics and recommends future research on seafood consumption. The researchers also emphasize the importance of lessening the dependence on plastic or ensuring recycling or a longer lifetime for plastic products. 
 
Introduction | A conservative estimate suggests that there are roughly 5.25 trillion plastic particles circulating in ocean waters. 80 of these plastic particles are suspected to have entered from land-based sources. They enter as trash, industrial discharge, litter through inland waterways, wastewater outflows, and transport by winds or tides. The physical and chemical degradation of these plastics can form smaller particles known as micro or nano plastic. Micro plastic is anything smaller than 5mm and nano plastic smaller than 1 nanometer in size. Degradation of the plastic polymers is dependent upon their polymer size, age, type, and environmental conditions such as weathering, temperature, irradiation, and pH. The type of plastic and its density also determines what depth it remains at within the ocean. Studies have shown that nanoplastic can be found in every organ. There is a growing body of evidence demonstrating a relationship between micro/nanoplastic exposure, toxicology, and human health. 
 
Methods | The researchers did a thorough literature review using several databases such as PubMed, Google Scholar, Natures database, and Science Direct. They focused on publications after 2004 given that the term “microplastic” was introduced. Other organizations such as Food and Agriculture Organization (FAO), The Group of Experts on Scientific Aspects of Marine Environmental Protection (GESAMP) of the United Nations, European Food Safety Authority (EFSA), UNited States Department of Agriculture (USDA), Food and Drug Administration (FDA), and National Oceanic and Atmospheric Administration (NOAA) for relevant information and sources. 
 
Background on Microplastics | Sources and DistributionMicroplastics are a mixture of varying plastic shapes, sizes, and types. There are two types of microplastics. First, primary microplastics were purposely made to be less than 5mm. Such an example would be microbeads found in a variety of hygiene products before they were banned in 2015. The second type of microplastics are called secondary microplastics that are formed from the breakdown of larger plastic types into a size smaller than 5mm. Some examples would be microfibers from clothing and tire dust.Physical and Chemical PropertiesSome lighter plastic types float to the top of seawater and some denser ones are found at varying depths with some expected to sink to the bottom. Plastic is made when two individual monomer units of a compound join together to make a polymer made of multiple monomers. Plastic is given special qualities in part by the additives used. There are several thousand all of which give the plastic certain characteristics. The polymer of plastic itself is non-reactive and thus largely non-toxic. However unreacted monomers and additives are extremely toxic to life. As the plastic degrades, the surface area to volume ratio will increase and thus increase the expected amount of additives that will leach out into the surrounding water.	Microplastics in the ocean also absorb persistent organic pollutants (POP)s. These chemicals bind to the microplastic more readily than water and tend to concentrate themselves onto the plastic surface. The exposure of POP’s to humans may be rather small via the microplastic pathway, but it should not be ignored.Degradation of Marine PlasticsPlastic can be degraded slowly by microorganisms, heat, oxidation, light, or hydrolysis. The rate of these processes is highly dependent upon the environmental conditions present.Exposure to Microplastics by Marine AnimalsIn 2016 the UN report documented more than 800 animal species that were contaminated with plastic via ingestion or entanglement. This is 69 greater than a 1977 review that estimated only 247 contaminated species. Microplastics have been found to be present in marine mammals, fish, invertebrates, and fish-eating birds. The micro/nano plastic is concentrated in the gut, but can move into the other organs and circulatory systemsHuman Exposure PathwaysExposure to microplastic via seafood is one method of exposure. Ingestion of microplastic by aquatic life can occur directly or via trophic transfer. It has even been documented in planktonic organisms and larvae which constitute the bottom of the food chain. Likely exposure could occur through bivalves and small fish. Microplastics have also been documented to be present in a beer, honey, and sea salt. This list is not exhaustive. The plastic in these foodstuffs could be due to uptake by the product itself, simple impurities formed during processing, or packaging contaminants.Due to gaps in data it is unknown what the human health effects are. However, it is most likely related to the concentration of plastic exposure. As stated earlier the exposure to microplastic also means exposure to associated chemicals. However, there is no research studying the effect of additives. There is mounting evidence that microplastic exposure and its associated chemicals is a threat to marine life. The health implications for humans requires a standardized and reproducible method. No standard exists as of yet. 
 
Toxicity to Humans | Microplastics may cause harm to humans both physically and chemically. However, with current data it is impossible to break down the pathways , but we the authors of this paper break it down for the purpose of discussion.Potential Physical Effects of MicroplasticThe physical effects are understudied, but preliminary research suggests some potentially harmful effects. There is a possibility for enhanced inflammation, size-related toxicity of particles, chemical transfer of adsorbed pollutants, and disruption of gut microbiome. The functional groups size, shape, surface charge, buoyancy, and hydrophobicity predict microplastic uptake into the body. Models of mammals suggest that certain microplastics can be taken into the body by M cells or dendritic cells and enter the lymphatic system where they will eventually accumulate in other organs. Some research suggests that it can cause inflammation, cellular proliferation, cell death, and compromise the immune system. In order to further test the effect of microplastic on humans it is important to monitor shellfish consumption and its effects.Nanoplastic particles are transported into the blood via M cells into the lymphatic system were they are able to travel throughout the body. Their hydrophobicity allows them to pass through the placenta and blood-brain-barrier. Nanoplastics have a higher surface area to volume ratio which could result in a more reactive compound. Studies show that introduction of nanoplastic to lung, liver, and brain cells in test tubes results in toxicity. It has been shown to produce cardiopulmonary responses, changes in metabolism, damage to the genome, inflammatory responses, oxidative stress, effects on nutrient absorption, gut microflora, and reproduction.Potential Effects of Chemical AdditivesExposure to chemicals present on microplastics poses a particular problem to juvenile humans and animals even at a lower dose. The interaction of microplastics will vary depending on the organism, however studies show increased toxicity from multiple microplastics and their associated chemicals. The exposure may be low, but if the effect is cumulative then this becomes of greater concern. The researchers suggest further research to estimate toxicity doses in humans from microplastics in seafood and several other studies.EpidemiologyMicroplastic is used to deliver medication inside the body, but its effects are generally unknown. It may produce a localized toxicity, but we currently have no method of verifying this. There is significant correlation between the amount of microplastic (BPA) in a persons urine and both cardiovascular disease and type 2 diabetes. However further research is strongly advised by the authors of this paper. Mitigation of and Adaptation to RisksThe effect of microplastic on human health is uncertain, but should not be ignored. The government, industry, and civil society all have vital roles in reducing the flow of plastic into the environment. 
 
Conclusion | 	Humans ingest microplastics. However, with the research available it is uncertain how the toxicity, kinetics, exposure, and bioavailability play a part in this issue. It is likely that toxicity is dependent upon the size, shape, polymer size, concentration, and associated chemicals. More research is required in this field and the authors list multiple future suggestions for potential studies to help fill the gaps.  
 
 
Aims | In this study, the researchers analyzed U.S data about injuries inflicted by police and private security guards to understand trends over time and by race/ethnicity. 
 
Introduction | Police violence/brutality is a medical and public health concern. Public health and medical professionals have called for more research about the health consequences of policing. Recent research has examined relationships between racial discrimination by police on health, as well as how public health surveillance can be used to provide more data about police-related deaths and injuries.	However, basic epidemiological questions about police violence have not been answered. These questions include how the number of injuries related to police brutality has changed over time, or how many of these injuries are classified as “legal interventions” in hospitals according to the International Classification of Diseases (ID). There has also been little research on how private security guards use excessive force and cause injury, because they are not included in the ICD definition of legal intervention.	In this study, the researchers analyzed data about injuries caused by police and private security guards who were treated in emergency departments (EDs). In doing so, they tried to understand how many of these injuries happen, whether the number of injuries has changed over time, and whether the rate of these injuries happening varies by race/ethnicity. 
 
Results | From 2001-2014, there were 683,033 legal intervention injuries treated in EDs. 14.3 of these injuries belonged to women, and 86.5 belonged to men. For a small number of cases, gender was unknown and excluded from the study.	The rate of legal intervention injuries increased from 2001-2014 by 47.4. Men experienced a 50.8 increase and women experienced a 26.2 increase.	Analysis of racial/ethnic differences found that black people were 4.90 times more likely to experience legal intervention injuries than white people. The rate at which black people experienced legal intervention injuries was similar for both men and women. The calculated rate differences demonstrate that if black people experienced legal intervention injuries at the same rate as whites, there would have been 242,320 less injuries from 2001-2014.	Estimates for the number of legal intervention injuries experienced by Hispanic people and other people of color were unreliable due to a high coefficient of variation. Although the estimate for Latinos for legal intervention injuries was higher than white people, the difference was not statistically significant. 
 
Discussion | The researchers found that legal intervention injuries are an important contributor to ED visits in people aged 15-34, especially for men. For men, the number of legal intervention injuries was similar to the number of people injured by motor vehicle accidents. In addition, the number of ED visits due to legal intervention injuries increased from 2001-2014, more for men than for women. Finally, black people were found to be 4.90 times more likely to be subjected to legal intervention injury. This is consistent with previous studies that found that black people are more likely to experience police violence and die from legal intervention injuries.	Limitations of this study include a high level of missing data, and also the lack of data of how legal intervention injuries were treated during the ED visits. There was also no data as to whether the use of force that caused these injuries was legally justified. 
 
	Methods | The researchers used data from the National Electronic Injury Surveillance System-All Injuries program (NEISS-AIP), which collects data about ED visits in 66 U.S hospitals. Collected data includes demographic characteristics of gender, age, and race/ethnicity. These visits are categorized in four kinds of injuries, including legal intervention. A visit is categorized as a legal intervention when an injury was inflicted by police or other legal authorities (including private security guards) while trying to enforce the law.	The data from the NEISS-AIP was accessed through the CDC. Data was available from 2001-2014, and had sampling/survey design accounted for to create nationally representative estimates for the number of injuries. The researchers restricted the data to ages 15-34, who were the highest risk for legal intervention injury, and made up 61.1 of legal intervention injuries over the study period.	Stata was used to analyze the data using linear regression. The researchers tested for trends in rates of legal intervention each year. They also calculated the rates and differences in rates in black, Hispanic, and other populations of color and compared them to those of white people. They conducted all analyses for both the entire population and also by gender. 
 
Conclusion | Legal intervention injuries harm the individual, their families, and their communities. It is important for public health officials to monitor the prevalence of these injuries. This monitoring can provide data for the public that improves understanding of how large the issue of police violence is and whether it is getting better or worse over time. 
 
 
Abstract | The Pan-Cancer Analysis of Whole Genomes Consortium has identified somatic mutations that represent a profile of characteristic signatures. The size of the curated dataset makes this discovery of mutation signatures the most comprehensive dataset yet. Estimated contributions of characteristic signatures for each cancer type can be associated with causes of cancer that originate in the body or from the environment. 
 
Aims | The study aims to characterize the contribution of mutations from multiple origins that make up a signature. Combinations of different types and magnitude of signatures can characterize a cancer sample.  
 
Introduction | Mathematical models can be used to deconstruct mutations in cancer genomes into three types of signatures. Previous studies focused on one type of signature analysis on a limited part of a whole cancer genome. Using the whole genome and analyzing four types of signatures enables better separation between different types of cancer.  
 
Results | Single base substitution signatures are profiles based on mutating one base pair in a sequence. Double base substitution signatures are profiles based on mutating two base pairs in a sequence. Insertion signatures are profiles based on inserting a short-length fragment into a sequence. Deletion signatures are profiles based on deleting a short-length fragment from a sequence. In total, four signature types were extracted as visualized in Figure 2. The median similarity metric compared to previously identified signature was 0.95, which suggests high similarity that associates newly derived signature profiles and previously identified signature profiles. The newly derived signature profiles show an improved degree of separation between different types of cancer. Previous signatures such as SBS7, SBS10 and SBS17 were split into multiple signatures that supports the existence of unique combinations and magnitudes of mutational processes. The strand of DNA that is transcribed shows a bias observed by an increase in mutations. A positive correlation between the timing of cancer diagnosis and the number of mutations shows that accumulation of mutations occur throughout the life of a cell. 
 
Discussion | Signatures extracted from whole genomes are considered mathematical approximations. Variation and nuances of signature profiles exist which are not fully captured in the signature representation. The majority of naturally occurring signatures in human cancer have been described. Further research into location and time based mutations as part of mutation signatures can expand knowledge of cancer initiation and detection. 
 
Methods | SigProfiler is a framework that deconstructs whole cancer genomes into signature profiles through a two-step matrix factoring approach. SigProfiler is the successor to SignatureAnalyzer. 23, 829 cancer genomes were analyzed by SigProfiler. The method was manually fine tuned to reflect biologically plausible circumstances observed in previous DNA damage and repair literature.  
 
Conclusion | The study provides a comprehensive description of mutation signature profiles based on common human cancer types. The analysis was expansive in the number of cancer sequences and supports the existence of characteristic profiles. The research contributes to knowledge of cancer initiation and evolution with a promising outlook in clinical and public health environments.  
 
 
Abstract | Recent studies have reported an increase in uninsured patients being transferred from emergency departments (EDs) to other hospitals, which may result from financial incentives. In this study, the researchers wanted to understand differences in transfer and discharge rates by patient insurance status. To do so, they analyzed ED visits for pulmonary disease between January and December 2015. These visits were at hospitals that could provide care necessary for the treatment of pulmonary disease. The primary outcomes were ED discharges, transfers, and hospital admissions. The researchers calculated the rates at which uninsured patients were discharged or transferred compared to patients with Medicaid/Medicare or private insurance. They also examined whether the hospital being nonprofit or for-profit had an effect on these rates.The researchers analyzed 215,028 ED visits at 160 hospitals. The average age of patients was 55 years old, and they were mostly female. The researchers found significant differences in ED discharge and transfer, and hospital admission across different EDs. They also found that compared to patients with private insurance, uninsured patients were more likely to be discharged and transferred. Patients on Medicaid had similar rates of discharge but higher rates of transfer compared to patients with private insurance. For-profit hospitals had higher rates of ED transfer than non-profit hospitals.In conclusion, the study found that uninsured patients and patients on Medicaid were subjected to higher rates of hospital transfer, even when they had the same medical conditions as patients with private insurance. 
 
Aims | The researchers wanted to identify and understand differences in transfer and discharge rates between patients with different insurance statuses. They also wanted to understand if hospital ownership status (nonprofit or for-profit) had an effect on these differences. 
 
Introduction | The United States passed the Emergency Medical Treatment and Active Labor Act (EMTALA) in 1986, which works to ensure equitable access to emergency care. The act was passed because at the time, many hospitals refused to provide care to patients who went to emergency departments (EDs) and were uninsured or underinsured. This resulted in these patients being transferred to other hospitals, which compromised their care.Although blatant violations of EMTALA are rare, more subtle violations that occur after admission into the ED have not been examined.Previous studies show that uninsured/underinsured patients are more likely to be transferred than admitted, especially for conditions requiring specialized (and usually expensive) care. However, these studies did not account for differences in whether hospitals could provide this specialized care at all. So, these results may reflect actual patient needs for specialty care. Previous studies also did not include discharge, in addition to transfer and refusal of hospital admission, as a potential way to limit access to care.In this study, the researchers tested the hypothesis that uninsured/underinsured patients with pulmonary conditions are more likely to be transferred or discharged from the ED even though the hospital could provide the necessary specialized care. They also sought to understand whether hospital ownership status had an effect on whether uninsured/underinsured patients were transferred or discharged. 
 
Results | Characteristics of Study Sample215,028 studies were identified at 160 intensive-care capable hospitals. Of these visits for pulmonary diseases, 66.5 resulted in ED discharge, 1.5 resulted in ED transfer, and 32.1 resulted in hospital admission. Patients had a median age of 55 and were mostly female. 9.4 of visits were uninsured, 25.5 insured by Medicaid, 65.1 insured by Medicare or private insurance.The hospitals included in the study were mostly non-teaching hospitals in urban areas. The median number of ED visits for pulmonary conditions was 1175.Main FindingsHospital-Level Variation in ED DispositionAt the hospital level, the researchers found a lot of variation in ED discharge, ED transfer, and hospital admission rates. Variation was particularly high for ED transfers.ED Disposition and Insurance StatusUninsured/Medicaid patients were transferred more often than privately insured/Medicare patients, even after adjusting for other variables. In addition, uninsured patients were more likely to be discharged, but Medicaid patients had similar rates of discharge to privately insured/Medicare patients.Hospital Ownership StatusAmong the 71 hospitals included in the secondary analysis, 23 were for-profit and 48 were nonprofit. The probability of ED transfer for uninsured patients was lower than that of privately insured patients in nonprofit hospitals, but higher in for-profit hospitals. Uninsured patients also had higher probability of ED discharge both non-profit and for-profit hospitals. Medicaid patients had lower probabilities of ED transfer in both non-profit and for-profit hospitals. 
 
Discussion | In this study, the researchers found that uninsured/Medicaid patients were more likely to be transferred to another hospital than patients with private insurance, even if they have the same medical conditions and hospitals have the capability to care for them. This is consistent with previous studies and confirm that a patient’s ability to pay may influence decisions about hospitalization.	Uninsured patients were also more likely to be discharged from EDs. Uninsured patients had nearly half the hospital admission rate of privately insured patients even though guidelines for diagnosis and hospitalizations for pulmonary conditions are standardized across hospitals. These findings suggest that there may be a higher threshold for admitting uninsured patients than for insured patients, which has also been confirmed in previous studies about trauma, cardiovascular, and pulmonary diseases. Lack of admission for these diseases has been associated with increases in deaths.	Traditional violations of EMTALA through complete refusal of ED care are rare. However, the results of this study suggest that there may be more subtle violations of EMTALA after patients enter the ED, and that there may be financial incentives associated with hospital admission from the ED. Policymakers should seek to address this loophole to develop policies that fully support the hospitalization of uninsured patients.	The researchers restricted analysis to hospitals that were able to provide critical care for patients with pulmonary conditions. This enabled them to more accurately say that ED transfers/discharges are financially motivated. By accounting for discharges, transfers, and admissions, the researchers were also able to consider all kinds of ED disposition.	An encouraging finding is that patients with Medicaid/Medicare had similar rates for hospital admission with privately insured patients. This aligns with previous studies that found that access to care for people with public insurance has improved.	In contrast to previous studies, this study found that for-profit hospitals were more likely to transfer uninsured patients compared to non-profit hospitals. Although the financial incentive behind these findings are clear, more studies should be done to make conclusions.  
 
Methods | Study Design and SettingThe researchers analyzed ED visits from the 2015 National Emergency Department Sample (NEDS) between January and December.Selection of Participants and MeasurementsThe researchers included all ED visits of patients over 18 years old that resulted in transfer, discharge, or hospital admission. Demographic data of these visits included age, sex, insurance status, median income of the area where they lived, and diagnoses. The researchers accounted for comorbidities and identified insurance statuses as uninsured , Medicaid, Medicare, or private.For the primary analysis, the researchers examined ED visits for uninsured patients and Medicaid patients, since previous research suggested higher transfer rates for these groups.The researchers limited ED visits to common medical conditions not requiring specialized care. Specifically, they included visits for pneumonia, asthma, and chronic obstructive pulmonary disease (COPD). The researchers also limited the visits to those that had critical care capabilities for these conditions.For secondary analysis, the researchers collected data about hospital ownership from NEDS, and categorized hospitals as nonprofit or for-profit.OutcomesThe hospital-level primary outcome was ED discharge, ED transfer, and hospital admission rates. The patient-level primary outcome was ED discharge, Ed transfer, or hospital admission status. These outcomes were reported based on patient insurance status.ED discharge was defined as discharge to the patient’s home, transfer to a care facility, or home health care. ED transfer was defined as a transfer from the ED to another hospital. Hospital admission was defined as admission from the ED to its respective hospital.Statistical AnalysisPrimary analysis was conducted at the patient- and hospital-level. At the hospital level, the researchers calculated the rates of ED discharge and transfer, and hospital admission rates. At the patient level, the researchers calculated the probability of ED transfer or discharge compared to hospital admission based on patient insurance status.For the secondary analysis, the researchers used data from 71 hospitals that provided information about hospital ownership. They calculated the probability of ED discharge or transfer compared with hospital admission for uninsured/Medicaid patients and Medicare/privately insured patients in nonprofit and for-profit hospitals.All analyses were performed using SAS. 
 
Conclusion | 3 decades after EMTALA, there are still differences in access to hospital care based on insurance status. Policymakers should improve access to hospital care by more broadly addressing hospital quality, payment, and certification initiatives. 
 
 
Abstract | This study uses testosterone levels in the blood, prenatal testosterone levels, and testosterone receptor levels to see if testosterone effects love style. They found that low testosterone is associated with Eros, Ludus, Pragma, and Mania love styles. Receptor levels had no correlation with love style. 
 
Aims | This study aims to see if testosterone levels have an effect on love styles. 
 
Introduction | There are three primary love styles: Eros, Ludus, and Storge. Eros is passionate and romantic love, based on intuition and chemistry. Ludus is the playful style, so they date for fun and do not like intimacy. Storge is associated with a strong relationship that has formed from a deep friendship. The three secondary love styles are Manic, Pragma, and Agape. Manic love is thought to be obsessive and possessive. Pragma is business like, practical, and realistic. Agape love is selfless, unconditional, and committed love.It is unclear whether testosterone levels impact things like marital and relationship status, or the other way around. There is evidence and good rationale for both. Studies do show that gender can play a role in love style, so this leads this research team to hypothesize that testosterone controls love style.The ratio between the second and fourth finger, called the digit ratio, measures prenatal testosterone levels. The digit ratio can predict jealousy and number of sex partners in men.Measuring testosterone receptors can be used to measure genetic factors that may affect love style as well. 
 
Results | High blood testosterone levels were associated with low romantic and selfless love styles. Low prenatal testosterone levels were associated with higher romantic and game like love styles. The genetic testing of the receptors did not have any correlations. 
 
Discussion | The results show that high testosterone levels reduce passionate, intimate, committed love styles. High testosterone levels are not associated with long term attachment in relationships. Lower testosterone levels may be associated with long lasting and stable relationships. Though we see associations, there is not evidence to say that testosterone causes these trends. It is possible that long term relationships may cause low levels of testosterone. Single men and men in new relationships have higher testosterone levels, but men in long term relationships have lower levels. Studies have shown that men with high testosterone levels in the saliva are more likely to get divorced, spend less time with children, have more sexual partners, and are more competitive. The digit ratio has shown similar correlations between high testosterone and certain behaviors as well as physical characteristics. This study has shown that there is a relationship between prenatal testosterone levels and love styles. 
 
Methods | 65 students ages 19-21 were given questionnaires to assess their love style. Blood samples were taken to assess the testosterone levels. Saliva samples were used to get genetic information on the testosterone receptors. Hand scans were taken to calculate the digit ratio of the participants. 
 
Conclusion | Love style may be partially due to biology. Future studies with less limitation can help tell us more about testosterone and love styles. 
