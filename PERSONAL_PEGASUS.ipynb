{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PERSONAL_PEGASUS",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYdH6K2nYSIX",
        "colab_type": "text"
      },
      "source": [
        "SETUP AND INSTALLATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba8fLBipjTjB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "b9ba871a-039e-4ab2-b6a8-f2809df3ae15"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Aug 29 20:57:19 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO2K5NsH__Gu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b221671e-f741-4aef-81e9-c4c101192863"
      },
      "source": [
        "%%bash\n",
        "cd /content/\n",
        "git clone https://github.com/dcyphr/dcyphr-NLP.git\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dcyphr-NLP'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5J70LqGC8UG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        },
        "outputId": "ab60a6f2-6bf0-4b1c-8967-2db41e133cdc"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%cd transformers\n",
        "!pip install -q -e .\n",
        "%cd examples\n",
        "!pip install -U -q -r requirements.txt\n",
        "!pip install -U pyarrow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 39728, done.\u001b[K\n",
            "remote: Total 39728 (delta 0), reused 0 (delta 0), pack-reused 39728\u001b[K\n",
            "Receiving objects: 100% (39728/39728), 28.55 MiB | 25.85 MiB/s, done.\n",
            "Resolving deltas: 100% (27585/27585), done.\n",
            "/content/transformers\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 4.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 13.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 15.6MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content/transformers/examples\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 4.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 48.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4MB 32.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 317kB 55.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 11.6MB 52.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7MB 57.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.2MB 40.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 225kB 57.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.5MB 56.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7MB 52.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 12.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 55.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 58.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 56.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 15.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4MB 44.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 56.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 43.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 56.5MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.3.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 1.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pytorch-lightning 0.8.5 has requirement future>=0.17.1, but you'll have future 0.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: nlp 0.4.0 has requirement pyarrow>=0.16.0, but you'll have pyarrow 0.14.1 which is incompatible.\u001b[0m\n",
            "Collecting pyarrow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/99/0a605f016121ca314d1469dc9069e4978395bc46fda40f73099d90ad3ba4/pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 201kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.18.5)\n",
            "Installing collected packages: pyarrow\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed pyarrow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU8j03AAC-no",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "767ce540-502f-4b3f-cb48-8a6ebcbf2493"
      },
      "source": [
        "%cd /content/transformers/examples/seq2seq/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers/examples/seq2seq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gg53EbEYXy-",
        "colab_type": "text"
      },
      "source": [
        "This installs the XSUM Dataset and is unneccesary if you are working with your own dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME7pQTdnjzCT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "45135793-e100-4c96-dc4a-b5e0d73c9e7e"
      },
      "source": [
        "!wget https://s3.amazonaws.com/datasets.huggingface.co/summarization/xsum.tar.gz\n",
        "!tar -xzvf xsum.tar.gz\n",
        "!export XSUM_DIR=${PWD}/xsum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-29 17:14:32--  https://s3.amazonaws.com/datasets.huggingface.co/summarization/xsum.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.1.22\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.1.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 204844092 (195M) [application/x-tar]\n",
            "Saving to: ‘xsum.tar.gz’\n",
            "\n",
            "xsum.tar.gz         100%[===================>] 195.35M  44.8MB/s    in 4.8s    \n",
            "\n",
            "2020-08-29 17:14:37 (40.5 MB/s) - ‘xsum.tar.gz’ saved [204844092/204844092]\n",
            "\n",
            "xsum/\n",
            "xsum/train.target\n",
            "xsum/train.source\n",
            "xsum/val.source\n",
            "xsum/val.target\n",
            "xsum/test.source\n",
            "xsum/test.target\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf_whcahYlWN",
        "colab_type": "text"
      },
      "source": [
        "This Finetunes the PEGASUS Model for One epoch on the Dcyphr fine-tuning data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDvxD4sQDDqR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4562794f-afd9-40ac-a46e-6d1472d2ac24"
      },
      "source": [
        "!bash finetune_pegasus_xsum.sh \\\n",
        "  --model_name_or_path google/pegasus-xsum \\\n",
        "  --data_dir /content/dcyphr-NLP/fine_tuning_data \\\n",
        "  --output_dir xsum_pegasus_test_5 \\\n",
        "  --train_batch_size 2 \\\n",
        "  --eval_batch_size 2 \\\n",
        "  --num_train_epochs 1 \\\n",
        "  --n_train 100 \\\n",
        "  --n_val 100 \\\n",
        "  --sortish_sampler \\\n",
        "  --gpus 1 \\\n",
        "  --val_check_interval 0.25 \\\n",
        "  --gradient_accumulation_steps 4 \\"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version 1.6.0+cu101 available.\n",
            "2020-08-29 20:59:44.133297: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "TensorFlow version 2.3.0 available.\n",
            "https://s3.amazonaws.com/models.huggingface.co/bert/google/pegasus-xsum/config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpuc9e5ea6\n",
            "storing https://s3.amazonaws.com/models.huggingface.co/bert/google/pegasus-xsum/config.json in cache at /root/.cache/torch/transformers/b5be2b326342de3aafd13a93209b8d485791b202dcc54707b1b9c0971baa0a0e.f45c72b25fcb58b55589c0dfccde9d4314362d7297bb2bfd980655f4a3cbe3b7\n",
            "creating metadata file for /root/.cache/torch/transformers/b5be2b326342de3aafd13a93209b8d485791b202dcc54707b1b9c0971baa0a0e.f45c72b25fcb58b55589c0dfccde9d4314362d7297bb2bfd980655f4a3cbe3b7\n",
            "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/google/pegasus-xsum/config.json from cache at /root/.cache/torch/transformers/b5be2b326342de3aafd13a93209b8d485791b202dcc54707b1b9c0971baa0a0e.f45c72b25fcb58b55589c0dfccde9d4314362d7297bb2bfd980655f4a3cbe3b7\n",
            "Model config PegasusConfig {\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 64,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/google/pegasus-xsum/config.json from cache at /root/.cache/torch/transformers/b5be2b326342de3aafd13a93209b8d485791b202dcc54707b1b9c0971baa0a0e.f45c72b25fcb58b55589c0dfccde9d4314362d7297bb2bfd980655f4a3cbe3b7\n",
            "Model config PegasusConfig {\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 64,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "Model name 'google/pegasus-xsum' not found in model shortcut name list (google/reformer-crime-and-punishment). Assuming 'google/pegasus-xsum' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "https://s3.amazonaws.com/models.huggingface.co/bert/google/pegasus-xsum/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpk_wsrjcg\n",
            "storing https://s3.amazonaws.com/models.huggingface.co/bert/google/pegasus-xsum/spiece.model in cache at /root/.cache/torch/transformers/3848e191fec9935f1369d13fe14c5d785a9ff32b812559047361f135a53aaf13.efce77b8dcd2c57b109b0d10170fcdcd53f23c21286974d4f66706536758ab6e\n",
            "creating metadata file for /root/.cache/torch/transformers/3848e191fec9935f1369d13fe14c5d785a9ff32b812559047361f135a53aaf13.efce77b8dcd2c57b109b0d10170fcdcd53f23c21286974d4f66706536758ab6e\n",
            "https://s3.amazonaws.com/models.huggingface.co/bert/google/pegasus-xsum/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpicksgen9\n",
            "storing https://s3.amazonaws.com/models.huggingface.co/bert/google/pegasus-xsum/special_tokens_map.json in cache at /root/.cache/torch/transformers/bc045ff6a50eaed77dd55c18cb2baf14d21b5288b0fb06615ade9cb08983bd38.d142dfa55f201f5033fe9ee40eb8fe1ca965dcb0f38b175386020492986d507f\n",
            "creating metadata file for /root/.cache/torch/transformers/bc045ff6a50eaed77dd55c18cb2baf14d21b5288b0fb06615ade9cb08983bd38.d142dfa55f201f5033fe9ee40eb8fe1ca965dcb0f38b175386020492986d507f\n",
            "https://s3.amazonaws.com/models.huggingface.co/bert/google/pegasus-xsum/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpp8r9wv2c\n",
            "storing https://s3.amazonaws.com/models.huggingface.co/bert/google/pegasus-xsum/tokenizer_config.json in cache at /root/.cache/torch/transformers/1cc20bfd3eea66838b0cfe76e83bfd96b26ef1ab1ba0e8119f4850fa781a5710.c7d99a644bcf983aa23a0081b95cf8be1bc67c66b6afc27a266363ca1d8e463e\n",
            "creating metadata file for /root/.cache/torch/transformers/1cc20bfd3eea66838b0cfe76e83bfd96b26ef1ab1ba0e8119f4850fa781a5710.c7d99a644bcf983aa23a0081b95cf8be1bc67c66b6afc27a266363ca1d8e463e\n",
            "loading file https://s3.amazonaws.com/models.huggingface.co/bert/google/pegasus-xsum/spiece.model from cache at /root/.cache/torch/transformers/3848e191fec9935f1369d13fe14c5d785a9ff32b812559047361f135a53aaf13.efce77b8dcd2c57b109b0d10170fcdcd53f23c21286974d4f66706536758ab6e\n",
            "loading file https://s3.amazonaws.com/models.huggingface.co/bert/google/pegasus-xsum/added_tokens.json from cache at None\n",
            "loading file https://s3.amazonaws.com/models.huggingface.co/bert/google/pegasus-xsum/special_tokens_map.json from cache at /root/.cache/torch/transformers/bc045ff6a50eaed77dd55c18cb2baf14d21b5288b0fb06615ade9cb08983bd38.d142dfa55f201f5033fe9ee40eb8fe1ca965dcb0f38b175386020492986d507f\n",
            "loading file https://s3.amazonaws.com/models.huggingface.co/bert/google/pegasus-xsum/tokenizer_config.json from cache at /root/.cache/torch/transformers/1cc20bfd3eea66838b0cfe76e83bfd96b26ef1ab1ba0e8119f4850fa781a5710.c7d99a644bcf983aa23a0081b95cf8be1bc67c66b6afc27a266363ca1d8e463e\n",
            "loading file https://s3.amazonaws.com/models.huggingface.co/bert/google/pegasus-xsum/tokenizer.json from cache at None\n",
            "https://cdn.huggingface.co/google/pegasus-xsum/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpk9j77e7_\n",
            "storing https://cdn.huggingface.co/google/pegasus-xsum/pytorch_model.bin in cache at /root/.cache/torch/transformers/e466332a46461ce88caa55d5a284abfdf7cbf66283df357bef0c91afb83cc10b.ac3ab95cf010da450ccc70c8a93ca82528d30d449daacd7502b8f2e89344ff1a\n",
            "creating metadata file for /root/.cache/torch/transformers/e466332a46461ce88caa55d5a284abfdf7cbf66283df357bef0c91afb83cc10b.ac3ab95cf010da450ccc70c8a93ca82528d30d449daacd7502b8f2e89344ff1a\n",
            "loading weights file https://cdn.huggingface.co/google/pegasus-xsum/pytorch_model.bin from cache at /root/.cache/torch/transformers/e466332a46461ce88caa55d5a284abfdf7cbf66283df357bef0c91afb83cc10b.ac3ab95cf010da450ccc70c8a93ca82528d30d449daacd7502b8f2e89344ff1a\n",
            "All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n",
            "\n",
            "All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at google/pegasus-xsum.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "Epoch 1:  13% 12/90 [00:06<00:43,  1.79it/s, loss=253.176, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  14% 13/90 [00:09<00:58,  1.33it/s, loss=253.176, v_num=0]\n",
            "Epoch 1:  16% 14/90 [00:12<01:08,  1.12it/s, loss=253.176, v_num=0]\n",
            "Epoch 1:  17% 15/90 [00:14<01:13,  1.02it/s, loss=253.176, v_num=0]\n",
            "Epoch 1:  18% 16/90 [00:16<01:17,  1.05s/it, loss=253.176, v_num=0]\n",
            "Epoch 1:  19% 17/90 [00:19<01:25,  1.16s/it, loss=253.176, v_num=0]\n",
            "Epoch 1:  20% 18/90 [00:21<01:27,  1.22s/it, loss=253.176, v_num=0]\n",
            "Epoch 1:  21% 19/90 [00:24<01:31,  1.28s/it, loss=253.176, v_num=0]\n",
            "Epoch 1:  22% 20/90 [00:26<01:33,  1.33s/it, loss=253.176, v_num=0]\n",
            "Epoch 1:  23% 21/90 [00:28<01:34,  1.38s/it, loss=253.176, v_num=0]\n",
            "Epoch 1:  24% 22/90 [00:31<01:37,  1.44s/it, loss=253.176, v_num=0]/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "Configuration saved in xsum_pegasus_test_5/best_tfmr/config.json\n",
            "Model weights saved in xsum_pegasus_test_5/best_tfmr/pytorch_model.bin\n",
            "Epoch 1:  24% 22/90 [03:29<10:47,  9.53s/it, loss=253.176, v_num=0]\n",
            "Epoch 1:  38% 34/90 [03:36<05:56,  6.37s/it, loss=245.345, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  39% 35/90 [03:39<05:44,  6.27s/it, loss=245.345, v_num=0]\n",
            "Epoch 1:  40% 36/90 [03:41<05:32,  6.15s/it, loss=245.345, v_num=0]\n",
            "Epoch 1:  41% 37/90 [03:43<05:20,  6.04s/it, loss=245.345, v_num=0]\n",
            "Epoch 1:  42% 38/90 [03:45<05:08,  5.94s/it, loss=245.345, v_num=0]\n",
            "Epoch 1:  43% 39/90 [03:48<04:59,  5.86s/it, loss=245.345, v_num=0]\n",
            "Epoch 1:  44% 40/90 [03:50<04:48,  5.77s/it, loss=245.345, v_num=0]\n",
            "Epoch 1:  46% 41/90 [03:53<04:38,  5.69s/it, loss=245.345, v_num=0]\n",
            "Epoch 1:  47% 42/90 [03:55<04:29,  5.61s/it, loss=245.345, v_num=0]\n",
            "Epoch 1:  48% 43/90 [03:57<04:20,  5.53s/it, loss=245.345, v_num=0]\n",
            "Epoch 1:  49% 44/90 [04:00<04:11,  5.47s/it, loss=245.345, v_num=0]\n",
            "Epoch 1:  62% 56/90 [04:06<02:29,  4.41s/it, loss=238.305, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  63% 57/90 [04:09<02:24,  4.38s/it, loss=238.305, v_num=0]\n",
            "Epoch 1:  64% 58/90 [04:11<02:18,  4.34s/it, loss=238.305, v_num=0]\n",
            "Epoch 1:  66% 59/90 [04:14<02:13,  4.31s/it, loss=238.305, v_num=0]\n",
            "Epoch 1:  67% 60/90 [04:16<02:08,  4.27s/it, loss=238.305, v_num=0]\n",
            "Epoch 1:  68% 61/90 [04:19<02:03,  4.25s/it, loss=238.305, v_num=0]\n",
            "Epoch 1:  69% 62/90 [04:21<01:58,  4.21s/it, loss=238.305, v_num=0]\n",
            "Epoch 1:  70% 63/90 [04:23<01:53,  4.19s/it, loss=238.305, v_num=0]\n",
            "Epoch 1:  71% 64/90 [04:25<01:48,  4.16s/it, loss=238.305, v_num=0]\n",
            "Epoch 1:  72% 65/90 [04:28<01:43,  4.13s/it, loss=238.305, v_num=0]\n",
            "Epoch 1:  73% 66/90 [04:31<01:38,  4.12s/it, loss=238.305, v_num=0]\n",
            "Epoch 1:  87% 78/90 [04:37<00:42,  3.55s/it, loss=234.625, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  88% 79/90 [04:39<00:38,  3.54s/it, loss=234.625, v_num=0]\n",
            "Epoch 1:  89% 80/90 [04:42<00:35,  3.53s/it, loss=234.625, v_num=0]\n",
            "Epoch 1:  90% 81/90 [04:44<00:31,  3.51s/it, loss=234.625, v_num=0]\n",
            "Epoch 1:  91% 82/90 [04:46<00:27,  3.49s/it, loss=234.625, v_num=0]\n",
            "Epoch 1:  92% 83/90 [04:49<00:24,  3.49s/it, loss=234.625, v_num=0]\n",
            "Epoch 1:  93% 84/90 [04:51<00:20,  3.47s/it, loss=234.625, v_num=0]\n",
            "Epoch 1:  94% 85/90 [04:53<00:17,  3.46s/it, loss=234.625, v_num=0]\n",
            "Epoch 1:  96% 86/90 [04:57<00:13,  3.46s/it, loss=234.625, v_num=0]\n",
            "Epoch 1:  97% 87/90 [04:59<00:10,  3.45s/it, loss=234.625, v_num=0]\n",
            "Epoch 1:  98% 88/90 [05:03<00:06,  3.44s/it, loss=234.625, v_num=0]\n",
            "Epoch 1: 100% 90/90 [05:04<00:00,  3.38s/it, loss=234.625, v_num=0]\n",
            "finetune_pegasus_xsum.sh: line 14:   348 Killed                  python finetune.py --learning_rate=1e-4 --do_train --do_predict --n_val 1000 --val_check_interval 0.25 --max_source_length 512 --max_target_length 56 --freeze_embeds --max_target_length 56 --label_smoothing 0.1 \"$@\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJGRWhbQy14N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "ae2388d7-efce-4147-f978-06c7e9f3e775"
      },
      "source": [
        "%%bash\n",
        "mkdir gens\n",
        "export DATA_DIR=xsum\n",
        "python run_eval.py google/pegasus-xsum \\\n",
        "    $DATA_DIR/test.source gens/peg_xsum_test_generation.txt \\\n",
        "    --reference_path $DATA_DIR/test.target \\\n",
        "    --score_path gens/peg_xsum_rouge.txt --task summarization \\\n",
        "    --device cuda \\\n",
        "    --bs 8"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version 1.6.0+cu101 available.\n",
            "2020-08-29 21:08:23.895870: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "TensorFlow version 2.3.0 available.\n",
            "Traceback (most recent call last):\n",
            "  File \"run_eval.py\", line 137, in <module>\n",
            "    run_generate()\n",
            "  File \"run_eval.py\", line 104, in run_generate\n",
            "    examples = [\" \" + x.rstrip() if \"t5\" in args.model_name else x.rstrip() for x in open(args.input_path).readlines()]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'xsum/test.source'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5pAV-OBYyzX",
        "colab_type": "text"
      },
      "source": [
        "**Training on Dcyphr Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjvoR88sZXjY",
        "colab_type": "text"
      },
      "source": [
        "Command to Finetune on the dcyphr dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0rUC-QMkJaV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b61703be-aa5a-4124-a809-6caac74334e5"
      },
      "source": [
        "%%bash\n",
        "export DATA_DIR=/content/dcyphr-NLP/fine_tuning_data\n",
        "python run_eval.py sshleifer/distilbart-cnn-12-6 $DATA_DIR/val.source dbart_val_generations.txt \\\n",
        "    --reference_path $DATA_DIR/val.target \\\n",
        "    --score_path cnn_rouge.json \\\n",
        "    --task summarization \\\n",
        "    --n_obs 100 \\\n",
        "    --device cuda \\\n",
        "    --bs 32"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'rouge1': 32.9453, 'rouge2': 9.8099, 'rougeL': 19.7652, 'n_obs': 20, 'runtime': 13.766160488128662, 'seconds_per_sample': 0.6883}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "PyTorch version 1.6.0+cu101 available.\n",
            "2020-08-29 21:08:32.962542: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "TensorFlow version 2.3.0 available.\n",
            "https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp2ce3wln4\n",
            "storing https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/config.json in cache at /root/.cache/torch/transformers/90dbb6d4e8ba2227a79a0e5cc64eb216091a1d5c362a83c52c6c242a44d89b50.e1484cfc83ca98dbf8dbb660097e95a5ef503f348dd354064e58fa28f5e3ae16\n",
            "creating metadata file for /root/.cache/torch/transformers/90dbb6d4e8ba2227a79a0e5cc64eb216091a1d5c362a83c52c6c242a44d89b50.e1484cfc83ca98dbf8dbb660097e95a5ef503f348dd354064e58fa28f5e3ae16\n",
            "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/config.json from cache at /root/.cache/torch/transformers/90dbb6d4e8ba2227a79a0e5cc64eb216091a1d5c362a83c52c6c242a44d89b50.e1484cfc83ca98dbf8dbb660097e95a5ef503f348dd354064e58fa28f5e3ae16\n",
            "Model config BartConfig {\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"force_bos_token_to_be_generated\": true,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 142,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 56,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"replacing_rate\": 0,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"student_decoder_layers\": null,\n",
            "  \"student_encoder_layers\": null,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4\n",
            "    }\n",
            "  },\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "https://cdn.huggingface.co/sshleifer/distilbart-cnn-12-6/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpvq7kar6_\n",
            "storing https://cdn.huggingface.co/sshleifer/distilbart-cnn-12-6/pytorch_model.bin in cache at /root/.cache/torch/transformers/14e37ad7876e80795e5bf0f13ddc7b83a8fb8dff8ef857451052bc2e34797003.71e977223cb272c823f1ee09496c0b291b1f230435f303707d15dcc6cfe9071f\n",
            "creating metadata file for /root/.cache/torch/transformers/14e37ad7876e80795e5bf0f13ddc7b83a8fb8dff8ef857451052bc2e34797003.71e977223cb272c823f1ee09496c0b291b1f230435f303707d15dcc6cfe9071f\n",
            "loading weights file https://cdn.huggingface.co/sshleifer/distilbart-cnn-12-6/pytorch_model.bin from cache at /root/.cache/torch/transformers/14e37ad7876e80795e5bf0f13ddc7b83a8fb8dff8ef857451052bc2e34797003.71e977223cb272c823f1ee09496c0b291b1f230435f303707d15dcc6cfe9071f\n",
            "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
            "\n",
            "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/distilbart-cnn-12-6.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
            "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/config.json from cache at /root/.cache/torch/transformers/90dbb6d4e8ba2227a79a0e5cc64eb216091a1d5c362a83c52c6c242a44d89b50.e1484cfc83ca98dbf8dbb660097e95a5ef503f348dd354064e58fa28f5e3ae16\n",
            "Model config BartConfig {\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"force_bos_token_to_be_generated\": true,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 142,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 56,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"replacing_rate\": 0,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"student_decoder_layers\": null,\n",
            "  \"student_encoder_layers\": null,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4\n",
            "    }\n",
            "  },\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "Model name 'sshleifer/distilbart-cnn-12-6' not found in model shortcut name list (facebook/bart-base, facebook/bart-large, facebook/bart-large-mnli, facebook/bart-large-cnn, facebook/bart-large-xsum, yjernite/bart_eli5). Assuming 'sshleifer/distilbart-cnn-12-6' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpaidofpdi\n",
            "storing https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/vocab.json in cache at /root/.cache/torch/transformers/c43535d7925e8df7929ff33258438f051b865efeb565a524105194edd7543aa2.6a4061e8fc00057d21d80413635a86fdcf55b6e7594ad9e25257d2f99a02f4be\n",
            "creating metadata file for /root/.cache/torch/transformers/c43535d7925e8df7929ff33258438f051b865efeb565a524105194edd7543aa2.6a4061e8fc00057d21d80413635a86fdcf55b6e7594ad9e25257d2f99a02f4be\n",
            "https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpkt4d6kub\n",
            "storing https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/merges.txt in cache at /root/.cache/torch/transformers/3d48487241499d5bcbcae41319e70e8e838f79b2ea1e8df5301e362d70fe3664.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "creating metadata file for /root/.cache/torch/transformers/3d48487241499d5bcbcae41319e70e8e838f79b2ea1e8df5301e362d70fe3664.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpzg1hy1g5\n",
            "storing https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/tokenizer_config.json in cache at /root/.cache/torch/transformers/0731a7027a83bcc6caa8200c7ed255653dbb2ea38a82a49b783401aa6ecfd028.d596a549211eb890d3bb341f3a03307b199bc2d5ed81b3451618cbcb04d1f1bc\n",
            "creating metadata file for /root/.cache/torch/transformers/0731a7027a83bcc6caa8200c7ed255653dbb2ea38a82a49b783401aa6ecfd028.d596a549211eb890d3bb341f3a03307b199bc2d5ed81b3451618cbcb04d1f1bc\n",
            "loading file https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/vocab.json from cache at /root/.cache/torch/transformers/c43535d7925e8df7929ff33258438f051b865efeb565a524105194edd7543aa2.6a4061e8fc00057d21d80413635a86fdcf55b6e7594ad9e25257d2f99a02f4be\n",
            "loading file https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/merges.txt from cache at /root/.cache/torch/transformers/3d48487241499d5bcbcae41319e70e8e838f79b2ea1e8df5301e362d70fe3664.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "loading file https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/added_tokens.json from cache at None\n",
            "loading file https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/special_tokens_map.json from cache at None\n",
            "loading file https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/tokenizer_config.json from cache at /root/.cache/torch/transformers/0731a7027a83bcc6caa8200c7ed255653dbb2ea38a82a49b783401aa6ecfd028.d596a549211eb890d3bb341f3a03307b199bc2d5ed81b3451618cbcb04d1f1bc\n",
            "loading file https://s3.amazonaws.com/models.huggingface.co/bert/sshleifer/distilbart-cnn-12-6/tokenizer.json from cache at None\n",
            "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:13<00:00, 13.77s/it]\r100%|██████████| 1/1 [00:13<00:00, 13.77s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8oiUsm8SgPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "be93eb34-4de1-4261-ff68-8002aa122cc6"
      },
      "source": [
        "%%bash\n",
        "ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bertabs\n",
            "callbacks.py\n",
            "cnn_rouge.json\n",
            "convert_model_to_fp16.py\n",
            "dbart_val_generations.txt\n",
            "distillation.py\n",
            "download_wmt.py\n",
            "finetune_bart_tiny.sh\n",
            "finetune_pegasus_xsum.sh\n",
            "finetune.py\n",
            "finetune.sh\n",
            "finetune_t5.sh\n",
            "gens\n",
            "initialization_utils.py\n",
            "__init__.py\n",
            "lightning_logs\n",
            "minify_dataset.py\n",
            "pack_dataset.py\n",
            "__pycache__\n",
            "README.md\n",
            "romanian_postprocessing.md\n",
            "run_distiller.sh\n",
            "run_eval.py\n",
            "test_bash_script.py\n",
            "test_data\n",
            "test_seq2seq_examples.py\n",
            "train_distilbart_cnn.sh\n",
            "train_distilbart_xsum.sh\n",
            "train_mbart_cc25_enro.sh\n",
            "utils.py\n",
            "xsum_pegasus_test_5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk_wTV6ZA2oZ",
        "colab_type": "text"
      },
      "source": [
        "Okay so the output of the data can be found at transformers/examples/seq2seq/dbart_val_generation"
      ]
    }
  ]
}