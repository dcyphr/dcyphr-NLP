{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SummaryBART.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0zxFlolZYeo"
      },
      "source": [
        "TO PREVENT CUDA OVERLOAD ERROR, PLEASE ERASE --fp16 form finetune.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGmlUZ6keNzC"
      },
      "source": [
        "Instructions for Use:\n",
        "1. Run notebook\n",
        "2. After installing the transformers repo , go to transformers/examples/seq2seq/finetuning.sh and erase the line saying --fp16\n",
        "3. After running the notebook, you can find the output at \n",
        " at transformers/examples/seq2seq/dbart_val_generation\n",
        "\n",
        "4. I have also loaded the model as model= ......\n",
        "You can use this model for summarisation tasks too.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGe2oG_aj4m1",
        "outputId": "b598df7b-1017-41ab-f1e1-daaacf070280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%bash\n",
        "python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPoI1pagaEfc",
        "outputId": "107d3247-4a51-452f-f8d4-65052612338c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%bash\n",
        "cd /content/\n",
        "git clone https://github.com/dcyphr/dcyphr-NLP.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dcyphr-NLP'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UIUTdW71oun",
        "outputId": "5c68bea8-1a3e-49b3-8d0e-7db56c23f4a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "%%bash\n",
        "git clone https://github.com/huggingface/transformers.git\n",
        "cd transformers\n",
        "pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/transformers\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "    Preparing wheel metadata: started\n",
            "    Preparing wheel metadata: finished with status 'done'\n",
            "Collecting sacremoses\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (20.4)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.3.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.3.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.3.1) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.3.1) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (2.10)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517): started\n",
            "  Building wheel for transformers (PEP 517): finished with status 'done'\n",
            "  Created wheel for transformers: filename=transformers-3.3.1-cp36-none-any.whl size=1082350 sha256=fb3185c908054f9897e55d1562c0d0cb3c0437ca257ce3912408b2d72007cf46\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rh7iq3yf/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "Successfully built transformers\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py): started\n",
            "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=a6ffc2611a3de9217258408d12ae14e82c268aa4e16e620ebe9cfd8107054937\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3end1B_E9vf",
        "outputId": "2a6f01b6-371c-4617-8cd2-0ff5f75e02c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%bash\n",
        "\n",
        "cd transformers\n",
        "cd examples\n",
        "ls\n",
        "\n",
        "pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adversarial\n",
            "benchmarking\n",
            "bert-loses-patience\n",
            "bertology\n",
            "conftest.py\n",
            "contrib\n",
            "deebert\n",
            "distillation\n",
            "language-modeling\n",
            "lightning_base.py\n",
            "longform-qa\n",
            "lxmert\n",
            "movement-pruning\n",
            "multiple-choice\n",
            "question-answering\n",
            "rag\n",
            "README.md\n",
            "requirements.txt\n",
            "seq2seq\n",
            "test_examples.py\n",
            "test_xla_examples.py\n",
            "text-classification\n",
            "text-generation\n",
            "token-classification\n",
            "xla_spawn.py\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.22.2.post1)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/9d/89d9ac5d6506f8368ba5ae53b054cf26bf796935eff6a1945431c7a5d485/seqeval-0.0.17.tar.gz\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (5.4.8)\n",
            "Collecting sacrebleu\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n",
            "Collecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (2.1.0)\n",
            "Collecting pytorch-lightning==0.8.5\n",
            "  Downloading https://files.pythonhosted.org/packages/32/64/65a5bd6b0c286217f2e53bb067c4099c0584a8eff1d229046b9a35ae3e26/pytorch_lightning-0.8.5-py3-none-any.whl (313kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (3.2.2)\n",
            "Collecting git-python==1.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/de/0cc6353a45cdb1e137cffac5383097b300cc578e2e1133eeb847e23a1394/git_python-1.0.3-py2.py3-none-any.whl\n",
            "Collecting faiss-cpu\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/84/9de38703486d9f00b1a63590887a318d08c52f10f768968bd7626aee75da/faiss_cpu-1.6.3-cp36-cp36m-manylinux2010_x86_64.whl (7.2MB)\n",
            "Collecting streamlit\n",
            "  Downloading https://files.pythonhosted.org/packages/6c/0d/bb0bd245beeeee38a19286718069ffeef1c651106cd4bbebae9091e4fc1f/streamlit-0.67.1-py2.py3-none-any.whl (7.2MB)\n",
            "Collecting elasticsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/b7/f8f03019089671486e2910282c1b6fce26ccc8a513322df72ac8994ab2de/elasticsearch-7.9.1-py2.py3-none-any.whl (219kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 14)) (3.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 15)) (1.1.2)\n",
            "Collecting datasets\n",
            "  Downloading https://files.pythonhosted.org/packages/ec/20/6bd7ff328180804d50abe38180558fc33a95e4113163b0828abb723573e3/datasets-1.1.0-py3-none-any.whl (147kB)\n",
            "Collecting fire\n",
            "  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 18)) (3.6.4)\n",
            "Collecting conllu\n",
            "  Downloading https://files.pythonhosted.org/packages/89/02/e5a55ac2c88166996d13871217206ef0f022479354b39a3ab47aad538a5d/conllu-4.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 1)) (50.3.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 1)) (1.17.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 1)) (0.35.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 1)) (1.7.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 1)) (3.12.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 1)) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 1)) (1.32.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->-r requirements.txt (line 3)) (2.4.3)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r requirements.txt (line 7)) (0.3.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r requirements.txt (line 7)) (2.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r requirements.txt (line 7)) (4.41.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r requirements.txt (line 7)) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r requirements.txt (line 7)) (0.24.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r requirements.txt (line 7)) (20.2.0)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.8.5->-r requirements.txt (line 8)) (1.6.0+cu101)\n",
            "Collecting PyYAML>=5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 9)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 9)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 9)) (2.4.7)\n",
            "Collecting gitpython\n",
            "  Downloading https://files.pythonhosted.org/packages/c0/d7/b2b0672e0331567157adf9281f41ee731c412ee518ca5e6552c27fa73c91/GitPython-3.1.9-py3-none-any.whl (159kB)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->-r requirements.txt (line 12)) (4.1.0)\n",
            "Collecting boto3\n",
            "  Downloading https://files.pythonhosted.org/packages/33/73/e90df0e0a5c55291273697d8eaa33f920b10590b5f632e971bb68ec55988/boto3-1.15.10-py2.py3-none-any.whl (129kB)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->-r requirements.txt (line 12)) (5.1.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from streamlit->-r requirements.txt (line 12)) (0.10.1)\n",
            "Collecting watchdog\n",
            "  Downloading https://files.pythonhosted.org/packages/0e/06/121302598a4fc01aca942d937f4a2c33430b7181137b35758913a8db10ad/watchdog-0.10.3.tar.gz (94kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->-r requirements.txt (line 12)) (7.1.2)\n",
            "Collecting botocore>=1.13.44\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/3f/e55f26983b7315265066f1cdc614e8d7e2c6a7a798ac6be88f3fdff90533/botocore-1.18.10-py2.py3-none-any.whl (6.7MB)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "  Downloading https://files.pythonhosted.org/packages/51/1e/296f4108bf357e684617a776ecaf06ee93b43e30c35996dfac1aa985aa6c/pydeck-0.5.0b1-py2.py3-none-any.whl (4.4MB)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->-r requirements.txt (line 12)) (4.1.1)\n",
            "Collecting validators\n",
            "  Downloading https://files.pythonhosted.org/packages/41/4a/3360ff3cf2b4a1b9721ac1fbff5f84663f41047d9874b3aa1ac82e862c44/validators-0.18.1-py3-none-any.whl\n",
            "Collecting blinker\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz (111kB)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.6/dist-packages (from streamlit->-r requirements.txt (line 12)) (0.8.1)\n",
            "Collecting enum-compat\n",
            "  Downloading https://files.pythonhosted.org/packages/55/ae/467bc4509246283bb59746e21a1a2f5a8aecbef56b1fa6eaca78cd438c8b/enum_compat-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->-r requirements.txt (line 12)) (7.0.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (from streamlit->-r requirements.txt (line 12)) (0.14.1)\n",
            "Collecting base58\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/03/58572025c77b9e6027155b272a1b96298e711cd4f95c24967f7137ab0c4b/base58-2.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.6/dist-packages (from streamlit->-r requirements.txt (line 12)) (1.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from streamlit->-r requirements.txt (line 12)) (20.4)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from elasticsearch->-r requirements.txt (line 13)) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from elasticsearch->-r requirements.txt (line 13)) (2020.6.20)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 15)) (2018.9)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets->-r requirements.txt (line 16)) (0.7)\n",
            "Collecting xxhash\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets->-r requirements.txt (line 16)) (0.70.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from datasets->-r requirements.txt (line 16)) (3.0.12)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 18)) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 18)) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 18)) (8.5.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r requirements.txt (line 18)) (1.9.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 1)) (4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r requirements.txt (line 3)) (2.10.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets->-r requirements.txt (line 7)) (1.52.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit->-r requirements.txt (line 12)) (2.11.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit->-r requirements.txt (line 12)) (0.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit->-r requirements.txt (line 12)) (2.6.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit->-r requirements.txt (line 12)) (0.11.1)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (4.3.3)\n",
            "Collecting ipykernel>=5.1.2; python_version >= \"3.4\"\n",
            "  Downloading https://files.pythonhosted.org/packages/52/19/c2812690d8b340987eecd2cbc18549b1d130b94c5d97fcbe49f5f8710edf/ipykernel-5.3.4-py3-none-any.whl (120kB)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (7.5.1)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from validators->streamlit->-r requirements.txt (line 12)) (4.4.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->-r requirements.txt (line 1)) (3.2.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->altair>=3.2.0->streamlit->-r requirements.txt (line 12)) (1.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (5.3.5)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (5.0.7)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (3.5.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (2.6.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (4.6.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (19.0.2)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (5.3.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.6.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.9.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (1.4.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (3.2.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.5.1)\n",
            "Building wheels for collected packages: seqeval, fire, PyYAML, watchdog, blinker, pathtools\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.17-cp36-none-any.whl size=7640 sha256=848fec0f0e34bd1fdd092131ee70380ced438d9acf06840cde6357e4b514c5ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/c8/cf/7b9d5d52984c08ce4d27d6f858a682ef74a3738f43f489166a\n",
            "  Building wheel for fire (setup.py): started\n",
            "  Building wheel for fire (setup.py): finished with status 'done'\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=5920b7b7dfc80f9b9d31a91523e86f9afc6b6615284357e16a0409a819ffe302\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "  Building wheel for PyYAML (setup.py): started\n",
            "  Building wheel for PyYAML (setup.py): finished with status 'done'\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44619 sha256=b06e2d8102dc5a293f6506daf68cf6acbe7e44448ed774c99516e76a533d5eee\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for watchdog (setup.py): started\n",
            "  Building wheel for watchdog (setup.py): finished with status 'done'\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.3-cp36-none-any.whl size=73873 sha256=8fbe02abb4449011d4ab9fa85b5bfaa7cf4d2138a6d3fceaf73d16e2dbdf689f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1d/38/2c19bb311f67cc7b4d07a2ec5ea36ab1a0a0ea50db994a5bc7\n",
            "  Building wheel for blinker (setup.py): started\n",
            "  Building wheel for blinker (setup.py): finished with status 'done'\n",
            "  Created wheel for blinker: filename=blinker-1.4-cp36-none-any.whl size=13450 sha256=c765c8fb653f3710596bc4aecb03781386ed843c5162efa987092eaf99cf4d49\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n",
            "  Building wheel for pathtools (setup.py): started\n",
            "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8785 sha256=df33adec6727e1864c3ebe8f15b1fba8da4ea7fd17c199e3c22c508d8a280099\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built seqeval fire PyYAML watchdog blinker pathtools\n",
            "Installing collected packages: seqeval, portalocker, sacrebleu, rouge-score, PyYAML, pytorch-lightning, smmap, gitdb, gitpython, git-python, faiss-cpu, jmespath, botocore, s3transfer, boto3, pathtools, watchdog, ipykernel, pydeck, validators, blinker, enum-compat, base58, streamlit, elasticsearch, xxhash, datasets, fire, conllu\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "Successfully installed PyYAML-5.3.1 base58-2.0.1 blinker-1.4 boto3-1.15.10 botocore-1.18.10 conllu-4.2 datasets-1.1.0 elasticsearch-7.9.1 enum-compat-0.0.3 faiss-cpu-1.6.3 fire-0.3.1 git-python-1.0.3 gitdb-4.0.5 gitpython-3.1.9 ipykernel-5.3.4 jmespath-0.10.0 pathtools-0.1.2 portalocker-2.0.0 pydeck-0.5.0b1 pytorch-lightning-0.8.5 rouge-score-0.0.4 s3transfer-0.3.3 sacrebleu-1.4.14 seqeval-0.0.17 smmap-3.0.4 streamlit-0.67.1 validators-0.18.1 watchdog-0.10.3 xxhash-2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.3.4 which is incompatible.\n",
            "ERROR: pytorch-lightning 0.8.5 has requirement future>=0.17.1, but you'll have future 0.16.0 which is incompatible.\n",
            "ERROR: datasets 1.1.0 has requirement pyarrow>=0.17.1, but you'll have pyarrow 0.14.1 which is incompatible.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOrWsz3MlVb9",
        "outputId": "238a7e90-c6ac-407a-d659-7f841c2abd95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!pip install pyarrow==0.16.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyarrow==0.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/d2/695bab1e1e7a4554b6dbd287d55cca096214bd441037058a432afd724bb1/pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1MB)\n",
            "\u001b[K     |████████████████████████████████| 63.2MB 51kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow==0.16.0) (1.18.5)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow==0.16.0) (1.15.0)\n",
            "\u001b[31mERROR: datasets 1.1.0 has requirement pyarrow>=0.17.1, but you'll have pyarrow 0.16.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyarrow\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed pyarrow-0.16.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc48Udgnq7ED",
        "outputId": "f84f9b74-cf17-4539-91a3-193129a8762c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%bash\n",
        "\n",
        "cd transformers\n",
        "cd examples\n",
        "cd seq2seq\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "./finetune.sh \\\n",
        "    --data_dir /content/dcyphr-NLP/fine_tuning_data/ \\\n",
        "    --train_batch_size=1 \\\n",
        "    --eval_batch_size=1 \\\n",
        "    --output_dir=xsum_results \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --n_train 100 \\\n",
        "    --n_val 100 \\\n",
        "    --model_name_or_path facebook/bart-large-cnn\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rValidation sanity check: 0it [00:00, ?it/s]\rValidation sanity check:  50%|█████     | 1/2 [00:02<00:02,  2.72s/it]\rValidation sanity check: 100%|██████████| 2/2 [00:04<00:00,  2.49s/it]\r                                                                      \r\rTraining: 0it [00:00, ?it/s]\rTraining:   0%|          | 0/300 [00:00<?, ?it/s]\rEpoch 1:   0%|          | 0/300 [00:00<?, ?it/s] \rEpoch 1:   0%|          | 1/300 [00:00<03:27,  1.44it/s]\rEpoch 1:   0%|          | 1/300 [00:00<03:27,  1.44it/s, loss=3.562, v_num=0]\rEpoch 1:   1%|          | 2/300 [00:01<02:35,  1.91it/s, loss=3.562, v_num=0]\rEpoch 1:   1%|          | 2/300 [00:01<02:35,  1.91it/s, loss=2.830, v_num=0]\rEpoch 1:   1%|          | 3/300 [00:01<02:14,  2.20it/s, loss=2.830, v_num=0]\rEpoch 1:   1%|          | 3/300 [00:01<02:14,  2.20it/s, loss=2.524, v_num=0]\rEpoch 1:   1%|▏         | 4/300 [00:01<02:11,  2.24it/s, loss=2.524, v_num=0]\rEpoch 1:   1%|▏         | 4/300 [00:01<02:11,  2.24it/s, loss=2.449, v_num=0]\rEpoch 1:   2%|▏         | 5/300 [00:02<02:20,  2.10it/s, loss=2.449, v_num=0]\rEpoch 1:   2%|▏         | 5/300 [00:02<02:20,  2.10it/s, loss=2.677, v_num=0]\rEpoch 1:   2%|▏         | 6/300 [00:02<02:09,  2.28it/s, loss=2.677, v_num=0]\rEpoch 1:   2%|▏         | 6/300 [00:02<02:09,  2.28it/s, loss=2.651, v_num=0]\rEpoch 1:   2%|▏         | 7/300 [00:03<02:14,  2.18it/s, loss=2.651, v_num=0]\rEpoch 1:   2%|▏         | 7/300 [00:03<02:14,  2.18it/s, loss=2.624, v_num=0]\rEpoch 1:   3%|▎         | 8/300 [00:03<02:19,  2.09it/s, loss=2.624, v_num=0]\rEpoch 1:   3%|▎         | 8/300 [00:03<02:19,  2.09it/s, loss=2.625, v_num=0]\rEpoch 1:   3%|▎         | 9/300 [00:04<02:12,  2.19it/s, loss=2.625, v_num=0]\rEpoch 1:   3%|▎         | 9/300 [00:04<02:12,  2.19it/s, loss=2.524, v_num=0]\rEpoch 1:   3%|▎         | 10/300 [00:04<02:12,  2.19it/s, loss=2.524, v_num=0]\rEpoch 1:   3%|▎         | 10/300 [00:04<02:12,  2.18it/s, loss=2.430, v_num=0]\n",
            "\rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\rValidating:   5%|▌         | 1/20 [00:02<00:41,  2.19s/it]\u001b[A\rEpoch 1:   4%|▎         | 11/300 [00:06<02:57,  1.63it/s, loss=2.430, v_num=0]\n",
            "\rValidating:  10%|█         | 2/20 [00:03<00:37,  2.07s/it]\u001b[A\rEpoch 1:   4%|▍         | 12/300 [00:08<03:25,  1.40it/s, loss=2.430, v_num=0]\n",
            "\rValidating:  15%|█▌        | 3/20 [00:06<00:35,  2.10s/it]\u001b[A\rEpoch 1:   4%|▍         | 13/300 [00:10<03:56,  1.21it/s, loss=2.430, v_num=0]\n",
            "\rValidating:  20%|██        | 4/20 [00:08<00:33,  2.11s/it]\u001b[A\rEpoch 1:   5%|▍         | 14/300 [00:12<04:22,  1.09it/s, loss=2.430, v_num=0]\n",
            "\rValidating:  25%|██▌       | 5/20 [00:10<00:31,  2.07s/it]\u001b[A\rEpoch 1:   5%|▌         | 15/300 [00:14<04:41,  1.01it/s, loss=2.430, v_num=0]\n",
            "\rValidating:  30%|███       | 6/20 [00:12<00:28,  2.05s/it]\u001b[A\rEpoch 1:   5%|▌         | 16/300 [00:16<04:58,  1.05s/it, loss=2.430, v_num=0]\n",
            "\rValidating:  35%|███▌      | 7/20 [00:14<00:27,  2.09s/it]\u001b[A\rEpoch 1:   6%|▌         | 17/300 [00:19<05:16,  1.12s/it, loss=2.430, v_num=0]\n",
            "\rValidating:  40%|████      | 8/20 [00:16<00:24,  2.04s/it]\u001b[A\rEpoch 1:   6%|▌         | 18/300 [00:20<05:28,  1.16s/it, loss=2.430, v_num=0]\n",
            "\rValidating:  45%|████▌     | 9/20 [00:18<00:23,  2.16s/it]\u001b[A\rEpoch 1:   6%|▋         | 19/300 [00:23<05:45,  1.23s/it, loss=2.430, v_num=0]\n",
            "\rValidating:  50%|█████     | 10/20 [00:20<00:21,  2.12s/it]\u001b[A\rEpoch 1:   7%|▋         | 20/300 [00:25<05:55,  1.27s/it, loss=2.430, v_num=0]\n",
            "\rValidating:  55%|█████▌    | 11/20 [00:23<00:19,  2.15s/it]\u001b[A\rEpoch 1:   7%|▋         | 21/300 [00:27<06:07,  1.32s/it, loss=2.430, v_num=0]\n",
            "\rValidating:  60%|██████    | 12/20 [00:25<00:17,  2.23s/it]\u001b[A\rEpoch 1:   7%|▋         | 22/300 [00:30<06:19,  1.37s/it, loss=2.430, v_num=0]\n",
            "\rValidating:  65%|██████▌   | 13/20 [00:27<00:16,  2.30s/it]\u001b[A\rEpoch 1:   8%|▊         | 23/300 [00:32<06:31,  1.41s/it, loss=2.430, v_num=0]\n",
            "\rValidating:  70%|███████   | 14/20 [00:30<00:13,  2.24s/it]\u001b[A\rEpoch 1:   8%|▊         | 24/300 [00:34<06:37,  1.44s/it, loss=2.430, v_num=0]\n",
            "\rValidating:  75%|███████▌  | 15/20 [00:32<00:11,  2.33s/it]\u001b[A\rEpoch 1:   8%|▊         | 25/300 [00:37<06:48,  1.49s/it, loss=2.430, v_num=0]\n",
            "\rValidating:  80%|████████  | 16/20 [00:34<00:09,  2.27s/it]\u001b[A\rEpoch 1:   9%|▊         | 26/300 [00:39<06:53,  1.51s/it, loss=2.430, v_num=0]\n",
            "\rValidating:  85%|████████▌ | 17/20 [00:36<00:06,  2.20s/it]\u001b[A\rEpoch 1:   9%|▉         | 27/300 [00:41<06:57,  1.53s/it, loss=2.430, v_num=0]\n",
            "\rValidating:  90%|█████████ | 18/20 [00:39<00:04,  2.28s/it]\u001b[A\rEpoch 1:   9%|▉         | 28/300 [00:43<07:05,  1.56s/it, loss=2.430, v_num=0]\n",
            "\rValidating:  95%|█████████▌| 19/20 [00:41<00:02,  2.17s/it]\u001b[A\rEpoch 1:  10%|▉         | 29/300 [00:45<07:07,  1.58s/it, loss=2.430, v_num=0]\n",
            "\rValidating: 100%|██████████| 20/20 [00:43<00:00,  2.14s/it]\u001b[A\rEpoch 1:  10%|█         | 30/300 [00:47<07:09,  1.59s/it, loss=2.430, v_num=0]\rEpoch 1:  10%|█         | 30/300 [03:00<27:05,  6.02s/it, loss=2.430, v_num=0]\n",
            "\r                                                           \u001b[A\rEpoch 1:  10%|█         | 31/300 [03:01<26:11,  5.84s/it, loss=2.430, v_num=0]\rEpoch 1:  10%|█         | 31/300 [03:01<26:11,  5.84s/it, loss=2.549, v_num=0]\rEpoch 1:  11%|█         | 32/300 [03:01<25:21,  5.68s/it, loss=2.549, v_num=0]\rEpoch 1:  11%|█         | 32/300 [03:01<25:21,  5.68s/it, loss=2.537, v_num=0]\rEpoch 1:  11%|█         | 33/300 [03:02<24:32,  5.52s/it, loss=2.537, v_num=0]\rEpoch 1:  11%|█         | 33/300 [03:02<24:32,  5.52s/it, loss=2.517, v_num=0]\rEpoch 1:  11%|█▏        | 34/300 [03:02<23:48,  5.37s/it, loss=2.517, v_num=0]\rEpoch 1:  11%|█▏        | 34/300 [03:02<23:48,  5.37s/it, loss=2.405, v_num=0]\rEpoch 1:  12%|█▏        | 35/300 [03:02<23:05,  5.23s/it, loss=2.405, v_num=0]\rEpoch 1:  12%|█▏        | 35/300 [03:02<23:05,  5.23s/it, loss=2.375, v_num=0]\rEpoch 1:  12%|█▏        | 36/300 [03:03<22:24,  5.09s/it, loss=2.375, v_num=0]\rEpoch 1:  12%|█▏        | 36/300 [03:03<22:24,  5.09s/it, loss=2.277, v_num=0]\rEpoch 1:  12%|█▏        | 37/300 [03:03<21:47,  4.97s/it, loss=2.277, v_num=0]\rEpoch 1:  12%|█▏        | 37/300 [03:03<21:47,  4.97s/it, loss=2.224, v_num=0]\rEpoch 1:  13%|█▎        | 38/300 [03:04<21:10,  4.85s/it, loss=2.224, v_num=0]\rEpoch 1:  13%|█▎        | 38/300 [03:04<21:10,  4.85s/it, loss=2.363, v_num=0]\rEpoch 1:  13%|█▎        | 39/300 [03:04<20:36,  4.74s/it, loss=2.363, v_num=0]\rEpoch 1:  13%|█▎        | 39/300 [03:04<20:36,  4.74s/it, loss=2.368, v_num=0]\rEpoch 1:  13%|█▎        | 40/300 [03:05<20:03,  4.63s/it, loss=2.368, v_num=0]\rEpoch 1:  13%|█▎        | 40/300 [03:05<20:03,  4.63s/it, loss=2.374, v_num=0]\n",
            "\rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\rValidating:   5%|▌         | 1/20 [00:02<00:43,  2.31s/it]\u001b[A\rEpoch 1:  14%|█▎        | 41/300 [03:07<19:44,  4.57s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  10%|█         | 2/20 [00:04<00:39,  2.18s/it]\u001b[A\rEpoch 1:  14%|█▍        | 42/300 [03:09<19:23,  4.51s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  15%|█▌        | 3/20 [00:05<00:34,  2.06s/it]\u001b[A\rEpoch 1:  14%|█▍        | 43/300 [03:11<19:02,  4.45s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  20%|██        | 4/20 [00:07<00:32,  2.05s/it]\u001b[A\rEpoch 1:  15%|█▍        | 44/300 [03:13<18:44,  4.39s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  25%|██▌       | 5/20 [00:09<00:29,  1.99s/it]\u001b[A\rEpoch 1:  15%|█▌        | 45/300 [03:15<18:25,  4.33s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  30%|███       | 6/20 [00:12<00:28,  2.05s/it]\u001b[A\rEpoch 1:  15%|█▌        | 46/300 [03:17<18:08,  4.29s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  35%|███▌      | 7/20 [00:13<00:25,  1.99s/it]\u001b[A\rEpoch 1:  16%|█▌        | 47/300 [03:19<17:51,  4.24s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  40%|████      | 8/20 [00:15<00:23,  1.92s/it]\u001b[A\rEpoch 1:  16%|█▌        | 48/300 [03:20<17:34,  4.18s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  45%|████▌     | 9/20 [00:17<00:21,  1.99s/it]\u001b[A\rEpoch 1:  16%|█▋        | 49/300 [03:22<17:19,  4.14s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  50%|█████     | 10/20 [00:19<00:19,  1.99s/it]\u001b[A\rEpoch 1:  17%|█▋        | 50/300 [03:24<17:04,  4.10s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  55%|█████▌    | 11/20 [00:21<00:18,  2.06s/it]\u001b[A\rEpoch 1:  17%|█▋        | 51/300 [03:27<16:51,  4.06s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  60%|██████    | 12/20 [00:24<00:16,  2.10s/it]\u001b[A\rEpoch 1:  17%|█▋        | 52/300 [03:29<16:38,  4.03s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  65%|██████▌   | 13/20 [00:26<00:15,  2.23s/it]\u001b[A\rEpoch 1:  18%|█▊        | 53/300 [03:31<16:27,  4.00s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  70%|███████   | 14/20 [00:29<00:13,  2.25s/it]\u001b[A\rEpoch 1:  18%|█▊        | 54/300 [03:34<16:15,  3.97s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  75%|███████▌  | 15/20 [00:31<00:11,  2.29s/it]\u001b[A\rEpoch 1:  18%|█▊        | 55/300 [03:36<16:04,  3.94s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  80%|████████  | 16/20 [00:33<00:08,  2.21s/it]\u001b[A\rEpoch 1:  19%|█▊        | 56/300 [03:38<15:52,  3.90s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  85%|████████▌ | 17/20 [00:35<00:06,  2.22s/it]\u001b[A\rEpoch 1:  19%|█▉        | 57/300 [03:40<15:41,  3.87s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  90%|█████████ | 18/20 [00:37<00:04,  2.20s/it]\u001b[A\rEpoch 1:  19%|█▉        | 58/300 [03:43<15:30,  3.84s/it, loss=2.374, v_num=0]\n",
            "\rValidating:  95%|█████████▌| 19/20 [00:39<00:02,  2.12s/it]\u001b[A\rEpoch 1:  20%|█▉        | 59/300 [03:44<15:18,  3.81s/it, loss=2.374, v_num=0]\n",
            "\rValidating: 100%|██████████| 20/20 [00:42<00:00,  2.22s/it]\u001b[A\rEpoch 1:  20%|██        | 60/300 [03:47<15:09,  3.79s/it, loss=2.374, v_num=0]\rEpoch 1:  20%|██        | 60/300 [03:47<15:10,  3.79s/it, loss=2.374, v_num=0]\n",
            "\r                                                           \u001b[A\rEpoch 1:  20%|██        | 61/300 [03:47<14:52,  3.74s/it, loss=2.374, v_num=0]\rEpoch 1:  20%|██        | 61/300 [03:47<14:52,  3.74s/it, loss=2.297, v_num=0]\rEpoch 1:  21%|██        | 62/300 [03:48<14:37,  3.69s/it, loss=2.297, v_num=0]\rEpoch 1:  21%|██        | 62/300 [03:48<14:37,  3.69s/it, loss=2.343, v_num=0]\rEpoch 1:  21%|██        | 63/300 [03:48<14:21,  3.63s/it, loss=2.343, v_num=0]\rEpoch 1:  21%|██        | 63/300 [03:48<14:21,  3.63s/it, loss=2.336, v_num=0]\rEpoch 1:  21%|██▏       | 64/300 [03:49<14:06,  3.59s/it, loss=2.336, v_num=0]\rEpoch 1:  21%|██▏       | 64/300 [03:49<14:06,  3.59s/it, loss=2.407, v_num=0]\rEpoch 1:  22%|██▏       | 65/300 [03:50<13:52,  3.54s/it, loss=2.407, v_num=0]\rEpoch 1:  22%|██▏       | 65/300 [03:50<13:52,  3.54s/it, loss=2.347, v_num=0]\rEpoch 1:  22%|██▏       | 66/300 [03:50<13:38,  3.50s/it, loss=2.347, v_num=0]\rEpoch 1:  22%|██▏       | 66/300 [03:50<13:38,  3.50s/it, loss=2.316, v_num=0]\rEpoch 1:  22%|██▏       | 67/300 [03:51<13:24,  3.45s/it, loss=2.316, v_num=0]\rEpoch 1:  22%|██▏       | 67/300 [03:51<13:24,  3.45s/it, loss=2.313, v_num=0]\rEpoch 1:  23%|██▎       | 68/300 [03:52<13:12,  3.41s/it, loss=2.313, v_num=0]\rEpoch 1:  23%|██▎       | 68/300 [03:52<13:12,  3.41s/it, loss=2.281, v_num=0]\rEpoch 1:  23%|██▎       | 69/300 [03:52<12:59,  3.37s/it, loss=2.281, v_num=0]\rEpoch 1:  23%|██▎       | 69/300 [03:52<12:59,  3.37s/it, loss=2.303, v_num=0]\rEpoch 1:  23%|██▎       | 70/300 [03:53<12:46,  3.33s/it, loss=2.303, v_num=0]\rEpoch 1:  23%|██▎       | 70/300 [03:53<12:46,  3.33s/it, loss=2.309, v_num=0]\n",
            "\rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\rValidating:   5%|▌         | 1/20 [00:02<00:47,  2.47s/it]\u001b[A\rEpoch 1:  24%|██▎       | 71/300 [03:55<12:40,  3.32s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  10%|█         | 2/20 [00:04<00:42,  2.39s/it]\u001b[A\rEpoch 1:  24%|██▍       | 72/300 [03:57<12:33,  3.30s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  15%|█▌        | 3/20 [00:06<00:38,  2.27s/it]\u001b[A\rEpoch 1:  24%|██▍       | 73/300 [03:59<12:25,  3.29s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  20%|██        | 4/20 [00:08<00:35,  2.22s/it]\u001b[A\rEpoch 1:  25%|██▍       | 74/300 [04:01<12:19,  3.27s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  25%|██▌       | 5/20 [00:10<00:31,  2.07s/it]\u001b[A\rEpoch 1:  25%|██▌       | 75/300 [04:03<12:11,  3.25s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  30%|███       | 6/20 [00:12<00:29,  2.08s/it]\u001b[A\rEpoch 1:  25%|██▌       | 76/300 [04:05<12:04,  3.23s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  35%|███▌      | 7/20 [00:14<00:26,  2.06s/it]\u001b[A\rEpoch 1:  26%|██▌       | 77/300 [04:07<11:57,  3.22s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  40%|████      | 8/20 [00:16<00:23,  1.99s/it]\u001b[A\rEpoch 1:  26%|██▌       | 78/300 [04:09<11:50,  3.20s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  45%|████▌     | 9/20 [00:19<00:24,  2.21s/it]\u001b[A\rEpoch 1:  26%|██▋       | 79/300 [04:12<11:46,  3.19s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  50%|█████     | 10/20 [00:21<00:21,  2.16s/it]\u001b[A\rEpoch 1:  27%|██▋       | 80/300 [04:14<11:39,  3.18s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  55%|█████▌    | 11/20 [00:23<00:20,  2.22s/it]\u001b[A\rEpoch 1:  27%|██▋       | 81/300 [04:16<11:34,  3.17s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  60%|██████    | 12/20 [00:26<00:18,  2.37s/it]\u001b[A\rEpoch 1:  27%|██▋       | 82/300 [04:19<11:29,  3.17s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  65%|██████▌   | 13/20 [00:28<00:16,  2.39s/it]\u001b[A\rEpoch 1:  28%|██▊       | 83/300 [04:21<11:24,  3.16s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  70%|███████   | 14/20 [00:30<00:13,  2.30s/it]\u001b[A\rEpoch 1:  28%|██▊       | 84/300 [04:24<11:18,  3.14s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  75%|███████▌  | 15/20 [00:32<00:11,  2.26s/it]\u001b[A\rEpoch 1:  28%|██▊       | 85/300 [04:26<11:13,  3.13s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  80%|████████  | 16/20 [00:35<00:09,  2.25s/it]\u001b[A\rEpoch 1:  29%|██▊       | 86/300 [04:28<11:07,  3.12s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  85%|████████▌ | 17/20 [00:37<00:06,  2.21s/it]\u001b[A\rEpoch 1:  29%|██▉       | 87/300 [04:30<11:02,  3.11s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  90%|█████████ | 18/20 [00:39<00:04,  2.22s/it]\u001b[A\rEpoch 1:  29%|██▉       | 88/300 [04:32<10:57,  3.10s/it, loss=2.309, v_num=0]\n",
            "\rValidating:  95%|█████████▌| 19/20 [00:41<00:02,  2.14s/it]\u001b[A\rEpoch 1:  30%|██▉       | 89/300 [04:34<10:51,  3.09s/it, loss=2.309, v_num=0]\n",
            "\rValidating: 100%|██████████| 20/20 [00:43<00:00,  2.07s/it]\u001b[A\rEpoch 1:  30%|███       | 90/300 [04:36<10:45,  3.07s/it, loss=2.309, v_num=0]\rEpoch 1:  30%|███       | 90/300 [06:49<15:55,  4.55s/it, loss=2.309, v_num=0]\n",
            "\r                                                           \u001b[A\rEpoch 1:  30%|███       | 91/300 [06:49<15:41,  4.51s/it, loss=2.309, v_num=0]\rEpoch 1:  30%|███       | 91/300 [06:49<15:41,  4.51s/it, loss=2.254, v_num=0]\rEpoch 1:  31%|███       | 92/300 [06:50<15:27,  4.46s/it, loss=2.254, v_num=0]\rEpoch 1:  31%|███       | 92/300 [06:50<15:27,  4.46s/it, loss=2.259, v_num=0]\rEpoch 1:  31%|███       | 93/300 [06:51<15:14,  4.42s/it, loss=2.259, v_num=0]\rEpoch 1:  31%|███       | 93/300 [06:51<15:14,  4.42s/it, loss=2.271, v_num=0]\rEpoch 1:  31%|███▏      | 94/300 [06:51<15:01,  4.38s/it, loss=2.271, v_num=0]\rEpoch 1:  31%|███▏      | 94/300 [06:51<15:01,  4.38s/it, loss=2.358, v_num=0]\rEpoch 1:  32%|███▏      | 95/300 [06:51<14:48,  4.34s/it, loss=2.358, v_num=0]\rEpoch 1:  32%|███▏      | 95/300 [06:51<14:48,  4.34s/it, loss=2.421, v_num=0]\rEpoch 1:  32%|███▏      | 96/300 [06:52<14:36,  4.29s/it, loss=2.421, v_num=0]\rEpoch 1:  32%|███▏      | 96/300 [06:52<14:36,  4.29s/it, loss=2.502, v_num=0]\rEpoch 1:  32%|███▏      | 97/300 [06:52<14:23,  4.25s/it, loss=2.502, v_num=0]\rEpoch 1:  32%|███▏      | 97/300 [06:52<14:23,  4.25s/it, loss=2.536, v_num=0]\rEpoch 1:  33%|███▎      | 98/300 [06:52<14:11,  4.21s/it, loss=2.536, v_num=0]\rEpoch 1:  33%|███▎      | 98/300 [06:52<14:11,  4.21s/it, loss=2.341, v_num=0]\rEpoch 1:  33%|███▎      | 99/300 [06:53<13:58,  4.17s/it, loss=2.341, v_num=0]\rEpoch 1:  33%|███▎      | 99/300 [06:53<13:58,  4.17s/it, loss=2.360, v_num=0]\rEpoch 1:  33%|███▎      | 100/300 [06:53<13:47,  4.14s/it, loss=2.360, v_num=0]\rEpoch 1:  33%|███▎      | 100/300 [06:53<13:47,  4.14s/it, loss=2.340, v_num=0]\n",
            "\rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\rValidating:   5%|▌         | 1/20 [00:02<00:47,  2.49s/it]\u001b[A\rEpoch 1:  34%|███▎      | 101/300 [06:56<13:40,  4.12s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  10%|█         | 2/20 [00:04<00:43,  2.42s/it]\u001b[A\rEpoch 1:  34%|███▍      | 102/300 [06:58<13:32,  4.10s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  15%|█▌        | 3/20 [00:06<00:37,  2.22s/it]\u001b[A\rEpoch 1:  34%|███▍      | 103/300 [07:00<13:24,  4.08s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  20%|██        | 4/20 [00:08<00:36,  2.28s/it]\u001b[A\rEpoch 1:  35%|███▍      | 104/300 [07:02<13:16,  4.07s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  25%|██▌       | 5/20 [00:10<00:32,  2.17s/it]\u001b[A\rEpoch 1:  35%|███▌      | 105/300 [07:04<13:08,  4.04s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  30%|███       | 6/20 [00:12<00:29,  2.14s/it]\u001b[A\rEpoch 1:  35%|███▌      | 106/300 [07:06<13:01,  4.03s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  35%|███▌      | 7/20 [00:15<00:28,  2.18s/it]\u001b[A\rEpoch 1:  36%|███▌      | 107/300 [07:09<12:53,  4.01s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  40%|████      | 8/20 [00:16<00:24,  2.06s/it]\u001b[A\rEpoch 1:  36%|███▌      | 108/300 [07:10<12:45,  3.99s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  45%|████▌     | 9/20 [00:19<00:24,  2.20s/it]\u001b[A\rEpoch 1:  36%|███▋      | 109/300 [07:13<12:39,  3.98s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  50%|█████     | 10/20 [00:21<00:22,  2.23s/it]\u001b[A\rEpoch 1:  37%|███▋      | 110/300 [07:15<12:32,  3.96s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  55%|█████▌    | 11/20 [00:24<00:20,  2.29s/it]\u001b[A\rEpoch 1:  37%|███▋      | 111/300 [07:18<12:25,  3.95s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  60%|██████    | 12/20 [00:27<00:19,  2.49s/it]\u001b[A\rEpoch 1:  37%|███▋      | 112/300 [07:21<12:20,  3.94s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  65%|██████▌   | 13/20 [00:29<00:17,  2.52s/it]\u001b[A\rEpoch 1:  38%|███▊      | 113/300 [07:23<12:14,  3.93s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  70%|███████   | 14/20 [00:32<00:14,  2.48s/it]\u001b[A\rEpoch 1:  38%|███▊      | 114/300 [07:25<12:07,  3.91s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  75%|███████▌  | 15/20 [00:34<00:12,  2.59s/it]\u001b[A\rEpoch 1:  38%|███▊      | 115/300 [07:28<12:02,  3.90s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  80%|████████  | 16/20 [00:37<00:10,  2.53s/it]\u001b[A\rEpoch 1:  39%|███▊      | 116/300 [07:31<11:55,  3.89s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  85%|████████▌ | 17/20 [00:39<00:07,  2.38s/it]\u001b[A\rEpoch 1:  39%|███▉      | 117/300 [07:33<11:48,  3.87s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  90%|█████████ | 18/20 [00:41<00:04,  2.29s/it]\u001b[A\rEpoch 1:  39%|███▉      | 118/300 [07:35<11:42,  3.86s/it, loss=2.340, v_num=0]\n",
            "\rValidating:  95%|█████████▌| 19/20 [00:43<00:02,  2.16s/it]\u001b[A\rEpoch 1:  40%|███▉      | 119/300 [07:37<11:35,  3.84s/it, loss=2.340, v_num=0]\n",
            "\rValidating: 100%|██████████| 20/20 [00:45<00:00,  2.20s/it]\u001b[A\rEpoch 1:  40%|████      | 120/300 [07:39<11:29,  3.83s/it, loss=2.340, v_num=0]\rEpoch 1:  40%|████      | 120/300 [07:39<11:29,  3.83s/it, loss=2.340, v_num=0]\n",
            "\r                                                           \u001b[A\rEpoch 1:  40%|████      | 121/300 [07:39<11:20,  3.80s/it, loss=2.340, v_num=0]\rEpoch 1:  40%|████      | 121/300 [07:39<11:20,  3.80s/it, loss=2.351, v_num=0]\rEpoch 1:  41%|████      | 122/300 [07:40<11:11,  3.77s/it, loss=2.351, v_num=0]\rEpoch 1:  41%|████      | 122/300 [07:40<11:11,  3.77s/it, loss=2.351, v_num=0]\rEpoch 1:  41%|████      | 123/300 [07:41<11:03,  3.75s/it, loss=2.351, v_num=0]\rEpoch 1:  41%|████      | 123/300 [07:41<11:03,  3.75s/it, loss=2.411, v_num=0]\rEpoch 1:  41%|████▏     | 124/300 [07:41<10:55,  3.72s/it, loss=2.411, v_num=0]\rEpoch 1:  41%|████▏     | 124/300 [07:41<10:55,  3.72s/it, loss=2.315, v_num=0]\rEpoch 1:  42%|████▏     | 125/300 [07:41<10:46,  3.70s/it, loss=2.315, v_num=0]\rEpoch 1:  42%|████▏     | 125/300 [07:41<10:46,  3.70s/it, loss=2.238, v_num=0]\rEpoch 1:  42%|████▏     | 126/300 [07:42<10:38,  3.67s/it, loss=2.238, v_num=0]\rEpoch 1:  42%|████▏     | 126/300 [07:42<10:38,  3.67s/it, loss=2.220, v_num=0]\rEpoch 1:  42%|████▏     | 127/300 [07:42<10:30,  3.65s/it, loss=2.220, v_num=0]\rEpoch 1:  42%|████▏     | 127/300 [07:42<10:30,  3.65s/it, loss=2.215, v_num=0]\rEpoch 1:  43%|████▎     | 128/300 [07:43<10:22,  3.62s/it, loss=2.215, v_num=0]\rEpoch 1:  43%|████▎     | 128/300 [07:43<10:22,  3.62s/it, loss=2.231, v_num=0]\rEpoch 1:  43%|████▎     | 129/300 [07:43<10:14,  3.59s/it, loss=2.231, v_num=0]\rEpoch 1:  43%|████▎     | 129/300 [07:43<10:14,  3.59s/it, loss=2.268, v_num=0]\rEpoch 1:  43%|████▎     | 130/300 [07:44<10:07,  3.57s/it, loss=2.268, v_num=0]\rEpoch 1:  43%|████▎     | 130/300 [07:44<10:07,  3.57s/it, loss=2.250, v_num=0]\n",
            "\rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\rValidating:   5%|▌         | 1/20 [00:02<00:51,  2.70s/it]\u001b[A\rEpoch 1:  44%|████▎     | 131/300 [07:47<10:02,  3.57s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  10%|█         | 2/20 [00:04<00:45,  2.53s/it]\u001b[A\rEpoch 1:  44%|████▍     | 132/300 [07:49<09:57,  3.56s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  15%|█▌        | 3/20 [00:06<00:39,  2.31s/it]\u001b[A\rEpoch 1:  44%|████▍     | 133/300 [07:51<09:51,  3.54s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  20%|██        | 4/20 [00:09<00:37,  2.36s/it]\u001b[A\rEpoch 1:  45%|████▍     | 134/300 [07:53<09:46,  3.53s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  25%|██▌       | 5/20 [00:10<00:32,  2.16s/it]\u001b[A\rEpoch 1:  45%|████▌     | 135/300 [07:55<09:40,  3.52s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  30%|███       | 6/20 [00:12<00:29,  2.11s/it]\u001b[A\rEpoch 1:  45%|████▌     | 136/300 [07:57<09:35,  3.51s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  35%|███▌      | 7/20 [00:14<00:26,  2.04s/it]\u001b[A\rEpoch 1:  46%|████▌     | 137/300 [07:59<09:30,  3.50s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  40%|████      | 8/20 [00:16<00:23,  1.94s/it]\u001b[A\rEpoch 1:  46%|████▌     | 138/300 [08:00<09:24,  3.48s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  45%|████▌     | 9/20 [00:18<00:22,  2.02s/it]\u001b[A\rEpoch 1:  46%|████▋     | 139/300 [08:03<09:19,  3.47s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  50%|█████     | 10/20 [00:21<00:22,  2.25s/it]\u001b[A\rEpoch 1:  47%|████▋     | 140/300 [08:05<09:15,  3.47s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  55%|█████▌    | 11/20 [00:23<00:20,  2.27s/it]\u001b[A\rEpoch 1:  47%|████▋     | 141/300 [08:08<09:10,  3.46s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  60%|██████    | 12/20 [00:26<00:19,  2.41s/it]\u001b[A\rEpoch 1:  47%|████▋     | 142/300 [08:10<09:06,  3.46s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  65%|██████▌   | 13/20 [00:28<00:16,  2.35s/it]\u001b[A\rEpoch 1:  48%|████▊     | 143/300 [08:13<09:01,  3.45s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  70%|███████   | 14/20 [00:30<00:13,  2.31s/it]\u001b[A\rEpoch 1:  48%|████▊     | 144/300 [08:15<08:56,  3.44s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  75%|███████▌  | 15/20 [00:33<00:12,  2.41s/it]\u001b[A\rEpoch 1:  48%|████▊     | 145/300 [08:17<08:52,  3.43s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  80%|████████  | 16/20 [00:35<00:09,  2.34s/it]\u001b[A\rEpoch 1:  49%|████▊     | 146/300 [08:20<08:47,  3.43s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  85%|████████▌ | 17/20 [00:37<00:06,  2.26s/it]\u001b[A\rEpoch 1:  49%|████▉     | 147/300 [08:22<08:42,  3.42s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  90%|█████████ | 18/20 [00:39<00:04,  2.25s/it]\u001b[A\rEpoch 1:  49%|████▉     | 148/300 [08:24<08:38,  3.41s/it, loss=2.250, v_num=0]\n",
            "\rValidating:  95%|█████████▌| 19/20 [00:42<00:02,  2.38s/it]\u001b[A\rEpoch 1:  50%|████▉     | 149/300 [08:27<08:33,  3.40s/it, loss=2.250, v_num=0]\n",
            "\rValidating: 100%|██████████| 20/20 [00:44<00:00,  2.29s/it]\u001b[A\rEpoch 1:  50%|█████     | 150/300 [08:29<08:29,  3.39s/it, loss=2.250, v_num=0]\rEpoch 1:  50%|█████     | 150/300 [08:29<08:29,  3.40s/it, loss=2.250, v_num=0]\n",
            "\r                                                           \u001b[A\rEpoch 1:  50%|█████     | 151/300 [08:29<08:23,  3.38s/it, loss=2.250, v_num=0]\rEpoch 1:  50%|█████     | 151/300 [08:29<08:23,  3.38s/it, loss=2.269, v_num=0]\rEpoch 1:  51%|█████     | 152/300 [08:30<08:16,  3.36s/it, loss=2.269, v_num=0]\rEpoch 1:  51%|█████     | 152/300 [08:30<08:16,  3.36s/it, loss=2.273, v_num=0]\rEpoch 1:  51%|█████     | 153/300 [08:30<08:10,  3.34s/it, loss=2.273, v_num=0]\rEpoch 1:  51%|█████     | 153/300 [08:30<08:10,  3.34s/it, loss=2.254, v_num=0]\rEpoch 1:  51%|█████▏    | 154/300 [08:31<08:04,  3.32s/it, loss=2.254, v_num=0]\rEpoch 1:  51%|█████▏    | 154/300 [08:31<08:04,  3.32s/it, loss=2.249, v_num=0]\rEpoch 1:  52%|█████▏    | 155/300 [08:31<07:58,  3.30s/it, loss=2.249, v_num=0]\rEpoch 1:  52%|█████▏    | 155/300 [08:31<07:58,  3.30s/it, loss=2.189, v_num=0]\rEpoch 1:  52%|█████▏    | 156/300 [08:32<07:52,  3.28s/it, loss=2.189, v_num=0]\rEpoch 1:  52%|█████▏    | 156/300 [08:32<07:52,  3.28s/it, loss=2.157, v_num=0]\rEpoch 1:  52%|█████▏    | 157/300 [08:32<07:46,  3.26s/it, loss=2.157, v_num=0]\rEpoch 1:  52%|█████▏    | 157/300 [08:32<07:46,  3.26s/it, loss=2.132, v_num=0]\rEpoch 1:  53%|█████▎    | 158/300 [08:33<07:41,  3.25s/it, loss=2.132, v_num=0]\rEpoch 1:  53%|█████▎    | 158/300 [08:33<07:41,  3.25s/it, loss=2.262, v_num=0]\rEpoch 1:  53%|█████▎    | 159/300 [08:33<07:35,  3.23s/it, loss=2.262, v_num=0]\rEpoch 1:  53%|█████▎    | 159/300 [08:33<07:35,  3.23s/it, loss=2.207, v_num=0]\rEpoch 1:  53%|█████▎    | 160/300 [08:34<07:29,  3.21s/it, loss=2.207, v_num=0]\rEpoch 1:  53%|█████▎    | 160/300 [08:34<07:29,  3.21s/it, loss=2.205, v_num=0]\n",
            "\rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\rValidating:   5%|▌         | 1/20 [00:02<00:56,  3.00s/it]\u001b[A\rEpoch 1:  54%|█████▎    | 161/300 [08:37<07:26,  3.21s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  10%|█         | 2/20 [00:05<00:49,  2.74s/it]\u001b[A\rEpoch 1:  54%|█████▍    | 162/300 [08:39<07:22,  3.21s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  15%|█▌        | 3/20 [00:06<00:41,  2.46s/it]\u001b[A\rEpoch 1:  54%|█████▍    | 163/300 [08:41<07:18,  3.20s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  20%|██        | 4/20 [00:09<00:39,  2.45s/it]\u001b[A\rEpoch 1:  55%|█████▍    | 164/300 [08:43<07:14,  3.19s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  25%|██▌       | 5/20 [00:11<00:33,  2.22s/it]\u001b[A\rEpoch 1:  55%|█████▌    | 165/300 [08:45<07:09,  3.18s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  30%|███       | 6/20 [00:13<00:32,  2.30s/it]\u001b[A\rEpoch 1:  55%|█████▌    | 166/300 [08:47<07:06,  3.18s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  35%|███▌      | 7/20 [00:15<00:28,  2.20s/it]\u001b[A\rEpoch 1:  56%|█████▌    | 167/300 [08:49<07:01,  3.17s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  40%|████      | 8/20 [00:17<00:24,  2.06s/it]\u001b[A\rEpoch 1:  56%|█████▌    | 168/300 [08:51<06:57,  3.16s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  45%|████▌     | 9/20 [00:20<00:25,  2.35s/it]\u001b[A\rEpoch 1:  56%|█████▋    | 169/300 [08:54<06:54,  3.16s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  50%|█████     | 10/20 [00:23<00:24,  2.49s/it]\u001b[A\rEpoch 1:  57%|█████▋    | 170/300 [08:57<06:50,  3.16s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  55%|█████▌    | 11/20 [00:25<00:21,  2.41s/it]\u001b[A\rEpoch 1:  57%|█████▋    | 171/300 [08:59<06:47,  3.16s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  60%|██████    | 12/20 [00:28<00:20,  2.56s/it]\u001b[A\rEpoch 1:  57%|█████▋    | 172/300 [09:02<06:43,  3.15s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  65%|██████▌   | 13/20 [00:30<00:17,  2.55s/it]\u001b[A\rEpoch 1:  58%|█████▊    | 173/300 [09:04<06:40,  3.15s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  70%|███████   | 14/20 [00:33<00:15,  2.54s/it]\u001b[A\rEpoch 1:  58%|█████▊    | 174/300 [09:07<06:36,  3.15s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  75%|███████▌  | 15/20 [00:35<00:12,  2.53s/it]\u001b[A\rEpoch 1:  58%|█████▊    | 175/300 [09:10<06:32,  3.14s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  80%|████████  | 16/20 [00:37<00:09,  2.38s/it]\u001b[A\rEpoch 1:  59%|█████▊    | 176/300 [09:12<06:28,  3.14s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  85%|████████▌ | 17/20 [00:39<00:06,  2.25s/it]\u001b[A\rEpoch 1:  59%|█████▉    | 177/300 [09:13<06:24,  3.13s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  90%|█████████ | 18/20 [00:42<00:04,  2.26s/it]\u001b[A\rEpoch 1:  59%|█████▉    | 178/300 [09:16<06:21,  3.13s/it, loss=2.205, v_num=0]\n",
            "\rValidating:  95%|█████████▌| 19/20 [00:44<00:02,  2.39s/it]\u001b[A\rEpoch 1:  60%|█████▉    | 179/300 [09:18<06:17,  3.12s/it, loss=2.205, v_num=0]\n",
            "\rValidating: 100%|██████████| 20/20 [00:46<00:00,  2.33s/it]\u001b[A\rEpoch 1:  60%|██████    | 180/300 [09:21<06:14,  3.12s/it, loss=2.205, v_num=0]\rEpoch 1:  60%|██████    | 180/300 [09:21<06:14,  3.12s/it, loss=2.205, v_num=0]\n",
            "\r                                                           \u001b[A\rEpoch 1:  60%|██████    | 181/300 [09:21<06:09,  3.10s/it, loss=2.205, v_num=0]\rEpoch 1:  60%|██████    | 181/300 [09:21<06:09,  3.10s/it, loss=2.145, v_num=0]\rEpoch 1:  61%|██████    | 182/300 [09:22<06:04,  3.09s/it, loss=2.145, v_num=0]\rEpoch 1:  61%|██████    | 182/300 [09:22<06:04,  3.09s/it, loss=2.119, v_num=0]\rEpoch 1:  61%|██████    | 183/300 [09:22<05:59,  3.07s/it, loss=2.119, v_num=0]\rEpoch 1:  61%|██████    | 183/300 [09:22<05:59,  3.07s/it, loss=2.077, v_num=0]\rEpoch 1:  61%|██████▏   | 184/300 [09:23<05:55,  3.06s/it, loss=2.077, v_num=0]\rEpoch 1:  61%|██████▏   | 184/300 [09:23<05:55,  3.06s/it, loss=2.075, v_num=0]\rEpoch 1:  62%|██████▏   | 185/300 [09:23<05:50,  3.05s/it, loss=2.075, v_num=0]\rEpoch 1:  62%|██████▏   | 185/300 [09:23<05:50,  3.05s/it, loss=2.133, v_num=0]\rEpoch 1:  62%|██████▏   | 186/300 [09:23<05:45,  3.03s/it, loss=2.133, v_num=0]\rEpoch 1:  62%|██████▏   | 186/300 [09:23<05:45,  3.03s/it, loss=2.165, v_num=0]\rEpoch 1:  62%|██████▏   | 187/300 [09:24<05:40,  3.02s/it, loss=2.165, v_num=0]\rEpoch 1:  62%|██████▏   | 187/300 [09:24<05:40,  3.02s/it, loss=2.150, v_num=0]\rEpoch 1:  63%|██████▎   | 188/300 [09:24<05:36,  3.00s/it, loss=2.150, v_num=0]\rEpoch 1:  63%|██████▎   | 188/300 [09:24<05:36,  3.00s/it, loss=2.147, v_num=0]\rEpoch 1:  63%|██████▎   | 189/300 [09:24<05:31,  2.99s/it, loss=2.147, v_num=0]\rEpoch 1:  63%|██████▎   | 189/300 [09:24<05:31,  2.99s/it, loss=2.054, v_num=0]\rEpoch 1:  63%|██████▎   | 190/300 [09:25<05:27,  2.97s/it, loss=2.054, v_num=0]\rEpoch 1:  63%|██████▎   | 190/300 [09:25<05:27,  2.97s/it, loss=2.121, v_num=0]\n",
            "\rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\rValidating:   5%|▌         | 1/20 [00:02<00:45,  2.38s/it]\u001b[A\rEpoch 1:  64%|██████▎   | 191/300 [09:27<05:23,  2.97s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  10%|█         | 2/20 [00:04<00:40,  2.23s/it]\u001b[A\rEpoch 1:  64%|██████▍   | 192/300 [09:29<05:20,  2.97s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  15%|█▌        | 3/20 [00:06<00:37,  2.18s/it]\u001b[A\rEpoch 1:  64%|██████▍   | 193/300 [09:31<05:16,  2.96s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  20%|██        | 4/20 [00:09<00:37,  2.33s/it]\u001b[A\rEpoch 1:  65%|██████▍   | 194/300 [09:34<05:13,  2.96s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  25%|██▌       | 5/20 [00:10<00:32,  2.13s/it]\u001b[A\rEpoch 1:  65%|██████▌   | 195/300 [09:35<05:09,  2.95s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  30%|███       | 6/20 [00:12<00:30,  2.17s/it]\u001b[A\rEpoch 1:  65%|██████▌   | 196/300 [09:37<05:06,  2.95s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  35%|███▌      | 7/20 [00:14<00:27,  2.13s/it]\u001b[A\rEpoch 1:  66%|██████▌   | 197/300 [09:40<05:03,  2.94s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  40%|████      | 8/20 [00:16<00:24,  2.00s/it]\u001b[A\rEpoch 1:  66%|██████▌   | 198/300 [09:41<04:59,  2.94s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  45%|████▌     | 9/20 [00:19<00:25,  2.34s/it]\u001b[A\rEpoch 1:  66%|██████▋   | 199/300 [09:44<04:56,  2.94s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  50%|█████     | 10/20 [00:22<00:23,  2.32s/it]\u001b[A\rEpoch 1:  67%|██████▋   | 200/300 [09:47<04:53,  2.94s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  55%|█████▌    | 11/20 [00:24<00:21,  2.39s/it]\u001b[A\rEpoch 1:  67%|██████▋   | 201/300 [09:49<04:50,  2.93s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  60%|██████    | 12/20 [00:27<00:20,  2.55s/it]\u001b[A\rEpoch 1:  67%|██████▋   | 202/300 [09:52<04:47,  2.93s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  65%|██████▌   | 13/20 [00:30<00:19,  2.75s/it]\u001b[A\rEpoch 1:  68%|██████▊   | 203/300 [09:55<04:44,  2.93s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  70%|███████   | 14/20 [00:33<00:15,  2.65s/it]\u001b[A\rEpoch 1:  68%|██████▊   | 204/300 [09:58<04:41,  2.93s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  75%|███████▌  | 15/20 [00:35<00:13,  2.68s/it]\u001b[A\rEpoch 1:  68%|██████▊   | 205/300 [10:00<04:38,  2.93s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  80%|████████  | 16/20 [00:38<00:10,  2.66s/it]\u001b[A\rEpoch 1:  69%|██████▊   | 206/300 [10:03<04:35,  2.93s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  85%|████████▌ | 17/20 [00:40<00:07,  2.52s/it]\u001b[A\rEpoch 1:  69%|██████▉   | 207/300 [10:05<04:32,  2.93s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  90%|█████████ | 18/20 [00:43<00:05,  2.56s/it]\u001b[A\rEpoch 1:  69%|██████▉   | 208/300 [10:08<04:29,  2.93s/it, loss=2.121, v_num=0]\n",
            "\rValidating:  95%|█████████▌| 19/20 [00:45<00:02,  2.50s/it]\u001b[A\rEpoch 1:  70%|██████▉   | 209/300 [10:10<04:25,  2.92s/it, loss=2.121, v_num=0]\n",
            "\rValidating: 100%|██████████| 20/20 [00:47<00:00,  2.40s/it]\u001b[A\rEpoch 1:  70%|███████   | 210/300 [10:12<04:22,  2.92s/it, loss=2.121, v_num=0]\rEpoch 1:  70%|███████   | 210/300 [10:13<04:22,  2.92s/it, loss=2.121, v_num=0]\n",
            "\r                                                           \u001b[A\rEpoch 1:  70%|███████   | 211/300 [10:13<04:18,  2.91s/it, loss=2.121, v_num=0]\rEpoch 1:  70%|███████   | 211/300 [10:13<04:18,  2.91s/it, loss=2.122, v_num=0]\rEpoch 1:  71%|███████   | 212/300 [10:13<04:14,  2.89s/it, loss=2.122, v_num=0]\rEpoch 1:  71%|███████   | 212/300 [10:13<04:14,  2.89s/it, loss=2.065, v_num=0]\rEpoch 1:  71%|███████   | 213/300 [10:14<04:10,  2.88s/it, loss=2.065, v_num=0]\rEpoch 1:  71%|███████   | 213/300 [10:14<04:10,  2.88s/it, loss=2.071, v_num=0]\rEpoch 1:  71%|███████▏  | 214/300 [10:14<04:06,  2.87s/it, loss=2.071, v_num=0]\rEpoch 1:  71%|███████▏  | 214/300 [10:14<04:06,  2.87s/it, loss=2.041, v_num=0]\rEpoch 1:  72%|███████▏  | 215/300 [10:14<04:03,  2.86s/it, loss=2.041, v_num=0]\rEpoch 1:  72%|███████▏  | 215/300 [10:14<04:03,  2.86s/it, loss=2.048, v_num=0]\rEpoch 1:  72%|███████▏  | 216/300 [10:15<03:59,  2.85s/it, loss=2.048, v_num=0]\rEpoch 1:  72%|███████▏  | 216/300 [10:15<03:59,  2.85s/it, loss=2.060, v_num=0]\rEpoch 1:  72%|███████▏  | 217/300 [10:15<03:55,  2.84s/it, loss=2.060, v_num=0]\rEpoch 1:  72%|███████▏  | 217/300 [10:15<03:55,  2.84s/it, loss=2.135, v_num=0]\rEpoch 1:  73%|███████▎  | 218/300 [10:15<03:51,  2.82s/it, loss=2.135, v_num=0]\rEpoch 1:  73%|███████▎  | 218/300 [10:15<03:51,  2.82s/it, loss=2.089, v_num=0]\rEpoch 1:  73%|███████▎  | 219/300 [10:16<03:47,  2.81s/it, loss=2.089, v_num=0]\rEpoch 1:  73%|███████▎  | 219/300 [10:16<03:47,  2.81s/it, loss=2.145, v_num=0]\rEpoch 1:  73%|███████▎  | 220/300 [10:16<03:44,  2.80s/it, loss=2.145, v_num=0]\rEpoch 1:  73%|███████▎  | 220/300 [10:16<03:44,  2.80s/it, loss=2.171, v_num=0]\n",
            "\rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\rValidating:   5%|▌         | 1/20 [00:02<00:45,  2.42s/it]\u001b[A\rEpoch 1:  74%|███████▎  | 221/300 [10:18<03:41,  2.80s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  10%|█         | 2/20 [00:04<00:43,  2.41s/it]\u001b[A\rEpoch 1:  74%|███████▍  | 222/300 [10:21<03:38,  2.80s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  15%|█▌        | 3/20 [00:07<00:40,  2.37s/it]\u001b[A\rEpoch 1:  74%|███████▍  | 223/300 [10:23<03:35,  2.80s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  20%|██        | 4/20 [00:09<00:39,  2.50s/it]\u001b[A\rEpoch 1:  75%|███████▍  | 224/300 [10:26<03:32,  2.80s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  25%|██▌       | 5/20 [00:11<00:33,  2.26s/it]\u001b[A\rEpoch 1:  75%|███████▌  | 225/300 [10:28<03:29,  2.79s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  30%|███       | 6/20 [00:14<00:32,  2.33s/it]\u001b[A\rEpoch 1:  75%|███████▌  | 226/300 [10:30<03:26,  2.79s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  35%|███▌      | 7/20 [00:16<00:29,  2.26s/it]\u001b[A\rEpoch 1:  76%|███████▌  | 227/300 [10:32<03:23,  2.79s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  40%|████      | 8/20 [00:18<00:26,  2.19s/it]\u001b[A\rEpoch 1:  76%|███████▌  | 228/300 [10:34<03:20,  2.78s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  45%|████▌     | 9/20 [00:21<00:26,  2.39s/it]\u001b[A\rEpoch 1:  76%|███████▋  | 229/300 [10:37<03:17,  2.78s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  50%|█████     | 10/20 [00:23<00:23,  2.39s/it]\u001b[A\rEpoch 1:  77%|███████▋  | 230/300 [10:39<03:14,  2.78s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  55%|█████▌    | 11/20 [00:25<00:21,  2.39s/it]\u001b[A\rEpoch 1:  77%|███████▋  | 231/300 [10:42<03:11,  2.78s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  60%|██████    | 12/20 [00:28<00:20,  2.52s/it]\u001b[A\rEpoch 1:  77%|███████▋  | 232/300 [10:45<03:09,  2.78s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  65%|██████▌   | 13/20 [00:31<00:17,  2.57s/it]\u001b[A\rEpoch 1:  78%|███████▊  | 233/300 [10:47<03:06,  2.78s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  70%|███████   | 14/20 [00:33<00:14,  2.43s/it]\u001b[A\rEpoch 1:  78%|███████▊  | 234/300 [10:49<03:03,  2.78s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  75%|███████▌  | 15/20 [00:35<00:11,  2.39s/it]\u001b[A\rEpoch 1:  78%|███████▊  | 235/300 [10:52<03:00,  2.78s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  80%|████████  | 16/20 [00:38<00:09,  2.35s/it]\u001b[A\rEpoch 1:  79%|███████▊  | 236/300 [10:54<02:57,  2.77s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  85%|████████▌ | 17/20 [00:40<00:06,  2.26s/it]\u001b[A\rEpoch 1:  79%|███████▉  | 237/300 [10:56<02:54,  2.77s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  90%|█████████ | 18/20 [00:42<00:04,  2.37s/it]\u001b[A\rEpoch 1:  79%|███████▉  | 238/300 [10:59<02:51,  2.77s/it, loss=2.171, v_num=0]\n",
            "\rValidating:  95%|█████████▌| 19/20 [00:45<00:02,  2.51s/it]\u001b[A\rEpoch 1:  80%|███████▉  | 239/300 [11:02<02:48,  2.77s/it, loss=2.171, v_num=0]\n",
            "\rValidating: 100%|██████████| 20/20 [00:47<00:00,  2.40s/it]\u001b[A\rEpoch 1:  80%|████████  | 240/300 [11:04<02:46,  2.77s/it, loss=2.171, v_num=0]\rEpoch 1:  80%|████████  | 240/300 [11:04<02:46,  2.77s/it, loss=2.171, v_num=0]\n",
            "\r                                                           \u001b[A\rEpoch 1:  80%|████████  | 241/300 [11:04<02:42,  2.76s/it, loss=2.171, v_num=0]\rEpoch 1:  80%|████████  | 241/300 [11:04<02:42,  2.76s/it, loss=2.191, v_num=0]\rEpoch 1:  81%|████████  | 242/300 [11:05<02:39,  2.75s/it, loss=2.191, v_num=0]\rEpoch 1:  81%|████████  | 242/300 [11:05<02:39,  2.75s/it, loss=2.160, v_num=0]\rEpoch 1:  81%|████████  | 243/300 [11:05<02:36,  2.74s/it, loss=2.160, v_num=0]\rEpoch 1:  81%|████████  | 243/300 [11:05<02:36,  2.74s/it, loss=2.195, v_num=0]\rEpoch 1:  81%|████████▏ | 244/300 [11:06<02:32,  2.73s/it, loss=2.195, v_num=0]\rEpoch 1:  81%|████████▏ | 244/300 [11:06<02:32,  2.73s/it, loss=2.261, v_num=0]\rEpoch 1:  82%|████████▏ | 245/300 [11:06<02:29,  2.72s/it, loss=2.261, v_num=0]\rEpoch 1:  82%|████████▏ | 245/300 [11:06<02:29,  2.72s/it, loss=2.275, v_num=0]\rEpoch 1:  82%|████████▏ | 246/300 [11:07<02:26,  2.71s/it, loss=2.275, v_num=0]\rEpoch 1:  82%|████████▏ | 246/300 [11:07<02:26,  2.71s/it, loss=2.261, v_num=0]\rEpoch 1:  82%|████████▏ | 247/300 [11:07<02:23,  2.70s/it, loss=2.261, v_num=0]\rEpoch 1:  82%|████████▏ | 247/300 [11:07<02:23,  2.70s/it, loss=2.245, v_num=0]\rEpoch 1:  83%|████████▎ | 248/300 [11:08<02:20,  2.69s/it, loss=2.245, v_num=0]\rEpoch 1:  83%|████████▎ | 248/300 [11:08<02:20,  2.69s/it, loss=2.179, v_num=0]\rEpoch 1:  83%|████████▎ | 249/300 [11:08<02:17,  2.69s/it, loss=2.179, v_num=0]\rEpoch 1:  83%|████████▎ | 249/300 [11:08<02:17,  2.69s/it, loss=2.184, v_num=0]\rEpoch 1:  83%|████████▎ | 250/300 [11:09<02:13,  2.68s/it, loss=2.184, v_num=0]\rEpoch 1:  83%|████████▎ | 250/300 [11:09<02:13,  2.68s/it, loss=2.239, v_num=0]\n",
            "\rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\rValidating:   5%|▌         | 1/20 [00:02<00:42,  2.26s/it]\u001b[A\rEpoch 1:  84%|████████▎ | 251/300 [11:11<02:11,  2.68s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  10%|█         | 2/20 [00:04<00:38,  2.14s/it]\u001b[A\rEpoch 1:  84%|████████▍ | 252/300 [11:13<02:08,  2.67s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  15%|█▌        | 3/20 [00:06<00:36,  2.15s/it]\u001b[A\rEpoch 1:  84%|████████▍ | 253/300 [11:15<02:05,  2.67s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  20%|██        | 4/20 [00:08<00:36,  2.28s/it]\u001b[A\rEpoch 1:  85%|████████▍ | 254/300 [11:18<02:02,  2.67s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  25%|██▌       | 5/20 [00:10<00:31,  2.10s/it]\u001b[A\rEpoch 1:  85%|████████▌ | 255/300 [11:20<02:00,  2.67s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  30%|███       | 6/20 [00:12<00:30,  2.17s/it]\u001b[A\rEpoch 1:  85%|████████▌ | 256/300 [11:22<01:57,  2.67s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  35%|███▌      | 7/20 [00:15<00:28,  2.21s/it]\u001b[A\rEpoch 1:  86%|████████▌ | 257/300 [11:24<01:54,  2.66s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  40%|████      | 8/20 [00:17<00:25,  2.15s/it]\u001b[A\rEpoch 1:  86%|████████▌ | 258/300 [11:26<01:51,  2.66s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  45%|████▌     | 9/20 [00:20<00:26,  2.37s/it]\u001b[A\rEpoch 1:  86%|████████▋ | 259/300 [11:29<01:49,  2.66s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  50%|█████     | 10/20 [00:22<00:23,  2.32s/it]\u001b[A\rEpoch 1:  87%|████████▋ | 260/300 [11:31<01:46,  2.66s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  55%|█████▌    | 11/20 [00:24<00:21,  2.35s/it]\u001b[A\rEpoch 1:  87%|████████▋ | 261/300 [11:34<01:43,  2.66s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  60%|██████    | 12/20 [00:27<00:20,  2.51s/it]\u001b[A\rEpoch 1:  87%|████████▋ | 262/300 [11:37<01:41,  2.66s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  65%|██████▌   | 13/20 [00:30<00:17,  2.51s/it]\u001b[A\rEpoch 1:  88%|████████▊ | 263/300 [11:39<01:38,  2.66s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  70%|███████   | 14/20 [00:32<00:14,  2.45s/it]\u001b[A\rEpoch 1:  88%|████████▊ | 264/300 [11:41<01:35,  2.66s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  75%|███████▌  | 15/20 [00:34<00:12,  2.45s/it]\u001b[A\rEpoch 1:  88%|████████▊ | 265/300 [11:44<01:33,  2.66s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  80%|████████  | 16/20 [00:36<00:09,  2.33s/it]\u001b[A\rEpoch 1:  89%|████████▊ | 266/300 [11:46<01:30,  2.66s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  85%|████████▌ | 17/20 [00:39<00:06,  2.30s/it]\u001b[A\rEpoch 1:  89%|████████▉ | 267/300 [11:48<01:27,  2.65s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  90%|█████████ | 18/20 [00:41<00:04,  2.41s/it]\u001b[A\rEpoch 1:  89%|████████▉ | 268/300 [11:51<01:24,  2.65s/it, loss=2.239, v_num=0]\n",
            "\rValidating:  95%|█████████▌| 19/20 [00:44<00:02,  2.46s/it]\u001b[A\rEpoch 1:  90%|████████▉ | 269/300 [11:53<01:22,  2.65s/it, loss=2.239, v_num=0]\n",
            "\rValidating: 100%|██████████| 20/20 [00:46<00:00,  2.40s/it]\u001b[A\rEpoch 1:  90%|█████████ | 270/300 [11:56<01:19,  2.65s/it, loss=2.239, v_num=0]\rEpoch 1:  90%|█████████ | 270/300 [11:56<01:19,  2.65s/it, loss=2.239, v_num=0]\n",
            "\r                                                           \u001b[A\rEpoch 1:  90%|█████████ | 271/300 [11:56<01:16,  2.64s/it, loss=2.239, v_num=0]\rEpoch 1:  90%|█████████ | 271/300 [11:56<01:16,  2.64s/it, loss=2.177, v_num=0]\rEpoch 1:  91%|█████████ | 272/300 [11:56<01:13,  2.64s/it, loss=2.177, v_num=0]\rEpoch 1:  91%|█████████ | 272/300 [11:56<01:13,  2.64s/it, loss=2.203, v_num=0]\rEpoch 1:  91%|█████████ | 273/300 [11:57<01:10,  2.63s/it, loss=2.203, v_num=0]\rEpoch 1:  91%|█████████ | 273/300 [11:57<01:10,  2.63s/it, loss=2.234, v_num=0]\rEpoch 1:  91%|█████████▏| 274/300 [11:58<01:08,  2.62s/it, loss=2.234, v_num=0]\rEpoch 1:  91%|█████████▏| 274/300 [11:58<01:08,  2.62s/it, loss=2.191, v_num=0]\rEpoch 1:  92%|█████████▏| 275/300 [11:58<01:05,  2.61s/it, loss=2.191, v_num=0]\rEpoch 1:  92%|█████████▏| 275/300 [11:58<01:05,  2.61s/it, loss=2.196, v_num=0]\rEpoch 1:  92%|█████████▏| 276/300 [11:59<01:02,  2.61s/it, loss=2.196, v_num=0]\rEpoch 1:  92%|█████████▏| 276/300 [11:59<01:02,  2.61s/it, loss=2.178, v_num=0]\rEpoch 1:  92%|█████████▏| 277/300 [11:59<00:59,  2.60s/it, loss=2.178, v_num=0]\rEpoch 1:  92%|█████████▏| 277/300 [11:59<00:59,  2.60s/it, loss=2.096, v_num=0]\rEpoch 1:  93%|█████████▎| 278/300 [12:00<00:57,  2.59s/it, loss=2.096, v_num=0]\rEpoch 1:  93%|█████████▎| 278/300 [12:00<00:57,  2.59s/it, loss=2.055, v_num=0]\rEpoch 1:  93%|█████████▎| 279/300 [12:00<00:54,  2.58s/it, loss=2.055, v_num=0]\rEpoch 1:  93%|█████████▎| 279/300 [12:00<00:54,  2.58s/it, loss=1.997, v_num=0]\rEpoch 1:  93%|█████████▎| 280/300 [12:01<00:51,  2.58s/it, loss=1.997, v_num=0]\rEpoch 1:  93%|█████████▎| 280/300 [12:01<00:51,  2.58s/it, loss=2.001, v_num=0]\n",
            "\rValidating: 0it [00:00, ?it/s]\u001b[A\n",
            "\rValidating:   5%|▌         | 1/20 [00:02<00:46,  2.46s/it]\u001b[A\rEpoch 1:  94%|█████████▎| 281/300 [12:03<00:48,  2.58s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  10%|█         | 2/20 [00:04<00:41,  2.32s/it]\u001b[A\rEpoch 1:  94%|█████████▍| 282/300 [12:05<00:46,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  15%|█▌        | 3/20 [00:06<00:39,  2.31s/it]\u001b[A\rEpoch 1:  94%|█████████▍| 283/300 [12:08<00:43,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  20%|██        | 4/20 [00:09<00:38,  2.38s/it]\u001b[A\rEpoch 1:  95%|█████████▍| 284/300 [12:10<00:41,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  25%|██▌       | 5/20 [00:11<00:33,  2.23s/it]\u001b[A\rEpoch 1:  95%|█████████▌| 285/300 [12:12<00:38,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  30%|███       | 6/20 [00:13<00:31,  2.28s/it]\u001b[A\rEpoch 1:  95%|█████████▌| 286/300 [12:14<00:35,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  35%|███▌      | 7/20 [00:16<00:31,  2.40s/it]\u001b[A\rEpoch 1:  96%|█████████▌| 287/300 [12:17<00:33,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  40%|████      | 8/20 [00:18<00:26,  2.23s/it]\u001b[A\rEpoch 1:  96%|█████████▌| 288/300 [12:19<00:30,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  45%|████▌     | 9/20 [00:20<00:26,  2.37s/it]\u001b[A\rEpoch 1:  96%|█████████▋| 289/300 [12:22<00:28,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  50%|█████     | 10/20 [00:22<00:22,  2.29s/it]\u001b[A\rEpoch 1:  97%|█████████▋| 290/300 [12:24<00:25,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  55%|█████▌    | 11/20 [00:25<00:21,  2.35s/it]\u001b[A\rEpoch 1:  97%|█████████▋| 291/300 [12:26<00:23,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  60%|██████    | 12/20 [00:28<00:21,  2.71s/it]\u001b[A\rEpoch 1:  97%|█████████▋| 292/300 [12:30<00:20,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  65%|██████▌   | 13/20 [00:31<00:18,  2.71s/it]\u001b[A\rEpoch 1:  98%|█████████▊| 293/300 [12:32<00:17,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  70%|███████   | 14/20 [00:34<00:15,  2.62s/it]\u001b[A\rEpoch 1:  98%|█████████▊| 294/300 [12:35<00:15,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  75%|███████▌  | 15/20 [00:36<00:13,  2.61s/it]\u001b[A\rEpoch 1:  98%|█████████▊| 295/300 [12:37<00:12,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  80%|████████  | 16/20 [00:38<00:09,  2.42s/it]\u001b[A\rEpoch 1:  99%|█████████▊| 296/300 [12:39<00:10,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  85%|████████▌ | 17/20 [00:40<00:06,  2.32s/it]\u001b[A\rEpoch 1:  99%|█████████▉| 297/300 [12:41<00:07,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  90%|█████████ | 18/20 [00:43<00:04,  2.39s/it]\u001b[A\rEpoch 1:  99%|█████████▉| 298/300 [12:44<00:05,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating:  95%|█████████▌| 19/20 [00:45<00:02,  2.40s/it]\u001b[A\rEpoch 1: 100%|█████████▉| 299/300 [12:46<00:02,  2.57s/it, loss=2.001, v_num=0]\n",
            "\rValidating: 100%|██████████| 20/20 [00:47<00:00,  2.36s/it]\u001b[A\rEpoch 1: 100%|██████████| 300/300 [12:49<00:00,  2.56s/it, loss=2.001, v_num=0]\rEpoch 1: 100%|██████████| 300/300 [12:49<00:00,  2.56s/it, loss=2.001, v_num=0]\n",
            "\r                                                           \u001b[A\rEpoch 1: 100%|██████████| 300/300 [12:49<00:00,  2.56s/it, loss=2.001, v_num=0]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-02 18:44:38.142429: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "\rDownloading:   0%|          | 0.00/1.34k [00:00<?, ?B/s]\rDownloading: 100%|██████████| 1.34k/1.34k [00:00<00:00, 1.12MB/s]\n",
            "\rDownloading:   0%|          | 0.00/899k [00:00<?, ?B/s]\rDownloading:   4%|▍         | 34.8k/899k [00:00<00:03, 254kB/s]\rDownloading:  23%|██▎       | 209k/899k [00:00<00:02, 334kB/s] \rDownloading: 100%|██████████| 899k/899k [00:00<00:00, 2.50MB/s]\n",
            "\rDownloading:   0%|          | 0.00/456k [00:00<?, ?B/s]\rDownloading:  11%|█▏        | 52.2k/456k [00:00<00:00, 428kB/s]\rDownloading:  53%|█████▎    | 244k/456k [00:00<00:00, 547kB/s] \rDownloading: 100%|██████████| 456k/456k [00:00<00:00, 1.83MB/s]\n",
            "\rDownloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]\rDownloading:   0%|          | 4.83M/1.63G [00:00<00:33, 48.3MB/s]\rDownloading:   1%|          | 11.8M/1.63G [00:00<00:30, 53.2MB/s]\rDownloading:   1%|          | 17.5M/1.63G [00:00<00:29, 54.3MB/s]\rDownloading:   1%|▏         | 22.8M/1.63G [00:00<00:29, 53.9MB/s]\rDownloading:   2%|▏         | 28.8M/1.63G [00:00<00:28, 55.6MB/s]\rDownloading:   2%|▏         | 33.6M/1.63G [00:00<00:31, 50.8MB/s]\rDownloading:   2%|▏         | 40.0M/1.63G [00:00<00:29, 54.1MB/s]\rDownloading:   3%|▎         | 47.4M/1.63G [00:00<00:26, 58.7MB/s]\rDownloading:   3%|▎         | 53.2M/1.63G [00:00<00:27, 57.8MB/s]\rDownloading:   4%|▎         | 59.0M/1.63G [00:01<00:39, 39.4MB/s]\rDownloading:   4%|▍         | 65.4M/1.63G [00:01<00:34, 44.6MB/s]\rDownloading:   4%|▍         | 71.7M/1.63G [00:01<00:31, 48.8MB/s]\rDownloading:   5%|▍         | 78.5M/1.63G [00:01<00:28, 53.4MB/s]\rDownloading:   5%|▌         | 84.5M/1.63G [00:01<00:29, 52.6MB/s]\rDownloading:   6%|▌         | 90.1M/1.63G [00:01<00:28, 53.6MB/s]\rDownloading:   6%|▌         | 95.8M/1.63G [00:01<00:33, 45.8MB/s]\rDownloading:   6%|▌         | 101M/1.63G [00:02<00:47, 32.1MB/s] \rDownloading:   6%|▋         | 105M/1.63G [00:02<00:56, 27.1MB/s]\rDownloading:   7%|▋         | 109M/1.63G [00:02<00:49, 30.4MB/s]\rDownloading:   7%|▋         | 113M/1.63G [00:02<00:49, 30.3MB/s]\rDownloading:   7%|▋         | 116M/1.63G [00:02<00:50, 29.6MB/s]\rDownloading:   7%|▋         | 119M/1.63G [00:02<00:55, 26.9MB/s]\rDownloading:   8%|▊         | 123M/1.63G [00:02<00:52, 28.7MB/s]\rDownloading:   8%|▊         | 126M/1.63G [00:03<00:53, 27.8MB/s]\rDownloading:   8%|▊         | 129M/1.63G [00:03<00:56, 26.6MB/s]\rDownloading:   8%|▊         | 133M/1.63G [00:03<00:49, 29.9MB/s]\rDownloading:   8%|▊         | 137M/1.63G [00:03<00:46, 31.7MB/s]\rDownloading:   9%|▊         | 141M/1.63G [00:03<00:43, 34.0MB/s]\rDownloading:   9%|▉         | 145M/1.63G [00:03<00:45, 32.6MB/s]\rDownloading:   9%|▉         | 150M/1.63G [00:03<00:40, 36.7MB/s]\rDownloading:  10%|▉         | 155M/1.63G [00:03<00:36, 40.5MB/s]\rDownloading:  10%|▉         | 160M/1.63G [00:03<00:35, 41.2MB/s]\rDownloading:  10%|█         | 165M/1.63G [00:03<00:33, 43.2MB/s]\rDownloading:  10%|█         | 169M/1.63G [00:04<00:38, 37.9MB/s]\rDownloading:  11%|█         | 175M/1.63G [00:04<00:34, 42.5MB/s]\rDownloading:  11%|█         | 182M/1.63G [00:04<00:29, 48.3MB/s]\rDownloading:  12%|█▏        | 189M/1.63G [00:04<00:27, 52.0MB/s]\rDownloading:  12%|█▏        | 195M/1.63G [00:04<00:26, 54.4MB/s]\rDownloading:  12%|█▏        | 200M/1.63G [00:04<00:25, 55.0MB/s]\rDownloading:  13%|█▎        | 206M/1.63G [00:04<00:27, 52.0MB/s]\rDownloading:  13%|█▎        | 214M/1.63G [00:04<00:24, 57.3MB/s]\rDownloading:  14%|█▎        | 221M/1.63G [00:04<00:22, 62.2MB/s]\rDownloading:  14%|█▍        | 228M/1.63G [00:05<00:23, 60.4MB/s]\rDownloading:  14%|█▍        | 234M/1.63G [00:05<00:23, 60.1MB/s]\rDownloading:  15%|█▍        | 240M/1.63G [00:05<00:23, 60.1MB/s]\rDownloading:  15%|█▌        | 249M/1.63G [00:05<00:20, 66.3MB/s]\rDownloading:  16%|█▌        | 256M/1.63G [00:05<00:20, 65.9MB/s]\rDownloading:  16%|█▌        | 263M/1.63G [00:05<00:21, 64.7MB/s]\rDownloading:  17%|█▋        | 270M/1.63G [00:05<00:36, 37.5MB/s]\rDownloading:  17%|█▋        | 276M/1.63G [00:06<00:31, 43.5MB/s]\rDownloading:  17%|█▋        | 282M/1.63G [00:06<00:28, 46.7MB/s]\rDownloading:  18%|█▊        | 289M/1.63G [00:06<00:25, 51.7MB/s]\rDownloading:  18%|█▊        | 297M/1.63G [00:06<00:23, 57.1MB/s]\rDownloading:  19%|█▊        | 304M/1.63G [00:06<00:21, 60.3MB/s]\rDownloading:  19%|█▉        | 310M/1.63G [00:06<00:23, 55.7MB/s]\rDownloading:  19%|█▉        | 316M/1.63G [00:06<00:23, 54.9MB/s]\rDownloading:  20%|█▉        | 324M/1.63G [00:06<00:21, 59.8MB/s]\rDownloading:  20%|██        | 331M/1.63G [00:06<00:20, 62.2MB/s]\rDownloading:  21%|██        | 339M/1.63G [00:07<00:19, 65.8MB/s]\rDownloading:  21%|██▏       | 345M/1.63G [00:07<00:21, 59.2MB/s]\rDownloading:  22%|██▏       | 352M/1.63G [00:07<00:20, 60.7MB/s]\rDownloading:  22%|██▏       | 358M/1.63G [00:07<00:21, 59.8MB/s]\rDownloading:  22%|██▏       | 365M/1.63G [00:07<00:20, 62.3MB/s]\rDownloading:  23%|██▎       | 371M/1.63G [00:07<00:20, 62.6MB/s]\rDownloading:  23%|██▎       | 378M/1.63G [00:07<00:20, 60.8MB/s]\rDownloading:  24%|██▎       | 384M/1.63G [00:07<00:23, 52.0MB/s]\rDownloading:  24%|██▍       | 389M/1.63G [00:07<00:24, 51.0MB/s]\rDownloading:  24%|██▍       | 395M/1.63G [00:08<00:29, 41.5MB/s]\rDownloading:  25%|██▍       | 402M/1.63G [00:08<00:26, 46.2MB/s]\rDownloading:  25%|██▌       | 407M/1.63G [00:08<00:25, 46.9MB/s]\rDownloading:  26%|██▌       | 415M/1.63G [00:08<00:22, 54.2MB/s]\rDownloading:  26%|██▌       | 421M/1.63G [00:08<00:21, 55.4MB/s]\rDownloading:  26%|██▋       | 428M/1.63G [00:08<00:20, 58.4MB/s]\rDownloading:  27%|██▋       | 435M/1.63G [00:08<00:19, 60.5MB/s]\rDownloading:  27%|██▋       | 441M/1.63G [00:08<00:20, 57.6MB/s]\rDownloading:  27%|██▋       | 447M/1.63G [00:08<00:20, 57.3MB/s]\rDownloading:  28%|██▊       | 453M/1.63G [00:09<00:30, 38.1MB/s]\rDownloading:  28%|██▊       | 458M/1.63G [00:09<00:35, 32.5MB/s]\rDownloading:  29%|██▊       | 465M/1.63G [00:09<00:29, 39.2MB/s]\rDownloading:  29%|██▉       | 470M/1.63G [00:09<00:27, 42.4MB/s]\rDownloading:  29%|██▉       | 478M/1.63G [00:09<00:23, 48.4MB/s]\rDownloading:  30%|██▉       | 483M/1.63G [00:09<00:23, 49.6MB/s]\rDownloading:  30%|███       | 489M/1.63G [00:10<00:24, 46.7MB/s]\rDownloading:  31%|███       | 496M/1.63G [00:10<00:21, 52.4MB/s]\rDownloading:  31%|███       | 502M/1.63G [00:10<00:21, 52.9MB/s]\rDownloading:  31%|███▏      | 508M/1.63G [00:10<00:20, 54.1MB/s]\rDownloading:  32%|███▏      | 514M/1.63G [00:10<00:21, 51.2MB/s]\rDownloading:  32%|███▏      | 521M/1.63G [00:10<00:19, 55.6MB/s]\rDownloading:  32%|███▏      | 528M/1.63G [00:10<00:18, 59.3MB/s]\rDownloading:  33%|███▎      | 534M/1.63G [00:10<00:27, 40.2MB/s]\rDownloading:  33%|███▎      | 541M/1.63G [00:11<00:23, 45.5MB/s]\rDownloading:  34%|███▎      | 548M/1.63G [00:11<00:21, 50.8MB/s]\rDownloading:  34%|███▍      | 556M/1.63G [00:11<00:18, 57.0MB/s]\rDownloading:  35%|███▍      | 562M/1.63G [00:11<00:17, 59.4MB/s]\rDownloading:  35%|███▌      | 569M/1.63G [00:11<00:16, 62.7MB/s]\rDownloading:  35%|███▌      | 576M/1.63G [00:11<00:17, 58.6MB/s]\rDownloading:  36%|███▌      | 582M/1.63G [00:11<00:28, 36.6MB/s]\rDownloading:  36%|███▋      | 590M/1.63G [00:11<00:24, 43.0MB/s]\rDownloading:  37%|███▋      | 595M/1.63G [00:12<00:26, 39.2MB/s]\rDownloading:  37%|███▋      | 600M/1.63G [00:12<00:33, 30.7MB/s]\rDownloading:  37%|███▋      | 607M/1.63G [00:12<00:27, 37.0MB/s]\rDownloading:  38%|███▊      | 614M/1.63G [00:12<00:24, 40.9MB/s]\rDownloading:  38%|███▊      | 620M/1.63G [00:12<00:21, 46.2MB/s]\rDownloading:  38%|███▊      | 626M/1.63G [00:12<00:20, 48.4MB/s]\rDownloading:  39%|███▉      | 632M/1.63G [00:12<00:20, 49.2MB/s]\rDownloading:  39%|███▉      | 637M/1.63G [00:13<00:21, 45.5MB/s]\rDownloading:  40%|███▉      | 642M/1.63G [00:13<00:21, 46.1MB/s]\rDownloading:  40%|███▉      | 650M/1.63G [00:13<00:18, 52.5MB/s]\rDownloading:  40%|████      | 656M/1.63G [00:13<00:19, 49.9MB/s]\rDownloading:  41%|████      | 661M/1.63G [00:13<00:23, 41.1MB/s]\rDownloading:  41%|████      | 666M/1.63G [00:13<00:22, 42.6MB/s]\rDownloading:  41%|████▏     | 671M/1.63G [00:13<00:20, 46.2MB/s]\rDownloading:  42%|████▏     | 676M/1.63G [00:13<00:22, 42.9MB/s]\rDownloading:  42%|████▏     | 685M/1.63G [00:14<00:18, 50.8MB/s]\rDownloading:  43%|████▎     | 692M/1.63G [00:14<00:17, 53.8MB/s]\rDownloading:  43%|████▎     | 699M/1.63G [00:14<00:15, 59.2MB/s]\rDownloading:  43%|████▎     | 706M/1.63G [00:14<00:14, 61.4MB/s]\rDownloading:  44%|████▍     | 713M/1.63G [00:14<00:14, 62.5MB/s]\rDownloading:  44%|████▍     | 719M/1.63G [00:14<00:21, 43.1MB/s]\rDownloading:  45%|████▍     | 725M/1.63G [00:14<00:19, 45.9MB/s]\rDownloading:  45%|████▌     | 733M/1.63G [00:14<00:16, 52.7MB/s]\rDownloading:  45%|████▌     | 739M/1.63G [00:14<00:15, 56.3MB/s]\rDownloading:  46%|████▌     | 746M/1.63G [00:15<00:16, 51.9MB/s]\rDownloading:  46%|████▋     | 752M/1.63G [00:15<00:16, 54.6MB/s]\rDownloading:  47%|████▋     | 758M/1.63G [00:15<00:18, 48.0MB/s]\rDownloading:  47%|████▋     | 763M/1.63G [00:15<00:21, 39.8MB/s]\rDownloading:  47%|████▋     | 768M/1.63G [00:15<00:20, 41.7MB/s]\rDownloading:  48%|████▊     | 774M/1.63G [00:15<00:18, 45.5MB/s]\rDownloading:  48%|████▊     | 781M/1.63G [00:15<00:16, 50.9MB/s]\rDownloading:  49%|████▊     | 789M/1.63G [00:15<00:14, 56.8MB/s]\rDownloading:  49%|████▉     | 795M/1.63G [00:16<00:15, 54.0MB/s]\rDownloading:  49%|████▉     | 802M/1.63G [00:16<00:14, 57.7MB/s]\rDownloading:  50%|████▉     | 808M/1.63G [00:16<00:17, 46.0MB/s]\rDownloading:  50%|█████     | 814M/1.63G [00:16<00:17, 46.0MB/s]\rDownloading:  50%|█████     | 820M/1.63G [00:16<00:15, 50.9MB/s]\rDownloading:  51%|█████     | 826M/1.63G [00:16<00:15, 52.3MB/s]\rDownloading:  51%|█████     | 832M/1.63G [00:16<00:14, 53.7MB/s]\rDownloading:  52%|█████▏    | 838M/1.63G [00:17<00:18, 42.7MB/s]\rDownloading:  52%|█████▏    | 843M/1.63G [00:17<00:17, 45.4MB/s]\rDownloading:  52%|█████▏    | 848M/1.63G [00:17<00:18, 42.5MB/s]\rDownloading:  53%|█████▎    | 855M/1.63G [00:17<00:16, 48.1MB/s]\rDownloading:  53%|█████▎    | 860M/1.63G [00:17<00:16, 47.3MB/s]\rDownloading:  53%|█████▎    | 866M/1.63G [00:17<00:15, 49.2MB/s]\rDownloading:  54%|█████▎    | 872M/1.63G [00:17<00:15, 47.7MB/s]\rDownloading:  54%|█████▍    | 877M/1.63G [00:17<00:23, 32.0MB/s]\rDownloading:  54%|█████▍    | 881M/1.63G [00:18<00:42, 17.5MB/s]\rDownloading:  54%|█████▍    | 884M/1.63G [00:19<01:09, 10.7MB/s]\rDownloading:  55%|█████▍    | 888M/1.63G [00:19<00:55, 13.3MB/s]\rDownloading:  55%|█████▍    | 890M/1.63G [00:19<00:51, 14.4MB/s]\rDownloading:  55%|█████▍    | 893M/1.63G [00:19<00:49, 14.7MB/s]\rDownloading:  55%|█████▌    | 895M/1.63G [00:19<00:46, 15.6MB/s]\rDownloading:  55%|█████▌    | 899M/1.63G [00:19<00:38, 18.9MB/s]\rDownloading:  55%|█████▌    | 902M/1.63G [00:19<00:33, 21.6MB/s]\rDownloading:  56%|█████▌    | 907M/1.63G [00:19<00:27, 25.8MB/s]\rDownloading:  56%|█████▌    | 910M/1.63G [00:19<00:29, 24.1MB/s]\rDownloading:  56%|█████▌    | 913M/1.63G [00:20<00:27, 25.6MB/s]\rDownloading:  56%|█████▋    | 916M/1.63G [00:20<00:26, 26.4MB/s]\rDownloading:  57%|█████▋    | 919M/1.63G [00:20<00:29, 23.9MB/s]\rDownloading:  57%|█████▋    | 923M/1.63G [00:20<00:25, 27.0MB/s]\rDownloading:  57%|█████▋    | 927M/1.63G [00:20<00:26, 26.3MB/s]\rDownloading:  57%|█████▋    | 929M/1.63G [00:20<00:29, 23.6MB/s]\rDownloading:  57%|█████▋    | 933M/1.63G [00:20<00:26, 25.8MB/s]\rDownloading:  58%|█████▊    | 938M/1.63G [00:20<00:22, 30.5MB/s]\rDownloading:  58%|█████▊    | 942M/1.63G [00:21<00:21, 31.2MB/s]\rDownloading:  58%|█████▊    | 948M/1.63G [00:21<00:18, 37.1MB/s]\rDownloading:  59%|█████▊    | 953M/1.63G [00:21<00:23, 28.2MB/s]\rDownloading:  59%|█████▉    | 958M/1.63G [00:21<00:20, 32.5MB/s]\rDownloading:  59%|█████▉    | 965M/1.63G [00:21<00:16, 39.0MB/s]\rDownloading:  60%|█████▉    | 970M/1.63G [00:21<00:18, 36.2MB/s]\rDownloading:  60%|██████    | 977M/1.63G [00:21<00:15, 42.0MB/s]\rDownloading:  60%|██████    | 982M/1.63G [00:21<00:14, 43.5MB/s]\rDownloading:  61%|██████    | 987M/1.63G [00:22<00:14, 42.8MB/s]\rDownloading:  61%|██████    | 992M/1.63G [00:22<00:14, 42.5MB/s]\rDownloading:  61%|██████▏   | 996M/1.63G [00:22<00:17, 36.1MB/s]\rDownloading:  62%|██████▏   | 1.00G/1.63G [00:22<00:18, 33.5MB/s]\rDownloading:  62%|██████▏   | 1.00G/1.63G [00:22<00:18, 33.1MB/s]\rDownloading:  62%|██████▏   | 1.01G/1.63G [00:22<00:18, 33.6MB/s]\rDownloading:  62%|██████▏   | 1.01G/1.63G [00:22<00:16, 36.2MB/s]\rDownloading:  63%|██████▎   | 1.02G/1.63G [00:22<00:15, 40.3MB/s]\rDownloading:  63%|██████▎   | 1.02G/1.63G [00:23<00:13, 44.8MB/s]\rDownloading:  63%|██████▎   | 1.03G/1.63G [00:23<00:12, 46.9MB/s]\rDownloading:  64%|██████▎   | 1.03G/1.63G [00:23<00:12, 46.2MB/s]\rDownloading:  64%|██████▍   | 1.04G/1.63G [00:23<00:14, 40.0MB/s]\rDownloading:  64%|██████▍   | 1.04G/1.63G [00:23<00:16, 34.8MB/s]\rDownloading:  65%|██████▍   | 1.05G/1.63G [00:23<00:14, 38.9MB/s]\rDownloading:  65%|██████▍   | 1.05G/1.63G [00:23<00:14, 40.7MB/s]\rDownloading:  65%|██████▌   | 1.06G/1.63G [00:23<00:12, 44.4MB/s]\rDownloading:  65%|██████▌   | 1.06G/1.63G [00:24<00:15, 35.5MB/s]\rDownloading:  66%|██████▌   | 1.07G/1.63G [00:24<00:14, 38.1MB/s]\rDownloading:  66%|██████▌   | 1.07G/1.63G [00:24<00:13, 41.6MB/s]\rDownloading:  66%|██████▋   | 1.08G/1.63G [00:24<00:13, 41.4MB/s]\rDownloading:  67%|██████▋   | 1.08G/1.63G [00:24<00:12, 43.4MB/s]\rDownloading:  67%|██████▋   | 1.09G/1.63G [00:24<00:11, 47.3MB/s]\rDownloading:  67%|██████▋   | 1.09G/1.63G [00:24<00:11, 46.2MB/s]\rDownloading:  68%|██████▊   | 1.10G/1.63G [00:24<00:11, 44.9MB/s]\rDownloading:  68%|██████▊   | 1.11G/1.63G [00:24<00:10, 49.7MB/s]\rDownloading:  68%|██████▊   | 1.11G/1.63G [00:25<00:10, 48.0MB/s]\rDownloading:  69%|██████▉   | 1.12G/1.63G [00:25<00:09, 54.5MB/s]\rDownloading:  69%|██████▉   | 1.13G/1.63G [00:25<00:09, 55.3MB/s]\rDownloading:  70%|██████▉   | 1.13G/1.63G [00:25<00:11, 43.3MB/s]\rDownloading:  70%|██████▉   | 1.14G/1.63G [00:25<00:11, 44.3MB/s]\rDownloading:  70%|███████   | 1.14G/1.63G [00:25<00:09, 51.1MB/s]\rDownloading:  71%|███████   | 1.15G/1.63G [00:25<00:09, 50.3MB/s]\rDownloading:  71%|███████   | 1.16G/1.63G [00:25<00:09, 50.2MB/s]\rDownloading:  71%|███████▏  | 1.16G/1.63G [00:26<00:10, 44.5MB/s]\rDownloading:  72%|███████▏  | 1.17G/1.63G [00:26<00:09, 49.9MB/s]\rDownloading:  72%|███████▏  | 1.17G/1.63G [00:26<00:08, 51.9MB/s]\rDownloading:  73%|███████▎  | 1.18G/1.63G [00:26<00:09, 48.7MB/s]\rDownloading:  73%|███████▎  | 1.18G/1.63G [00:26<00:09, 46.8MB/s]\rDownloading:  73%|███████▎  | 1.19G/1.63G [00:26<00:08, 51.2MB/s]\rDownloading:  74%|███████▎  | 1.20G/1.63G [00:26<00:09, 44.0MB/s]\rDownloading:  74%|███████▍  | 1.20G/1.63G [00:26<00:12, 34.5MB/s]\rDownloading:  74%|███████▍  | 1.21G/1.63G [00:27<00:16, 24.9MB/s]\rDownloading:  74%|███████▍  | 1.21G/1.63G [00:27<00:14, 29.6MB/s]\rDownloading:  75%|███████▍  | 1.22G/1.63G [00:27<00:11, 34.9MB/s]\rDownloading:  75%|███████▌  | 1.22G/1.63G [00:27<00:10, 39.3MB/s]\rDownloading:  76%|███████▌  | 1.23G/1.63G [00:27<00:09, 43.9MB/s]\rDownloading:  76%|███████▌  | 1.24G/1.63G [00:27<00:09, 41.7MB/s]\rDownloading:  76%|███████▋  | 1.24G/1.63G [00:28<00:14, 25.7MB/s]\rDownloading:  77%|███████▋  | 1.25G/1.63G [00:28<00:12, 30.9MB/s]\rDownloading:  77%|███████▋  | 1.25G/1.63G [00:28<00:14, 25.7MB/s]\rDownloading:  77%|███████▋  | 1.25G/1.63G [00:28<00:13, 28.3MB/s]\rDownloading:  77%|███████▋  | 1.26G/1.63G [00:28<00:13, 27.8MB/s]\rDownloading:  78%|███████▊  | 1.26G/1.63G [00:28<00:13, 26.3MB/s]\rDownloading:  78%|███████▊  | 1.27G/1.63G [00:29<00:11, 30.1MB/s]\rDownloading:  78%|███████▊  | 1.27G/1.63G [00:29<00:10, 34.9MB/s]\rDownloading:  79%|███████▊  | 1.28G/1.63G [00:29<00:09, 37.9MB/s]\rDownloading:  79%|███████▉  | 1.29G/1.63G [00:29<00:07, 44.1MB/s]\rDownloading:  79%|███████▉  | 1.29G/1.63G [00:29<00:08, 39.9MB/s]\rDownloading:  80%|███████▉  | 1.30G/1.63G [00:29<00:07, 44.9MB/s]\rDownloading:  80%|████████  | 1.30G/1.63G [00:29<00:07, 45.9MB/s]\rDownloading:  80%|████████  | 1.31G/1.63G [00:29<00:06, 46.4MB/s]\rDownloading:  81%|████████  | 1.31G/1.63G [00:29<00:06, 49.3MB/s]\rDownloading:  81%|████████  | 1.32G/1.63G [00:30<00:05, 53.5MB/s]\rDownloading:  82%|████████▏ | 1.33G/1.63G [00:30<00:05, 51.6MB/s]\rDownloading:  82%|████████▏ | 1.33G/1.63G [00:30<00:06, 48.8MB/s]\rDownloading:  82%|████████▏ | 1.34G/1.63G [00:30<00:05, 51.7MB/s]\rDownloading:  83%|████████▎ | 1.34G/1.63G [00:30<00:05, 48.9MB/s]\rDownloading:  83%|████████▎ | 1.35G/1.63G [00:30<00:06, 41.9MB/s]\rDownloading:  83%|████████▎ | 1.35G/1.63G [00:30<00:06, 44.7MB/s]\rDownloading:  84%|████████▎ | 1.36G/1.63G [00:30<00:06, 39.4MB/s]\rDownloading:  84%|████████▍ | 1.36G/1.63G [00:31<00:06, 43.1MB/s]\rDownloading:  84%|████████▍ | 1.37G/1.63G [00:31<00:06, 37.0MB/s]\rDownloading:  85%|████████▍ | 1.37G/1.63G [00:31<00:06, 41.4MB/s]\rDownloading:  85%|████████▍ | 1.38G/1.63G [00:31<00:05, 47.2MB/s]\rDownloading:  85%|████████▌ | 1.39G/1.63G [00:31<00:04, 52.1MB/s]\rDownloading:  86%|████████▌ | 1.40G/1.63G [00:31<00:04, 56.1MB/s]\rDownloading:  86%|████████▋ | 1.40G/1.63G [00:31<00:03, 61.9MB/s]\rDownloading:  87%|████████▋ | 1.41G/1.63G [00:31<00:04, 49.6MB/s]\rDownloading:  87%|████████▋ | 1.42G/1.63G [00:32<00:04, 49.9MB/s]\rDownloading:  88%|████████▊ | 1.42G/1.63G [00:32<00:03, 53.8MB/s]\rDownloading:  88%|████████▊ | 1.43G/1.63G [00:32<00:03, 55.7MB/s]\rDownloading:  88%|████████▊ | 1.43G/1.63G [00:32<00:03, 55.3MB/s]\rDownloading:  89%|████████▊ | 1.44G/1.63G [00:32<00:03, 53.8MB/s]\rDownloading:  89%|████████▉ | 1.45G/1.63G [00:32<00:03, 54.2MB/s]\rDownloading:  89%|████████▉ | 1.45G/1.63G [00:32<00:03, 49.8MB/s]\rDownloading:  90%|████████▉ | 1.46G/1.63G [00:32<00:03, 52.2MB/s]\rDownloading:  90%|█████████ | 1.46G/1.63G [00:32<00:02, 57.7MB/s]\rDownloading:  90%|█████████ | 1.47G/1.63G [00:32<00:02, 58.1MB/s]\rDownloading:  91%|█████████ | 1.48G/1.63G [00:33<00:02, 61.5MB/s]\rDownloading:  91%|█████████▏| 1.48G/1.63G [00:33<00:02, 56.4MB/s]\rDownloading:  92%|█████████▏| 1.49G/1.63G [00:33<00:02, 49.0MB/s]\rDownloading:  92%|█████████▏| 1.50G/1.63G [00:33<00:02, 49.6MB/s]\rDownloading:  92%|█████████▏| 1.50G/1.63G [00:33<00:02, 46.7MB/s]\rDownloading:  93%|█████████▎| 1.51G/1.63G [00:33<00:03, 39.8MB/s]\rDownloading:  93%|█████████▎| 1.51G/1.63G [00:33<00:02, 42.4MB/s]\rDownloading:  93%|█████████▎| 1.52G/1.63G [00:33<00:02, 47.5MB/s]\rDownloading:  94%|█████████▎| 1.52G/1.63G [00:34<00:02, 41.2MB/s]\rDownloading:  94%|█████████▍| 1.53G/1.63G [00:34<00:02, 46.2MB/s]\rDownloading:  94%|█████████▍| 1.54G/1.63G [00:34<00:01, 51.5MB/s]\rDownloading:  95%|█████████▍| 1.54G/1.63G [00:34<00:01, 56.6MB/s]\rDownloading:  95%|█████████▌| 1.55G/1.63G [00:34<00:01, 55.8MB/s]\rDownloading:  96%|█████████▌| 1.56G/1.63G [00:34<00:01, 60.1MB/s]\rDownloading:  96%|█████████▌| 1.56G/1.63G [00:34<00:00, 62.5MB/s]\rDownloading:  97%|█████████▋| 1.57G/1.63G [00:34<00:00, 58.3MB/s]\rDownloading:  97%|█████████▋| 1.58G/1.63G [00:34<00:00, 57.6MB/s]\rDownloading:  97%|█████████▋| 1.58G/1.63G [00:35<00:00, 60.2MB/s]\rDownloading:  98%|█████████▊| 1.59G/1.63G [00:35<00:00, 47.3MB/s]\rDownloading:  98%|█████████▊| 1.59G/1.63G [00:35<00:00, 45.3MB/s]\rDownloading:  98%|█████████▊| 1.60G/1.63G [00:35<00:00, 48.4MB/s]\rDownloading:  99%|█████████▉| 1.61G/1.63G [00:35<00:00, 48.2MB/s]\rDownloading:  99%|█████████▉| 1.61G/1.63G [00:35<00:00, 54.6MB/s]\rDownloading: 100%|█████████▉| 1.62G/1.63G [00:35<00:00, 59.5MB/s]\rDownloading: 100%|██████████| 1.63G/1.63G [00:35<00:00, 45.3MB/s]\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "./finetune.sh: line 10:   308 Killed                  python finetune.py --learning_rate=3e-5 --gpus 1 --do_train --do_predict --n_val 1000 --val_check_interval 0.1 \"$@\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCDwd4r-4gRG"
      },
      "source": [
        "# Running Inference on the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb0UfuZT7N51"
      },
      "source": [
        "output_dir= 'transformers/examples/seq2seq/xsum_results/best_tfmr'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m_a-Gw94mEl"
      },
      "source": [
        "\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(f'{output_dir}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrSr2Odh_dgZ",
        "outputId": "e4d21f2d-8360-4a55-a9b0-37ab3c9f0651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "%%bash\n",
        "mkdir gens\n",
        "export DATA_DIR=/content/dcyphr-NLP/fine_tuning_data\n",
        "\n",
        "cd transformers/examples/seq2seq/\n",
        "\n",
        "python run_eval.py facebook/bart-large-cnn \\\n",
        "    $DATA_DIR/test.source gens/peg_xsum_test_generation.txt \\\n",
        "    --reference_path $DATA_DIR/test.target \\\n",
        "    --score_path gens/peg_xsum_rouge.txt --task summarization \\\n",
        "    --device cuda \\\n",
        "    --bs 8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'rouge1': 31.139, 'rouge2': 10.7674, 'rougeL': 21.4948, 'rougeLsum': 28.7083, 'n_obs': 20, 'runtime': 24, 'seconds_per_sample': 1.2}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-02 00:53:50.431666: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "\r  0%|          | 0/3 [00:00<?, ?it/s]\r 33%|███▎      | 1/3 [00:09<00:18,  9.37s/it]\r 67%|██████▋   | 2/3 [00:19<00:09,  9.52s/it]\r100%|██████████| 3/3 [00:24<00:00,  8.20s/it]\r100%|██████████| 3/3 [00:24<00:00,  8.11s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ITWQiOS04CS",
        "outputId": "3f9c2608-f048-4564-f044-458148285ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "!apt-get install python3-venv\n",
        "!python -m venv my-env"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3.6-venv\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-venv python3.6-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 1,660 kB of archives.\n",
            "After this operation, 1,902 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.2 [1,653 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3.6-venv amd64 3.6.9-1~18.04ubuntu1.1 [6,184 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-venv amd64 3.6.7-1~18.04 [1,208 B]\n",
            "Fetched 1,660 kB in 1s (1,202 kB/s)\n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 144618 files and directories currently installed.)\n",
            "Preparing to unpack .../python-pip-whl_9.0.1-2.3~ubuntu1.18.04.2_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.2) ...\n",
            "Selecting previously unselected package python3.6-venv.\n",
            "Preparing to unpack .../python3.6-venv_3.6.9-1~18.04ubuntu1.1_amd64.deb ...\n",
            "Unpacking python3.6-venv (3.6.9-1~18.04ubuntu1.1) ...\n",
            "Selecting previously unselected package python3-venv.\n",
            "Preparing to unpack .../python3-venv_3.6.7-1~18.04_amd64.deb ...\n",
            "Unpacking python3-venv (3.6.7-1~18.04) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.2) ...\n",
            "Setting up python3.6-venv (3.6.9-1~18.04ubuntu1.1) ...\n",
            "Setting up python3-venv (3.6.7-1~18.04) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0ubznZz3AxH",
        "outputId": "e8646822-2055-4570-d03d-146a12f3b8b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "!. my-env/bin/activate\n",
        "!pip install Flask\n",
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask) (2.11.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask) (1.1.1)\n",
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZV7wMck_-Q3"
      },
      "source": [
        "\"\"\" Code for model.py file to host model on /summary REST endpoint\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from flask import Flask\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "def predict(payload):\n",
        "    output_dir= 'transformers/examples/seq2seq/xsum_results'\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(f'{output_dir}/best_tfmr')\n",
        "    tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "    ARTICLE_TO_SUMMARIZE = payload\n",
        "    # ARTICLE_TO_SUMMARIZE = \"My friends are cool but they eat too many carbs.\"\n",
        "    inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors='pt', truncation=True)\n",
        "    # Generate Summary\n",
        "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=500, early_stopping=True)\n",
        "    return [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
        "    # print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])\n",
        "\n",
        "\n",
        "@app.route('/summary', methods=['POST'])\n",
        "def produceSummary():\n",
        "  result = predict(request.json['text'])\n",
        "  return jsonify({'result': result[0]}), 200\n",
        "\n",
        "@app.route('/')\n",
        "def helloworld():\n",
        "  return 'hello world'\n",
        "\n",
        "app.run()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3QGw8FH5Cv7",
        "outputId": "ef141398-c9dc-4f47-bbdb-3ffac0b7e7f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!python model.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-02 20:52:20.937716: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            " * Serving Flask app \"model\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n",
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
            " * Running on http://f9add6f44b66.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB32tSzLTPgN",
        "outputId": "6808cc32-84c0-4467-f8b0-5dbc54661a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "ARTICLE_TO_SUMMARIZE = \"<NbChars_0.5><LevSim_0.5>The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\"\n",
        "ARTICLE_TO_SUMMARISE_TEST = \"My friends are cool but they eat too many carbs.\"\n",
        "inputs = tokenizer([ARTICLE_TO_SUMMARISE_TEST], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "# Generate Summary\n",
        "summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=500, early_stopping=True)\n",
        "print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"My friends are cool but they eat too many carbs. They eat too much carbs. My friends eat carbs. I eat carbs too much. I like carbs, but I don't like carbs very much, so I like to eat carbs very little. I'm not a carb eater.\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1p5meG_Quh_",
        "outputId": "22670515-fac8-4282-d782-955181a5f235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "%%bash\n",
        "\n",
        "# zipping the model \n",
        "zip -r /content/model.zip /content/transformers/examples/seq2seq/xsum_results/best_tfmr\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: content/transformers/examples/seq2seq/xsum_results/best_tfmr/ (stored 0%)\n",
            "updating: content/transformers/examples/seq2seq/xsum_results/best_tfmr/special_tokens_map.json (deflated 83%)\n",
            "updating: content/transformers/examples/seq2seq/xsum_results/best_tfmr/merges.txt (deflated 53%)\n",
            "updating: content/transformers/examples/seq2seq/xsum_results/best_tfmr/tokenizer_config.json (stored 0%)\n",
            "updating: content/transformers/examples/seq2seq/xsum_results/best_tfmr/config.json (deflated 63%)\n",
            "updating: content/transformers/examples/seq2seq/xsum_results/best_tfmr/vocab.json (deflated 63%)\n",
            "updating: content/transformers/examples/seq2seq/xsum_results/best_tfmr/pytorch_model.bin (deflated 7%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWUMaBQRAPCr",
        "outputId": "54bdcd2f-56e6-4b2a-d491-4804d5d0031f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!ls -lh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1.5G\n",
            "drwxr-xr-x  7 root root 4.0K Oct  2 18:42 dcyphr-NLP\n",
            "-rw-r--r--  1 root root 1.3K Oct  2 19:23 model.py\n",
            "-rw-r--r--  1 root root 1.5G Oct  2 20:52 model.zip\n",
            "drwxr-xr-x  6 root root 4.0K Oct  2 19:22 my-env\n",
            "drwxr-xr-x  1 root root 4.0K Oct  1 16:28 sample_data\n",
            "drwxr-xr-x 15 root root 4.0K Oct  2 18:43 transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w_FIJlGUsmZ",
        "outputId": "82ab4da9-3911-4fb0-97c3-54dfb2f4c28a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "# Downloading zip file\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/model.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_cf86ce94-9ff4-476f-a345-9657e0d93b8d\", \"model.zip\", 1507160666)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6gVtSZE4gwS",
        "outputId": "fefb4c14-59c3-4977-a7ca-42922e3d76a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "f = open(\"dcyphr-NLP/fine_tuning_data/train.source\", \"r\")\n",
        "max_len = 0\n",
        "min_len = 10000000\n",
        "avg_len = 0\n",
        "i = 0\n",
        "for line in f:\n",
        "  i+=1\n",
        "  x = line.split()\n",
        "  avg_len += len(x)\n",
        "  min_len = min(min_len, len(x))\n",
        "  max_len = max(max_len,len(x))\n",
        "avg_len /= i\n",
        "\n",
        "\n",
        "print('Max length: ' + str(max_len))\n",
        "print('Min length: ' + str(min_len))\n",
        "print('Average length: ' + str(avg_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length: 7999\n",
            "Min length: 34\n",
            "Average length: 617.66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "146hzeXjRrtu",
        "outputId": "7e386911-a11d-414a-ca18-3bbf6bb68e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}